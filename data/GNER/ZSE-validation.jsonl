{"dataset":"mit-movie","split":"dev","label_list":["character","trailer","average ratings","director","rating","actor","review","year","genre","song","plot","title"],"instance":{"id":"0","words":["are","there","any","good","romantic","comedies","out","right","now"],"labels":["O","O","O","O","B-genre","I-genre","O","B-year","I-year"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, trailer, average ratings, director, rating, actor, review, year, genre, song, plot, title and O.\nSentence: are there any good romantic comedies out right now","prompt_labels":"are(O) there(O) any(O) good(O) romantic(B-genre) comedies(I-genre) out(O) right(B-year) now(I-year)"}}
{"dataset":"mit-movie","split":"dev","label_list":["year","rating","average ratings","actor","title","song","plot","review","trailer","character","director","genre"],"instance":{"id":"1","words":["show","me","a","movie","about","cars","that","talk"],"labels":["O","O","O","O","O","B-plot","I-plot","I-plot"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: year, rating, average ratings, actor, title, song, plot, review, trailer, character, director, genre and O.\nSentence: show me a movie about cars that talk","prompt_labels":"show(O) me(O) a(O) movie(O) about(O) cars(B-plot) that(I-plot) talk(I-plot)"}}
{"dataset":"mit-movie","split":"dev","label_list":["director","average ratings","song","review","trailer","plot","title","genre","actor","rating","character","year"],"instance":{"id":"2","words":["list","the","five","star","rated","movies","starring","mel","gibson"],"labels":["O","O","B-average ratings","I-average ratings","O","O","O","B-actor","I-actor"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, average ratings, song, review, trailer, plot, title, genre, actor, rating, character, year and O.\nSentence: list the five star rated movies starring mel gibson","prompt_labels":"list(O) the(O) five(B-average ratings) star(I-average ratings) rated(O) movies(O) starring(O) mel(B-actor) gibson(I-actor)"}}
{"dataset":"mit-movie","split":"dev","label_list":["average ratings","plot","review","genre","year","director","rating","character","title","trailer","song","actor"],"instance":{"id":"3","words":["what","science","fiction","films","have","come","out","recently"],"labels":["O","B-genre","I-genre","O","O","O","O","B-year"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: average ratings, plot, review, genre, year, director, rating, character, title, trailer, song, actor and O.\nSentence: what science fiction films have come out recently","prompt_labels":"what(O) science(B-genre) fiction(I-genre) films(O) have(O) come(O) out(O) recently(B-year)"}}
{"dataset":"mit-movie","split":"dev","label_list":["actor","title","review","character","rating","year","average ratings","director","genre","song","trailer","plot"],"instance":{"id":"4","words":["did","the","same","director","make","all","of","the","harry","potter","movies"],"labels":["O","O","O","O","O","O","O","O","B-title","I-title","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, title, review, character, rating, year, average ratings, director, genre, song, trailer, plot and O.\nSentence: did the same director make all of the harry potter movies","prompt_labels":"did(O) the(O) same(O) director(O) make(O) all(O) of(O) the(O) harry(B-title) potter(I-title) movies(O)"}}
{"dataset":"mit-movie","split":"dev","label_list":["plot","actor","title","review","song","rating","character","year","average ratings","genre","trailer","director"],"instance":{"id":"5","words":["show","me","1980s","action","movies"],"labels":["O","O","B-year","B-genre","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, actor, title, review, song, rating, character, year, average ratings, genre, trailer, director and O.\nSentence: show me 1980s action movies","prompt_labels":"show(O) me(O) 1980s(B-year) action(B-genre) movies(O)"}}
{"dataset":"mit-movie","split":"dev","label_list":["genre","plot","average ratings","character","trailer","rating","director","year","song","actor","review","title"],"instance":{"id":"6","words":["what","is","the","name","of","the","third","movie","in","the","star","trek","series"],"labels":["O","O","O","O","O","O","O","O","O","O","B-title","I-title","I-title"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, plot, average ratings, character, trailer, rating, director, year, song, actor, review, title and O.\nSentence: what is the name of the third movie in the star trek series","prompt_labels":"what(O) is(O) the(O) name(O) of(O) the(O) third(O) movie(O) in(O) the(O) star(B-title) trek(I-title) series(I-title)"}}
{"dataset":"mit-movie","split":"dev","label_list":["actor","trailer","review","genre","year","character","title","rating","average ratings","director","song","plot"],"instance":{"id":"7","words":["can","you","get","a","soundtrac","for","the","harry","potter","films"],"labels":["O","O","O","O","B-song","O","O","B-title","I-title","I-title"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, trailer, review, genre, year, character, title, rating, average ratings, director, song, plot and O.\nSentence: can you get a soundtrac for the harry potter films","prompt_labels":"can(O) you(O) get(O) a(O) soundtrac(B-song) for(O) the(O) harry(B-title) potter(I-title) films(I-title)"}}
{"dataset":"mit-movie","split":"dev","label_list":["trailer","review","actor","rating","title","genre","year","plot","song","character","director","average ratings"],"instance":{"id":"8","words":["find","me","science","fiction","movies","since","2005"],"labels":["O","O","B-genre","I-genre","O","B-year","I-year"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: trailer, review, actor, rating, title, genre, year, plot, song, character, director, average ratings and O.\nSentence: find me science fiction movies since 2005","prompt_labels":"find(O) me(O) science(B-genre) fiction(I-genre) movies(O) since(B-year) 2005(I-year)"}}
{"dataset":"mit-movie","split":"dev","label_list":["song","character","year","actor","rating","director","genre","average ratings","trailer","review","plot","title"],"instance":{"id":"9","words":["what","is","the","most","current","movie","featuring","mat","damon"],"labels":["O","O","O","O","B-year","O","O","B-actor","I-actor"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, character, year, actor, rating, director, genre, average ratings, trailer, review, plot, title and O.\nSentence: what is the most current movie featuring mat damon","prompt_labels":"what(O) is(O) the(O) most(O) current(B-year) movie(O) featuring(O) mat(B-actor) damon(I-actor)"}}
{"dataset":"mit-movie","split":"dev","label_list":["genre","year","trailer","actor","review","rating","character","title","average ratings","song","director","plot"],"instance":{"id":"10","words":["show","me","films","where","jim","carrey","is","a","detective"],"labels":["O","O","O","O","B-actor","I-actor","O","O","B-character"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, year, trailer, actor, review, rating, character, title, average ratings, song, director, plot and O.\nSentence: show me films where jim carrey is a detective","prompt_labels":"show(O) me(O) films(O) where(O) jim(B-actor) carrey(I-actor) is(O) a(O) detective(B-character)"}}
{"dataset":"mit-movie","split":"dev","label_list":["plot","director","rating","year","genre","song","title","average ratings","character","actor","trailer","review"],"instance":{"id":"11","words":["did","george","clooney","make","a","musical","in","the","1980s"],"labels":["O","B-actor","I-actor","O","O","B-genre","O","O","B-year"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, director, rating, year, genre, song, title, average ratings, character, actor, trailer, review and O.\nSentence: did george clooney make a musical in the 1980s","prompt_labels":"did(O) george(B-actor) clooney(I-actor) make(O) a(O) musical(B-genre) in(O) the(O) 1980s(B-year)"}}
{"dataset":"mit-movie","split":"dev","label_list":["director","average ratings","plot","review","actor","year","song","trailer","title","rating","genre","character"],"instance":{"id":"12","words":["show","me","films","with","both","matt","damon","ad","ben","affleck"],"labels":["O","O","O","O","O","B-actor","I-actor","O","B-actor","I-actor"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, average ratings, plot, review, actor, year, song, trailer, title, rating, genre, character and O.\nSentence: show me films with both matt damon ad ben affleck","prompt_labels":"show(O) me(O) films(O) with(O) both(O) matt(B-actor) damon(I-actor) ad(O) ben(B-actor) affleck(I-actor)"}}
{"dataset":"mit-movie","split":"dev","label_list":["song","rating","year","character","actor","trailer","director","title","review","genre","plot","average ratings"],"instance":{"id":"13","words":["what","is","the","borrowers","movie"],"labels":["O","O","O","B-title","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, rating, year, character, actor, trailer, director, title, review, genre, plot, average ratings and O.\nSentence: what is the borrowers movie","prompt_labels":"what(O) is(O) the(O) borrowers(B-title) movie(O)"}}
{"dataset":"mit-movie","split":"dev","label_list":["character","average ratings","title","rating","plot","genre","actor","trailer","review","director","year","song"],"instance":{"id":"14","words":["have","u","movie","hm","about","to","pg","18"],"labels":["O","O","O","O","O","O","B-rating","I-rating"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, average ratings, title, rating, plot, genre, actor, trailer, review, director, year, song and O.\nSentence: have u movie hm about to pg 18","prompt_labels":"have(O) u(O) movie(O) hm(O) about(O) to(O) pg(B-rating) 18(I-rating)"}}
{"dataset":"mit-movie","split":"dev","label_list":["plot","average ratings","title","genre","character","song","rating","director","actor","review","year","trailer"],"instance":{"id":"15","words":["find","rated","g","films","with","flying","cars"],"labels":["O","O","B-rating","O","O","B-plot","I-plot"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, average ratings, title, genre, character, song, rating, director, actor, review, year, trailer and O.\nSentence: find rated g films with flying cars","prompt_labels":"find(O) rated(O) g(B-rating) films(O) with(O) flying(B-plot) cars(I-plot)"}}
{"dataset":"mit-movie","split":"dev","label_list":["rating","character","actor","song","title","trailer","review","director","year","average ratings","genre","plot"],"instance":{"id":"16","words":["what","was","the","best","rated","stanley","kubrick","film"],"labels":["O","O","O","B-review","O","B-director","I-director","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, character, actor, song, title, trailer, review, director, year, average ratings, genre, plot and O.\nSentence: what was the best rated stanley kubrick film","prompt_labels":"what(O) was(O) the(O) best(B-review) rated(O) stanley(B-director) kubrick(I-director) film(O)"}}
{"dataset":"mit-movie","split":"dev","label_list":["review","song","genre","plot","director","rating","title","trailer","character","year","actor","average ratings"],"instance":{"id":"17","words":["are","there","any","films","directed","by","shawn","levy","about","large","families"],"labels":["O","O","O","O","O","O","B-director","I-director","O","B-plot","I-plot"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, song, genre, plot, director, rating, title, trailer, character, year, actor, average ratings and O.\nSentence: are there any films directed by shawn levy about large families","prompt_labels":"are(O) there(O) any(O) films(O) directed(O) by(O) shawn(B-director) levy(I-director) about(O) large(B-plot) families(I-plot)"}}
{"dataset":"mit-movie","split":"dev","label_list":["year","average ratings","song","title","trailer","review","plot","character","rating","director","actor","genre"],"instance":{"id":"18","words":["list","pg","rated","movies","about","cars","released","in","the","1990s"],"labels":["O","B-rating","O","O","O","B-plot","O","O","O","B-year"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: year, average ratings, song, title, trailer, review, plot, character, rating, director, actor, genre and O.\nSentence: list pg rated movies about cars released in the 1990s","prompt_labels":"list(O) pg(B-rating) rated(O) movies(O) about(O) cars(B-plot) released(O) in(O) the(O) 1990s(B-year)"}}
{"dataset":"mit-movie","split":"dev","label_list":["genre","year","actor","title","plot","rating","review","director","song","average ratings","trailer","character"],"instance":{"id":"19","words":["what","movie","won","best","picure","at","the","2012","oscars"],"labels":["O","O","O","B-average ratings","I-average ratings","O","O","B-average ratings","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, year, actor, title, plot, rating, review, director, song, average ratings, trailer, character and O.\nSentence: what movie won best picure at the 2012 oscars","prompt_labels":"what(O) movie(O) won(O) best(B-average ratings) picure(I-average ratings) at(O) the(O) 2012(B-average ratings) oscars(O)"}}
{"dataset":"mit-movie","split":"dev","label_list":["average ratings","review","actor","trailer","plot","director","year","rating","character","title","genre","song"],"instance":{"id":"20","words":["find","me","childrens","movies","with","daniel","radcliffe","from","the","2000s"],"labels":["O","O","B-genre","I-genre","O","B-actor","I-actor","O","O","B-year"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: average ratings, review, actor, trailer, plot, director, year, rating, character, title, genre, song and O.\nSentence: find me childrens movies with daniel radcliffe from the 2000s","prompt_labels":"find(O) me(O) childrens(B-genre) movies(I-genre) with(O) daniel(B-actor) radcliffe(I-actor) from(O) the(O) 2000s(B-year)"}}
{"dataset":"mit-movie","split":"dev","label_list":["title","average ratings","trailer","rating","year","actor","song","director","character","plot","review","genre"],"instance":{"id":"21","words":["what","was","the","plot","behind","3","days","of","the","condor"],"labels":["O","O","O","O","O","B-title","I-title","I-title","I-title","I-title"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: title, average ratings, trailer, rating, year, actor, song, director, character, plot, review, genre and O.\nSentence: what was the plot behind 3 days of the condor","prompt_labels":"what(O) was(O) the(O) plot(O) behind(O) 3(B-title) days(I-title) of(I-title) the(I-title) condor(I-title)"}}
{"dataset":"mit-movie","split":"dev","label_list":["character","title","actor","trailer","director","year","average ratings","genre","song","review","rating","plot"],"instance":{"id":"22","words":["what","are","considered","the","must","see","sci","fi","movies","of","the","1970s"],"labels":["O","O","O","O","O","O","B-genre","I-genre","I-genre","O","O","B-year"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, title, actor, trailer, director, year, average ratings, genre, song, review, rating, plot and O.\nSentence: what are considered the must see sci fi movies of the 1970s","prompt_labels":"what(O) are(O) considered(O) the(O) must(O) see(O) sci(B-genre) fi(I-genre) movies(I-genre) of(O) the(O) 1970s(B-year)"}}
{"dataset":"mit-movie","split":"dev","label_list":["plot","title","average ratings","review","actor","song","year","trailer","rating","genre","director","character"],"instance":{"id":"23","words":["who","directed","the","film","pulp","fiction","that","starred","john","travolta"],"labels":["O","B-director","O","O","B-title","I-title","O","O","B-actor","I-actor"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, title, average ratings, review, actor, song, year, trailer, rating, genre, director, character and O.\nSentence: who directed the film pulp fiction that starred john travolta","prompt_labels":"who(O) directed(B-director) the(O) film(O) pulp(B-title) fiction(I-title) that(O) starred(O) john(B-actor) travolta(I-actor)"}}
{"dataset":"mit-movie","split":"dev","label_list":["actor","plot","year","character","average ratings","rating","trailer","genre","director","review","title","song"],"instance":{"id":"24","words":["which","film","has","the","highest","viewer","rating","this","year"],"labels":["O","O","O","O","B-average ratings","I-average ratings","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, plot, year, character, average ratings, rating, trailer, genre, director, review, title, song and O.\nSentence: which film has the highest viewer rating this year","prompt_labels":"which(O) film(O) has(O) the(O) highest(B-average ratings) viewer(I-average ratings) rating(O) this(O) year(O)"}}
{"dataset":"mit-movie","split":"dev","label_list":["year","average ratings","actor","trailer","song","review","character","director","plot","rating","title","genre"],"instance":{"id":"25","words":["what","was","the","first","movie","in","color"],"labels":["O","O","O","O","O","O","B-plot"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: year, average ratings, actor, trailer, song, review, character, director, plot, rating, title, genre and O.\nSentence: what was the first movie in color","prompt_labels":"what(O) was(O) the(O) first(O) movie(O) in(O) color(B-plot)"}}
{"dataset":"mit-movie","split":"dev","label_list":["plot","actor","song","rating","year","genre","trailer","director","character","average ratings","review","title"],"instance":{"id":"26","words":["may","i","have","the","highly","acclaimed","film","from","1985","directed","by","sylvester","stallone"],"labels":["O","O","O","O","B-review","I-review","O","O","B-average ratings","O","O","B-director","I-director"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, actor, song, rating, year, genre, trailer, director, character, average ratings, review, title and O.\nSentence: may i have the highly acclaimed film from 1985 directed by sylvester stallone","prompt_labels":"may(O) i(O) have(O) the(O) highly(B-review) acclaimed(I-review) film(O) from(O) 1985(B-average ratings) directed(O) by(O) sylvester(B-director) stallone(I-director)"}}
{"dataset":"mit-movie","split":"dev","label_list":["actor","genre","title","character","rating","trailer","year","review","director","average ratings","song","plot"],"instance":{"id":"27","words":["list","the","action","films","starring","hugh","jackman"],"labels":["O","O","B-genre","I-genre","O","B-actor","I-actor"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, genre, title, character, rating, trailer, year, review, director, average ratings, song, plot and O.\nSentence: list the action films starring hugh jackman","prompt_labels":"list(O) the(O) action(B-genre) films(I-genre) starring(O) hugh(B-actor) jackman(I-actor)"}}
{"dataset":"mit-movie","split":"dev","label_list":["review","year","rating","song","trailer","average ratings","character","title","director","genre","plot","actor"],"instance":{"id":"28","words":["what","is","a","bronx","tale","rated"],"labels":["O","O","O","B-title","I-title","B-rating"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, year, rating, song, trailer, average ratings, character, title, director, genre, plot, actor and O.\nSentence: what is a bronx tale rated","prompt_labels":"what(O) is(O) a(O) bronx(B-title) tale(I-title) rated(B-rating)"}}
{"dataset":"mit-movie","split":"dev","label_list":["plot","character","rating","review","year","genre","title","actor","average ratings","song","director","trailer"],"instance":{"id":"29","words":["is","there","a","pg","13","movie","thats","scary"],"labels":["O","O","O","B-rating","I-rating","O","O","B-genre"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, character, rating, review, year, genre, title, actor, average ratings, song, director, trailer and O.\nSentence: is there a pg 13 movie thats scary","prompt_labels":"is(O) there(O) a(O) pg(B-rating) 13(I-rating) movie(O) thats(O) scary(B-genre)"}}
{"dataset":"mit-movie","split":"dev","label_list":["review","plot","rating","genre","character","year","trailer","title","average ratings","song","director","actor"],"instance":{"id":"30","words":["what","movies","made","in","2004","were","pg"],"labels":["O","O","O","O","B-year","O","B-rating"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, plot, rating, genre, character, year, trailer, title, average ratings, song, director, actor and O.\nSentence: what movies made in 2004 were pg","prompt_labels":"what(O) movies(O) made(O) in(O) 2004(B-year) were(O) pg(B-rating)"}}
{"dataset":"mit-movie","split":"dev","label_list":["year","character","actor","average ratings","genre","trailer","plot","director","review","song","rating","title"],"instance":{"id":"31","words":["find","movies","with","robert","diniero","in","it"],"labels":["O","O","O","B-actor","I-actor","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: year, character, actor, average ratings, genre, trailer, plot, director, review, song, rating, title and O.\nSentence: find movies with robert diniero in it","prompt_labels":"find(O) movies(O) with(O) robert(B-actor) diniero(I-actor) in(O) it(O)"}}
{"dataset":"mit-movie","split":"dev","label_list":["character","actor","average ratings","title","genre","year","plot","director","song","review","rating","trailer"],"instance":{"id":"32","words":["have","pg","13","movies","for","the","kidz"],"labels":["O","B-rating","I-rating","O","O","O","B-genre"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, actor, average ratings, title, genre, year, plot, director, song, review, rating, trailer and O.\nSentence: have pg 13 movies for the kidz","prompt_labels":"have(O) pg(B-rating) 13(I-rating) movies(O) for(O) the(O) kidz(B-genre)"}}
{"dataset":"mit-movie","split":"dev","label_list":["average ratings","plot","review","title","year","rating","trailer","director","song","actor","character","genre"],"instance":{"id":"33","words":["list","the","science","fiction","movies","directed","by","shawn","levy"],"labels":["O","O","B-genre","I-genre","O","O","O","B-director","I-director"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: average ratings, plot, review, title, year, rating, trailer, director, song, actor, character, genre and O.\nSentence: list the science fiction movies directed by shawn levy","prompt_labels":"list(O) the(O) science(B-genre) fiction(I-genre) movies(O) directed(O) by(O) shawn(B-director) levy(I-director)"}}
{"dataset":"mit-movie","split":"dev","label_list":["rating","average ratings","title","review","trailer","plot","character","actor","song","director","year","genre"],"instance":{"id":"34","words":["what","was","the","last","film","elizabeth","montgomery","starred","in"],"labels":["O","O","O","B-year","O","B-actor","I-actor","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, average ratings, title, review, trailer, plot, character, actor, song, director, year, genre and O.\nSentence: what was the last film elizabeth montgomery starred in","prompt_labels":"what(O) was(O) the(O) last(B-year) film(O) elizabeth(B-actor) montgomery(I-actor) starred(O) in(O)"}}
{"dataset":"mit-movie","split":"dev","label_list":["plot","trailer","genre","song","rating","year","review","director","average ratings","character","title","actor"],"instance":{"id":"35","words":["did","george","clooney","direct","any","comedy","films"],"labels":["O","B-director","I-director","O","O","B-genre","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, trailer, genre, song, rating, year, review, director, average ratings, character, title, actor and O.\nSentence: did george clooney direct any comedy films","prompt_labels":"did(O) george(B-director) clooney(I-director) direct(O) any(O) comedy(B-genre) films(O)"}}
{"dataset":"mit-movie","split":"dev","label_list":["character","plot","actor","average ratings","director","review","year","genre","trailer","rating","title","song"],"instance":{"id":"36","words":["what","is","brad","pitts","first","movie"],"labels":["O","O","B-actor","I-actor","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, plot, actor, average ratings, director, review, year, genre, trailer, rating, title, song and O.\nSentence: what is brad pitts first movie","prompt_labels":"what(O) is(O) brad(B-actor) pitts(I-actor) first(O) movie(O)"}}
{"dataset":"mit-movie","split":"dev","label_list":["character","title","actor","director","trailer","review","rating","song","year","plot","average ratings","genre"],"instance":{"id":"37","words":["find","me","the","movie","that","has","a","aerosmith","song"],"labels":["O","O","O","O","O","O","O","B-song","I-song"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, title, actor, director, trailer, review, rating, song, year, plot, average ratings, genre and O.\nSentence: find me the movie that has a aerosmith song","prompt_labels":"find(O) me(O) the(O) movie(O) that(O) has(O) a(O) aerosmith(B-song) song(I-song)"}}
{"dataset":"mit-movie","split":"dev","label_list":["song","title","trailer","plot","character","genre","actor","director","average ratings","review","rating","year"],"instance":{"id":"38","words":["are","there","any","drama","movies","with","seth","green"],"labels":["O","O","O","B-genre","O","O","B-actor","I-actor"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, title, trailer, plot, character, genre, actor, director, average ratings, review, rating, year and O.\nSentence: are there any drama movies with seth green","prompt_labels":"are(O) there(O) any(O) drama(B-genre) movies(O) with(O) seth(B-actor) green(I-actor)"}}
{"dataset":"mit-movie","split":"dev","label_list":["title","year","plot","review","genre","character","trailer","actor","song","rating","director","average ratings"],"instance":{"id":"39","words":["what","is","the","movie","with","an","aerosmith","song"],"labels":["O","O","O","O","O","O","B-song","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: title, year, plot, review, genre, character, trailer, actor, song, rating, director, average ratings and O.\nSentence: what is the movie with an aerosmith song","prompt_labels":"what(O) is(O) the(O) movie(O) with(O) an(O) aerosmith(B-song) song(O)"}}
{"dataset":"mit-movie","split":"dev","label_list":["director","actor","character","trailer","song","title","plot","genre","rating","average ratings","review","year"],"instance":{"id":"40","words":["what","is","the","highest","rated","kids","new","release"],"labels":["O","O","O","B-average ratings","I-average ratings","B-genre","B-year","I-year"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, actor, character, trailer, song, title, plot, genre, rating, average ratings, review, year and O.\nSentence: what is the highest rated kids new release","prompt_labels":"what(O) is(O) the(O) highest(B-average ratings) rated(I-average ratings) kids(B-genre) new(B-year) release(I-year)"}}
{"dataset":"mit-movie","split":"dev","label_list":["actor","trailer","year","average ratings","director","rating","title","genre","character","plot","song","review"],"instance":{"id":"41","words":["worst","review","for","2011","movies"],"labels":["B-average ratings","I-average ratings","O","B-year","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, trailer, year, average ratings, director, rating, title, genre, character, plot, song, review and O.\nSentence: worst review for 2011 movies","prompt_labels":"worst(B-average ratings) review(I-average ratings) for(O) 2011(B-year) movies(O)"}}
{"dataset":"mit-movie","split":"dev","label_list":["rating","average ratings","plot","genre","character","year","review","song","actor","director","trailer","title"],"instance":{"id":"42","words":["show","me","the","milos","forman","movies","from","the","1980s"],"labels":["O","O","O","B-actor","I-actor","O","O","O","B-year"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, average ratings, plot, genre, character, year, review, song, actor, director, trailer, title and O.\nSentence: show me the milos forman movies from the 1980s","prompt_labels":"show(O) me(O) the(O) milos(B-actor) forman(I-actor) movies(O) from(O) the(O) 1980s(B-year)"}}
{"dataset":"mit-movie","split":"dev","label_list":["actor","genre","trailer","director","title","character","plot","review","year","rating","song","average ratings"],"instance":{"id":"43","words":["lets","find","an","independent","film","company"],"labels":["O","O","O","B-genre","I-genre","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, genre, trailer, director, title, character, plot, review, year, rating, song, average ratings and O.\nSentence: lets find an independent film company","prompt_labels":"lets(O) find(O) an(O) independent(B-genre) film(I-genre) company(O)"}}
{"dataset":"mit-movie","split":"dev","label_list":["year","rating","director","plot","character","review","average ratings","song","actor","title","trailer","genre"],"instance":{"id":"44","words":["which","movies","were","based","off","of","video","games","besides","resident","evil"],"labels":["O","O","O","B-plot","I-plot","I-plot","I-plot","I-plot","O","B-title","I-title"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: year, rating, director, plot, character, review, average ratings, song, actor, title, trailer, genre and O.\nSentence: which movies were based off of video games besides resident evil","prompt_labels":"which(O) movies(O) were(O) based(B-plot) off(I-plot) of(I-plot) video(I-plot) games(I-plot) besides(O) resident(B-title) evil(I-title)"}}
{"dataset":"mit-movie","split":"dev","label_list":["rating","genre","plot","song","title","year","average ratings","review","character","director","trailer","actor"],"instance":{"id":"45","words":["did","dame","judy","dench","star","in","a","british","film","about","queen","elizabeth"],"labels":["O","B-actor","I-actor","I-actor","O","O","O","B-plot","O","O","B-character","I-character"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, genre, plot, song, title, year, average ratings, review, character, director, trailer, actor and O.\nSentence: did dame judy dench star in a british film about queen elizabeth","prompt_labels":"did(O) dame(B-actor) judy(I-actor) dench(I-actor) star(O) in(O) a(O) british(B-plot) film(O) about(O) queen(B-character) elizabeth(I-character)"}}
{"dataset":"mit-movie","split":"dev","label_list":["title","average ratings","plot","year","rating","director","genre","review","song","trailer","character","actor"],"instance":{"id":"46","words":["present","list","of","family","movies","that","chris","columbus","directed"],"labels":["O","O","O","B-genre","I-genre","O","B-director","I-director","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: title, average ratings, plot, year, rating, director, genre, review, song, trailer, character, actor and O.\nSentence: present list of family movies that chris columbus directed","prompt_labels":"present(O) list(O) of(O) family(B-genre) movies(I-genre) that(O) chris(B-director) columbus(I-director) directed(O)"}}
{"dataset":"mit-movie","split":"dev","label_list":["title","director","review","trailer","character","plot","average ratings","year","rating","actor","genre","song"],"instance":{"id":"47","words":["find","a","movie","with","dogs","as","the","main","character"],"labels":["O","O","O","O","B-plot","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: title, director, review, trailer, character, plot, average ratings, year, rating, actor, genre, song and O.\nSentence: find a movie with dogs as the main character","prompt_labels":"find(O) a(O) movie(O) with(O) dogs(B-plot) as(O) the(O) main(O) character(O)"}}
{"dataset":"mit-movie","split":"dev","label_list":["average ratings","plot","genre","year","actor","rating","trailer","character","director","song","review","title"],"instance":{"id":"48","words":["show","me","movies","about","horse","racing"],"labels":["O","O","O","O","B-plot","I-plot"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: average ratings, plot, genre, year, actor, rating, trailer, character, director, song, review, title and O.\nSentence: show me movies about horse racing","prompt_labels":"show(O) me(O) movies(O) about(O) horse(B-plot) racing(I-plot)"}}
{"dataset":"mit-movie","split":"dev","label_list":["trailer","genre","rating","character","plot","title","average ratings","song","year","actor","review","director"],"instance":{"id":"49","words":["show","me","morgan","freeman","movies","from","the","90s"],"labels":["O","O","B-actor","I-actor","O","O","O","B-year"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: trailer, genre, rating, character, plot, title, average ratings, song, year, actor, review, director and O.\nSentence: show me morgan freeman movies from the 90s","prompt_labels":"show(O) me(O) morgan(B-actor) freeman(I-actor) movies(O) from(O) the(O) 90s(B-year)"}}
{"dataset":"mit-movie","split":"dev","label_list":["review","song","character","average ratings","rating","director","genre","year","actor","title","plot","trailer"],"instance":{"id":"50","words":["find","me","the","movies","that","starred","anne","hathaway","and","julie","andrews"],"labels":["O","O","O","O","O","O","B-actor","I-actor","O","B-actor","I-actor"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, song, character, average ratings, rating, director, genre, year, actor, title, plot, trailer and O.\nSentence: find me the movies that starred anne hathaway and julie andrews","prompt_labels":"find(O) me(O) the(O) movies(O) that(O) starred(O) anne(B-actor) hathaway(I-actor) and(O) julie(B-actor) andrews(I-actor)"}}
{"dataset":"mit-movie","split":"dev","label_list":["average ratings","trailer","title","plot","actor","rating","character","year","song","genre","director","review"],"instance":{"id":"51","words":["has","sandra","bullock","made","any","g","rated","movies"],"labels":["O","B-actor","I-actor","O","O","B-rating","I-rating","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: average ratings, trailer, title, plot, actor, rating, character, year, song, genre, director, review and O.\nSentence: has sandra bullock made any g rated movies","prompt_labels":"has(O) sandra(B-actor) bullock(I-actor) made(O) any(O) g(B-rating) rated(I-rating) movies(O)"}}
{"dataset":"mit-movie","split":"dev","label_list":["year","song","genre","rating","plot","average ratings","director","character","title","review","actor","trailer"],"instance":{"id":"52","words":["list","the","dirty","harry","films","from","the","1980s"],"labels":["O","O","B-title","I-title","O","O","O","B-year"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: year, song, genre, rating, plot, average ratings, director, character, title, review, actor, trailer and O.\nSentence: list the dirty harry films from the 1980s","prompt_labels":"list(O) the(O) dirty(B-title) harry(I-title) films(O) from(O) the(O) 1980s(B-year)"}}
{"dataset":"mit-movie","split":"dev","label_list":["year","character","review","trailer","plot","director","average ratings","genre","title","song","rating","actor"],"instance":{"id":"53","words":["show","me","movies","about","strippers"],"labels":["O","O","O","O","B-plot"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: year, character, review, trailer, plot, director, average ratings, genre, title, song, rating, actor and O.\nSentence: show me movies about strippers","prompt_labels":"show(O) me(O) movies(O) about(O) strippers(B-plot)"}}
{"dataset":"mit-movie","split":"dev","label_list":["character","genre","title","trailer","rating","director","average ratings","year","actor","song","plot","review"],"instance":{"id":"54","words":["are","there","any","meg","ryan","romantic","comedy","movies","that","are","considered","must","see"],"labels":["O","O","O","B-actor","I-actor","B-genre","I-genre","O","O","O","O","B-review","I-review"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, genre, title, trailer, rating, director, average ratings, year, actor, song, plot, review and O.\nSentence: are there any meg ryan romantic comedy movies that are considered must see","prompt_labels":"are(O) there(O) any(O) meg(B-actor) ryan(I-actor) romantic(B-genre) comedy(I-genre) movies(O) that(O) are(O) considered(O) must(B-review) see(I-review)"}}
{"dataset":"mit-movie","split":"dev","label_list":["rating","year","title","genre","director","average ratings","plot","trailer","character","song","review","actor"],"instance":{"id":"55","words":["what","was","james","camerons","directorial","debut"],"labels":["O","O","B-director","I-director","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, year, title, genre, director, average ratings, plot, trailer, character, song, review, actor and O.\nSentence: what was james camerons directorial debut","prompt_labels":"what(O) was(O) james(B-director) camerons(I-director) directorial(O) debut(O)"}}
{"dataset":"mit-movie","split":"dev","label_list":["review","title","genre","actor","director","song","average ratings","rating","character","trailer","plot","year"],"instance":{"id":"56","words":["what","are","top","50","movies","of","all","time"],"labels":["O","O","B-average ratings","I-average ratings","O","O","B-average ratings","I-average ratings"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, title, genre, actor, director, song, average ratings, rating, character, trailer, plot, year and O.\nSentence: what are top 50 movies of all time","prompt_labels":"what(O) are(O) top(B-average ratings) 50(I-average ratings) movies(O) of(O) all(B-average ratings) time(I-average ratings)"}}
{"dataset":"mit-movie","split":"dev","label_list":["genre","average ratings","plot","actor","year","director","song","trailer","character","title","rating","review"],"instance":{"id":"57","words":["find","me","comedy","movies","with","liam","hemsworth"],"labels":["O","O","B-genre","O","O","B-actor","I-actor"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, average ratings, plot, actor, year, director, song, trailer, character, title, rating, review and O.\nSentence: find me comedy movies with liam hemsworth","prompt_labels":"find(O) me(O) comedy(B-genre) movies(O) with(O) liam(B-actor) hemsworth(I-actor)"}}
{"dataset":"mit-movie","split":"dev","label_list":["review","average ratings","plot","director","genre","song","character","trailer","title","rating","actor","year"],"instance":{"id":"58","words":["i","want","to","see","cradle","2","the","grave"],"labels":["O","O","O","O","B-title","I-title","I-title","I-title"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, average ratings, plot, director, genre, song, character, trailer, title, rating, actor, year and O.\nSentence: i want to see cradle 2 the grave","prompt_labels":"i(O) want(O) to(O) see(O) cradle(B-title) 2(I-title) the(I-title) grave(I-title)"}}
{"dataset":"mit-movie","split":"dev","label_list":["genre","actor","year","title","song","character","trailer","plot","average ratings","director","rating","review"],"instance":{"id":"59","words":["what","was","the","most","popular","movie","from","2004"],"labels":["O","O","O","B-review","I-review","I-review","O","B-year"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, actor, year, title, song, character, trailer, plot, average ratings, director, rating, review and O.\nSentence: what was the most popular movie from 2004","prompt_labels":"what(O) was(O) the(O) most(B-review) popular(I-review) movie(I-review) from(O) 2004(B-year)"}}
{"dataset":"mit-movie","split":"dev","label_list":["review","trailer","average ratings","director","year","rating","character","title","actor","song","plot","genre"],"instance":{"id":"60","words":["what","is","the","g","rated","movie","about","rabbits","looking","for","a","new","home"],"labels":["O","O","O","B-rating","I-rating","O","O","B-plot","I-plot","I-plot","I-plot","I-plot","I-plot"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, trailer, average ratings, director, year, rating, character, title, actor, song, plot, genre and O.\nSentence: what is the g rated movie about rabbits looking for a new home","prompt_labels":"what(O) is(O) the(O) g(B-rating) rated(I-rating) movie(O) about(O) rabbits(B-plot) looking(I-plot) for(I-plot) a(I-plot) new(I-plot) home(I-plot)"}}
{"dataset":"mit-movie","split":"dev","label_list":["rating","genre","plot","average ratings","character","song","review","year","director","actor","trailer","title"],"instance":{"id":"61","words":["what","latest","3d","movie","of","any","genre","is","reccommend"],"labels":["O","O","B-plot","O","O","O","O","O","B-average ratings"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, genre, plot, average ratings, character, song, review, year, director, actor, trailer, title and O.\nSentence: what latest 3d movie of any genre is reccommend","prompt_labels":"what(O) latest(O) 3d(B-plot) movie(O) of(O) any(O) genre(O) is(O) reccommend(B-average ratings)"}}
{"dataset":"mit-movie","split":"dev","label_list":["plot","title","trailer","song","actor","rating","genre","average ratings","review","character","year","director"],"instance":{"id":"62","words":["how","many","movies","have","tim","burton","and","johnny","depp","done","together"],"labels":["O","O","O","O","B-actor","I-actor","O","B-actor","I-actor","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, title, trailer, song, actor, rating, genre, average ratings, review, character, year, director and O.\nSentence: how many movies have tim burton and johnny depp done together","prompt_labels":"how(O) many(O) movies(O) have(O) tim(B-actor) burton(I-actor) and(O) johnny(B-actor) depp(I-actor) done(O) together(O)"}}
{"dataset":"mit-movie","split":"dev","label_list":["genre","average ratings","song","title","year","director","plot","actor","review","character","trailer","rating"],"instance":{"id":"63","words":["how","many","times","has","matt","damon","been","jason","bourne"],"labels":["O","O","O","O","B-actor","I-actor","O","B-character","I-character"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, average ratings, song, title, year, director, plot, actor, review, character, trailer, rating and O.\nSentence: how many times has matt damon been jason bourne","prompt_labels":"how(O) many(O) times(O) has(O) matt(B-actor) damon(I-actor) been(O) jason(B-character) bourne(I-character)"}}
{"dataset":"mit-movie","split":"dev","label_list":["average ratings","review","year","character","rating","title","director","actor","trailer","song","genre","plot"],"instance":{"id":"64","words":["whats","the","latetest","foreign","romantic","movie","with","lots","of","sex","and","sadness"],"labels":["O","O","B-year","B-genre","I-genre","O","O","O","O","B-plot","O","B-plot"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: average ratings, review, year, character, rating, title, director, actor, trailer, song, genre, plot and O.\nSentence: whats the latetest foreign romantic movie with lots of sex and sadness","prompt_labels":"whats(O) the(O) latetest(B-year) foreign(B-genre) romantic(I-genre) movie(O) with(O) lots(O) of(O) sex(B-plot) and(O) sadness(B-plot)"}}
{"dataset":"mit-movie","split":"dev","label_list":["rating","character","actor","trailer","average ratings","year","song","review","genre","plot","title","director"],"instance":{"id":"65","words":["list","movies","with","jeremy","piven","released","in","the","1990s"],"labels":["O","O","O","B-actor","I-actor","O","O","O","B-year"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, character, actor, trailer, average ratings, year, song, review, genre, plot, title, director and O.\nSentence: list movies with jeremy piven released in the 1990s","prompt_labels":"list(O) movies(O) with(O) jeremy(B-actor) piven(I-actor) released(O) in(O) the(O) 1990s(B-year)"}}
{"dataset":"mit-movie","split":"dev","label_list":["director","year","song","review","title","plot","actor","genre","average ratings","rating","trailer","character"],"instance":{"id":"66","words":["show","me","the","collection","of","action","movies","of","arnold"],"labels":["O","O","O","O","O","B-genre","I-genre","O","B-actor"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, year, song, review, title, plot, actor, genre, average ratings, rating, trailer, character and O.\nSentence: show me the collection of action movies of arnold","prompt_labels":"show(O) me(O) the(O) collection(O) of(O) action(B-genre) movies(I-genre) of(O) arnold(B-actor)"}}
{"dataset":"mit-movie","split":"dev","label_list":["genre","review","character","year","song","trailer","average ratings","rating","director","title","actor","plot"],"instance":{"id":"67","words":["are","there","comic","book","movies","that","are","over","pg","13"],"labels":["O","O","B-genre","I-genre","I-genre","O","O","O","B-rating","I-rating"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, review, character, year, song, trailer, average ratings, rating, director, title, actor, plot and O.\nSentence: are there comic book movies that are over pg 13","prompt_labels":"are(O) there(O) comic(B-genre) book(I-genre) movies(I-genre) that(O) are(O) over(O) pg(B-rating) 13(I-rating)"}}
{"dataset":"mit-movie","split":"dev","label_list":["review","song","character","rating","genre","actor","plot","title","year","trailer","director","average ratings"],"instance":{"id":"68","words":["the","new","batman","movie","looks","epic"],"labels":["O","O","B-title","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, song, character, rating, genre, actor, plot, title, year, trailer, director, average ratings and O.\nSentence: the new batman movie looks epic","prompt_labels":"the(O) new(O) batman(B-title) movie(O) looks(O) epic(O)"}}
{"dataset":"mit-movie","split":"dev","label_list":["actor","year","trailer","rating","character","director","genre","title","plot","review","song","average ratings"],"instance":{"id":"69","words":["show","me","movies","who","won","awards"],"labels":["O","O","O","O","O","B-average ratings"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, year, trailer, rating, character, director, genre, title, plot, review, song, average ratings and O.\nSentence: show me movies who won awards","prompt_labels":"show(O) me(O) movies(O) who(O) won(O) awards(B-average ratings)"}}
{"dataset":"mit-movie","split":"dev","label_list":["year","actor","song","rating","plot","review","average ratings","character","director","genre","title","trailer"],"instance":{"id":"70","words":["what","is","the","year","that","dirty","dancing","was","released"],"labels":["O","O","O","B-year","O","B-title","I-title","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: year, actor, song, rating, plot, review, average ratings, character, director, genre, title, trailer and O.\nSentence: what is the year that dirty dancing was released","prompt_labels":"what(O) is(O) the(O) year(B-year) that(O) dirty(B-title) dancing(I-title) was(O) released(O)"}}
{"dataset":"mit-movie","split":"dev","label_list":["song","trailer","rating","year","genre","review","title","actor","average ratings","director","character","plot"],"instance":{"id":"71","words":["favorite","quote","from","action","movies"],"labels":["O","O","O","B-genre","I-genre"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, trailer, rating, year, genre, review, title, actor, average ratings, director, character, plot and O.\nSentence: favorite quote from action movies","prompt_labels":"favorite(O) quote(O) from(O) action(B-genre) movies(I-genre)"}}
{"dataset":"mit-movie","split":"dev","label_list":["title","rating","song","plot","genre","trailer","character","director","review","actor","year","average ratings"],"instance":{"id":"72","words":["find","me","the","g","rated","movies","with","dogs","that","were","released","in","the","2000s"],"labels":["O","O","O","B-rating","I-rating","O","O","B-plot","O","O","O","O","O","B-year"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: title, rating, song, plot, genre, trailer, character, director, review, actor, year, average ratings and O.\nSentence: find me the g rated movies with dogs that were released in the 2000s","prompt_labels":"find(O) me(O) the(O) g(B-rating) rated(I-rating) movies(O) with(O) dogs(B-plot) that(O) were(O) released(O) in(O) the(O) 2000s(B-year)"}}
{"dataset":"mit-movie","split":"dev","label_list":["genre","plot","title","character","director","average ratings","actor","year","rating","review","trailer","song"],"instance":{"id":"73","words":["are","there","any","silent","movies","made","after","1930"],"labels":["O","O","O","B-genre","O","O","B-year","I-year"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, plot, title, character, director, average ratings, actor, year, rating, review, trailer, song and O.\nSentence: are there any silent movies made after 1930","prompt_labels":"are(O) there(O) any(O) silent(B-genre) movies(O) made(O) after(B-year) 1930(I-year)"}}
{"dataset":"mit-movie","split":"dev","label_list":["director","average ratings","plot","review","genre","year","title","trailer","character","rating","song","actor"],"instance":{"id":"74","words":["who","was","the","actress","in","the","goodbye","girl","with","richard","dreyfuss"],"labels":["O","O","O","O","O","B-title","I-title","I-title","O","B-actor","I-actor"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, average ratings, plot, review, genre, year, title, trailer, character, rating, song, actor and O.\nSentence: who was the actress in the goodbye girl with richard dreyfuss","prompt_labels":"who(O) was(O) the(O) actress(O) in(O) the(B-title) goodbye(I-title) girl(I-title) with(O) richard(B-actor) dreyfuss(I-actor)"}}
{"dataset":"mit-movie","split":"dev","label_list":["title","year","genre","trailer","average ratings","actor","director","review","rating","character","song","plot"],"instance":{"id":"75","words":["which","movies","are","made","with","video","game","plots"],"labels":["O","O","O","O","O","B-plot","I-plot","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: title, year, genre, trailer, average ratings, actor, director, review, rating, character, song, plot and O.\nSentence: which movies are made with video game plots","prompt_labels":"which(O) movies(O) are(O) made(O) with(O) video(B-plot) game(I-plot) plots(O)"}}
{"dataset":"mit-movie","split":"dev","label_list":["year","rating","review","song","plot","actor","trailer","character","genre","title","average ratings","director"],"instance":{"id":"76","words":["what","video","game","movies","are","due","to","release","in","2013"],"labels":["O","B-plot","I-plot","I-plot","O","O","O","O","O","B-year"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: year, rating, review, song, plot, actor, trailer, character, genre, title, average ratings, director and O.\nSentence: what video game movies are due to release in 2013","prompt_labels":"what(O) video(B-plot) game(I-plot) movies(I-plot) are(O) due(O) to(O) release(O) in(O) 2013(B-year)"}}
{"dataset":"mit-movie","split":"dev","label_list":["average ratings","review","actor","plot","rating","year","director","song","title","character","genre","trailer"],"instance":{"id":"77","words":["id","like","the","not","to","be","missed","nicole","kidman","musical"],"labels":["O","O","O","O","O","O","O","B-actor","I-actor","B-genre"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: average ratings, review, actor, plot, rating, year, director, song, title, character, genre, trailer and O.\nSentence: id like the not to be missed nicole kidman musical","prompt_labels":"id(O) like(O) the(O) not(O) to(O) be(O) missed(O) nicole(B-actor) kidman(I-actor) musical(B-genre)"}}
{"dataset":"mit-movie","split":"dev","label_list":["plot","rating","actor","director","year","title","character","average ratings","review","song","genre","trailer"],"instance":{"id":"78","words":["what","movie","has","the","most","remakes"],"labels":["O","O","O","O","B-review","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, rating, actor, director, year, title, character, average ratings, review, song, genre, trailer and O.\nSentence: what movie has the most remakes","prompt_labels":"what(O) movie(O) has(O) the(O) most(B-review) remakes(O)"}}
{"dataset":"mit-movie","split":"dev","label_list":["trailer","director","rating","song","average ratings","plot","title","character","review","year","genre","actor"],"instance":{"id":"79","words":["what","shakespeare","films","take","place","in","italy"],"labels":["O","B-plot","O","O","O","O","B-plot"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: trailer, director, rating, song, average ratings, plot, title, character, review, year, genre, actor and O.\nSentence: what shakespeare films take place in italy","prompt_labels":"what(O) shakespeare(B-plot) films(O) take(O) place(O) in(O) italy(B-plot)"}}
{"dataset":"mit-movie","split":"dev","label_list":["actor","character","director","plot","year","rating","genre","review","trailer","song","average ratings","title"],"instance":{"id":"80","words":["what","was","channing","tatums","first","movie"],"labels":["O","O","B-actor","I-actor","B-year","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, character, director, plot, year, rating, genre, review, trailer, song, average ratings, title and O.\nSentence: what was channing tatums first movie","prompt_labels":"what(O) was(O) channing(B-actor) tatums(I-actor) first(B-year) movie(O)"}}
{"dataset":"mit-movie","split":"dev","label_list":["character","year","rating","genre","director","title","actor","song","average ratings","plot","trailer","review"],"instance":{"id":"81","words":["i","would","like","a","list","of","movies","about","dancing","from","the","past","10","years"],"labels":["O","O","O","O","O","O","O","O","B-plot","O","O","B-year","I-year","I-year"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, year, rating, genre, director, title, actor, song, average ratings, plot, trailer, review and O.\nSentence: i would like a list of movies about dancing from the past 10 years","prompt_labels":"i(O) would(O) like(O) a(O) list(O) of(O) movies(O) about(O) dancing(B-plot) from(O) the(O) past(B-year) 10(I-year) years(I-year)"}}
{"dataset":"mit-movie","split":"dev","label_list":["review","plot","character","rating","genre","title","average ratings","director","year","actor","trailer","song"],"instance":{"id":"82","words":["who","stars","in","project","x"],"labels":["O","O","O","B-title","I-title"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, plot, character, rating, genre, title, average ratings, director, year, actor, trailer, song and O.\nSentence: who stars in project x","prompt_labels":"who(O) stars(O) in(O) project(B-title) x(I-title)"}}
{"dataset":"mit-movie","split":"dev","label_list":["genre","director","rating","year","character","song","plot","actor","trailer","average ratings","title","review"],"instance":{"id":"83","words":["find","action","movies","featuring","comic","book","characters"],"labels":["O","B-genre","O","O","B-plot","I-plot","I-plot"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, director, rating, year, character, song, plot, actor, trailer, average ratings, title, review and O.\nSentence: find action movies featuring comic book characters","prompt_labels":"find(O) action(B-genre) movies(O) featuring(O) comic(B-plot) book(I-plot) characters(I-plot)"}}
{"dataset":"mit-movie","split":"dev","label_list":["trailer","plot","title","genre","song","rating","director","actor","average ratings","review","character","year"],"instance":{"id":"84","words":["what","are","some","g","rated","movies","with","fairies"],"labels":["O","O","O","B-rating","O","O","O","B-plot"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: trailer, plot, title, genre, song, rating, director, actor, average ratings, review, character, year and O.\nSentence: what are some g rated movies with fairies","prompt_labels":"what(O) are(O) some(O) g(B-rating) rated(O) movies(O) with(O) fairies(B-plot)"}}
{"dataset":"mit-movie","split":"dev","label_list":["character","average ratings","year","plot","song","trailer","rating","director","actor","genre","title","review"],"instance":{"id":"85","words":["name","a","movie","starring","britney","spears"],"labels":["O","O","O","O","B-actor","I-actor"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, average ratings, year, plot, song, trailer, rating, director, actor, genre, title, review and O.\nSentence: name a movie starring britney spears","prompt_labels":"name(O) a(O) movie(O) starring(O) britney(B-actor) spears(I-actor)"}}
{"dataset":"mit-movie","split":"dev","label_list":["song","actor","review","average ratings","director","trailer","title","rating","year","genre","character","plot"],"instance":{"id":"86","words":["what","movie","did","rod","serling","write"],"labels":["O","O","O","B-director","I-director","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, actor, review, average ratings, director, trailer, title, rating, year, genre, character, plot and O.\nSentence: what movie did rod serling write","prompt_labels":"what(O) movie(O) did(O) rod(B-director) serling(I-director) write(O)"}}
{"dataset":"mit-movie","split":"dev","label_list":["title","director","song","average ratings","character","year","rating","review","genre","actor","trailer","plot"],"instance":{"id":"87","words":["is","there","an","animated","adult","fantasy","movie"],"labels":["O","O","O","B-genre","I-genre","I-genre","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: title, director, song, average ratings, character, year, rating, review, genre, actor, trailer, plot and O.\nSentence: is there an animated adult fantasy movie","prompt_labels":"is(O) there(O) an(O) animated(B-genre) adult(I-genre) fantasy(I-genre) movie(O)"}}
{"dataset":"mit-movie","split":"dev","label_list":["song","average ratings","plot","character","genre","title","director","review","actor","year","rating","trailer"],"instance":{"id":"88","words":["the","song","sunshine","on","my","shoulders","was","the","soundtrack","for","what","movie"],"labels":["O","O","B-song","I-song","I-song","I-song","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, average ratings, plot, character, genre, title, director, review, actor, year, rating, trailer and O.\nSentence: the song sunshine on my shoulders was the soundtrack for what movie","prompt_labels":"the(O) song(O) sunshine(B-song) on(I-song) my(I-song) shoulders(I-song) was(O) the(O) soundtrack(O) for(O) what(O) movie(O)"}}
{"dataset":"mit-movie","split":"dev","label_list":["year","genre","song","rating","trailer","plot","review","character","actor","average ratings","director","title"],"instance":{"id":"89","words":["are","there","any","movies","about","popular","game","shows"],"labels":["O","O","O","O","O","B-plot","I-plot","I-plot"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: year, genre, song, rating, trailer, plot, review, character, actor, average ratings, director, title and O.\nSentence: are there any movies about popular game shows","prompt_labels":"are(O) there(O) any(O) movies(O) about(O) popular(B-plot) game(I-plot) shows(I-plot)"}}
{"dataset":"mit-movie","split":"dev","label_list":["trailer","review","year","average ratings","actor","song","genre","director","plot","rating","character","title"],"instance":{"id":"90","words":["find","me","the","name","of","the","actor","that","played","v","in","v","for","vendetta"],"labels":["O","O","O","O","O","O","O","O","O","B-character","O","B-title","I-title","I-title"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: trailer, review, year, average ratings, actor, song, genre, director, plot, rating, character, title and O.\nSentence: find me the name of the actor that played v in v for vendetta","prompt_labels":"find(O) me(O) the(O) name(O) of(O) the(O) actor(O) that(O) played(O) v(B-character) in(O) v(B-title) for(I-title) vendetta(I-title)"}}
{"dataset":"mit-movie","split":"dev","label_list":["year","song","review","actor","director","title","plot","rating","trailer","genre","character","average ratings"],"instance":{"id":"91","words":["what","was","the","last","terminator","sequel"],"labels":["O","O","O","O","B-title","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: year, song, review, actor, director, title, plot, rating, trailer, genre, character, average ratings and O.\nSentence: what was the last terminator sequel","prompt_labels":"what(O) was(O) the(O) last(O) terminator(B-title) sequel(O)"}}
{"dataset":"mit-movie","split":"dev","label_list":["actor","rating","character","year","director","plot","review","trailer","title","genre","song","average ratings"],"instance":{"id":"92","words":["what","science","fiction","movies","were","directed","by","george","lucas"],"labels":["O","B-genre","I-genre","O","O","O","O","B-director","I-director"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, rating, character, year, director, plot, review, trailer, title, genre, song, average ratings and O.\nSentence: what science fiction movies were directed by george lucas","prompt_labels":"what(O) science(B-genre) fiction(I-genre) movies(O) were(O) directed(O) by(O) george(B-director) lucas(I-director)"}}
{"dataset":"mit-movie","split":"dev","label_list":["song","plot","character","year","trailer","title","review","genre","rating","actor","average ratings","director"],"instance":{"id":"93","words":["who","directed","princess","bride"],"labels":["O","O","B-title","I-title"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, plot, character, year, trailer, title, review, genre, rating, actor, average ratings, director and O.\nSentence: who directed princess bride","prompt_labels":"who(O) directed(O) princess(B-title) bride(I-title)"}}
{"dataset":"mit-movie","split":"dev","label_list":["title","average ratings","actor","rating","song","plot","year","character","genre","director","trailer","review"],"instance":{"id":"94","words":["who","directed","james","and","the","giant","peach"],"labels":["O","B-director","B-title","I-title","I-title","I-title","I-title"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: title, average ratings, actor, rating, song, plot, year, character, genre, director, trailer, review and O.\nSentence: who directed james and the giant peach","prompt_labels":"who(O) directed(B-director) james(B-title) and(I-title) the(I-title) giant(I-title) peach(I-title)"}}
{"dataset":"mit-movie","split":"dev","label_list":["year","genre","trailer","average ratings","title","song","actor","character","review","plot","rating","director"],"instance":{"id":"95","words":["name","a","western","comedy"],"labels":["O","O","B-genre","I-genre"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: year, genre, trailer, average ratings, title, song, actor, character, review, plot, rating, director and O.\nSentence: name a western comedy","prompt_labels":"name(O) a(O) western(B-genre) comedy(I-genre)"}}
{"dataset":"mit-movie","split":"dev","label_list":["song","review","director","plot","trailer","rating","title","character","year","genre","actor","average ratings"],"instance":{"id":"96","words":["what","type","of","movie","is","nine"],"labels":["O","O","O","O","O","B-title"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, review, director, plot, trailer, rating, title, character, year, genre, actor, average ratings and O.\nSentence: what type of movie is nine","prompt_labels":"what(O) type(O) of(O) movie(O) is(O) nine(B-title)"}}
{"dataset":"mit-movie","split":"dev","label_list":["year","director","title","actor","rating","character","song","plot","average ratings","genre","trailer","review"],"instance":{"id":"97","words":["how","many","movies","have","starred","brad","pitt"],"labels":["O","O","O","O","O","B-actor","I-actor"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: year, director, title, actor, rating, character, song, plot, average ratings, genre, trailer, review and O.\nSentence: how many movies have starred brad pitt","prompt_labels":"how(O) many(O) movies(O) have(O) starred(O) brad(B-actor) pitt(I-actor)"}}
{"dataset":"mit-movie","split":"dev","label_list":["year","genre","average ratings","rating","character","review","trailer","director","actor","plot","song","title"],"instance":{"id":"98","words":["i","am","looking","for","a","movie","about","talking","animals"],"labels":["O","O","O","O","O","O","O","B-plot","I-plot"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: year, genre, average ratings, rating, character, review, trailer, director, actor, plot, song, title and O.\nSentence: i am looking for a movie about talking animals","prompt_labels":"i(O) am(O) looking(O) for(O) a(O) movie(O) about(O) talking(B-plot) animals(I-plot)"}}
{"dataset":"mit-movie","split":"dev","label_list":["average ratings","actor","year","plot","title","trailer","genre","director","rating","song","character","review"],"instance":{"id":"99","words":["find","a","john","malcovich","thriller"],"labels":["O","O","B-actor","I-actor","B-genre"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: average ratings, actor, year, plot, title, trailer, genre, director, rating, song, character, review and O.\nSentence: find a john malcovich thriller","prompt_labels":"find(O) a(O) john(B-actor) malcovich(I-actor) thriller(B-genre)"}}
{"dataset":"mit-movie","split":"dev","label_list":["character","average ratings","director","review","title","rating","year","genre","actor","trailer","plot","song"],"instance":{"id":"100","words":["channing","tatum","has","played","what","starring","roles"],"labels":["B-actor","I-actor","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, average ratings, director, review, title, rating, year, genre, actor, trailer, plot, song and O.\nSentence: channing tatum has played what starring roles","prompt_labels":"channing(B-actor) tatum(I-actor) has(O) played(O) what(O) starring(O) roles(O)"}}
{"dataset":"mit-movie","split":"dev","label_list":["title","rating","song","director","year","actor","review","trailer","average ratings","character","genre","plot"],"instance":{"id":"101","words":["list","of","actors","a","beautiful","mind"],"labels":["O","O","O","B-title","I-title","I-title"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: title, rating, song, director, year, actor, review, trailer, average ratings, character, genre, plot and O.\nSentence: list of actors a beautiful mind","prompt_labels":"list(O) of(O) actors(O) a(B-title) beautiful(I-title) mind(I-title)"}}
{"dataset":"mit-movie","split":"dev","label_list":["review","actor","trailer","genre","year","song","character","average ratings","plot","title","rating","director"],"instance":{"id":"102","words":["avatar","came","out","when","and","what","did","it","gross"],"labels":["B-title","O","O","B-year","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, actor, trailer, genre, year, song, character, average ratings, plot, title, rating, director and O.\nSentence: avatar came out when and what did it gross","prompt_labels":"avatar(B-title) came(O) out(O) when(B-year) and(O) what(O) did(O) it(O) gross(O)"}}
{"dataset":"mit-movie","split":"dev","label_list":["average ratings","year","character","title","plot","trailer","director","genre","song","actor","review","rating"],"instance":{"id":"103","words":["did","angelina","jolie","play","a","russian","in","salt"],"labels":["O","B-actor","I-actor","O","O","B-plot","O","B-title"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: average ratings, year, character, title, plot, trailer, director, genre, song, actor, review, rating and O.\nSentence: did angelina jolie play a russian in salt","prompt_labels":"did(O) angelina(B-actor) jolie(I-actor) play(O) a(O) russian(B-plot) in(O) salt(B-title)"}}
{"dataset":"mit-movie","split":"dev","label_list":["rating","year","genre","trailer","song","character","director","review","title","actor","average ratings","plot"],"instance":{"id":"104","words":["did","they","make","a","movie","version","of","absolutely","fabulous"],"labels":["O","O","O","O","O","O","O","B-title","I-title"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, year, genre, trailer, song, character, director, review, title, actor, average ratings, plot and O.\nSentence: did they make a movie version of absolutely fabulous","prompt_labels":"did(O) they(O) make(O) a(O) movie(O) version(O) of(O) absolutely(B-title) fabulous(I-title)"}}
{"dataset":"mit-movie","split":"dev","label_list":["plot","song","genre","character","director","average ratings","actor","title","review","rating","trailer","year"],"instance":{"id":"105","words":["show","me","a","comedy","movie","with","eddie","murphy"],"labels":["O","O","O","B-genre","O","O","B-actor","I-actor"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, song, genre, character, director, average ratings, actor, title, review, rating, trailer, year and O.\nSentence: show me a comedy movie with eddie murphy","prompt_labels":"show(O) me(O) a(O) comedy(B-genre) movie(O) with(O) eddie(B-actor) murphy(I-actor)"}}
{"dataset":"mit-movie","split":"dev","label_list":["plot","rating","director","title","character","year","average ratings","actor","genre","song","review","trailer"],"instance":{"id":"106","words":["what","is","brave","about"],"labels":["O","O","B-title","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, rating, director, title, character, year, average ratings, actor, genre, song, review, trailer and O.\nSentence: what is brave about","prompt_labels":"what(O) is(O) brave(B-title) about(O)"}}
{"dataset":"mit-movie","split":"dev","label_list":["genre","song","actor","rating","director","review","title","trailer","year","character","plot","average ratings"],"instance":{"id":"107","words":["has","ashton","kutcher","made","any","movies","with","zombies"],"labels":["O","B-actor","I-actor","O","O","O","O","B-plot"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, song, actor, rating, director, review, title, trailer, year, character, plot, average ratings and O.\nSentence: has ashton kutcher made any movies with zombies","prompt_labels":"has(O) ashton(B-actor) kutcher(I-actor) made(O) any(O) movies(O) with(O) zombies(B-plot)"}}
{"dataset":"mit-movie","split":"dev","label_list":["director","review","song","year","average ratings","trailer","plot","character","actor","title","genre","rating"],"instance":{"id":"108","words":["what","movie","stars","christopher","walken","an","sean","penn"],"labels":["O","O","O","B-actor","I-actor","O","B-actor","I-actor"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, review, song, year, average ratings, trailer, plot, character, actor, title, genre, rating and O.\nSentence: what movie stars christopher walken an sean penn","prompt_labels":"what(O) movie(O) stars(O) christopher(B-actor) walken(I-actor) an(O) sean(B-actor) penn(I-actor)"}}
{"dataset":"mit-movie","split":"dev","label_list":["review","average ratings","plot","character","title","year","trailer","rating","actor","genre","director","song"],"instance":{"id":"109","words":["show","me","movies","starring","michael","j","fox","from","1993"],"labels":["O","O","O","O","B-actor","I-actor","I-actor","O","B-year"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, average ratings, plot, character, title, year, trailer, rating, actor, genre, director, song and O.\nSentence: show me movies starring michael j fox from 1993","prompt_labels":"show(O) me(O) movies(O) starring(O) michael(B-actor) j(I-actor) fox(I-actor) from(O) 1993(B-year)"}}
{"dataset":"mit-movie","split":"dev","label_list":["rating","average ratings","director","genre","character","trailer","review","actor","song","title","year","plot"],"instance":{"id":"110","words":["who","starred","in","marley","and","me"],"labels":["O","O","O","B-title","I-title","I-title"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, average ratings, director, genre, character, trailer, review, actor, song, title, year, plot and O.\nSentence: who starred in marley and me","prompt_labels":"who(O) starred(O) in(O) marley(B-title) and(I-title) me(I-title)"}}
{"dataset":"mit-movie","split":"dev","label_list":["average ratings","review","plot","title","genre","song","character","year","trailer","actor","rating","director"],"instance":{"id":"111","words":["what","movie","has","the","song","down","with","the","sickness"],"labels":["O","O","O","O","O","B-song","I-song","I-song","I-song"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: average ratings, review, plot, title, genre, song, character, year, trailer, actor, rating, director and O.\nSentence: what movie has the song down with the sickness","prompt_labels":"what(O) movie(O) has(O) the(O) song(O) down(B-song) with(I-song) the(I-song) sickness(I-song)"}}
{"dataset":"mit-movie","split":"dev","label_list":["plot","song","average ratings","genre","review","year","trailer","director","character","actor","title","rating"],"instance":{"id":"112","words":["did","simon","pegg","write","any","movies"],"labels":["O","B-actor","I-actor","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, song, average ratings, genre, review, year, trailer, director, character, actor, title, rating and O.\nSentence: did simon pegg write any movies","prompt_labels":"did(O) simon(B-actor) pegg(I-actor) write(O) any(O) movies(O)"}}
{"dataset":"mit-movie","split":"dev","label_list":["review","genre","title","plot","rating","actor","director","song","year","trailer","average ratings","character"],"instance":{"id":"113","words":["are","there","any","pg","movies","with","car","chases"],"labels":["O","O","O","B-rating","I-rating","O","B-plot","I-plot"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, genre, title, plot, rating, actor, director, song, year, trailer, average ratings, character and O.\nSentence: are there any pg movies with car chases","prompt_labels":"are(O) there(O) any(O) pg(B-rating) movies(I-rating) with(O) car(B-plot) chases(I-plot)"}}
{"dataset":"mit-movie","split":"dev","label_list":["year","review","trailer","plot","title","character","rating","song","director","genre","actor","average ratings"],"instance":{"id":"114","words":["what","movie","won","the","most","awards","in","2005"],"labels":["O","O","O","O","B-average ratings","I-average ratings","O","B-year"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: year, review, trailer, plot, title, character, rating, song, director, genre, actor, average ratings and O.\nSentence: what movie won the most awards in 2005","prompt_labels":"what(O) movie(O) won(O) the(O) most(B-average ratings) awards(I-average ratings) in(O) 2005(B-year)"}}
{"dataset":"mit-movie","split":"dev","label_list":["trailer","title","actor","plot","genre","year","review","director","song","character","average ratings","rating"],"instance":{"id":"115","words":["what","is","puss","in","boots","about"],"labels":["O","O","B-title","I-title","I-title","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: trailer, title, actor, plot, genre, year, review, director, song, character, average ratings, rating and O.\nSentence: what is puss in boots about","prompt_labels":"what(O) is(O) puss(B-title) in(I-title) boots(I-title) about(O)"}}
{"dataset":"mit-movie","split":"dev","label_list":["genre","song","review","title","year","trailer","plot","average ratings","actor","rating","character","director"],"instance":{"id":"116","words":["how","many","movies","have","been","released","in","the","last","ten","years","that","involved","terrorism"],"labels":["O","O","O","O","O","O","O","O","B-year","I-year","I-year","O","O","B-plot"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, song, review, title, year, trailer, plot, average ratings, actor, rating, character, director and O.\nSentence: how many movies have been released in the last ten years that involved terrorism","prompt_labels":"how(O) many(O) movies(O) have(O) been(O) released(O) in(O) the(O) last(B-year) ten(I-year) years(I-year) that(O) involved(O) terrorism(B-plot)"}}
{"dataset":"mit-movie","split":"dev","label_list":["title","year","review","plot","character","director","rating","genre","actor","average ratings","song","trailer"],"instance":{"id":"117","words":["who","directed","runaway","jury"],"labels":["O","B-director","B-title","I-title"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: title, year, review, plot, character, director, rating, genre, actor, average ratings, song, trailer and O.\nSentence: who directed runaway jury","prompt_labels":"who(O) directed(B-director) runaway(B-title) jury(I-title)"}}
{"dataset":"mit-movie","split":"dev","label_list":["genre","plot","review","character","song","average ratings","director","rating","title","year","actor","trailer"],"instance":{"id":"118","words":["show","me","a","good","spy","movie","based","in","england"],"labels":["O","O","O","O","B-genre","O","O","O","B-plot"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, plot, review, character, song, average ratings, director, rating, title, year, actor, trailer and O.\nSentence: show me a good spy movie based in england","prompt_labels":"show(O) me(O) a(O) good(O) spy(B-genre) movie(O) based(O) in(O) england(B-plot)"}}
{"dataset":"mit-movie","split":"dev","label_list":["trailer","year","title","genre","plot","director","average ratings","actor","song","rating","review","character"],"instance":{"id":"119","words":["what","popular","films","released","last","month"],"labels":["O","B-review","O","O","B-year","I-year"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: trailer, year, title, genre, plot, director, average ratings, actor, song, rating, review, character and O.\nSentence: what popular films released last month","prompt_labels":"what(O) popular(B-review) films(O) released(O) last(B-year) month(I-year)"}}
{"dataset":"mit-movie","split":"dev","label_list":["review","average ratings","trailer","genre","song","character","year","actor","plot","rating","director","title"],"instance":{"id":"120","words":["did","dean","parisot","direct","sigourney","weaver","and","tim","allen","in","a","comedy"],"labels":["O","B-director","I-director","O","B-actor","I-actor","O","B-actor","I-actor","O","O","B-genre"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, average ratings, trailer, genre, song, character, year, actor, plot, rating, director, title and O.\nSentence: did dean parisot direct sigourney weaver and tim allen in a comedy","prompt_labels":"did(O) dean(B-director) parisot(I-director) direct(O) sigourney(B-actor) weaver(I-actor) and(O) tim(B-actor) allen(I-actor) in(O) a(O) comedy(B-genre)"}}
{"dataset":"mit-movie","split":"dev","label_list":["trailer","song","year","title","actor","average ratings","review","director","character","genre","plot","rating"],"instance":{"id":"121","words":["who","directed","the","help"],"labels":["O","O","B-title","I-title"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: trailer, song, year, title, actor, average ratings, review, director, character, genre, plot, rating and O.\nSentence: who directed the help","prompt_labels":"who(O) directed(O) the(B-title) help(I-title)"}}
{"dataset":"mit-movie","split":"dev","label_list":["title","rating","song","character","genre","director","trailer","actor","year","review","average ratings","plot"],"instance":{"id":"122","words":["what","is","the","title","of","woody","allens","first","movie"],"labels":["O","O","O","O","O","B-actor","I-actor","B-year","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: title, rating, song, character, genre, director, trailer, actor, year, review, average ratings, plot and O.\nSentence: what is the title of woody allens first movie","prompt_labels":"what(O) is(O) the(O) title(O) of(O) woody(B-actor) allens(I-actor) first(B-year) movie(O)"}}
{"dataset":"mit-movie","split":"dev","label_list":["title","average ratings","review","rating","actor","song","character","plot","director","trailer","year","genre"],"instance":{"id":"123","words":["what","are","some","police","dramas","from","the","90s"],"labels":["O","O","O","B-plot","B-genre","O","O","B-year"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: title, average ratings, review, rating, actor, song, character, plot, director, trailer, year, genre and O.\nSentence: what are some police dramas from the 90s","prompt_labels":"what(O) are(O) some(O) police(B-plot) dramas(B-genre) from(O) the(O) 90s(B-year)"}}
{"dataset":"mit-movie","split":"dev","label_list":["year","genre","trailer","song","character","actor","director","title","review","rating","plot","average ratings"],"instance":{"id":"124","words":["how","many","films","did","clive","owen","play","in"],"labels":["O","O","O","O","B-actor","I-actor","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: year, genre, trailer, song, character, actor, director, title, review, rating, plot, average ratings and O.\nSentence: how many films did clive owen play in","prompt_labels":"how(O) many(O) films(O) did(O) clive(B-actor) owen(I-actor) play(O) in(O)"}}
{"dataset":"mit-movie","split":"dev","label_list":["rating","genre","director","actor","review","character","title","trailer","song","plot","year","average ratings"],"instance":{"id":"125","words":["are","there","any","films","that","harmony","korine","regrets","directing","andor","releasing","to","the","public"],"labels":["O","O","O","O","O","B-director","I-director","B-review","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, genre, director, actor, review, character, title, trailer, song, plot, year, average ratings and O.\nSentence: are there any films that harmony korine regrets directing andor releasing to the public","prompt_labels":"are(O) there(O) any(O) films(O) that(O) harmony(B-director) korine(I-director) regrets(B-review) directing(O) andor(O) releasing(O) to(O) the(O) public(O)"}}
{"dataset":"mit-movie","split":"dev","label_list":["song","review","genre","year","character","title","plot","average ratings","actor","trailer","director","rating"],"instance":{"id":"126","words":["show","me","an","alfred","hitchcock","movie","about","trains"],"labels":["O","O","O","B-director","I-director","O","O","B-plot"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, review, genre, year, character, title, plot, average ratings, actor, trailer, director, rating and O.\nSentence: show me an alfred hitchcock movie about trains","prompt_labels":"show(O) me(O) an(O) alfred(B-director) hitchcock(I-director) movie(O) about(O) trains(B-plot)"}}
{"dataset":"mit-movie","split":"dev","label_list":["director","trailer","song","review","average ratings","genre","character","plot","year","rating","title","actor"],"instance":{"id":"127","words":["who","stars","in","rumble","in","the","bronx"],"labels":["O","O","O","B-title","I-title","I-title","I-title"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, trailer, song, review, average ratings, genre, character, plot, year, rating, title, actor and O.\nSentence: who stars in rumble in the bronx","prompt_labels":"who(O) stars(O) in(O) rumble(B-title) in(I-title) the(I-title) bronx(I-title)"}}
{"dataset":"mit-movie","split":"dev","label_list":["average ratings","year","title","review","genre","trailer","character","director","actor","song","plot","rating"],"instance":{"id":"128","words":["what","was","the","first","movie","patrick","stewart","played","in"],"labels":["O","O","O","B-year","O","B-actor","I-actor","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: average ratings, year, title, review, genre, trailer, character, director, actor, song, plot, rating and O.\nSentence: what was the first movie patrick stewart played in","prompt_labels":"what(O) was(O) the(O) first(B-year) movie(O) patrick(B-actor) stewart(I-actor) played(O) in(O)"}}
{"dataset":"mit-movie","split":"dev","label_list":["trailer","year","review","rating","director","actor","average ratings","song","character","genre","title","plot"],"instance":{"id":"129","words":["what","is","the","film","john","carter","about"],"labels":["O","O","O","O","B-title","I-title","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: trailer, year, review, rating, director, actor, average ratings, song, character, genre, title, plot and O.\nSentence: what is the film john carter about","prompt_labels":"what(O) is(O) the(O) film(O) john(B-title) carter(I-title) about(O)"}}
{"dataset":"mit-movie","split":"dev","label_list":["plot","title","year","director","actor","average ratings","trailer","review","rating","song","character","genre"],"instance":{"id":"130","words":["what","is","the","longest","running","time","for","a","movie","in","film","history"],"labels":["O","O","O","B-review","I-review","I-review","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, title, year, director, actor, average ratings, trailer, review, rating, song, character, genre and O.\nSentence: what is the longest running time for a movie in film history","prompt_labels":"what(O) is(O) the(O) longest(B-review) running(I-review) time(I-review) for(O) a(O) movie(O) in(O) film(O) history(O)"}}
{"dataset":"mit-movie","split":"dev","label_list":["character","review","genre","average ratings","rating","trailer","actor","song","title","plot","year","director"],"instance":{"id":"131","words":["what","was","the","release","year","for","notes","on","a","scandal"],"labels":["O","O","O","B-year","I-year","O","B-title","I-title","I-title","I-title"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, review, genre, average ratings, rating, trailer, actor, song, title, plot, year, director and O.\nSentence: what was the release year for notes on a scandal","prompt_labels":"what(O) was(O) the(O) release(B-year) year(I-year) for(O) notes(B-title) on(I-title) a(I-title) scandal(I-title)"}}
{"dataset":"mit-movie","split":"dev","label_list":["review","year","average ratings","trailer","character","song","rating","genre","actor","director","plot","title"],"instance":{"id":"132","words":["did","milos","forman","direct","a","film","with","edward","norton"],"labels":["O","B-director","I-director","O","O","O","O","B-actor","I-actor"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, year, average ratings, trailer, character, song, rating, genre, actor, director, plot, title and O.\nSentence: did milos forman direct a film with edward norton","prompt_labels":"did(O) milos(B-director) forman(I-director) direct(O) a(O) film(O) with(O) edward(B-actor) norton(I-actor)"}}
{"dataset":"mit-movie","split":"dev","label_list":["character","year","average ratings","director","song","trailer","plot","rating","review","actor","genre","title"],"instance":{"id":"133","words":["how","many","movies","did","christopher","walkin","star","in"],"labels":["O","O","O","O","B-actor","I-actor","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, year, average ratings, director, song, trailer, plot, rating, review, actor, genre, title and O.\nSentence: how many movies did christopher walkin star in","prompt_labels":"how(O) many(O) movies(O) did(O) christopher(B-actor) walkin(I-actor) star(O) in(O)"}}
{"dataset":"mit-movie","split":"dev","label_list":["review","actor","rating","title","plot","character","trailer","genre","song","year","director","average ratings"],"instance":{"id":"134","words":["i","want","to","find","a","list","of","pg","rated","comedies","of","this","year"],"labels":["O","O","O","O","O","O","O","B-rating","I-rating","B-genre","O","B-year","I-year"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, actor, rating, title, plot, character, trailer, genre, song, year, director, average ratings and O.\nSentence: i want to find a list of pg rated comedies of this year","prompt_labels":"i(O) want(O) to(O) find(O) a(O) list(O) of(O) pg(B-rating) rated(I-rating) comedies(B-genre) of(O) this(B-year) year(I-year)"}}
{"dataset":"mit-movie","split":"dev","label_list":["actor","director","title","genre","rating","year","character","trailer","song","plot","review","average ratings"],"instance":{"id":"135","words":["what","are","some","movies","from","the","80s","starring","bruce","willis"],"labels":["O","O","O","O","O","O","B-year","O","B-actor","I-actor"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, director, title, genre, rating, year, character, trailer, song, plot, review, average ratings and O.\nSentence: what are some movies from the 80s starring bruce willis","prompt_labels":"what(O) are(O) some(O) movies(O) from(O) the(O) 80s(B-year) starring(O) bruce(B-actor) willis(I-actor)"}}
{"dataset":"mit-movie","split":"dev","label_list":["plot","genre","review","trailer","character","year","average ratings","rating","title","actor","song","director"],"instance":{"id":"136","words":["waht","was","the","plot","of","the","deep","blue","sea"],"labels":["O","O","O","O","O","B-title","I-title","I-title","I-title"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, genre, review, trailer, character, year, average ratings, rating, title, actor, song, director and O.\nSentence: waht was the plot of the deep blue sea","prompt_labels":"waht(O) was(O) the(O) plot(O) of(O) the(B-title) deep(I-title) blue(I-title) sea(I-title)"}}
{"dataset":"mit-movie","split":"dev","label_list":["review","plot","genre","title","character","actor","rating","song","director","year","average ratings","trailer"],"instance":{"id":"137","words":["did","guillermo","del","toro","direct","any","moves","rated","pg"],"labels":["O","B-director","I-director","I-director","O","O","O","O","B-rating"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, plot, genre, title, character, actor, rating, song, director, year, average ratings, trailer and O.\nSentence: did guillermo del toro direct any moves rated pg","prompt_labels":"did(O) guillermo(B-director) del(I-director) toro(I-director) direct(O) any(O) moves(O) rated(O) pg(B-rating)"}}
{"dataset":"mit-movie","split":"dev","label_list":["plot","average ratings","genre","trailer","actor","director","song","year","character","title","rating","review"],"instance":{"id":"138","words":["who","played","james","in","james","and","the","giant","peach"],"labels":["O","O","B-character","O","B-title","I-title","I-title","I-title","I-title"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, average ratings, genre, trailer, actor, director, song, year, character, title, rating, review and O.\nSentence: who played james in james and the giant peach","prompt_labels":"who(O) played(O) james(B-character) in(O) james(B-title) and(I-title) the(I-title) giant(I-title) peach(I-title)"}}
{"dataset":"mit-movie","split":"dev","label_list":["trailer","title","song","director","review","year","actor","character","average ratings","rating","plot","genre"],"instance":{"id":"139","words":["what","movies","from","2006","star","val","kilmer"],"labels":["O","O","O","B-year","O","B-actor","I-actor"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: trailer, title, song, director, review, year, actor, character, average ratings, rating, plot, genre and O.\nSentence: what movies from 2006 star val kilmer","prompt_labels":"what(O) movies(O) from(O) 2006(B-year) star(O) val(B-actor) kilmer(I-actor)"}}
{"dataset":"mit-movie","split":"dev","label_list":["character","director","review","rating","actor","average ratings","year","title","plot","song","genre","trailer"],"instance":{"id":"140","words":["what","kind","of","movie","is","wanderlust"],"labels":["O","B-review","O","O","O","B-title"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, director, review, rating, actor, average ratings, year, title, plot, song, genre, trailer and O.\nSentence: what kind of movie is wanderlust","prompt_labels":"what(O) kind(B-review) of(O) movie(O) is(O) wanderlust(B-title)"}}
{"dataset":"mit-movie","split":"dev","label_list":["genre","title","review","actor","average ratings","character","song","plot","rating","director","year","trailer"],"instance":{"id":"141","words":["did","whitney","houston","sing","in","the","preachers","wife"],"labels":["O","B-actor","I-actor","O","O","B-title","I-title","I-title"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, title, review, actor, average ratings, character, song, plot, rating, director, year, trailer and O.\nSentence: did whitney houston sing in the preachers wife","prompt_labels":"did(O) whitney(B-actor) houston(I-actor) sing(O) in(O) the(B-title) preachers(I-title) wife(I-title)"}}
{"dataset":"mit-movie","split":"dev","label_list":["character","actor","director","review","song","genre","rating","title","plot","average ratings","trailer","year"],"instance":{"id":"142","words":["what","techno","thriller","gets","a","low","rating"],"labels":["O","B-genre","O","O","O","B-average ratings","I-average ratings"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, actor, director, review, song, genre, rating, title, plot, average ratings, trailer, year and O.\nSentence: what techno thriller gets a low rating","prompt_labels":"what(O) techno(B-genre) thriller(O) gets(O) a(O) low(B-average ratings) rating(I-average ratings)"}}
{"dataset":"mit-movie","split":"dev","label_list":["plot","actor","review","title","year","average ratings","director","trailer","genre","character","song","rating"],"instance":{"id":"143","words":["any","good","horror","films","that","came","out","in","2008"],"labels":["O","B-review","B-genre","O","O","O","O","O","B-year"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, actor, review, title, year, average ratings, director, trailer, genre, character, song, rating and O.\nSentence: any good horror films that came out in 2008","prompt_labels":"any(O) good(B-review) horror(B-genre) films(O) that(O) came(O) out(O) in(O) 2008(B-year)"}}
{"dataset":"mit-movie","split":"dev","label_list":["genre","average ratings","actor","review","trailer","rating","title","song","director","plot","character","year"],"instance":{"id":"144","words":["where","can","i","watch","a","preview","of","moneyball"],"labels":["O","O","O","O","O","B-trailer","O","B-title"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, average ratings, actor, review, trailer, rating, title, song, director, plot, character, year and O.\nSentence: where can i watch a preview of moneyball","prompt_labels":"where(O) can(O) i(O) watch(O) a(O) preview(B-trailer) of(O) moneyball(B-title)"}}
{"dataset":"mit-movie","split":"dev","label_list":["actor","song","rating","title","genre","character","year","trailer","average ratings","review","plot","director"],"instance":{"id":"145","words":["what","is","the","most","recent","sean","connery","film"],"labels":["O","O","O","B-year","I-year","B-actor","I-actor","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, song, rating, title, genre, character, year, trailer, average ratings, review, plot, director and O.\nSentence: what is the most recent sean connery film","prompt_labels":"what(O) is(O) the(O) most(B-year) recent(I-year) sean(B-actor) connery(I-actor) film(O)"}}
{"dataset":"mit-movie","split":"dev","label_list":["director","year","genre","rating","title","average ratings","plot","review","song","trailer","character","actor"],"instance":{"id":"146","words":["are","there","any","scary","pg","rated","movies"],"labels":["O","O","O","B-genre","B-rating","I-rating","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, year, genre, rating, title, average ratings, plot, review, song, trailer, character, actor and O.\nSentence: are there any scary pg rated movies","prompt_labels":"are(O) there(O) any(O) scary(B-genre) pg(B-rating) rated(I-rating) movies(O)"}}
{"dataset":"mit-movie","split":"dev","label_list":["character","plot","average ratings","actor","director","year","review","song","rating","title","genre","trailer"],"instance":{"id":"147","words":["what","is","a","recent","george","clooney","movie","with","high","viewers","rating"],"labels":["O","O","O","O","B-actor","I-actor","O","O","B-average ratings","I-average ratings","I-average ratings"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, plot, average ratings, actor, director, year, review, song, rating, title, genre, trailer and O.\nSentence: what is a recent george clooney movie with high viewers rating","prompt_labels":"what(O) is(O) a(O) recent(O) george(B-actor) clooney(I-actor) movie(O) with(O) high(B-average ratings) viewers(I-average ratings) rating(I-average ratings)"}}
{"dataset":"mit-movie","split":"dev","label_list":["rating","director","average ratings","song","character","title","actor","review","plot","trailer","year","genre"],"instance":{"id":"148","words":["which","animated","childrens","movies","are","considered","timeless"],"labels":["O","B-genre","I-genre","I-genre","O","B-review","I-review"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, director, average ratings, song, character, title, actor, review, plot, trailer, year, genre and O.\nSentence: which animated childrens movies are considered timeless","prompt_labels":"which(O) animated(B-genre) childrens(I-genre) movies(I-genre) are(O) considered(B-review) timeless(I-review)"}}
{"dataset":"mit-movie","split":"dev","label_list":["genre","rating","average ratings","year","director","review","plot","actor","trailer","character","song","title"],"instance":{"id":"149","words":["find","me","the","movie","with","the","song","my","heart","will","go","on"],"labels":["O","O","O","O","O","O","O","B-song","I-song","I-song","I-song","I-song"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, rating, average ratings, year, director, review, plot, actor, trailer, character, song, title and O.\nSentence: find me the movie with the song my heart will go on","prompt_labels":"find(O) me(O) the(O) movie(O) with(O) the(O) song(O) my(B-song) heart(I-song) will(I-song) go(I-song) on(I-song)"}}
{"dataset":"mit-movie","split":"dev","label_list":["character","title","year","rating","plot","song","director","review","genre","trailer","average ratings","actor"],"instance":{"id":"150","words":["what","are","some","batman","movies","from","the","1990s"],"labels":["O","O","O","B-title","I-title","O","O","B-year"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, title, year, rating, plot, song, director, review, genre, trailer, average ratings, actor and O.\nSentence: what are some batman movies from the 1990s","prompt_labels":"what(O) are(O) some(O) batman(B-title) movies(I-title) from(O) the(O) 1990s(B-year)"}}
{"dataset":"mit-movie","split":"dev","label_list":["genre","character","song","director","trailer","actor","title","rating","plot","average ratings","review","year"],"instance":{"id":"151","words":["what","horror","movies","have","marilyn","manson","on","the","soundtrack"],"labels":["O","B-genre","O","O","B-actor","I-actor","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, character, song, director, trailer, actor, title, rating, plot, average ratings, review, year and O.\nSentence: what horror movies have marilyn manson on the soundtrack","prompt_labels":"what(O) horror(B-genre) movies(O) have(O) marilyn(B-actor) manson(I-actor) on(O) the(O) soundtrack(O)"}}
{"dataset":"mit-movie","split":"dev","label_list":["title","director","genre","review","rating","actor","character","plot","song","average ratings","year","trailer"],"instance":{"id":"152","words":["show","me","terry","gilliam","movies","starring","jeff","bridges"],"labels":["O","O","B-director","I-director","O","O","B-actor","I-actor"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: title, director, genre, review, rating, actor, character, plot, song, average ratings, year, trailer and O.\nSentence: show me terry gilliam movies starring jeff bridges","prompt_labels":"show(O) me(O) terry(B-director) gilliam(I-director) movies(O) starring(O) jeff(B-actor) bridges(I-actor)"}}
{"dataset":"mit-movie","split":"dev","label_list":["average ratings","plot","character","year","song","title","trailer","genre","director","rating","review","actor"],"instance":{"id":"153","words":["was","there","a","trailer","for","bowling","for","columbine"],"labels":["O","O","O","O","O","B-title","I-title","I-title"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: average ratings, plot, character, year, song, title, trailer, genre, director, rating, review, actor and O.\nSentence: was there a trailer for bowling for columbine","prompt_labels":"was(O) there(O) a(O) trailer(O) for(O) bowling(B-title) for(I-title) columbine(I-title)"}}
{"dataset":"mit-movie","split":"dev","label_list":["genre","plot","director","character","rating","title","average ratings","year","review","trailer","actor","song"],"instance":{"id":"154","words":["when","did","interview","with","a","vampire","come","out"],"labels":["O","O","B-title","I-title","I-title","I-title","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, plot, director, character, rating, title, average ratings, year, review, trailer, actor, song and O.\nSentence: when did interview with a vampire come out","prompt_labels":"when(O) did(O) interview(B-title) with(I-title) a(I-title) vampire(I-title) come(O) out(O)"}}
{"dataset":"mit-movie","split":"dev","label_list":["character","trailer","song","director","rating","plot","title","review","average ratings","actor","genre","year"],"instance":{"id":"155","words":["who","starred","in","who","framed","roger","rabbit"],"labels":["O","O","O","B-title","I-title","I-title","I-title"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, trailer, song, director, rating, plot, title, review, average ratings, actor, genre, year and O.\nSentence: who starred in who framed roger rabbit","prompt_labels":"who(O) starred(O) in(O) who(B-title) framed(I-title) roger(I-title) rabbit(I-title)"}}
{"dataset":"mit-movie","split":"dev","label_list":["average ratings","year","review","genre","director","trailer","plot","character","title","actor","rating","song"],"instance":{"id":"156","words":["who","directed","310","to","yuma"],"labels":["O","B-director","B-title","I-title","I-title"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: average ratings, year, review, genre, director, trailer, plot, character, title, actor, rating, song and O.\nSentence: who directed 310 to yuma","prompt_labels":"who(O) directed(B-director) 310(B-title) to(I-title) yuma(I-title)"}}
{"dataset":"mit-movie","split":"dev","label_list":["trailer","actor","director","genre","average ratings","title","song","plot","character","year","review","rating"],"instance":{"id":"157","words":["what","movies","have","batman","and","robin"],"labels":["O","O","O","B-plot","I-plot","I-plot"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: trailer, actor, director, genre, average ratings, title, song, plot, character, year, review, rating and O.\nSentence: what movies have batman and robin","prompt_labels":"what(O) movies(O) have(O) batman(B-plot) and(I-plot) robin(I-plot)"}}
{"dataset":"mit-movie","split":"dev","label_list":["actor","character","year","title","trailer","plot","genre","song","average ratings","director","review","rating"],"instance":{"id":"158","words":["is","there","a","horror","movie","starring","jennifer","lopez"],"labels":["O","O","O","B-genre","O","O","B-actor","I-actor"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, character, year, title, trailer, plot, genre, song, average ratings, director, review, rating and O.\nSentence: is there a horror movie starring jennifer lopez","prompt_labels":"is(O) there(O) a(O) horror(B-genre) movie(O) starring(O) jennifer(B-actor) lopez(I-actor)"}}
{"dataset":"mit-movie","split":"dev","label_list":["title","trailer","rating","character","year","average ratings","director","song","genre","actor","plot","review"],"instance":{"id":"159","words":["did","the","mpaa","give","doubt","a","pg","13","rating"],"labels":["O","O","O","O","B-title","O","B-rating","I-rating","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: title, trailer, rating, character, year, average ratings, director, song, genre, actor, plot, review and O.\nSentence: did the mpaa give doubt a pg 13 rating","prompt_labels":"did(O) the(O) mpaa(O) give(O) doubt(B-title) a(O) pg(B-rating) 13(I-rating) rating(O)"}}
{"dataset":"mit-movie","split":"dev","label_list":["director","actor","rating","title","year","review","plot","character","song","trailer","average ratings","genre"],"instance":{"id":"160","words":["did","vin","diesel","star","in","any","comdedies"],"labels":["O","B-actor","I-actor","O","O","O","B-genre"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, actor, rating, title, year, review, plot, character, song, trailer, average ratings, genre and O.\nSentence: did vin diesel star in any comdedies","prompt_labels":"did(O) vin(B-actor) diesel(I-actor) star(O) in(O) any(O) comdedies(B-genre)"}}
{"dataset":"mit-movie","split":"dev","label_list":["year","trailer","rating","director","genre","actor","average ratings","title","character","plot","review","song"],"instance":{"id":"161","words":["did","ray","liota","direct","any","films"],"labels":["O","B-director","I-director","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: year, trailer, rating, director, genre, actor, average ratings, title, character, plot, review, song and O.\nSentence: did ray liota direct any films","prompt_labels":"did(O) ray(B-director) liota(I-director) direct(O) any(O) films(O)"}}
{"dataset":"mit-movie","split":"dev","label_list":["title","rating","trailer","character","actor","song","director","average ratings","plot","genre","year","review"],"instance":{"id":"162","words":["did","gwyneth","paltrow","play","a","mathematician","in","a","movie","with","anthony","hopkins"],"labels":["O","B-actor","I-actor","O","O","B-plot","O","O","O","O","B-actor","I-actor"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: title, rating, trailer, character, actor, song, director, average ratings, plot, genre, year, review and O.\nSentence: did gwyneth paltrow play a mathematician in a movie with anthony hopkins","prompt_labels":"did(O) gwyneth(B-actor) paltrow(I-actor) play(O) a(O) mathematician(B-plot) in(O) a(O) movie(O) with(O) anthony(B-actor) hopkins(I-actor)"}}
{"dataset":"mit-movie","split":"dev","label_list":["title","genre","plot","director","character","trailer","average ratings","rating","actor","song","review","year"],"instance":{"id":"163","words":["is","there","a","movie","based","on","a","shakespeare","play"],"labels":["O","O","O","O","O","O","O","B-plot","I-plot"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: title, genre, plot, director, character, trailer, average ratings, rating, actor, song, review, year and O.\nSentence: is there a movie based on a shakespeare play","prompt_labels":"is(O) there(O) a(O) movie(O) based(O) on(O) a(O) shakespeare(B-plot) play(I-plot)"}}
{"dataset":"mit-movie","split":"dev","label_list":["song","average ratings","title","actor","character","trailer","rating","year","genre","review","plot","director"],"instance":{"id":"164","words":["find","me","a","movie","with","the","song","lets","hear","it","for","the","boys"],"labels":["O","O","O","O","O","O","O","B-song","I-song","I-song","I-song","I-song","I-song"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, average ratings, title, actor, character, trailer, rating, year, genre, review, plot, director and O.\nSentence: find me a movie with the song lets hear it for the boys","prompt_labels":"find(O) me(O) a(O) movie(O) with(O) the(O) song(O) lets(B-song) hear(I-song) it(I-song) for(I-song) the(I-song) boys(I-song)"}}
{"dataset":"mit-movie","split":"dev","label_list":["title","song","trailer","actor","average ratings","genre","review","character","year","rating","director","plot"],"instance":{"id":"165","words":["what","was","the","fog","rated"],"labels":["O","O","B-title","I-title","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: title, song, trailer, actor, average ratings, genre, review, character, year, rating, director, plot and O.\nSentence: what was the fog rated","prompt_labels":"what(O) was(O) the(B-title) fog(I-title) rated(O)"}}
{"dataset":"mit-movie","split":"dev","label_list":["year","song","genre","rating","character","title","actor","trailer","director","plot","review","average ratings"],"instance":{"id":"166","words":["what","was","johnny","depps","first","movie"],"labels":["O","O","B-actor","I-actor","B-year","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: year, song, genre, rating, character, title, actor, trailer, director, plot, review, average ratings and O.\nSentence: what was johnny depps first movie","prompt_labels":"what(O) was(O) johnny(B-actor) depps(I-actor) first(B-year) movie(O)"}}
{"dataset":"mit-movie","split":"dev","label_list":["rating","year","character","director","plot","genre","average ratings","song","actor","review","trailer","title"],"instance":{"id":"167","words":["what","was","goodfellas","rated"],"labels":["O","O","B-title","B-rating"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, year, character, director, plot, genre, average ratings, song, actor, review, trailer, title and O.\nSentence: what was goodfellas rated","prompt_labels":"what(O) was(O) goodfellas(B-title) rated(B-rating)"}}
{"dataset":"mit-movie","split":"dev","label_list":["title","actor","director","average ratings","rating","plot","song","trailer","character","genre","review","year"],"instance":{"id":"168","words":["what","was","the","name","of","the","donkey","in","shrek"],"labels":["O","O","O","O","O","O","B-character","O","B-title"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: title, actor, director, average ratings, rating, plot, song, trailer, character, genre, review, year and O.\nSentence: what was the name of the donkey in shrek","prompt_labels":"what(O) was(O) the(O) name(O) of(O) the(O) donkey(B-character) in(O) shrek(B-title)"}}
{"dataset":"mit-movie","split":"dev","label_list":["trailer","title","genre","average ratings","plot","character","song","director","actor","year","rating","review"],"instance":{"id":"169","words":["did","joe","pesci","direct","any","films"],"labels":["O","B-director","I-director","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: trailer, title, genre, average ratings, plot, character, song, director, actor, year, rating, review and O.\nSentence: did joe pesci direct any films","prompt_labels":"did(O) joe(B-director) pesci(I-director) direct(O) any(O) films(O)"}}
{"dataset":"mit-movie","split":"dev","label_list":["rating","trailer","review","director","year","plot","character","title","genre","actor","song","average ratings"],"instance":{"id":"170","words":["what","are","some","horror","movies","from","the","1970s"],"labels":["O","O","O","B-genre","O","O","O","B-year"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, trailer, review, director, year, plot, character, title, genre, actor, song, average ratings and O.\nSentence: what are some horror movies from the 1970s","prompt_labels":"what(O) are(O) some(O) horror(B-genre) movies(O) from(O) the(O) 1970s(B-year)"}}
{"dataset":"mit-movie","split":"dev","label_list":["rating","character","plot","year","actor","director","review","average ratings","song","title","trailer","genre"],"instance":{"id":"171","words":["show","me","a","deborah","harry","movie"],"labels":["O","O","O","B-actor","I-actor","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, character, plot, year, actor, director, review, average ratings, song, title, trailer, genre and O.\nSentence: show me a deborah harry movie","prompt_labels":"show(O) me(O) a(O) deborah(B-actor) harry(I-actor) movie(O)"}}
{"dataset":"mit-movie","split":"dev","label_list":["actor","genre","trailer","review","character","year","director","plot","title","average ratings","rating","song"],"instance":{"id":"172","words":["kung","fu","panda","2"],"labels":["B-title","I-title","I-title","I-title"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, genre, trailer, review, character, year, director, plot, title, average ratings, rating, song and O.\nSentence: kung fu panda 2","prompt_labels":"kung(B-title) fu(I-title) panda(I-title) 2(I-title)"}}
{"dataset":"mit-movie","split":"dev","label_list":["title","actor","genre","rating","song","review","director","character","average ratings","plot","year","trailer"],"instance":{"id":"173","words":["what","year","was","the","movie","the","seven","year","itch","made"],"labels":["O","B-year","O","O","O","B-title","I-title","I-title","I-title","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: title, actor, genre, rating, song, review, director, character, average ratings, plot, year, trailer and O.\nSentence: what year was the movie the seven year itch made","prompt_labels":"what(O) year(B-year) was(O) the(O) movie(O) the(B-title) seven(I-title) year(I-title) itch(I-title) made(O)"}}
{"dataset":"mit-movie","split":"dev","label_list":["rating","actor","director","plot","trailer","character","song","average ratings","title","review","year","genre"],"instance":{"id":"174","words":["is","there","a","comedy","crime","drama"],"labels":["O","O","O","B-genre","I-genre","I-genre"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, actor, director, plot, trailer, character, song, average ratings, title, review, year, genre and O.\nSentence: is there a comedy crime drama","prompt_labels":"is(O) there(O) a(O) comedy(B-genre) crime(I-genre) drama(I-genre)"}}
{"dataset":"mit-movie","split":"dev","label_list":["title","genre","trailer","review","year","actor","character","song","plot","rating","director","average ratings"],"instance":{"id":"175","words":["what","movie","stared","john","travolta","and","debra","winger"],"labels":["O","O","O","B-actor","I-actor","O","B-actor","I-actor"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: title, genre, trailer, review, year, actor, character, song, plot, rating, director, average ratings and O.\nSentence: what movie stared john travolta and debra winger","prompt_labels":"what(O) movie(O) stared(O) john(B-actor) travolta(I-actor) and(O) debra(B-actor) winger(I-actor)"}}
{"dataset":"mit-movie","split":"dev","label_list":["year","title","genre","average ratings","character","director","trailer","review","rating","plot","song","actor"],"instance":{"id":"176","words":["directors","of","all","the","batman","movies"],"labels":["O","O","O","O","B-title","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: year, title, genre, average ratings, character, director, trailer, review, rating, plot, song, actor and O.\nSentence: directors of all the batman movies","prompt_labels":"directors(O) of(O) all(O) the(O) batman(B-title) movies(O)"}}
{"dataset":"mit-movie","split":"dev","label_list":["average ratings","title","year","plot","rating","song","genre","trailer","review","director","actor","character"],"instance":{"id":"177","words":["what","are","the","best","werewolf","movies"],"labels":["O","O","O","B-review","B-plot","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: average ratings, title, year, plot, rating, song, genre, trailer, review, director, actor, character and O.\nSentence: what are the best werewolf movies","prompt_labels":"what(O) are(O) the(O) best(B-review) werewolf(B-plot) movies(O)"}}
{"dataset":"mit-movie","split":"dev","label_list":["director","year","genre","review","average ratings","trailer","character","rating","actor","plot","song","title"],"instance":{"id":"178","words":["who","voices","shrek","in","shrek"],"labels":["O","O","B-character","O","B-title"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, year, genre, review, average ratings, trailer, character, rating, actor, plot, song, title and O.\nSentence: who voices shrek in shrek","prompt_labels":"who(O) voices(O) shrek(B-character) in(O) shrek(B-title)"}}
{"dataset":"mit-movie","split":"dev","label_list":["genre","rating","review","year","trailer","title","song","average ratings","character","director","plot","actor"],"instance":{"id":"179","words":["was","ray","liota","in","any","comedies"],"labels":["O","B-actor","I-actor","O","O","B-genre"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, rating, review, year, trailer, title, song, average ratings, character, director, plot, actor and O.\nSentence: was ray liota in any comedies","prompt_labels":"was(O) ray(B-actor) liota(I-actor) in(O) any(O) comedies(B-genre)"}}
{"dataset":"mit-movie","split":"dev","label_list":["rating","average ratings","year","genre","trailer","plot","title","review","song","director","actor","character"],"instance":{"id":"180","words":["what","movie","stars","reese","witherspoon","in","2004"],"labels":["O","O","O","B-actor","I-actor","O","B-year"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, average ratings, year, genre, trailer, plot, title, review, song, director, actor, character and O.\nSentence: what movie stars reese witherspoon in 2004","prompt_labels":"what(O) movie(O) stars(O) reese(B-actor) witherspoon(I-actor) in(O) 2004(B-year)"}}
{"dataset":"mit-movie","split":"dev","label_list":["title","song","trailer","genre","rating","director","plot","average ratings","year","review","character","actor"],"instance":{"id":"181","words":["what","movie","did","ursula","andress","first","appear","in"],"labels":["O","O","O","B-actor","I-actor","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: title, song, trailer, genre, rating, director, plot, average ratings, year, review, character, actor and O.\nSentence: what movie did ursula andress first appear in","prompt_labels":"what(O) movie(O) did(O) ursula(B-actor) andress(I-actor) first(O) appear(O) in(O)"}}
{"dataset":"mit-movie","split":"dev","label_list":["actor","average ratings","title","genre","song","character","plot","review","year","rating","trailer","director"],"instance":{"id":"182","words":["are","there","any","movies","set","in","the","middle","east","starring","george","clooney"],"labels":["O","O","O","O","O","O","O","B-plot","I-plot","O","B-actor","I-actor"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, average ratings, title, genre, song, character, plot, review, year, rating, trailer, director and O.\nSentence: are there any movies set in the middle east starring george clooney","prompt_labels":"are(O) there(O) any(O) movies(O) set(O) in(O) the(O) middle(B-plot) east(I-plot) starring(O) george(B-actor) clooney(I-actor)"}}
{"dataset":"mit-movie","split":"dev","label_list":["genre","title","average ratings","character","year","trailer","song","review","director","rating","plot","actor"],"instance":{"id":"183","words":["what","was","a","love","story","about","a","woman","who","had","alzheimers"],"labels":["O","O","O","B-plot","I-plot","I-plot","I-plot","I-plot","I-plot","I-plot","I-plot"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, title, average ratings, character, year, trailer, song, review, director, rating, plot, actor and O.\nSentence: what was a love story about a woman who had alzheimers","prompt_labels":"what(O) was(O) a(O) love(B-plot) story(I-plot) about(I-plot) a(I-plot) woman(I-plot) who(I-plot) had(I-plot) alzheimers(I-plot)"}}
{"dataset":"mit-movie","split":"dev","label_list":["actor","plot","trailer","rating","year","director","character","average ratings","song","genre","title","review"],"instance":{"id":"184","words":["whats","a","john","huston","flick","from","the","1970s"],"labels":["O","O","B-director","I-director","O","O","O","B-year"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, plot, trailer, rating, year, director, character, average ratings, song, genre, title, review and O.\nSentence: whats a john huston flick from the 1970s","prompt_labels":"whats(O) a(O) john(B-director) huston(I-director) flick(O) from(O) the(O) 1970s(B-year)"}}
{"dataset":"mit-movie","split":"dev","label_list":["plot","title","review","year","song","director","average ratings","genre","character","actor","trailer","rating"],"instance":{"id":"185","words":["who","played","as","princess","fiona","in","shrek"],"labels":["O","O","O","B-character","I-character","O","B-title"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, title, review, year, song, director, average ratings, genre, character, actor, trailer, rating and O.\nSentence: who played as princess fiona in shrek","prompt_labels":"who(O) played(O) as(O) princess(B-character) fiona(I-character) in(O) shrek(B-title)"}}
{"dataset":"mit-movie","split":"dev","label_list":["rating","average ratings","character","actor","title","director","trailer","year","song","plot","genre","review"],"instance":{"id":"186","words":["is","the","last","airbender","rated","g"],"labels":["O","B-title","I-title","I-title","B-rating","I-rating"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, average ratings, character, actor, title, director, trailer, year, song, plot, genre, review and O.\nSentence: is the last airbender rated g","prompt_labels":"is(O) the(B-title) last(I-title) airbender(I-title) rated(B-rating) g(I-rating)"}}
{"dataset":"mit-movie","split":"dev","label_list":["genre","trailer","plot","rating","character","director","actor","year","song","title","average ratings","review"],"instance":{"id":"187","words":["show","me","some","grat","action","movies","from","the","90s"],"labels":["O","O","O","O","B-genre","I-genre","O","O","B-year"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, trailer, plot, rating, character, director, actor, year, song, title, average ratings, review and O.\nSentence: show me some grat action movies from the 90s","prompt_labels":"show(O) me(O) some(O) grat(O) action(B-genre) movies(I-genre) from(O) the(O) 90s(B-year)"}}
{"dataset":"mit-movie","split":"dev","label_list":["director","title","rating","song","character","year","plot","actor","trailer","average ratings","review","genre"],"instance":{"id":"188","words":["show","me","dramas","about","the","british","royal","family"],"labels":["O","O","B-genre","O","O","B-plot","I-plot","I-plot"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, title, rating, song, character, year, plot, actor, trailer, average ratings, review, genre and O.\nSentence: show me dramas about the british royal family","prompt_labels":"show(O) me(O) dramas(B-genre) about(O) the(O) british(B-plot) royal(I-plot) family(I-plot)"}}
{"dataset":"mit-movie","split":"dev","label_list":["rating","song","character","director","plot","title","review","trailer","actor","average ratings","genre","year"],"instance":{"id":"189","words":["what","was","the","first","movie","ever","released"],"labels":["O","O","O","B-year","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, song, character, director, plot, title, review, trailer, actor, average ratings, genre, year and O.\nSentence: what was the first movie ever released","prompt_labels":"what(O) was(O) the(O) first(B-year) movie(O) ever(O) released(O)"}}
{"dataset":"mit-movie","split":"dev","label_list":["director","rating","song","title","actor","plot","character","average ratings","year","trailer","review","genre"],"instance":{"id":"190","words":["are","there","any","movies","with","catherine","ohara","that","were","set","during","christmas","time"],"labels":["O","O","O","O","O","B-actor","I-actor","O","O","B-plot","I-plot","I-plot","I-plot"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, rating, song, title, actor, plot, character, average ratings, year, trailer, review, genre and O.\nSentence: are there any movies with catherine ohara that were set during christmas time","prompt_labels":"are(O) there(O) any(O) movies(O) with(O) catherine(B-actor) ohara(I-actor) that(O) were(O) set(B-plot) during(I-plot) christmas(I-plot) time(I-plot)"}}
{"dataset":"mit-movie","split":"dev","label_list":["average ratings","year","title","song","actor","rating","character","director","plot","genre","review","trailer"],"instance":{"id":"191","words":["show","me","a","james","bond","movie","starring","sean","connery"],"labels":["O","O","O","B-character","I-character","O","O","B-actor","I-actor"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: average ratings, year, title, song, actor, rating, character, director, plot, genre, review, trailer and O.\nSentence: show me a james bond movie starring sean connery","prompt_labels":"show(O) me(O) a(O) james(B-character) bond(I-character) movie(O) starring(O) sean(B-actor) connery(I-actor)"}}
{"dataset":"mit-movie","split":"dev","label_list":["rating","actor","year","average ratings","title","director","plot","trailer","genre","review","character","song"],"instance":{"id":"192","words":["what","was","the","title","of","the","bio","pic","about","robert","e","howard"],"labels":["O","O","O","O","O","O","O","O","O","B-actor","I-actor","I-actor"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, actor, year, average ratings, title, director, plot, trailer, genre, review, character, song and O.\nSentence: what was the title of the bio pic about robert e howard","prompt_labels":"what(O) was(O) the(O) title(O) of(O) the(O) bio(O) pic(O) about(O) robert(B-actor) e(I-actor) howard(I-actor)"}}
{"dataset":"mit-movie","split":"dev","label_list":["genre","review","average ratings","director","trailer","actor","character","song","rating","year","plot","title"],"instance":{"id":"193","words":["what","is","the","theme","song","to","stand","by","me"],"labels":["O","O","O","O","O","O","B-title","I-title","I-title"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, review, average ratings, director, trailer, actor, character, song, rating, year, plot, title and O.\nSentence: what is the theme song to stand by me","prompt_labels":"what(O) is(O) the(O) theme(O) song(O) to(O) stand(B-title) by(I-title) me(I-title)"}}
{"dataset":"mit-movie","split":"dev","label_list":["average ratings","genre","title","trailer","year","director","character","song","plot","review","rating","actor"],"instance":{"id":"194","words":["when","did","runaway","jury","come","out"],"labels":["O","O","B-title","I-title","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: average ratings, genre, title, trailer, year, director, character, song, plot, review, rating, actor and O.\nSentence: when did runaway jury come out","prompt_labels":"when(O) did(O) runaway(B-title) jury(I-title) come(O) out(O)"}}
{"dataset":"mit-movie","split":"dev","label_list":["genre","director","title","actor","plot","average ratings","review","year","trailer","song","character","rating"],"instance":{"id":"195","words":["who","directed","the","japanese","film","versus"],"labels":["O","O","O","O","O","B-title"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, director, title, actor, plot, average ratings, review, year, trailer, song, character, rating and O.\nSentence: who directed the japanese film versus","prompt_labels":"who(O) directed(O) the(O) japanese(O) film(O) versus(B-title)"}}
{"dataset":"mit-movie","split":"dev","label_list":["rating","genre","song","character","title","year","plot","review","actor","director","average ratings","trailer"],"instance":{"id":"196","words":["show","me","a","film","that","ben","stiller","directed"],"labels":["O","O","O","O","O","B-director","I-director","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, genre, song, character, title, year, plot, review, actor, director, average ratings, trailer and O.\nSentence: show me a film that ben stiller directed","prompt_labels":"show(O) me(O) a(O) film(O) that(O) ben(B-director) stiller(I-director) directed(O)"}}
{"dataset":"mit-movie","split":"dev","label_list":["rating","actor","director","title","review","year","plot","song","genre","average ratings","trailer","character"],"instance":{"id":"197","words":["name","a","kirk","douglas","science","fiction","film"],"labels":["O","O","B-actor","I-actor","B-genre","I-genre","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, actor, director, title, review, year, plot, song, genre, average ratings, trailer, character and O.\nSentence: name a kirk douglas science fiction film","prompt_labels":"name(O) a(O) kirk(B-actor) douglas(I-actor) science(B-genre) fiction(I-genre) film(O)"}}
{"dataset":"mit-movie","split":"dev","label_list":["review","actor","character","year","song","average ratings","trailer","rating","title","director","genre","plot"],"instance":{"id":"198","words":["are","there","any","five","star","kevin","bacon","movies"],"labels":["O","O","O","B-average ratings","I-average ratings","B-actor","I-actor","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, actor, character, year, song, average ratings, trailer, rating, title, director, genre, plot and O.\nSentence: are there any five star kevin bacon movies","prompt_labels":"are(O) there(O) any(O) five(B-average ratings) star(I-average ratings) kevin(B-actor) bacon(I-actor) movies(O)"}}
{"dataset":"mit-movie","split":"dev","label_list":["plot","trailer","year","title","rating","song","genre","director","review","average ratings","character","actor"],"instance":{"id":"199","words":["who","stars","in","the","girl","with","the","dragon","tattoo"],"labels":["O","O","O","O","B-title","I-title","I-title","I-title","I-title"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, trailer, year, title, rating, song, genre, director, review, average ratings, character, actor and O.\nSentence: who stars in the girl with the dragon tattoo","prompt_labels":"who(O) stars(O) in(O) the(O) girl(B-title) with(I-title) the(I-title) dragon(I-title) tattoo(I-title)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Rating","Amenity","Price","Location","Restaurant Name","Hours","Dish","Cuisine"],"instance":{"id":"0","words":["a","four","star","restaurant","with","a","bar"],"labels":["O","B-Rating","I-Rating","O","B-Location","I-Location","B-Amenity"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Rating, Amenity, Price, Location, Restaurant Name, Hours, Dish, Cuisine and O.\nSentence: a four star restaurant with a bar","prompt_labels":"a(O) four(B-Rating) star(I-Rating) restaurant(O) with(B-Location) a(I-Location) bar(B-Amenity)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Price","Cuisine","Hours","Amenity","Restaurant Name","Location","Rating","Dish"],"instance":{"id":"1","words":["any","asian","cuisine","around"],"labels":["O","B-Cuisine","O","B-Location"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Cuisine, Hours, Amenity, Restaurant Name, Location, Rating, Dish and O.\nSentence: any asian cuisine around","prompt_labels":"any(O) asian(B-Cuisine) cuisine(O) around(B-Location)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Dish","Hours","Restaurant Name","Price","Amenity","Rating","Cuisine","Location"],"instance":{"id":"2","words":["any","bbq","places","open","before","5","nearby"],"labels":["O","B-Cuisine","O","B-Hours","I-Hours","I-Hours","B-Location"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Dish, Hours, Restaurant Name, Price, Amenity, Rating, Cuisine, Location and O.\nSentence: any bbq places open before 5 nearby","prompt_labels":"any(O) bbq(B-Cuisine) places(O) open(B-Hours) before(I-Hours) 5(I-Hours) nearby(B-Location)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Rating","Hours","Location","Cuisine","Price","Restaurant Name","Amenity","Dish"],"instance":{"id":"3","words":["any","dancing","establishments","with","reasonable","pricing"],"labels":["O","B-Location","I-Location","O","B-Price","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Rating, Hours, Location, Cuisine, Price, Restaurant Name, Amenity, Dish and O.\nSentence: any dancing establishments with reasonable pricing","prompt_labels":"any(O) dancing(B-Location) establishments(I-Location) with(O) reasonable(B-Price) pricing(O)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Dish","Amenity","Cuisine","Price","Location","Rating","Restaurant Name","Hours"],"instance":{"id":"4","words":["any","good","cheap","german","restaurants","nearby"],"labels":["O","O","B-Price","B-Cuisine","O","B-Location"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Dish, Amenity, Cuisine, Price, Location, Rating, Restaurant Name, Hours and O.\nSentence: any good cheap german restaurants nearby","prompt_labels":"any(O) good(O) cheap(B-Price) german(B-Cuisine) restaurants(O) nearby(B-Location)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Cuisine","Dish","Restaurant Name","Hours","Price","Location","Rating","Amenity"],"instance":{"id":"5","words":["any","good","ice","cream","parlors","around"],"labels":["O","B-Rating","B-Cuisine","I-Cuisine","I-Cuisine","B-Location"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Dish, Restaurant Name, Hours, Price, Location, Rating, Amenity and O.\nSentence: any good ice cream parlors around","prompt_labels":"any(O) good(B-Rating) ice(B-Cuisine) cream(I-Cuisine) parlors(I-Cuisine) around(B-Location)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Restaurant Name","Hours","Cuisine","Price","Rating","Amenity","Dish","Location"],"instance":{"id":"6","words":["any","good","place","to","get","a","pie","at","an","affordable","price"],"labels":["O","B-Rating","O","O","O","O","B-Dish","O","O","B-Price","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Hours, Cuisine, Price, Rating, Amenity, Dish, Location and O.\nSentence: any good place to get a pie at an affordable price","prompt_labels":"any(O) good(B-Rating) place(O) to(O) get(O) a(O) pie(B-Dish) at(O) an(O) affordable(B-Price) price(O)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Price","Cuisine","Hours","Location","Dish","Rating","Restaurant Name","Amenity"],"instance":{"id":"7","words":["any","good","vegan","spots","nearby"],"labels":["O","O","B-Cuisine","O","B-Location"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Cuisine, Hours, Location, Dish, Rating, Restaurant Name, Amenity and O.\nSentence: any good vegan spots nearby","prompt_labels":"any(O) good(O) vegan(B-Cuisine) spots(O) nearby(B-Location)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Dish","Rating","Location","Restaurant Name","Hours","Cuisine","Amenity","Price"],"instance":{"id":"8","words":["any","mexican","places","have","a","tameles","special","today"],"labels":["O","B-Cuisine","O","O","O","B-Dish","B-Amenity","I-Amenity"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Dish, Rating, Location, Restaurant Name, Hours, Cuisine, Amenity, Price and O.\nSentence: any mexican places have a tameles special today","prompt_labels":"any(O) mexican(B-Cuisine) places(O) have(O) a(O) tameles(B-Dish) special(B-Amenity) today(I-Amenity)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Hours","Location","Rating","Restaurant Name","Dish","Cuisine","Amenity","Price"],"instance":{"id":"9","words":["any","place","along","the","road","has","a","good","beer","selection","that","also","serves","ribs"],"labels":["O","O","B-Location","I-Location","I-Location","O","O","B-Rating","B-Dish","O","O","O","O","B-Dish"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Location, Rating, Restaurant Name, Dish, Cuisine, Amenity, Price and O.\nSentence: any place along the road has a good beer selection that also serves ribs","prompt_labels":"any(O) place(O) along(B-Location) the(I-Location) road(I-Location) has(O) a(O) good(B-Rating) beer(B-Dish) selection(O) that(O) also(O) serves(O) ribs(B-Dish)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Price","Cuisine","Location","Amenity","Rating","Hours","Restaurant Name","Dish"],"instance":{"id":"10","words":["any","places","around","here","that","has","a","nice","view"],"labels":["O","O","B-Location","I-Location","O","O","O","B-Amenity","I-Amenity"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Cuisine, Location, Amenity, Rating, Hours, Restaurant Name, Dish and O.\nSentence: any places around here that has a nice view","prompt_labels":"any(O) places(O) around(B-Location) here(I-Location) that(O) has(O) a(O) nice(B-Amenity) view(I-Amenity)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Hours","Rating","Location","Amenity","Price","Restaurant Name","Cuisine","Dish"],"instance":{"id":"11","words":["any","reasonably","priced","indian","restaurants","in","the","theater","district"],"labels":["O","B-Price","O","B-Cuisine","O","B-Location","I-Location","I-Location","I-Location"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Rating, Location, Amenity, Price, Restaurant Name, Cuisine, Dish and O.\nSentence: any reasonably priced indian restaurants in the theater district","prompt_labels":"any(O) reasonably(B-Price) priced(O) indian(B-Cuisine) restaurants(O) in(B-Location) the(I-Location) theater(I-Location) district(I-Location)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Restaurant Name","Price","Amenity","Location","Dish","Cuisine","Rating","Hours"],"instance":{"id":"12","words":["any","restaurants","open","right","now"],"labels":["O","O","B-Hours","I-Hours","I-Hours"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Price, Amenity, Location, Dish, Cuisine, Rating, Hours and O.\nSentence: any restaurants open right now","prompt_labels":"any(O) restaurants(O) open(B-Hours) right(I-Hours) now(I-Hours)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Cuisine","Amenity","Price","Dish","Rating","Location","Restaurant Name","Hours"],"instance":{"id":"13","words":["any","restaurants","that","still","allow","smoking"],"labels":["O","O","O","O","O","B-Amenity"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Amenity, Price, Dish, Rating, Location, Restaurant Name, Hours and O.\nSentence: any restaurants that still allow smoking","prompt_labels":"any(O) restaurants(O) that(O) still(O) allow(O) smoking(B-Amenity)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Rating","Hours","Price","Cuisine","Dish","Amenity","Restaurant Name","Location"],"instance":{"id":"14","words":["any","stores","around","where","i","could","buy","a","pasta","dish","where","the","prices","are","not","too","high"],"labels":["O","O","B-Location","O","O","O","O","O","B-Dish","O","O","O","B-Price","I-Price","I-Price","I-Price","I-Price"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Rating, Hours, Price, Cuisine, Dish, Amenity, Restaurant Name, Location and O.\nSentence: any stores around where i could buy a pasta dish where the prices are not too high","prompt_labels":"any(O) stores(O) around(B-Location) where(O) i(O) could(O) buy(O) a(O) pasta(B-Dish) dish(O) where(O) the(O) prices(B-Price) are(I-Price) not(I-Price) too(I-Price) high(I-Price)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Dish","Cuisine","Restaurant Name","Amenity","Rating","Hours","Location","Price"],"instance":{"id":"15","words":["anything","on","the","avenue"],"labels":["O","O","O","B-Location"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Dish, Cuisine, Restaurant Name, Amenity, Rating, Hours, Location, Price and O.\nSentence: anything on the avenue","prompt_labels":"anything(O) on(O) the(O) avenue(B-Location)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Rating","Dish","Hours","Location","Price","Cuisine","Amenity","Restaurant Name"],"instance":{"id":"16","words":["anything","open","after","midnight","with","reasonable","prices"],"labels":["O","B-Hours","I-Hours","I-Hours","O","B-Price","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Rating, Dish, Hours, Location, Price, Cuisine, Amenity, Restaurant Name and O.\nSentence: anything open after midnight with reasonable prices","prompt_labels":"anything(O) open(B-Hours) after(I-Hours) midnight(I-Hours) with(O) reasonable(B-Price) prices(O)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Location","Amenity","Dish","Cuisine","Price","Restaurant Name","Rating","Hours"],"instance":{"id":"17","words":["are","children","allowed","in","this","particular","sitting","area"],"labels":["O","B-Amenity","O","O","O","O","B-Amenity","I-Amenity"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Location, Amenity, Dish, Cuisine, Price, Restaurant Name, Rating, Hours and O.\nSentence: are children allowed in this particular sitting area","prompt_labels":"are(O) children(B-Amenity) allowed(O) in(O) this(O) particular(O) sitting(B-Amenity) area(I-Amenity)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Hours","Restaurant Name","Amenity","Rating","Dish","Location","Cuisine","Price"],"instance":{"id":"18","words":["are","reservations","available","for","four","people","for","8","pm","tonight","at","112","eatery"],"labels":["O","O","O","O","O","O","O","O","O","O","O","B-Restaurant Name","I-Restaurant Name"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Restaurant Name, Amenity, Rating, Dish, Location, Cuisine, Price and O.\nSentence: are reservations available for four people for 8 pm tonight at 112 eatery","prompt_labels":"are(O) reservations(O) available(O) for(O) four(O) people(O) for(O) 8(O) pm(O) tonight(O) at(O) 112(B-Restaurant Name) eatery(I-Restaurant Name)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Price","Location","Cuisine","Rating","Restaurant Name","Hours","Dish","Amenity"],"instance":{"id":"19","words":["are","the","portion","at","le","bec","fin","large","or","very","small"],"labels":["O","O","O","O","B-Restaurant Name","I-Restaurant Name","I-Restaurant Name","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Location, Cuisine, Rating, Restaurant Name, Hours, Dish, Amenity and O.\nSentence: are the portion at le bec fin large or very small","prompt_labels":"are(O) the(O) portion(O) at(O) le(B-Restaurant Name) bec(I-Restaurant Name) fin(I-Restaurant Name) large(O) or(O) very(O) small(O)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Amenity","Price","Hours","Rating","Cuisine","Location","Dish","Restaurant Name"],"instance":{"id":"20","words":["are","there","any","24","hour","breakfast","places","nearby"],"labels":["O","O","O","B-Hours","I-Hours","B-Cuisine","O","B-Location"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Price, Hours, Rating, Cuisine, Location, Dish, Restaurant Name and O.\nSentence: are there any 24 hour breakfast places nearby","prompt_labels":"are(O) there(O) any(O) 24(B-Hours) hour(I-Hours) breakfast(B-Cuisine) places(O) nearby(B-Location)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Price","Cuisine","Dish","Location","Hours","Restaurant Name","Amenity","Rating"],"instance":{"id":"21","words":["are","there","any","50s","style","diners","in","glendale"],"labels":["O","O","O","B-Amenity","I-Amenity","B-Cuisine","O","B-Location"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Cuisine, Dish, Location, Hours, Restaurant Name, Amenity, Rating and O.\nSentence: are there any 50s style diners in glendale","prompt_labels":"are(O) there(O) any(O) 50s(B-Amenity) style(I-Amenity) diners(B-Cuisine) in(O) glendale(B-Location)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Rating","Amenity","Dish","Location","Price","Restaurant Name","Cuisine","Hours"],"instance":{"id":"22","words":["are","there","any","authentic","mexican","restaurants","in","the","area"],"labels":["O","O","O","B-Cuisine","I-Cuisine","O","B-Location","I-Location","I-Location"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Rating, Amenity, Dish, Location, Price, Restaurant Name, Cuisine, Hours and O.\nSentence: are there any authentic mexican restaurants in the area","prompt_labels":"are(O) there(O) any(O) authentic(B-Cuisine) mexican(I-Cuisine) restaurants(O) in(B-Location) the(I-Location) area(I-Location)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Cuisine","Amenity","Restaurant Name","Hours","Price","Rating","Location","Dish"],"instance":{"id":"23","words":["are","there","any","bars","nearby","that","serve","food","like","italian","or","french"],"labels":["O","O","O","B-Cuisine","B-Location","O","O","O","O","B-Cuisine","O","B-Cuisine"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Amenity, Restaurant Name, Hours, Price, Rating, Location, Dish and O.\nSentence: are there any bars nearby that serve food like italian or french","prompt_labels":"are(O) there(O) any(O) bars(B-Cuisine) nearby(B-Location) that(O) serve(O) food(O) like(O) italian(B-Cuisine) or(O) french(B-Cuisine)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Price","Dish","Rating","Restaurant Name","Amenity","Hours","Cuisine","Location"],"instance":{"id":"24","words":["are","there","any","brewpubs","downtown"],"labels":["O","O","O","B-Cuisine","B-Location"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Dish, Rating, Restaurant Name, Amenity, Hours, Cuisine, Location and O.\nSentence: are there any brewpubs downtown","prompt_labels":"are(O) there(O) any(O) brewpubs(B-Cuisine) downtown(B-Location)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Restaurant Name","Price","Location","Hours","Amenity","Dish","Cuisine","Rating"],"instance":{"id":"25","words":["are","there","any","cafeterias","near"],"labels":["O","O","O","B-Cuisine","B-Location"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Price, Location, Hours, Amenity, Dish, Cuisine, Rating and O.\nSentence: are there any cafeterias near","prompt_labels":"are(O) there(O) any(O) cafeterias(B-Cuisine) near(B-Location)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Location","Cuisine","Price","Rating","Dish","Restaurant Name","Amenity","Hours"],"instance":{"id":"26","words":["are","there","any","charlestown","restaurants","open","very","early","for","lunch"],"labels":["O","O","O","B-Location","O","B-Hours","I-Hours","I-Hours","O","B-Hours"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Location, Cuisine, Price, Rating, Dish, Restaurant Name, Amenity, Hours and O.\nSentence: are there any charlestown restaurants open very early for lunch","prompt_labels":"are(O) there(O) any(O) charlestown(B-Location) restaurants(O) open(B-Hours) very(I-Hours) early(I-Hours) for(O) lunch(B-Hours)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Restaurant Name","Hours","Location","Price","Amenity","Dish","Cuisine","Rating"],"instance":{"id":"27","words":["are","there","any","chick","fil","as","in","the","city","open","on","sunday"],"labels":["O","O","O","B-Restaurant Name","I-Restaurant Name","I-Restaurant Name","B-Location","I-Location","I-Location","O","O","B-Hours"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Hours, Location, Price, Amenity, Dish, Cuisine, Rating and O.\nSentence: are there any chick fil as in the city open on sunday","prompt_labels":"are(O) there(O) any(O) chick(B-Restaurant Name) fil(I-Restaurant Name) as(I-Restaurant Name) in(B-Location) the(I-Location) city(I-Location) open(O) on(O) sunday(B-Hours)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Rating","Restaurant Name","Location","Price","Amenity","Cuisine","Dish","Hours"],"instance":{"id":"28","words":["are","there","any","chicken","wing","places","nearby"],"labels":["O","O","O","B-Dish","I-Dish","O","B-Location"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Rating, Restaurant Name, Location, Price, Amenity, Cuisine, Dish, Hours and O.\nSentence: are there any chicken wing places nearby","prompt_labels":"are(O) there(O) any(O) chicken(B-Dish) wing(I-Dish) places(O) nearby(B-Location)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Hours","Restaurant Name","Amenity","Rating","Price","Dish","Location","Cuisine"],"instance":{"id":"29","words":["are","there","any","child","friendly","restaurants","within","ten","miles"],"labels":["O","O","O","B-Amenity","I-Amenity","O","B-Location","I-Location","I-Location"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Restaurant Name, Amenity, Rating, Price, Dish, Location, Cuisine and O.\nSentence: are there any child friendly restaurants within ten miles","prompt_labels":"are(O) there(O) any(O) child(B-Amenity) friendly(I-Amenity) restaurants(O) within(B-Location) ten(I-Location) miles(I-Location)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Price","Rating","Hours","Location","Amenity","Dish","Restaurant Name","Cuisine"],"instance":{"id":"30","words":["are","there","any","chinese","restaurants","near","cheyenne"],"labels":["O","O","O","B-Cuisine","O","B-Location","I-Location"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Rating, Hours, Location, Amenity, Dish, Restaurant Name, Cuisine and O.\nSentence: are there any chinese restaurants near cheyenne","prompt_labels":"are(O) there(O) any(O) chinese(B-Cuisine) restaurants(O) near(B-Location) cheyenne(I-Location)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Location","Amenity","Restaurant Name","Cuisine","Hours","Dish","Rating","Price"],"instance":{"id":"31","words":["are","there","any","crab","restaurants","near","here","that","are","open","late","until","2","a","m"],"labels":["O","O","O","B-Cuisine","O","O","O","O","O","B-Hours","I-Hours","I-Hours","I-Hours","I-Hours","I-Hours"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Location, Amenity, Restaurant Name, Cuisine, Hours, Dish, Rating, Price and O.\nSentence: are there any crab restaurants near here that are open late until 2 a m","prompt_labels":"are(O) there(O) any(O) crab(B-Cuisine) restaurants(O) near(O) here(O) that(O) are(O) open(B-Hours) late(I-Hours) until(I-Hours) 2(I-Hours) a(I-Hours) m(I-Hours)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Rating","Hours","Cuisine","Dish","Price","Restaurant Name","Location","Amenity"],"instance":{"id":"32","words":["are","there","any","dining","specials","at","le","bec","fin"],"labels":["O","O","O","O","B-Amenity","O","B-Restaurant Name","I-Restaurant Name","I-Restaurant Name"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Rating, Hours, Cuisine, Dish, Price, Restaurant Name, Location, Amenity and O.\nSentence: are there any dining specials at le bec fin","prompt_labels":"are(O) there(O) any(O) dining(O) specials(B-Amenity) at(O) le(B-Restaurant Name) bec(I-Restaurant Name) fin(I-Restaurant Name)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Hours","Restaurant Name","Location","Price","Dish","Amenity","Cuisine","Rating"],"instance":{"id":"33","words":["are","there","any","donut","and","donuts","within","5","minutes","drive","that","has","an","extensive","beer","menu"],"labels":["O","O","O","B-Restaurant Name","I-Restaurant Name","I-Restaurant Name","B-Location","I-Location","I-Location","I-Location","O","O","O","B-Amenity","I-Amenity","I-Amenity"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Restaurant Name, Location, Price, Dish, Amenity, Cuisine, Rating and O.\nSentence: are there any donut and donuts within 5 minutes drive that has an extensive beer menu","prompt_labels":"are(O) there(O) any(O) donut(B-Restaurant Name) and(I-Restaurant Name) donuts(I-Restaurant Name) within(B-Location) 5(I-Location) minutes(I-Location) drive(I-Location) that(O) has(O) an(O) extensive(B-Amenity) beer(I-Amenity) menu(I-Amenity)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Price","Dish","Rating","Amenity","Cuisine","Restaurant Name","Hours","Location"],"instance":{"id":"34","words":["are","there","any","eatery","at","the","hotel","downtown"],"labels":["O","O","O","O","O","O","B-Location","I-Location"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Dish, Rating, Amenity, Cuisine, Restaurant Name, Hours, Location and O.\nSentence: are there any eatery at the hotel downtown","prompt_labels":"are(O) there(O) any(O) eatery(O) at(O) the(O) hotel(B-Location) downtown(I-Location)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Dish","Cuisine","Amenity","Hours","Restaurant Name","Location","Price","Rating"],"instance":{"id":"35","words":["are","there","any","exciting","joints","along","the","way","thats","reasonably","priced"],"labels":["O","O","O","B-Amenity","O","B-Location","I-Location","I-Location","O","B-Price","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Dish, Cuisine, Amenity, Hours, Restaurant Name, Location, Price, Rating and O.\nSentence: are there any exciting joints along the way thats reasonably priced","prompt_labels":"are(O) there(O) any(O) exciting(B-Amenity) joints(O) along(B-Location) the(I-Location) way(I-Location) thats(O) reasonably(B-Price) priced(O)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Cuisine","Location","Price","Rating","Restaurant Name","Dish","Amenity","Hours"],"instance":{"id":"36","words":["are","there","any","fancy","cambodian","places","on","seaver","street"],"labels":["O","O","O","B-Amenity","B-Cuisine","O","O","B-Location","I-Location"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Location, Price, Rating, Restaurant Name, Dish, Amenity, Hours and O.\nSentence: are there any fancy cambodian places on seaver street","prompt_labels":"are(O) there(O) any(O) fancy(B-Amenity) cambodian(B-Cuisine) places(O) on(O) seaver(B-Location) street(I-Location)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Dish","Rating","Restaurant Name","Location","Amenity","Price","Cuisine","Hours"],"instance":{"id":"37","words":["are","there","any","fast","food","joints","east","of","here"],"labels":["O","O","O","B-Cuisine","I-Cuisine","O","B-Location","I-Location","I-Location"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Dish, Rating, Restaurant Name, Location, Amenity, Price, Cuisine, Hours and O.\nSentence: are there any fast food joints east of here","prompt_labels":"are(O) there(O) any(O) fast(B-Cuisine) food(I-Cuisine) joints(O) east(B-Location) of(I-Location) here(I-Location)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Hours","Price","Dish","Restaurant Name","Amenity","Cuisine","Location","Rating"],"instance":{"id":"38","words":["are","there","any","fast","food","restaurants","that","are","kid","friendly"],"labels":["O","O","O","B-Cuisine","I-Cuisine","O","O","O","B-Amenity","I-Amenity"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Price, Dish, Restaurant Name, Amenity, Cuisine, Location, Rating and O.\nSentence: are there any fast food restaurants that are kid friendly","prompt_labels":"are(O) there(O) any(O) fast(B-Cuisine) food(I-Cuisine) restaurants(O) that(O) are(O) kid(B-Amenity) friendly(I-Amenity)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Location","Dish","Hours","Cuisine","Amenity","Rating","Restaurant Name","Price"],"instance":{"id":"39","words":["are","there","any","fine","dining","options","within","5","miles","of","my","location"],"labels":["O","O","O","B-Amenity","I-Amenity","O","B-Location","I-Location","I-Location","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Location, Dish, Hours, Cuisine, Amenity, Rating, Restaurant Name, Price and O.\nSentence: are there any fine dining options within 5 miles of my location","prompt_labels":"are(O) there(O) any(O) fine(B-Amenity) dining(I-Amenity) options(O) within(B-Location) 5(I-Location) miles(I-Location) of(O) my(O) location(O)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Restaurant Name","Amenity","Hours","Location","Dish","Cuisine","Rating","Price"],"instance":{"id":"40","words":["are","there","any","five","star","restaurants","around","here"],"labels":["O","O","O","B-Rating","I-Rating","O","B-Location","I-Location"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Amenity, Hours, Location, Dish, Cuisine, Rating, Price and O.\nSentence: are there any five star restaurants around here","prompt_labels":"are(O) there(O) any(O) five(B-Rating) star(I-Rating) restaurants(O) around(B-Location) here(I-Location)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Hours","Location","Amenity","Restaurant Name","Cuisine","Price","Dish","Rating"],"instance":{"id":"41","words":["are","there","any","four","star","restaurants","in","this","town"],"labels":["O","O","O","B-Rating","I-Rating","O","O","O","B-Location"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Location, Amenity, Restaurant Name, Cuisine, Price, Dish, Rating and O.\nSentence: are there any four star restaurants in this town","prompt_labels":"are(O) there(O) any(O) four(B-Rating) star(I-Rating) restaurants(O) in(O) this(O) town(B-Location)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Hours","Cuisine","Rating","Dish","Location","Restaurant Name","Amenity","Price"],"instance":{"id":"42","words":["are","there","any","fun","restaurants","serving","brisket","in","town"],"labels":["O","O","O","B-Amenity","O","O","B-Dish","B-Location","I-Location"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Cuisine, Rating, Dish, Location, Restaurant Name, Amenity, Price and O.\nSentence: are there any fun restaurants serving brisket in town","prompt_labels":"are(O) there(O) any(O) fun(B-Amenity) restaurants(O) serving(O) brisket(B-Dish) in(B-Location) town(I-Location)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Rating","Price","Cuisine","Hours","Location","Dish","Amenity","Restaurant Name"],"instance":{"id":"43","words":["are","there","any","good","family","style","restaurants","around","boston"],"labels":["O","O","O","O","B-Amenity","I-Amenity","O","B-Location","I-Location"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Rating, Price, Cuisine, Hours, Location, Dish, Amenity, Restaurant Name and O.\nSentence: are there any good family style restaurants around boston","prompt_labels":"are(O) there(O) any(O) good(O) family(B-Amenity) style(I-Amenity) restaurants(O) around(B-Location) boston(I-Location)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Amenity","Restaurant Name","Location","Cuisine","Rating","Hours","Price","Dish"],"instance":{"id":"44","words":["are","there","any","good","soul","food","restaurants","near","by"],"labels":["O","O","O","B-Rating","B-Cuisine","O","O","B-Location","I-Location"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Restaurant Name, Location, Cuisine, Rating, Hours, Price, Dish and O.\nSentence: are there any good soul food restaurants near by","prompt_labels":"are(O) there(O) any(O) good(B-Rating) soul(B-Cuisine) food(O) restaurants(O) near(B-Location) by(I-Location)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Rating","Price","Hours","Amenity","Dish","Cuisine","Location","Restaurant Name"],"instance":{"id":"45","words":["are","there","any","greek","restaurants","in","the","area"],"labels":["O","O","O","B-Cuisine","O","B-Location","I-Location","I-Location"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Rating, Price, Hours, Amenity, Dish, Cuisine, Location, Restaurant Name and O.\nSentence: are there any greek restaurants in the area","prompt_labels":"are(O) there(O) any(O) greek(B-Cuisine) restaurants(O) in(B-Location) the(I-Location) area(I-Location)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Hours","Price","Cuisine","Dish","Rating","Restaurant Name","Amenity","Location"],"instance":{"id":"46","words":["are","there","any","greek","restaurants","in","the","theater","district","of","the","back","bay"],"labels":["O","O","O","B-Cuisine","O","O","O","B-Location","I-Location","O","O","B-Location","I-Location"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Price, Cuisine, Dish, Rating, Restaurant Name, Amenity, Location and O.\nSentence: are there any greek restaurants in the theater district of the back bay","prompt_labels":"are(O) there(O) any(O) greek(B-Cuisine) restaurants(O) in(O) the(O) theater(B-Location) district(I-Location) of(O) the(O) back(B-Location) bay(I-Location)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Cuisine","Dish","Price","Amenity","Hours","Location","Restaurant Name","Rating"],"instance":{"id":"47","words":["are","there","any","hamburger","restaurants","close","by"],"labels":["O","O","O","B-Cuisine","O","B-Location","I-Location"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Dish, Price, Amenity, Hours, Location, Restaurant Name, Rating and O.\nSentence: are there any hamburger restaurants close by","prompt_labels":"are(O) there(O) any(O) hamburger(B-Cuisine) restaurants(O) close(B-Location) by(I-Location)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Restaurant Name","Location","Hours","Price","Rating","Dish","Amenity","Cuisine"],"instance":{"id":"48","words":["are","there","any","hotels","nearby","that","have","private","rooms","available","at","1","am"],"labels":["O","O","O","O","O","O","O","O","O","O","O","B-Hours","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Location, Hours, Price, Rating, Dish, Amenity, Cuisine and O.\nSentence: are there any hotels nearby that have private rooms available at 1 am","prompt_labels":"are(O) there(O) any(O) hotels(O) nearby(O) that(O) have(O) private(O) rooms(O) available(O) at(O) 1(B-Hours) am(O)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Price","Amenity","Hours","Rating","Restaurant Name","Location","Cuisine","Dish"],"instance":{"id":"49","words":["are","there","any","ice","cream","shops","in","my","neighborhood","that","are","open","right","now"],"labels":["O","O","O","B-Cuisine","I-Cuisine","O","B-Location","I-Location","I-Location","O","O","B-Hours","I-Hours","I-Hours"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Amenity, Hours, Rating, Restaurant Name, Location, Cuisine, Dish and O.\nSentence: are there any ice cream shops in my neighborhood that are open right now","prompt_labels":"are(O) there(O) any(O) ice(B-Cuisine) cream(I-Cuisine) shops(O) in(B-Location) my(I-Location) neighborhood(I-Location) that(O) are(O) open(B-Hours) right(I-Hours) now(I-Hours)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Hours","Price","Cuisine","Dish","Location","Restaurant Name","Rating","Amenity"],"instance":{"id":"50","words":["are","there","any","indian","restaurants","on","long","island"],"labels":["O","O","O","B-Cuisine","O","O","B-Location","I-Location"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Price, Cuisine, Dish, Location, Restaurant Name, Rating, Amenity and O.\nSentence: are there any indian restaurants on long island","prompt_labels":"are(O) there(O) any(O) indian(B-Cuisine) restaurants(O) on(O) long(B-Location) island(I-Location)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Restaurant Name","Hours","Price","Rating","Location","Dish","Amenity","Cuisine"],"instance":{"id":"51","words":["are","there","any","italian","eateries","nearby"],"labels":["O","O","O","B-Cuisine","O","B-Location"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Hours, Price, Rating, Location, Dish, Amenity, Cuisine and O.\nSentence: are there any italian eateries nearby","prompt_labels":"are(O) there(O) any(O) italian(B-Cuisine) eateries(O) nearby(B-Location)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Cuisine","Restaurant Name","Amenity","Rating","Price","Location","Dish","Hours"],"instance":{"id":"52","words":["are","there","any","japanese","restaurants","in","town","that","do","discounts","for","bulk","orders","of","sushi"],"labels":["O","O","O","B-Cuisine","O","B-Location","I-Location","O","O","B-Amenity","I-Amenity","I-Amenity","I-Amenity","O","B-Amenity"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Restaurant Name, Amenity, Rating, Price, Location, Dish, Hours and O.\nSentence: are there any japanese restaurants in town that do discounts for bulk orders of sushi","prompt_labels":"are(O) there(O) any(O) japanese(B-Cuisine) restaurants(O) in(B-Location) town(I-Location) that(O) do(O) discounts(B-Amenity) for(I-Amenity) bulk(I-Amenity) orders(I-Amenity) of(O) sushi(B-Amenity)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Cuisine","Hours","Location","Rating","Amenity","Price","Restaurant Name","Dish"],"instance":{"id":"53","words":["are","there","any","jazz","clubs","that","serve","food"],"labels":["O","O","O","B-Amenity","I-Amenity","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Hours, Location, Rating, Amenity, Price, Restaurant Name, Dish and O.\nSentence: are there any jazz clubs that serve food","prompt_labels":"are(O) there(O) any(O) jazz(B-Amenity) clubs(I-Amenity) that(O) serve(O) food(O)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Price","Amenity","Restaurant Name","Hours","Cuisine","Location","Rating","Dish"],"instance":{"id":"54","words":["are","there","any","kid","friendly","restaurants","close","by"],"labels":["O","O","O","B-Amenity","I-Amenity","O","B-Location","I-Location"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Amenity, Restaurant Name, Hours, Cuisine, Location, Rating, Dish and O.\nSentence: are there any kid friendly restaurants close by","prompt_labels":"are(O) there(O) any(O) kid(B-Amenity) friendly(I-Amenity) restaurants(O) close(B-Location) by(I-Location)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Restaurant Name","Amenity","Price","Location","Dish","Rating","Cuisine","Hours"],"instance":{"id":"55","words":["are","there","any","kid","friendly","restaurants","with","valet","parking"],"labels":["O","O","O","B-Amenity","I-Amenity","O","O","B-Amenity","I-Amenity"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Amenity, Price, Location, Dish, Rating, Cuisine, Hours and O.\nSentence: are there any kid friendly restaurants with valet parking","prompt_labels":"are(O) there(O) any(O) kid(B-Amenity) friendly(I-Amenity) restaurants(O) with(O) valet(B-Amenity) parking(I-Amenity)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Restaurant Name","Location","Rating","Dish","Hours","Amenity","Cuisine","Price"],"instance":{"id":"56","words":["are","there","any","locally","owned","franchises","that","give","money","to","charity"],"labels":["O","O","O","B-Amenity","I-Amenity","O","O","B-Amenity","I-Amenity","I-Amenity","I-Amenity"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Location, Rating, Dish, Hours, Amenity, Cuisine, Price and O.\nSentence: are there any locally owned franchises that give money to charity","prompt_labels":"are(O) there(O) any(O) locally(B-Amenity) owned(I-Amenity) franchises(O) that(O) give(B-Amenity) money(I-Amenity) to(I-Amenity) charity(I-Amenity)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Cuisine","Amenity","Dish","Price","Restaurant Name","Rating","Location","Hours"],"instance":{"id":"57","words":["are","there","any","maid","cafe","in","town"],"labels":["O","O","O","B-Restaurant Name","I-Restaurant Name","B-Location","I-Location"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Amenity, Dish, Price, Restaurant Name, Rating, Location, Hours and O.\nSentence: are there any maid cafe in town","prompt_labels":"are(O) there(O) any(O) maid(B-Restaurant Name) cafe(I-Restaurant Name) in(B-Location) town(I-Location)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Restaurant Name","Dish","Amenity","Location","Cuisine","Hours","Price","Rating"],"instance":{"id":"58","words":["are","there","any","mcdonalds","that","i","can","drive","too","in","3","minutes"],"labels":["O","O","O","B-Restaurant Name","O","O","O","O","O","B-Location","I-Location","I-Location"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Dish, Amenity, Location, Cuisine, Hours, Price, Rating and O.\nSentence: are there any mcdonalds that i can drive too in 3 minutes","prompt_labels":"are(O) there(O) any(O) mcdonalds(B-Restaurant Name) that(O) i(O) can(O) drive(O) too(O) in(B-Location) 3(I-Location) minutes(I-Location)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Restaurant Name","Amenity","Price","Location","Hours","Rating","Cuisine","Dish"],"instance":{"id":"59","words":["are","there","any","mid","priced","restaurants","within","5","miles","that","offer","curb","side","pickup"],"labels":["O","O","O","B-Price","O","O","B-Location","I-Location","I-Location","O","B-Amenity","I-Amenity","I-Amenity","I-Amenity"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Amenity, Price, Location, Hours, Rating, Cuisine, Dish and O.\nSentence: are there any mid priced restaurants within 5 miles that offer curb side pickup","prompt_labels":"are(O) there(O) any(O) mid(B-Price) priced(O) restaurants(O) within(B-Location) 5(I-Location) miles(I-Location) that(O) offer(B-Amenity) curb(I-Amenity) side(I-Amenity) pickup(I-Amenity)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Cuisine","Restaurant Name","Location","Dish","Hours","Amenity","Rating","Price"],"instance":{"id":"60","words":["are","there","any","nationally","known","chefs","with","restaurants","in","this","city"],"labels":["O","O","O","B-Rating","I-Rating","O","O","O","B-Location","I-Location","I-Location"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Restaurant Name, Location, Dish, Hours, Amenity, Rating, Price and O.\nSentence: are there any nationally known chefs with restaurants in this city","prompt_labels":"are(O) there(O) any(O) nationally(B-Rating) known(I-Rating) chefs(O) with(O) restaurants(O) in(B-Location) this(I-Location) city(I-Location)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Hours","Rating","Cuisine","Dish","Restaurant Name","Amenity","Location","Price"],"instance":{"id":"61","words":["are","there","any","new","restaurants","nearby","that","i","can","try"],"labels":["O","O","O","B-Amenity","O","B-Location","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Rating, Cuisine, Dish, Restaurant Name, Amenity, Location, Price and O.\nSentence: are there any new restaurants nearby that i can try","prompt_labels":"are(O) there(O) any(O) new(B-Amenity) restaurants(O) nearby(B-Location) that(O) i(O) can(O) try(O)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Dish","Cuisine","Rating","Hours","Amenity","Restaurant Name","Price","Location"],"instance":{"id":"62","words":["are","there","any","nice","taco","places","nearby","open","for","breakfast"],"labels":["O","O","O","B-Rating","B-Cuisine","O","B-Location","B-Hours","I-Hours","I-Hours"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Dish, Cuisine, Rating, Hours, Amenity, Restaurant Name, Price, Location and O.\nSentence: are there any nice taco places nearby open for breakfast","prompt_labels":"are(O) there(O) any(O) nice(B-Rating) taco(B-Cuisine) places(O) nearby(B-Location) open(B-Hours) for(I-Hours) breakfast(I-Hours)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Price","Restaurant Name","Cuisine","Dish","Amenity","Location","Hours","Rating"],"instance":{"id":"63","words":["are","there","any","place","close","by","that","is","open","24","hours"],"labels":["O","O","O","O","B-Location","O","O","O","B-Hours","I-Hours","I-Hours"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Restaurant Name, Cuisine, Dish, Amenity, Location, Hours, Rating and O.\nSentence: are there any place close by that is open 24 hours","prompt_labels":"are(O) there(O) any(O) place(O) close(B-Location) by(O) that(O) is(O) open(B-Hours) 24(I-Hours) hours(I-Hours)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Price","Dish","Restaurant Name","Amenity","Hours","Location","Cuisine","Rating"],"instance":{"id":"64","words":["are","there","any","places","around","here","that","has","tomato","sauce","based","dishes"],"labels":["O","O","O","O","B-Location","I-Location","O","O","B-Dish","I-Dish","I-Dish","I-Dish"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Dish, Restaurant Name, Amenity, Hours, Location, Cuisine, Rating and O.\nSentence: are there any places around here that has tomato sauce based dishes","prompt_labels":"are(O) there(O) any(O) places(O) around(B-Location) here(I-Location) that(O) has(O) tomato(B-Dish) sauce(I-Dish) based(I-Dish) dishes(I-Dish)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Hours","Rating","Dish","Amenity","Price","Restaurant Name","Location","Cuisine"],"instance":{"id":"65","words":["are","there","any","places","left","that","allow","smoking","in","a","restaraunt"],"labels":["O","O","O","O","O","O","B-Amenity","I-Amenity","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Rating, Dish, Amenity, Price, Restaurant Name, Location, Cuisine and O.\nSentence: are there any places left that allow smoking in a restaraunt","prompt_labels":"are(O) there(O) any(O) places(O) left(O) that(O) allow(B-Amenity) smoking(I-Amenity) in(O) a(O) restaraunt(O)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Hours","Restaurant Name","Amenity","Location","Dish","Cuisine","Rating","Price"],"instance":{"id":"66","words":["are","there","any","places","near","by","that","sell","hamburgers","and","pizza"],"labels":["O","O","O","O","B-Location","I-Location","O","O","B-Dish","O","B-Dish"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Restaurant Name, Amenity, Location, Dish, Cuisine, Rating, Price and O.\nSentence: are there any places near by that sell hamburgers and pizza","prompt_labels":"are(O) there(O) any(O) places(O) near(B-Location) by(I-Location) that(O) sell(O) hamburgers(B-Dish) and(O) pizza(B-Dish)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Dish","Rating","Price","Restaurant Name","Cuisine","Amenity","Hours","Location"],"instance":{"id":"67","words":["are","there","any","places","near","by","that","serve","lunch","all","day"],"labels":["O","O","O","O","B-Location","I-Location","O","O","B-Hours","I-Hours","I-Hours"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Dish, Rating, Price, Restaurant Name, Cuisine, Amenity, Hours, Location and O.\nSentence: are there any places near by that serve lunch all day","prompt_labels":"are(O) there(O) any(O) places(O) near(B-Location) by(I-Location) that(O) serve(O) lunch(B-Hours) all(I-Hours) day(I-Hours)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Cuisine","Rating","Restaurant Name","Price","Amenity","Location","Dish","Hours"],"instance":{"id":"68","words":["are","there","any","places","to","eat","in","the","area","that","offer","a","two","for","one","special"],"labels":["O","O","O","O","O","O","B-Location","I-Location","I-Location","O","O","O","B-Amenity","I-Amenity","I-Amenity","I-Amenity"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Rating, Restaurant Name, Price, Amenity, Location, Dish, Hours and O.\nSentence: are there any places to eat in the area that offer a two for one special","prompt_labels":"are(O) there(O) any(O) places(O) to(O) eat(O) in(B-Location) the(I-Location) area(I-Location) that(O) offer(O) a(O) two(B-Amenity) for(I-Amenity) one(I-Amenity) special(I-Amenity)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Cuisine","Rating","Location","Price","Dish","Restaurant Name","Hours","Amenity"],"instance":{"id":"69","words":["are","there","any","places","with","a","notable","beer","list","on","white","st"],"labels":["O","O","O","O","O","O","B-Rating","B-Amenity","I-Amenity","O","B-Location","I-Location"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Rating, Location, Price, Dish, Restaurant Name, Hours, Amenity and O.\nSentence: are there any places with a notable beer list on white st","prompt_labels":"are(O) there(O) any(O) places(O) with(O) a(O) notable(B-Rating) beer(B-Amenity) list(I-Amenity) on(O) white(B-Location) st(I-Location)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Amenity","Dish","Rating","Restaurant Name","Cuisine","Location","Price","Hours"],"instance":{"id":"70","words":["are","there","any","reasonably","priced","restaurants","on","east","haverhill","street","that","serve","cheese"],"labels":["O","O","O","B-Price","O","O","O","B-Location","I-Location","I-Location","O","O","B-Dish"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Dish, Rating, Restaurant Name, Cuisine, Location, Price, Hours and O.\nSentence: are there any reasonably priced restaurants on east haverhill street that serve cheese","prompt_labels":"are(O) there(O) any(O) reasonably(B-Price) priced(O) restaurants(O) on(O) east(B-Location) haverhill(I-Location) street(I-Location) that(O) serve(O) cheese(B-Dish)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Price","Rating","Location","Restaurant Name","Amenity","Hours","Cuisine","Dish"],"instance":{"id":"71","words":["are","there","any","restaurant","nearby","that","serve","thai","food"],"labels":["O","O","O","O","B-Location","O","O","B-Cuisine","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Rating, Location, Restaurant Name, Amenity, Hours, Cuisine, Dish and O.\nSentence: are there any restaurant nearby that serve thai food","prompt_labels":"are(O) there(O) any(O) restaurant(O) nearby(B-Location) that(O) serve(O) thai(B-Cuisine) food(O)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Price","Dish","Cuisine","Amenity","Hours","Restaurant Name","Rating","Location"],"instance":{"id":"72","words":["are","there","any","restaurants","around","with","a","smoking","area"],"labels":["O","O","O","O","O","O","O","B-Amenity","I-Amenity"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Dish, Cuisine, Amenity, Hours, Restaurant Name, Rating, Location and O.\nSentence: are there any restaurants around with a smoking area","prompt_labels":"are(O) there(O) any(O) restaurants(O) around(O) with(O) a(O) smoking(B-Amenity) area(I-Amenity)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Amenity","Rating","Price","Hours","Restaurant Name","Cuisine","Location","Dish"],"instance":{"id":"73","words":["are","there","any","restaurants","for","diabetics","that","serve","sugar","free","desserts"],"labels":["O","O","O","O","O","O","O","O","B-Dish","I-Dish","I-Dish"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Rating, Price, Hours, Restaurant Name, Cuisine, Location, Dish and O.\nSentence: are there any restaurants for diabetics that serve sugar free desserts","prompt_labels":"are(O) there(O) any(O) restaurants(O) for(O) diabetics(O) that(O) serve(O) sugar(B-Dish) free(I-Dish) desserts(I-Dish)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Location","Rating","Hours","Restaurant Name","Dish","Cuisine","Amenity","Price"],"instance":{"id":"74","words":["are","there","any","restaurants","nearby","that","have","great","reviews","and","plenty","of","parking"],"labels":["O","O","O","O","B-Location","O","O","B-Rating","I-Rating","O","B-Amenity","I-Amenity","I-Amenity"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Location, Rating, Hours, Restaurant Name, Dish, Cuisine, Amenity, Price and O.\nSentence: are there any restaurants nearby that have great reviews and plenty of parking","prompt_labels":"are(O) there(O) any(O) restaurants(O) nearby(B-Location) that(O) have(O) great(B-Rating) reviews(I-Rating) and(O) plenty(B-Amenity) of(I-Amenity) parking(I-Amenity)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Restaurant Name","Location","Cuisine","Rating","Amenity","Price","Dish","Hours"],"instance":{"id":"75","words":["are","there","any","restaurants","nearby","that","have","outdoor","dining"],"labels":["O","O","O","O","B-Location","O","O","B-Amenity","I-Amenity"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Location, Cuisine, Rating, Amenity, Price, Dish, Hours and O.\nSentence: are there any restaurants nearby that have outdoor dining","prompt_labels":"are(O) there(O) any(O) restaurants(O) nearby(B-Location) that(O) have(O) outdoor(B-Amenity) dining(I-Amenity)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Cuisine","Rating","Hours","Price","Amenity","Restaurant Name","Location","Dish"],"instance":{"id":"76","words":["are","there","any","restaurants","on","kilmarnock","street","that","feature","large","portions","and","a","brewpub"],"labels":["O","O","O","O","O","B-Location","I-Location","O","O","B-Amenity","I-Amenity","O","O","B-Amenity"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Rating, Hours, Price, Amenity, Restaurant Name, Location, Dish and O.\nSentence: are there any restaurants on kilmarnock street that feature large portions and a brewpub","prompt_labels":"are(O) there(O) any(O) restaurants(O) on(O) kilmarnock(B-Location) street(I-Location) that(O) feature(O) large(B-Amenity) portions(I-Amenity) and(O) a(O) brewpub(B-Amenity)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Price","Amenity","Rating","Restaurant Name","Hours","Dish","Cuisine","Location"],"instance":{"id":"77","words":["are","there","any","restaurants","on","the","way","that","serve","hamburgers","and","are","open","after","1","am"],"labels":["O","O","O","O","O","O","B-Location","O","O","B-Dish","O","O","B-Hours","I-Hours","I-Hours","I-Hours"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Amenity, Rating, Restaurant Name, Hours, Dish, Cuisine, Location and O.\nSentence: are there any restaurants on the way that serve hamburgers and are open after 1 am","prompt_labels":"are(O) there(O) any(O) restaurants(O) on(O) the(O) way(B-Location) that(O) serve(O) hamburgers(B-Dish) and(O) are(O) open(B-Hours) after(I-Hours) 1(I-Hours) am(I-Hours)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Rating","Restaurant Name","Cuisine","Location","Dish","Price","Hours","Amenity"],"instance":{"id":"78","words":["are","there","any","restaurants","on","the","way","to","my","destination","that","have","a","fireplace","inside"],"labels":["O","O","O","O","O","O","B-Location","I-Location","I-Location","I-Location","O","O","O","B-Amenity","I-Amenity"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Rating, Restaurant Name, Cuisine, Location, Dish, Price, Hours, Amenity and O.\nSentence: are there any restaurants on the way to my destination that have a fireplace inside","prompt_labels":"are(O) there(O) any(O) restaurants(O) on(O) the(O) way(B-Location) to(I-Location) my(I-Location) destination(I-Location) that(O) have(O) a(O) fireplace(B-Amenity) inside(I-Amenity)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Location","Rating","Cuisine","Restaurant Name","Amenity","Price","Hours","Dish"],"instance":{"id":"79","words":["are","there","any","restaurants","on","this","side","of","the","river"],"labels":["O","O","O","O","O","B-Location","I-Location","I-Location","I-Location","I-Location"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Location, Rating, Cuisine, Restaurant Name, Amenity, Price, Hours, Dish and O.\nSentence: are there any restaurants on this side of the river","prompt_labels":"are(O) there(O) any(O) restaurants(O) on(O) this(B-Location) side(I-Location) of(I-Location) the(I-Location) river(I-Location)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Restaurant Name","Price","Cuisine","Dish","Rating","Location","Amenity","Hours"],"instance":{"id":"80","words":["are","there","any","restaurants","open","after","2","am"],"labels":["O","O","O","O","B-Hours","I-Hours","I-Hours","I-Hours"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Price, Cuisine, Dish, Rating, Location, Amenity, Hours and O.\nSentence: are there any restaurants open after 2 am","prompt_labels":"are(O) there(O) any(O) restaurants(O) open(B-Hours) after(I-Hours) 2(I-Hours) am(I-Hours)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Location","Cuisine","Rating","Dish","Price","Amenity","Hours","Restaurant Name"],"instance":{"id":"81","words":["are","there","any","restaurants","that","are","open","24","hours"],"labels":["O","O","O","O","O","O","O","B-Hours","I-Hours"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Location, Cuisine, Rating, Dish, Price, Amenity, Hours, Restaurant Name and O.\nSentence: are there any restaurants that are open 24 hours","prompt_labels":"are(O) there(O) any(O) restaurants(O) that(O) are(O) open(O) 24(B-Hours) hours(I-Hours)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Cuisine","Dish","Hours","Rating","Price","Restaurant Name","Amenity","Location"],"instance":{"id":"82","words":["are","there","any","restaurants","that","serve","raw","and","organic","food","nearby"],"labels":["O","O","O","O","O","O","B-Cuisine","I-Cuisine","I-Cuisine","O","B-Location"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Dish, Hours, Rating, Price, Restaurant Name, Amenity, Location and O.\nSentence: are there any restaurants that serve raw and organic food nearby","prompt_labels":"are(O) there(O) any(O) restaurants(O) that(O) serve(O) raw(B-Cuisine) and(I-Cuisine) organic(I-Cuisine) food(O) nearby(B-Location)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Location","Price","Rating","Amenity","Cuisine","Dish","Hours","Restaurant Name"],"instance":{"id":"83","words":["are","there","any","restaurants","that","will","let","me","take","my","dog","in","with","me"],"labels":["O","O","O","O","O","O","O","O","B-Amenity","I-Amenity","I-Amenity","I-Amenity","I-Amenity","I-Amenity"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Location, Price, Rating, Amenity, Cuisine, Dish, Hours, Restaurant Name and O.\nSentence: are there any restaurants that will let me take my dog in with me","prompt_labels":"are(O) there(O) any(O) restaurants(O) that(O) will(O) let(O) me(O) take(B-Amenity) my(I-Amenity) dog(I-Amenity) in(I-Amenity) with(I-Amenity) me(I-Amenity)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Dish","Hours","Location","Cuisine","Amenity","Restaurant Name","Rating","Price"],"instance":{"id":"84","words":["are","there","any","restaurants","with","happy","hour","in","the","area"],"labels":["O","O","O","O","O","B-Amenity","I-Amenity","B-Location","I-Location","I-Location"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Dish, Hours, Location, Cuisine, Amenity, Restaurant Name, Rating, Price and O.\nSentence: are there any restaurants with happy hour in the area","prompt_labels":"are(O) there(O) any(O) restaurants(O) with(O) happy(B-Amenity) hour(I-Amenity) in(B-Location) the(I-Location) area(I-Location)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Hours","Location","Restaurant Name","Rating","Dish","Amenity","Price","Cuisine"],"instance":{"id":"85","words":["are","there","any","restaurants","with","valet","parking","and","a","multilingual","staff","near","here"],"labels":["O","O","O","O","O","B-Amenity","I-Amenity","O","O","B-Amenity","I-Amenity","B-Location","I-Location"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Location, Restaurant Name, Rating, Dish, Amenity, Price, Cuisine and O.\nSentence: are there any restaurants with valet parking and a multilingual staff near here","prompt_labels":"are(O) there(O) any(O) restaurants(O) with(O) valet(B-Amenity) parking(I-Amenity) and(O) a(O) multilingual(B-Amenity) staff(I-Amenity) near(B-Location) here(I-Location)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Restaurant Name","Amenity","Cuisine","Dish","Price","Hours","Location","Rating"],"instance":{"id":"86","words":["are","there","any","restaurants","within","5","miles","that","accept","travelers","checks"],"labels":["O","O","O","O","B-Location","I-Location","I-Location","O","B-Amenity","I-Amenity","I-Amenity"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Amenity, Cuisine, Dish, Price, Hours, Location, Rating and O.\nSentence: are there any restaurants within 5 miles that accept travelers checks","prompt_labels":"are(O) there(O) any(O) restaurants(O) within(B-Location) 5(I-Location) miles(I-Location) that(O) accept(B-Amenity) travelers(I-Amenity) checks(I-Amenity)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Hours","Restaurant Name","Amenity","Location","Price","Dish","Cuisine","Rating"],"instance":{"id":"87","words":["are","there","any","rib","joints","nearby"],"labels":["O","O","O","B-Cuisine","I-Cuisine","B-Location"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Restaurant Name, Amenity, Location, Price, Dish, Cuisine, Rating and O.\nSentence: are there any rib joints nearby","prompt_labels":"are(O) there(O) any(O) rib(B-Cuisine) joints(I-Cuisine) nearby(B-Location)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Hours","Amenity","Cuisine","Restaurant Name","Price","Rating","Dish","Location"],"instance":{"id":"88","words":["are","there","any","seafood","restaurants","near","government","center","where","i","can","make","online","reservations"],"labels":["O","O","O","B-Cuisine","O","B-Location","I-Location","I-Location","O","O","O","O","B-Location","I-Location"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Amenity, Cuisine, Restaurant Name, Price, Rating, Dish, Location and O.\nSentence: are there any seafood restaurants near government center where i can make online reservations","prompt_labels":"are(O) there(O) any(O) seafood(B-Cuisine) restaurants(O) near(B-Location) government(I-Location) center(I-Location) where(O) i(O) can(O) make(O) online(B-Location) reservations(I-Location)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Location","Cuisine","Price","Amenity","Hours","Restaurant Name","Rating","Dish"],"instance":{"id":"89","words":["are","there","any","spanish","restaurants","that","are","cheap"],"labels":["O","O","O","B-Cuisine","O","O","O","B-Price"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Location, Cuisine, Price, Amenity, Hours, Restaurant Name, Rating, Dish and O.\nSentence: are there any spanish restaurants that are cheap","prompt_labels":"are(O) there(O) any(O) spanish(B-Cuisine) restaurants(O) that(O) are(O) cheap(B-Price)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Restaurant Name","Rating","Hours","Location","Cuisine","Amenity","Dish","Price"],"instance":{"id":"90","words":["are","there","any","steak","houses","within","3","miles","of","me"],"labels":["O","O","O","B-Dish","O","B-Location","I-Location","I-Location","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Rating, Hours, Location, Cuisine, Amenity, Dish, Price and O.\nSentence: are there any steak houses within 3 miles of me","prompt_labels":"are(O) there(O) any(O) steak(B-Dish) houses(O) within(B-Location) 3(I-Location) miles(I-Location) of(O) me(O)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Dish","Price","Rating","Location","Cuisine","Hours","Restaurant Name","Amenity"],"instance":{"id":"91","words":["are","there","any","sub","sandwich","shops","that","also","serve","beer"],"labels":["O","O","O","B-Cuisine","I-Cuisine","O","O","O","O","B-Dish"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Dish, Price, Rating, Location, Cuisine, Hours, Restaurant Name, Amenity and O.\nSentence: are there any sub sandwich shops that also serve beer","prompt_labels":"are(O) there(O) any(O) sub(B-Cuisine) sandwich(I-Cuisine) shops(O) that(O) also(O) serve(O) beer(B-Dish)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Cuisine","Restaurant Name","Hours","Amenity","Rating","Location","Dish","Price"],"instance":{"id":"92","words":["are","there","any","sushi","restaurants","near","colonel","bell","drive"],"labels":["O","O","O","B-Cuisine","O","B-Location","I-Location","I-Location","I-Location"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Restaurant Name, Hours, Amenity, Rating, Location, Dish, Price and O.\nSentence: are there any sushi restaurants near colonel bell drive","prompt_labels":"are(O) there(O) any(O) sushi(B-Cuisine) restaurants(O) near(B-Location) colonel(I-Location) bell(I-Location) drive(I-Location)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Location","Rating","Cuisine","Amenity","Restaurant Name","Dish","Hours","Price"],"instance":{"id":"93","words":["are","there","any","tapas","restaurants","with","good","reviews","nearby"],"labels":["O","O","O","B-Dish","O","O","B-Rating","I-Rating","B-Location"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Location, Rating, Cuisine, Amenity, Restaurant Name, Dish, Hours, Price and O.\nSentence: are there any tapas restaurants with good reviews nearby","prompt_labels":"are(O) there(O) any(O) tapas(B-Dish) restaurants(O) with(O) good(B-Rating) reviews(I-Rating) nearby(B-Location)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Amenity","Hours","Price","Restaurant Name","Dish","Rating","Cuisine","Location"],"instance":{"id":"94","words":["are","there","any","turkish","restaurants","in","florida"],"labels":["O","O","O","B-Cuisine","O","O","B-Location"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Hours, Price, Restaurant Name, Dish, Rating, Cuisine, Location and O.\nSentence: are there any turkish restaurants in florida","prompt_labels":"are(O) there(O) any(O) turkish(B-Cuisine) restaurants(O) in(O) florida(B-Location)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Price","Amenity","Rating","Restaurant Name","Cuisine","Hours","Location","Dish"],"instance":{"id":"95","words":["are","there","any","vegan","spots","that","are","open","after","11","at","night"],"labels":["O","O","O","B-Cuisine","I-Cuisine","O","O","B-Hours","I-Hours","I-Hours","I-Hours","I-Hours"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Amenity, Rating, Restaurant Name, Cuisine, Hours, Location, Dish and O.\nSentence: are there any vegan spots that are open after 11 at night","prompt_labels":"are(O) there(O) any(O) vegan(B-Cuisine) spots(I-Cuisine) that(O) are(O) open(B-Hours) after(I-Hours) 11(I-Hours) at(I-Hours) night(I-Hours)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Hours","Price","Cuisine","Restaurant Name","Amenity","Location","Dish","Rating"],"instance":{"id":"96","words":["are","there","any","vegetarian","restaurants","in","this","town"],"labels":["O","O","O","B-Cuisine","O","B-Location","I-Location","I-Location"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Price, Cuisine, Restaurant Name, Amenity, Location, Dish, Rating and O.\nSentence: are there any vegetarian restaurants in this town","prompt_labels":"are(O) there(O) any(O) vegetarian(B-Cuisine) restaurants(O) in(B-Location) this(I-Location) town(I-Location)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Cuisine","Hours","Dish","Location","Price","Rating","Restaurant Name","Amenity"],"instance":{"id":"97","words":["are","there","any","vegetarian","restaurants","that","allow","you","to","order","online","ahead","of","time"],"labels":["O","O","O","B-Cuisine","O","O","O","O","O","B-Amenity","I-Amenity","I-Amenity","I-Amenity","I-Amenity"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Hours, Dish, Location, Price, Rating, Restaurant Name, Amenity and O.\nSentence: are there any vegetarian restaurants that allow you to order online ahead of time","prompt_labels":"are(O) there(O) any(O) vegetarian(B-Cuisine) restaurants(O) that(O) allow(O) you(O) to(O) order(B-Amenity) online(I-Amenity) ahead(I-Amenity) of(I-Amenity) time(I-Amenity)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Hours","Cuisine","Rating","Dish","Restaurant Name","Location","Amenity","Price"],"instance":{"id":"98","words":["are","there","any","vietnamese","restaurants","nearby"],"labels":["O","O","O","B-Cuisine","O","B-Location"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Cuisine, Rating, Dish, Restaurant Name, Location, Amenity, Price and O.\nSentence: are there any vietnamese restaurants nearby","prompt_labels":"are(O) there(O) any(O) vietnamese(B-Cuisine) restaurants(O) nearby(B-Location)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Dish","Rating","Hours","Location","Cuisine","Price","Restaurant Name","Amenity"],"instance":{"id":"99","words":["are","there","are","any","cracker","barrells","on","long","island"],"labels":["O","O","O","O","B-Restaurant Name","I-Restaurant Name","O","B-Location","I-Location"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Dish, Rating, Hours, Location, Cuisine, Price, Restaurant Name, Amenity and O.\nSentence: are there are any cracker barrells on long island","prompt_labels":"are(O) there(O) are(O) any(O) cracker(B-Restaurant Name) barrells(I-Restaurant Name) on(O) long(B-Location) island(I-Location)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Hours","Amenity","Restaurant Name","Rating","Dish","Location","Price","Cuisine"],"instance":{"id":"100","words":["are","there","reservations","still","available","for","bar","la","grassa","for","2","tomorrow","at","7","pm"],"labels":["O","O","O","O","O","O","B-Restaurant Name","I-Restaurant Name","I-Restaurant Name","O","O","B-Hours","I-Hours","I-Hours","I-Hours"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Amenity, Restaurant Name, Rating, Dish, Location, Price, Cuisine and O.\nSentence: are there reservations still available for bar la grassa for 2 tomorrow at 7 pm","prompt_labels":"are(O) there(O) reservations(O) still(O) available(O) for(O) bar(B-Restaurant Name) la(I-Restaurant Name) grassa(I-Restaurant Name) for(O) 2(O) tomorrow(B-Hours) at(I-Hours) 7(I-Hours) pm(I-Hours)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Restaurant Name","Cuisine","Rating","Dish","Amenity","Hours","Location","Price"],"instance":{"id":"101","words":["areas","that","allow","smoking"],"labels":["O","O","B-Amenity","I-Amenity"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Cuisine, Rating, Dish, Amenity, Hours, Location, Price and O.\nSentence: areas that allow smoking","prompt_labels":"areas(O) that(O) allow(B-Amenity) smoking(I-Amenity)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Price","Dish","Location","Hours","Rating","Amenity","Restaurant Name","Cuisine"],"instance":{"id":"102","words":["asian","cuisine","in","my","zip","code"],"labels":["B-Cuisine","O","B-Location","I-Location","I-Location","I-Location"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Dish, Location, Hours, Rating, Amenity, Restaurant Name, Cuisine and O.\nSentence: asian cuisine in my zip code","prompt_labels":"asian(B-Cuisine) cuisine(O) in(B-Location) my(I-Location) zip(I-Location) code(I-Location)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Restaurant Name","Hours","Cuisine","Amenity","Location","Dish","Price","Rating"],"instance":{"id":"103","words":["at","which","french","restaurant","can","i","dine","outdoors"],"labels":["O","O","B-Cuisine","O","O","O","B-Amenity","I-Amenity"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Hours, Cuisine, Amenity, Location, Dish, Price, Rating and O.\nSentence: at which french restaurant can i dine outdoors","prompt_labels":"at(O) which(O) french(B-Cuisine) restaurant(O) can(O) i(O) dine(B-Amenity) outdoors(I-Amenity)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Price","Restaurant Name","Rating","Hours","Dish","Amenity","Cuisine","Location"],"instance":{"id":"104","words":["beer","and","hot","wings","in","town"],"labels":["B-Dish","O","B-Dish","I-Dish","B-Location","I-Location"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Restaurant Name, Rating, Hours, Dish, Amenity, Cuisine, Location and O.\nSentence: beer and hot wings in town","prompt_labels":"beer(B-Dish) and(O) hot(B-Dish) wings(I-Dish) in(B-Location) town(I-Location)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Dish","Restaurant Name","Location","Hours","Cuisine","Amenity","Rating","Price"],"instance":{"id":"105","words":["best","chinese","food","in","the","area"],"labels":["B-Rating","B-Cuisine","O","B-Location","I-Location","I-Location"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Dish, Restaurant Name, Location, Hours, Cuisine, Amenity, Rating, Price and O.\nSentence: best chinese food in the area","prompt_labels":"best(B-Rating) chinese(B-Cuisine) food(O) in(B-Location) the(I-Location) area(I-Location)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Cuisine","Restaurant Name","Amenity","Dish","Location","Price","Rating","Hours"],"instance":{"id":"106","words":["borscht"],"labels":["B-Dish"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Restaurant Name, Amenity, Dish, Location, Price, Rating, Hours and O.\nSentence: borscht","prompt_labels":"borscht(B-Dish)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Rating","Dish","Price","Cuisine","Hours","Location","Amenity","Restaurant Name"],"instance":{"id":"107","words":["bradford","lantern","cafe","directions"],"labels":["B-Restaurant Name","I-Restaurant Name","I-Restaurant Name","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Rating, Dish, Price, Cuisine, Hours, Location, Amenity, Restaurant Name and O.\nSentence: bradford lantern cafe directions","prompt_labels":"bradford(B-Restaurant Name) lantern(I-Restaurant Name) cafe(I-Restaurant Name) directions(O)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Hours","Rating","Amenity","Location","Restaurant Name","Dish","Cuisine","Price"],"instance":{"id":"108","words":["brasil","cuisine","near","me"],"labels":["B-Cuisine","O","B-Location","I-Location"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Rating, Amenity, Location, Restaurant Name, Dish, Cuisine, Price and O.\nSentence: brasil cuisine near me","prompt_labels":"brasil(B-Cuisine) cuisine(O) near(B-Location) me(I-Location)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Hours","Location","Amenity","Price","Rating","Cuisine","Dish","Restaurant Name"],"instance":{"id":"109","words":["burgers"],"labels":["B-Dish"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Location, Amenity, Price, Rating, Cuisine, Dish, Restaurant Name and O.\nSentence: burgers","prompt_labels":"burgers(B-Dish)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Location","Dish","Hours","Amenity","Restaurant Name","Cuisine","Price","Rating"],"instance":{"id":"110","words":["cafes","on","ashlannd","street"],"labels":["B-Cuisine","O","B-Location","I-Location"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Location, Dish, Hours, Amenity, Restaurant Name, Cuisine, Price, Rating and O.\nSentence: cafes on ashlannd street","prompt_labels":"cafes(B-Cuisine) on(O) ashlannd(B-Location) street(I-Location)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Dish","Hours","Amenity","Price","Cuisine","Rating","Location","Restaurant Name"],"instance":{"id":"111","words":["call","cheeseboard","in","berkeley","for","me"],"labels":["O","B-Restaurant Name","O","B-Location","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Dish, Hours, Amenity, Price, Cuisine, Rating, Location, Restaurant Name and O.\nSentence: call cheeseboard in berkeley for me","prompt_labels":"call(O) cheeseboard(B-Restaurant Name) in(O) berkeley(B-Location) for(O) me(O)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Cuisine","Restaurant Name","Price","Rating","Hours","Amenity","Location","Dish"],"instance":{"id":"112","words":["call","chinese"],"labels":["O","B-Cuisine"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Restaurant Name, Price, Rating, Hours, Amenity, Location, Dish and O.\nSentence: call chinese","prompt_labels":"call(O) chinese(B-Cuisine)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Price","Cuisine","Hours","Restaurant Name","Rating","Dish","Amenity","Location"],"instance":{"id":"113","words":["call","dominos"],"labels":["O","B-Restaurant Name"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Cuisine, Hours, Restaurant Name, Rating, Dish, Amenity, Location and O.\nSentence: call dominos","prompt_labels":"call(O) dominos(B-Restaurant Name)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Cuisine","Price","Rating","Location","Hours","Amenity","Restaurant Name","Dish"],"instance":{"id":"114","words":["call","the","closest","korean","restaurant"],"labels":["O","O","B-Location","B-Cuisine","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Price, Rating, Location, Hours, Amenity, Restaurant Name, Dish and O.\nSentence: call the closest korean restaurant","prompt_labels":"call(O) the(O) closest(B-Location) korean(B-Cuisine) restaurant(O)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Rating","Cuisine","Restaurant Name","Price","Hours","Amenity","Dish","Location"],"instance":{"id":"115","words":["can","i","bring","my","kid","to","any","of","the","restaurants","down","town","that","have","bars","attached"],"labels":["O","O","O","B-Amenity","I-Amenity","O","O","O","O","O","B-Location","I-Location","O","O","B-Amenity","I-Amenity"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Rating, Cuisine, Restaurant Name, Price, Hours, Amenity, Dish, Location and O.\nSentence: can i bring my kid to any of the restaurants down town that have bars attached","prompt_labels":"can(O) i(O) bring(O) my(B-Amenity) kid(I-Amenity) to(O) any(O) of(O) the(O) restaurants(O) down(B-Location) town(I-Location) that(O) have(O) bars(B-Amenity) attached(I-Amenity)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Price","Location","Dish","Cuisine","Restaurant Name","Hours","Amenity","Rating"],"instance":{"id":"116","words":["can","i","bring","my","pet","iguana","to","the","japanese","restaurant"],"labels":["O","O","O","O","B-Amenity","O","O","O","B-Cuisine","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Location, Dish, Cuisine, Restaurant Name, Hours, Amenity, Rating and O.\nSentence: can i bring my pet iguana to the japanese restaurant","prompt_labels":"can(O) i(O) bring(O) my(O) pet(B-Amenity) iguana(O) to(O) the(O) japanese(B-Cuisine) restaurant(O)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Hours","Amenity","Rating","Price","Location","Dish","Restaurant Name","Cuisine"],"instance":{"id":"117","words":["can","i","dine","at","the","barat","a","nossa","casa"],"labels":["O","O","O","O","O","B-Restaurant Name","I-Restaurant Name","I-Restaurant Name","I-Restaurant Name"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Amenity, Rating, Price, Location, Dish, Restaurant Name, Cuisine and O.\nSentence: can i dine at the barat a nossa casa","prompt_labels":"can(O) i(O) dine(O) at(O) the(O) barat(B-Restaurant Name) a(I-Restaurant Name) nossa(I-Restaurant Name) casa(I-Restaurant Name)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Location","Restaurant Name","Cuisine","Rating","Amenity","Hours","Price","Dish"],"instance":{"id":"118","words":["can","i","find","a","bar","and","grill","within","short","walking","distance","of","the","shopping","district"],"labels":["O","O","O","O","B-Cuisine","I-Cuisine","I-Cuisine","O","B-Location","I-Location","I-Location","I-Location","I-Location","I-Location","I-Location"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Location, Restaurant Name, Cuisine, Rating, Amenity, Hours, Price, Dish and O.\nSentence: can i find a bar and grill within short walking distance of the shopping district","prompt_labels":"can(O) i(O) find(O) a(O) bar(B-Cuisine) and(I-Cuisine) grill(I-Cuisine) within(O) short(B-Location) walking(I-Location) distance(I-Location) of(I-Location) the(I-Location) shopping(I-Location) district(I-Location)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Cuisine","Price","Location","Amenity","Restaurant Name","Rating","Hours","Dish"],"instance":{"id":"119","words":["can","i","find","a","good","chinese","buffet","within","3","miles","from","me"],"labels":["O","O","O","O","B-Rating","B-Cuisine","B-Amenity","B-Location","I-Location","I-Location","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Price, Location, Amenity, Restaurant Name, Rating, Hours, Dish and O.\nSentence: can i find a good chinese buffet within 3 miles from me","prompt_labels":"can(O) i(O) find(O) a(O) good(B-Rating) chinese(B-Cuisine) buffet(B-Amenity) within(B-Location) 3(I-Location) miles(I-Location) from(O) me(O)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Amenity","Cuisine","Restaurant Name","Price","Hours","Dish","Rating","Location"],"instance":{"id":"120","words":["can","i","find","any","restaurants","close","by","with","a","meal","under","8"],"labels":["O","O","O","O","O","B-Location","I-Location","O","O","B-Price","I-Price","I-Price"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Cuisine, Restaurant Name, Price, Hours, Dish, Rating, Location and O.\nSentence: can i find any restaurants close by with a meal under 8","prompt_labels":"can(O) i(O) find(O) any(O) restaurants(O) close(B-Location) by(I-Location) with(O) a(O) meal(B-Price) under(I-Price) 8(I-Price)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Cuisine","Rating","Hours","Location","Amenity","Dish","Restaurant Name","Price"],"instance":{"id":"121","words":["can","i","find","good","portugues"],"labels":["O","O","O","B-Rating","B-Cuisine"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Rating, Hours, Location, Amenity, Dish, Restaurant Name, Price and O.\nSentence: can i find good portugues","prompt_labels":"can(O) i(O) find(O) good(B-Rating) portugues(B-Cuisine)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Dish","Amenity","Hours","Cuisine","Rating","Location","Restaurant Name","Price"],"instance":{"id":"122","words":["can","i","get","a","chefands","table","on","north","bedford","street","very","late","at","night"],"labels":["O","O","O","O","B-Amenity","I-Amenity","O","B-Location","I-Location","I-Location","B-Hours","I-Hours","I-Hours","I-Hours"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Dish, Amenity, Hours, Cuisine, Rating, Location, Restaurant Name, Price and O.\nSentence: can i get a chefands table on north bedford street very late at night","prompt_labels":"can(O) i(O) get(O) a(O) chefands(B-Amenity) table(I-Amenity) on(O) north(B-Location) bedford(I-Location) street(I-Location) very(B-Hours) late(I-Hours) at(I-Hours) night(I-Hours)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Restaurant Name","Rating","Location","Price","Amenity","Cuisine","Hours","Dish"],"instance":{"id":"123","words":["can","i","get","a","list","of","close","fast","food","places"],"labels":["O","O","O","O","O","O","B-Location","B-Cuisine","I-Cuisine","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Rating, Location, Price, Amenity, Cuisine, Hours, Dish and O.\nSentence: can i get a list of close fast food places","prompt_labels":"can(O) i(O) get(O) a(O) list(O) of(O) close(B-Location) fast(B-Cuisine) food(I-Cuisine) places(O)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Hours","Dish","Cuisine","Price","Location","Restaurant Name","Rating","Amenity"],"instance":{"id":"124","words":["can","i","get","gluten","free","pizza","within","10","miles","of","here"],"labels":["O","O","O","B-Dish","I-Dish","I-Dish","B-Location","I-Location","I-Location","I-Location","I-Location"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Dish, Cuisine, Price, Location, Restaurant Name, Rating, Amenity and O.\nSentence: can i get gluten free pizza within 10 miles of here","prompt_labels":"can(O) i(O) get(O) gluten(B-Dish) free(I-Dish) pizza(I-Dish) within(B-Location) 10(I-Location) miles(I-Location) of(I-Location) here(I-Location)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Amenity","Hours","Dish","Cuisine","Location","Rating","Price","Restaurant Name"],"instance":{"id":"125","words":["can","i","get","hambers","at","lone","star"],"labels":["O","O","O","B-Dish","O","B-Restaurant Name","I-Restaurant Name"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Hours, Dish, Cuisine, Location, Rating, Price, Restaurant Name and O.\nSentence: can i get hambers at lone star","prompt_labels":"can(O) i(O) get(O) hambers(B-Dish) at(O) lone(B-Restaurant Name) star(I-Restaurant Name)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Dish","Restaurant Name","Rating","Location","Cuisine","Price","Amenity","Hours"],"instance":{"id":"126","words":["can","i","get","raw","vegan","food","in","honolulu"],"labels":["O","O","O","B-Cuisine","I-Cuisine","O","O","B-Location"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Dish, Restaurant Name, Rating, Location, Cuisine, Price, Amenity, Hours and O.\nSentence: can i get raw vegan food in honolulu","prompt_labels":"can(O) i(O) get(O) raw(B-Cuisine) vegan(I-Cuisine) food(O) in(O) honolulu(B-Location)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Rating","Amenity","Restaurant Name","Hours","Location","Price","Dish","Cuisine"],"instance":{"id":"127","words":["can","i","get","sushi","on","a","prix","fixe","menu","with","reasonable","prices"],"labels":["O","O","O","B-Dish","O","O","B-Amenity","I-Amenity","I-Amenity","O","B-Price","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Rating, Amenity, Restaurant Name, Hours, Location, Price, Dish, Cuisine and O.\nSentence: can i get sushi on a prix fixe menu with reasonable prices","prompt_labels":"can(O) i(O) get(O) sushi(B-Dish) on(O) a(O) prix(B-Amenity) fixe(I-Amenity) menu(I-Amenity) with(O) reasonable(B-Price) prices(O)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Location","Amenity","Hours","Cuisine","Dish","Restaurant Name","Rating","Price"],"instance":{"id":"128","words":["can","i","have","the","phone","number","for","kfc","in","los","angeles","ca"],"labels":["O","O","O","O","O","O","O","B-Restaurant Name","O","B-Location","I-Location","I-Location"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Location, Amenity, Hours, Cuisine, Dish, Restaurant Name, Rating, Price and O.\nSentence: can i have the phone number for kfc in los angeles ca","prompt_labels":"can(O) i(O) have(O) the(O) phone(O) number(O) for(O) kfc(B-Restaurant Name) in(O) los(B-Location) angeles(I-Location) ca(I-Location)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Hours","Price","Restaurant Name","Dish","Rating","Amenity","Location","Cuisine"],"instance":{"id":"129","words":["can","i","see","hamburger","restaurants","nearby"],"labels":["O","O","O","B-Dish","O","B-Location"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Price, Restaurant Name, Dish, Rating, Amenity, Location, Cuisine and O.\nSentence: can i see hamburger restaurants nearby","prompt_labels":"can(O) i(O) see(O) hamburger(B-Dish) restaurants(O) nearby(B-Location)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Location","Dish","Hours","Amenity","Cuisine","Price","Restaurant Name","Rating"],"instance":{"id":"130","words":["can","i","valet","park","at","the","blue","coyote","grill"],"labels":["O","O","B-Amenity","I-Amenity","O","O","B-Restaurant Name","I-Restaurant Name","I-Restaurant Name"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Location, Dish, Hours, Amenity, Cuisine, Price, Restaurant Name, Rating and O.\nSentence: can i valet park at the blue coyote grill","prompt_labels":"can(O) i(O) valet(B-Amenity) park(I-Amenity) at(O) the(O) blue(B-Restaurant Name) coyote(I-Restaurant Name) grill(I-Restaurant Name)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Restaurant Name","Rating","Location","Cuisine","Hours","Dish","Amenity","Price"],"instance":{"id":"131","words":["can","i","wear","shorts"],"labels":["O","O","B-Amenity","I-Amenity"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Rating, Location, Cuisine, Hours, Dish, Amenity, Price and O.\nSentence: can i wear shorts","prompt_labels":"can(O) i(O) wear(B-Amenity) shorts(I-Amenity)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Cuisine","Amenity","Restaurant Name","Rating","Dish","Price","Hours","Location"],"instance":{"id":"132","words":["can","you","find","a","bar","that","serves","tapas","and","takes","reservations","for","happy","hour"],"labels":["O","O","O","O","B-Amenity","O","O","B-Dish","O","O","B-Amenity","O","B-Amenity","I-Amenity"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Amenity, Restaurant Name, Rating, Dish, Price, Hours, Location and O.\nSentence: can you find a bar that serves tapas and takes reservations for happy hour","prompt_labels":"can(O) you(O) find(O) a(O) bar(B-Amenity) that(O) serves(O) tapas(B-Dish) and(O) takes(O) reservations(B-Amenity) for(O) happy(B-Amenity) hour(I-Amenity)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Restaurant Name","Location","Hours","Cuisine","Rating","Price","Dish","Amenity"],"instance":{"id":"133","words":["can","you","find","a","burger","joint","with","a","smoking","section"],"labels":["O","O","O","O","B-Cuisine","I-Cuisine","O","O","B-Amenity","I-Amenity"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Location, Hours, Cuisine, Rating, Price, Dish, Amenity and O.\nSentence: can you find a burger joint with a smoking section","prompt_labels":"can(O) you(O) find(O) a(O) burger(B-Cuisine) joint(I-Cuisine) with(O) a(O) smoking(B-Amenity) section(I-Amenity)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Rating","Restaurant Name","Amenity","Hours","Location","Price","Cuisine","Dish"],"instance":{"id":"134","words":["can","you","find","a","cheap","vietnamese","restaurant"],"labels":["O","O","O","O","B-Price","B-Cuisine","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Rating, Restaurant Name, Amenity, Hours, Location, Price, Cuisine, Dish and O.\nSentence: can you find a cheap vietnamese restaurant","prompt_labels":"can(O) you(O) find(O) a(O) cheap(B-Price) vietnamese(B-Cuisine) restaurant(O)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Rating","Dish","Hours","Location","Cuisine","Restaurant Name","Price","Amenity"],"instance":{"id":"135","words":["can","you","find","a","fast","food","restaurant"],"labels":["O","O","O","O","B-Cuisine","I-Cuisine","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Rating, Dish, Hours, Location, Cuisine, Restaurant Name, Price, Amenity and O.\nSentence: can you find a fast food restaurant","prompt_labels":"can(O) you(O) find(O) a(O) fast(B-Cuisine) food(I-Cuisine) restaurant(O)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Hours","Cuisine","Price","Amenity","Restaurant Name","Location","Rating","Dish"],"instance":{"id":"136","words":["can","you","find","a","highly","rated","long","john","silvers","open","this","late"],"labels":["O","O","O","O","B-Rating","I-Rating","B-Restaurant Name","I-Restaurant Name","I-Restaurant Name","B-Hours","I-Hours","I-Hours"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Cuisine, Price, Amenity, Restaurant Name, Location, Rating, Dish and O.\nSentence: can you find a highly rated long john silvers open this late","prompt_labels":"can(O) you(O) find(O) a(O) highly(B-Rating) rated(I-Rating) long(B-Restaurant Name) john(I-Restaurant Name) silvers(I-Restaurant Name) open(B-Hours) this(I-Hours) late(I-Hours)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Price","Cuisine","Rating","Amenity","Location","Restaurant Name","Dish","Hours"],"instance":{"id":"137","words":["can","you","find","a","middle","eastern","place","with","great","prices"],"labels":["O","O","O","O","B-Cuisine","I-Cuisine","O","O","B-Price","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Cuisine, Rating, Amenity, Location, Restaurant Name, Dish, Hours and O.\nSentence: can you find a middle eastern place with great prices","prompt_labels":"can(O) you(O) find(O) a(O) middle(B-Cuisine) eastern(I-Cuisine) place(O) with(O) great(B-Price) prices(O)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Rating","Dish","Hours","Amenity","Location","Price","Restaurant Name","Cuisine"],"instance":{"id":"138","words":["can","you","find","a","pizza","place","with","a","buffet","within","15","miles"],"labels":["O","O","O","O","B-Cuisine","O","O","O","B-Amenity","B-Location","I-Location","I-Location"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Rating, Dish, Hours, Amenity, Location, Price, Restaurant Name, Cuisine and O.\nSentence: can you find a pizza place with a buffet within 15 miles","prompt_labels":"can(O) you(O) find(O) a(O) pizza(B-Cuisine) place(O) with(O) a(O) buffet(B-Amenity) within(B-Location) 15(I-Location) miles(I-Location)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Restaurant Name","Hours","Amenity","Location","Dish","Price","Rating","Cuisine"],"instance":{"id":"139","words":["can","you","find","a","pub","downtown"],"labels":["O","O","O","O","B-Cuisine","B-Location"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Hours, Amenity, Location, Dish, Price, Rating, Cuisine and O.\nSentence: can you find a pub downtown","prompt_labels":"can(O) you(O) find(O) a(O) pub(B-Cuisine) downtown(B-Location)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Price","Cuisine","Rating","Hours","Amenity","Dish","Location","Restaurant Name"],"instance":{"id":"140","words":["can","you","find","a","restaurant","that","serves","bean","soup","in","the","morning","and","isnt","too","expensive"],"labels":["O","O","O","O","O","O","O","B-Dish","I-Dish","O","O","B-Hours","O","B-Price","I-Price","I-Price"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Cuisine, Rating, Hours, Amenity, Dish, Location, Restaurant Name and O.\nSentence: can you find a restaurant that serves bean soup in the morning and isnt too expensive","prompt_labels":"can(O) you(O) find(O) a(O) restaurant(O) that(O) serves(O) bean(B-Dish) soup(I-Dish) in(O) the(O) morning(B-Hours) and(O) isnt(B-Price) too(I-Price) expensive(I-Price)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Rating","Price","Location","Cuisine","Restaurant Name","Hours","Amenity","Dish"],"instance":{"id":"141","words":["can","you","find","a","restaurant","that","serves","duck","that","not","cheap","near","here"],"labels":["O","O","O","O","O","O","O","B-Dish","O","B-Price","I-Price","B-Location","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Rating, Price, Location, Cuisine, Restaurant Name, Hours, Amenity, Dish and O.\nSentence: can you find a restaurant that serves duck that not cheap near here","prompt_labels":"can(O) you(O) find(O) a(O) restaurant(O) that(O) serves(O) duck(B-Dish) that(O) not(B-Price) cheap(I-Price) near(B-Location) here(O)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Dish","Price","Cuisine","Restaurant Name","Location","Amenity","Hours","Rating"],"instance":{"id":"142","words":["can","you","find","a","restaurant","under","20","per","dish"],"labels":["O","O","O","O","O","B-Price","I-Price","I-Price","I-Price"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Dish, Price, Cuisine, Restaurant Name, Location, Amenity, Hours, Rating and O.\nSentence: can you find a restaurant under 20 per dish","prompt_labels":"can(O) you(O) find(O) a(O) restaurant(O) under(B-Price) 20(I-Price) per(I-Price) dish(I-Price)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Hours","Dish","Location","Cuisine","Price","Rating","Restaurant Name","Amenity"],"instance":{"id":"143","words":["can","you","find","a","seafood","restaurant"],"labels":["O","O","O","O","B-Cuisine","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Dish, Location, Cuisine, Price, Rating, Restaurant Name, Amenity and O.\nSentence: can you find a seafood restaurant","prompt_labels":"can(O) you(O) find(O) a(O) seafood(B-Cuisine) restaurant(O)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Location","Restaurant Name","Price","Hours","Amenity","Rating","Dish","Cuisine"],"instance":{"id":"144","words":["can","you","find","a","site","where","i","can","see","reviews","on","restaurant","downtown"],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","B-Location"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Location, Restaurant Name, Price, Hours, Amenity, Rating, Dish, Cuisine and O.\nSentence: can you find a site where i can see reviews on restaurant downtown","prompt_labels":"can(O) you(O) find(O) a(O) site(O) where(O) i(O) can(O) see(O) reviews(O) on(O) restaurant(O) downtown(B-Location)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Location","Cuisine","Rating","Hours","Restaurant Name","Amenity","Price","Dish"],"instance":{"id":"145","words":["can","you","find","a","steak","house","that","serves","wine"],"labels":["O","O","O","O","B-Cuisine","I-Cuisine","O","O","B-Dish"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Location, Cuisine, Rating, Hours, Restaurant Name, Amenity, Price, Dish and O.\nSentence: can you find a steak house that serves wine","prompt_labels":"can(O) you(O) find(O) a(O) steak(B-Cuisine) house(I-Cuisine) that(O) serves(O) wine(B-Dish)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Rating","Restaurant Name","Hours","Location","Amenity","Price","Dish","Cuisine"],"instance":{"id":"146","words":["can","you","find","a","thai","japanese","fusion","restaurant","in","town"],"labels":["O","O","O","O","B-Cuisine","I-Cuisine","I-Cuisine","O","B-Location","I-Location"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Rating, Restaurant Name, Hours, Location, Amenity, Price, Dish, Cuisine and O.\nSentence: can you find a thai japanese fusion restaurant in town","prompt_labels":"can(O) you(O) find(O) a(O) thai(B-Cuisine) japanese(I-Cuisine) fusion(I-Cuisine) restaurant(O) in(B-Location) town(I-Location)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Price","Dish","Rating","Location","Hours","Amenity","Cuisine","Restaurant Name"],"instance":{"id":"147","words":["can","you","find","an","italian","restaurant","nearby"],"labels":["O","O","O","O","B-Cuisine","O","B-Location"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Dish, Rating, Location, Hours, Amenity, Cuisine, Restaurant Name and O.\nSentence: can you find an italian restaurant nearby","prompt_labels":"can(O) you(O) find(O) an(O) italian(B-Cuisine) restaurant(O) nearby(B-Location)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Rating","Restaurant Name","Dish","Amenity","Price","Cuisine","Hours","Location"],"instance":{"id":"148","words":["can","you","find","an","italian","restaurant","that","serves","brunch","on","sunday"],"labels":["O","O","O","O","B-Cuisine","O","O","O","B-Hours","O","B-Hours"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Rating, Restaurant Name, Dish, Amenity, Price, Cuisine, Hours, Location and O.\nSentence: can you find an italian restaurant that serves brunch on sunday","prompt_labels":"can(O) you(O) find(O) an(O) italian(B-Cuisine) restaurant(O) that(O) serves(O) brunch(B-Hours) on(O) sunday(B-Hours)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Hours","Amenity","Dish","Rating","Cuisine","Price","Restaurant Name","Location"],"instance":{"id":"149","words":["can","you","find","an","italian","restaurant","where","i","can","wear","casual","atire"],"labels":["O","O","O","O","B-Cuisine","O","O","O","O","O","B-Amenity","I-Amenity"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Amenity, Dish, Rating, Cuisine, Price, Restaurant Name, Location and O.\nSentence: can you find an italian restaurant where i can wear casual atire","prompt_labels":"can(O) you(O) find(O) an(O) italian(B-Cuisine) restaurant(O) where(O) i(O) can(O) wear(O) casual(B-Amenity) atire(I-Amenity)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Dish","Cuisine","Hours","Amenity","Rating","Price","Restaurant Name","Location"],"instance":{"id":"150","words":["can","you","find","east","dedham","pizzeria","that","have","a","dine","at","bar","location"],"labels":["O","O","O","B-Restaurant Name","B-Location","B-Cuisine","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Dish, Cuisine, Hours, Amenity, Rating, Price, Restaurant Name, Location and O.\nSentence: can you find east dedham pizzeria that have a dine at bar location","prompt_labels":"can(O) you(O) find(O) east(B-Restaurant Name) dedham(B-Location) pizzeria(B-Cuisine) that(O) have(O) a(O) dine(O) at(O) bar(O) location(O)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Price","Amenity","Restaurant Name","Dish","Rating","Hours","Location","Cuisine"],"instance":{"id":"151","words":["can","you","find","latin","american","cuisine","within","a","hotel","along","the","way"],"labels":["O","O","O","B-Cuisine","I-Cuisine","O","B-Location","I-Location","I-Location","I-Location","I-Location","I-Location"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Amenity, Restaurant Name, Dish, Rating, Hours, Location, Cuisine and O.\nSentence: can you find latin american cuisine within a hotel along the way","prompt_labels":"can(O) you(O) find(O) latin(B-Cuisine) american(I-Cuisine) cuisine(O) within(B-Location) a(I-Location) hotel(I-Location) along(I-Location) the(I-Location) way(I-Location)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Rating","Location","Dish","Amenity","Hours","Cuisine","Restaurant Name","Price"],"instance":{"id":"152","words":["can","you","find","me","a","burmese","restaurant","with","a","parking","spot"],"labels":["O","O","O","O","O","B-Cuisine","O","O","O","B-Amenity","I-Amenity"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Rating, Location, Dish, Amenity, Hours, Cuisine, Restaurant Name, Price and O.\nSentence: can you find me a burmese restaurant with a parking spot","prompt_labels":"can(O) you(O) find(O) me(O) a(O) burmese(B-Cuisine) restaurant(O) with(O) a(O) parking(B-Amenity) spot(I-Amenity)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Restaurant Name","Hours","Dish","Rating","Amenity","Price","Cuisine","Location"],"instance":{"id":"153","words":["can","you","find","me","a","fredas","thats","not","too","busy"],"labels":["O","O","O","O","O","B-Restaurant Name","O","B-Amenity","I-Amenity","I-Amenity"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Hours, Dish, Rating, Amenity, Price, Cuisine, Location and O.\nSentence: can you find me a fredas thats not too busy","prompt_labels":"can(O) you(O) find(O) me(O) a(O) fredas(B-Restaurant Name) thats(O) not(B-Amenity) too(I-Amenity) busy(I-Amenity)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Restaurant Name","Amenity","Rating","Cuisine","Location","Dish","Price","Hours"],"instance":{"id":"154","words":["can","you","find","me","a","good","place","to","eat","chowder"],"labels":["O","O","O","O","O","B-Rating","O","O","O","B-Dish"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Amenity, Rating, Cuisine, Location, Dish, Price, Hours and O.\nSentence: can you find me a good place to eat chowder","prompt_labels":"can(O) you(O) find(O) me(O) a(O) good(B-Rating) place(O) to(O) eat(O) chowder(B-Dish)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Location","Dish","Cuisine","Amenity","Hours","Rating","Price","Restaurant Name"],"instance":{"id":"155","words":["can","you","find","me","a","kid","friendly","seafood","restaurant"],"labels":["O","O","O","O","O","B-Amenity","I-Amenity","B-Cuisine","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Location, Dish, Cuisine, Amenity, Hours, Rating, Price, Restaurant Name and O.\nSentence: can you find me a kid friendly seafood restaurant","prompt_labels":"can(O) you(O) find(O) me(O) a(O) kid(B-Amenity) friendly(I-Amenity) seafood(B-Cuisine) restaurant(O)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Amenity","Rating","Dish","Price","Cuisine","Hours","Location","Restaurant Name"],"instance":{"id":"156","words":["can","you","find","me","a","kid","friendly","sushi","restaurant"],"labels":["O","O","O","O","O","B-Amenity","I-Amenity","B-Cuisine","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Rating, Dish, Price, Cuisine, Hours, Location, Restaurant Name and O.\nSentence: can you find me a kid friendly sushi restaurant","prompt_labels":"can(O) you(O) find(O) me(O) a(O) kid(B-Amenity) friendly(I-Amenity) sushi(B-Cuisine) restaurant(O)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Price","Location","Cuisine","Dish","Restaurant Name","Hours","Amenity","Rating"],"instance":{"id":"157","words":["can","you","find","me","a","moderately","priced","italian","restaurant"],"labels":["O","O","O","O","O","B-Price","O","B-Cuisine","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Location, Cuisine, Dish, Restaurant Name, Hours, Amenity, Rating and O.\nSentence: can you find me a moderately priced italian restaurant","prompt_labels":"can(O) you(O) find(O) me(O) a(O) moderately(B-Price) priced(O) italian(B-Cuisine) restaurant(O)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Cuisine","Location","Hours","Amenity","Dish","Restaurant Name","Price","Rating"],"instance":{"id":"158","words":["can","you","find","me","a","nice","italian","restaurant","that","takes","reservations"],"labels":["O","O","O","O","O","B-Rating","B-Cuisine","O","O","O","B-Amenity"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Location, Hours, Amenity, Dish, Restaurant Name, Price, Rating and O.\nSentence: can you find me a nice italian restaurant that takes reservations","prompt_labels":"can(O) you(O) find(O) me(O) a(O) nice(B-Rating) italian(B-Cuisine) restaurant(O) that(O) takes(O) reservations(B-Amenity)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Price","Amenity","Restaurant Name","Dish","Rating","Hours","Cuisine","Location"],"instance":{"id":"159","words":["can","you","find","me","a","not","cheap","lunch","spot","that","serves","pasteur"],"labels":["O","O","O","O","O","B-Price","I-Price","B-Hours","O","O","O","B-Dish"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Amenity, Restaurant Name, Dish, Rating, Hours, Cuisine, Location and O.\nSentence: can you find me a not cheap lunch spot that serves pasteur","prompt_labels":"can(O) you(O) find(O) me(O) a(O) not(B-Price) cheap(I-Price) lunch(B-Hours) spot(O) that(O) serves(O) pasteur(B-Dish)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Price","Hours","Dish","Restaurant Name","Rating","Amenity","Location","Cuisine"],"instance":{"id":"160","words":["can","you","find","me","a","pizza","place"],"labels":["O","O","O","O","O","B-Dish","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Hours, Dish, Restaurant Name, Rating, Amenity, Location, Cuisine and O.\nSentence: can you find me a pizza place","prompt_labels":"can(O) you(O) find(O) me(O) a(O) pizza(B-Dish) place(O)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Amenity","Rating","Restaurant Name","Hours","Dish","Location","Price","Cuisine"],"instance":{"id":"161","words":["can","you","find","me","a","pizzeria","that","delivers","after","midnight"],"labels":["O","O","O","O","O","B-Cuisine","O","B-Amenity","B-Hours","I-Hours"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Rating, Restaurant Name, Hours, Dish, Location, Price, Cuisine and O.\nSentence: can you find me a pizzeria that delivers after midnight","prompt_labels":"can(O) you(O) find(O) me(O) a(O) pizzeria(B-Cuisine) that(O) delivers(B-Amenity) after(B-Hours) midnight(I-Hours)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Dish","Hours","Restaurant Name","Rating","Location","Cuisine","Price","Amenity"],"instance":{"id":"162","words":["can","you","find","me","a","place","nearby","thats","open","after","12","pm","with","bean","dishes"],"labels":["O","O","O","O","O","O","B-Location","O","O","B-Hours","I-Hours","I-Hours","O","B-Dish","I-Dish"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Dish, Hours, Restaurant Name, Rating, Location, Cuisine, Price, Amenity and O.\nSentence: can you find me a place nearby thats open after 12 pm with bean dishes","prompt_labels":"can(O) you(O) find(O) me(O) a(O) place(O) nearby(B-Location) thats(O) open(O) after(B-Hours) 12(I-Hours) pm(I-Hours) with(O) bean(B-Dish) dishes(I-Dish)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Price","Restaurant Name","Dish","Location","Rating","Cuisine","Hours","Amenity"],"instance":{"id":"163","words":["can","you","find","me","a","place","that","serves","french","fries"],"labels":["O","O","O","O","O","O","O","O","B-Dish","I-Dish"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Restaurant Name, Dish, Location, Rating, Cuisine, Hours, Amenity and O.\nSentence: can you find me a place that serves french fries","prompt_labels":"can(O) you(O) find(O) me(O) a(O) place(O) that(O) serves(O) french(B-Dish) fries(I-Dish)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Amenity","Location","Price","Hours","Restaurant Name","Rating","Dish","Cuisine"],"instance":{"id":"164","words":["can","you","find","me","a","restaurant","that","has","a","bar","in","it"],"labels":["O","O","O","O","O","O","O","O","O","B-Amenity","I-Amenity","I-Amenity"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Location, Price, Hours, Restaurant Name, Rating, Dish, Cuisine and O.\nSentence: can you find me a restaurant that has a bar in it","prompt_labels":"can(O) you(O) find(O) me(O) a(O) restaurant(O) that(O) has(O) a(O) bar(B-Amenity) in(I-Amenity) it(I-Amenity)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Amenity","Dish","Restaurant Name","Rating","Cuisine","Price","Location","Hours"],"instance":{"id":"165","words":["can","you","find","me","a","restaurant","that","has","entrees","priced","between","15","and","20","dollars"],"labels":["O","O","O","O","O","O","O","O","O","O","B-Price","I-Price","I-Price","I-Price","I-Price"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Dish, Restaurant Name, Rating, Cuisine, Price, Location, Hours and O.\nSentence: can you find me a restaurant that has entrees priced between 15 and 20 dollars","prompt_labels":"can(O) you(O) find(O) me(O) a(O) restaurant(O) that(O) has(O) entrees(O) priced(O) between(B-Price) 15(I-Price) and(I-Price) 20(I-Price) dollars(I-Price)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Cuisine","Dish","Rating","Price","Amenity","Hours","Restaurant Name","Location"],"instance":{"id":"166","words":["can","you","find","me","a","thai","restaurant","that","is","caual"],"labels":["O","O","O","O","O","B-Cuisine","O","O","O","B-Amenity"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Dish, Rating, Price, Amenity, Hours, Restaurant Name, Location and O.\nSentence: can you find me a thai restaurant that is caual","prompt_labels":"can(O) you(O) find(O) me(O) a(O) thai(B-Cuisine) restaurant(O) that(O) is(O) caual(B-Amenity)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Amenity","Location","Rating","Price","Restaurant Name","Cuisine","Dish","Hours"],"instance":{"id":"167","words":["can","you","find","me","chinese","restaurant","with","a","smoking","section"],"labels":["O","O","O","O","B-Cuisine","O","O","O","B-Amenity","I-Amenity"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Location, Rating, Price, Restaurant Name, Cuisine, Dish, Hours and O.\nSentence: can you find me chinese restaurant with a smoking section","prompt_labels":"can(O) you(O) find(O) me(O) chinese(B-Cuisine) restaurant(O) with(O) a(O) smoking(B-Amenity) section(I-Amenity)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Amenity","Price","Restaurant Name","Hours","Location","Dish","Cuisine","Rating"],"instance":{"id":"168","words":["can","you","find","me","hotel","dining","with","comfort","food"],"labels":["O","O","O","O","B-Restaurant Name","I-Restaurant Name","O","B-Cuisine","I-Cuisine"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Price, Restaurant Name, Hours, Location, Dish, Cuisine, Rating and O.\nSentence: can you find me hotel dining with comfort food","prompt_labels":"can(O) you(O) find(O) me(O) hotel(B-Restaurant Name) dining(I-Restaurant Name) with(O) comfort(B-Cuisine) food(I-Cuisine)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Hours","Amenity","Cuisine","Rating","Dish","Restaurant Name","Location","Price"],"instance":{"id":"169","words":["can","you","find","me","some","malaysian","food","late","at","night"],"labels":["O","O","O","O","O","B-Cuisine","O","B-Hours","I-Hours","I-Hours"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Amenity, Cuisine, Rating, Dish, Restaurant Name, Location, Price and O.\nSentence: can you find me some malaysian food late at night","prompt_labels":"can(O) you(O) find(O) me(O) some(O) malaysian(B-Cuisine) food(O) late(B-Hours) at(I-Hours) night(I-Hours)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Dish","Cuisine","Restaurant Name","Hours","Rating","Price","Location","Amenity"],"instance":{"id":"170","words":["can","you","find","me","some","take","out","ribs"],"labels":["O","O","O","O","O","B-Amenity","I-Amenity","B-Dish"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Dish, Cuisine, Restaurant Name, Hours, Rating, Price, Location, Amenity and O.\nSentence: can you find me some take out ribs","prompt_labels":"can(O) you(O) find(O) me(O) some(O) take(B-Amenity) out(I-Amenity) ribs(B-Dish)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Rating","Amenity","Price","Restaurant Name","Dish","Cuisine","Location","Hours"],"instance":{"id":"171","words":["can","you","find","out","if","the","best","little","restaurant","has","dancing","and","a","good","looking","atmosphere"],"labels":["O","O","O","O","O","O","B-Restaurant Name","I-Restaurant Name","I-Restaurant Name","O","B-Amenity","O","O","B-Amenity","I-Amenity","I-Amenity"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Rating, Amenity, Price, Restaurant Name, Dish, Cuisine, Location, Hours and O.\nSentence: can you find out if the best little restaurant has dancing and a good looking atmosphere","prompt_labels":"can(O) you(O) find(O) out(O) if(O) the(O) best(B-Restaurant Name) little(I-Restaurant Name) restaurant(I-Restaurant Name) has(O) dancing(B-Amenity) and(O) a(O) good(B-Amenity) looking(I-Amenity) atmosphere(I-Amenity)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Cuisine","Amenity","Rating","Location","Hours","Dish","Price","Restaurant Name"],"instance":{"id":"172","words":["can","you","find","starting","gate","restaurant","thats","hard","to","find","with","a","huge","price"],"labels":["O","O","O","B-Restaurant Name","I-Restaurant Name","I-Restaurant Name","O","O","O","O","O","O","B-Price","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Amenity, Rating, Location, Hours, Dish, Price, Restaurant Name and O.\nSentence: can you find starting gate restaurant thats hard to find with a huge price","prompt_labels":"can(O) you(O) find(O) starting(B-Restaurant Name) gate(I-Restaurant Name) restaurant(I-Restaurant Name) thats(O) hard(O) to(O) find(O) with(O) a(O) huge(B-Price) price(O)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Amenity","Restaurant Name","Cuisine","Rating","Hours","Location","Price","Dish"],"instance":{"id":"173","words":["can","you","find","the","closest","ihop"],"labels":["O","O","O","O","B-Location","B-Restaurant Name"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Restaurant Name, Cuisine, Rating, Hours, Location, Price, Dish and O.\nSentence: can you find the closest ihop","prompt_labels":"can(O) you(O) find(O) the(O) closest(B-Location) ihop(B-Restaurant Name)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Rating","Hours","Cuisine","Amenity","Dish","Price","Restaurant Name","Location"],"instance":{"id":"174","words":["can","you","find","the","nearest","health","food","store","and","bar"],"labels":["O","O","O","O","B-Location","B-Cuisine","I-Cuisine","I-Cuisine","O","B-Cuisine"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Rating, Hours, Cuisine, Amenity, Dish, Price, Restaurant Name, Location and O.\nSentence: can you find the nearest health food store and bar","prompt_labels":"can(O) you(O) find(O) the(O) nearest(B-Location) health(B-Cuisine) food(I-Cuisine) store(I-Cuisine) and(O) bar(B-Cuisine)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Hours","Price","Rating","Cuisine","Dish","Location","Amenity","Restaurant Name"],"instance":{"id":"175","words":["can","you","find","the","waterfront","restaurant","albertos","deli","of","course","thats","open","until","11","pm"],"labels":["O","O","O","O","B-Location","O","B-Restaurant Name","I-Restaurant Name","O","O","O","B-Hours","I-Hours","I-Hours","I-Hours"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Price, Rating, Cuisine, Dish, Location, Amenity, Restaurant Name and O.\nSentence: can you find the waterfront restaurant albertos deli of course thats open until 11 pm","prompt_labels":"can(O) you(O) find(O) the(O) waterfront(B-Location) restaurant(O) albertos(B-Restaurant Name) deli(I-Restaurant Name) of(O) course(O) thats(O) open(B-Hours) until(I-Hours) 11(I-Hours) pm(I-Hours)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Hours","Price","Cuisine","Dish","Amenity","Location","Restaurant Name","Rating"],"instance":{"id":"176","words":["can","you","find","us","an","ice","cream","shop","near","haight","street"],"labels":["O","O","O","O","O","B-Cuisine","I-Cuisine","O","B-Location","I-Location","I-Location"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Price, Cuisine, Dish, Amenity, Location, Restaurant Name, Rating and O.\nSentence: can you find us an ice cream shop near haight street","prompt_labels":"can(O) you(O) find(O) us(O) an(O) ice(B-Cuisine) cream(I-Cuisine) shop(O) near(B-Location) haight(I-Location) street(I-Location)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Location","Cuisine","Dish","Restaurant Name","Hours","Amenity","Rating","Price"],"instance":{"id":"177","words":["can","you","get","me","a","list","of","chinese","food","places","in","great","neck","ny"],"labels":["O","O","O","O","O","O","O","B-Cuisine","O","O","O","B-Location","I-Location","I-Location"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Location, Cuisine, Dish, Restaurant Name, Hours, Amenity, Rating, Price and O.\nSentence: can you get me a list of chinese food places in great neck ny","prompt_labels":"can(O) you(O) get(O) me(O) a(O) list(O) of(O) chinese(B-Cuisine) food(O) places(O) in(O) great(B-Location) neck(I-Location) ny(I-Location)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Hours","Rating","Cuisine","Location","Restaurant Name","Amenity","Dish","Price"],"instance":{"id":"178","words":["can","you","get","pork","in","chinatown"],"labels":["O","O","O","B-Dish","O","B-Location"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Rating, Cuisine, Location, Restaurant Name, Amenity, Dish, Price and O.\nSentence: can you get pork in chinatown","prompt_labels":"can(O) you(O) get(O) pork(B-Dish) in(O) chinatown(B-Location)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Amenity","Rating","Location","Hours","Restaurant Name","Dish","Price","Cuisine"],"instance":{"id":"179","words":["can","you","give","me","the","name","of","the","restaurant","on","green","st"],"labels":["O","O","O","O","O","B-Restaurant Name","O","O","O","O","B-Location","I-Location"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Rating, Location, Hours, Restaurant Name, Dish, Price, Cuisine and O.\nSentence: can you give me the name of the restaurant on green st","prompt_labels":"can(O) you(O) give(O) me(O) the(O) name(B-Restaurant Name) of(O) the(O) restaurant(O) on(O) green(B-Location) st(I-Location)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Cuisine","Location","Restaurant Name","Price","Rating","Amenity","Dish","Hours"],"instance":{"id":"180","words":["can","you","give","me","the","phone","number","for","the","nearest","mexican","restaurant","that","is","both","affordable","and","has","good","quality","food"],"labels":["O","O","O","O","O","O","O","O","O","B-Location","B-Cuisine","O","O","O","O","B-Price","O","O","B-Rating","I-Rating","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Location, Restaurant Name, Price, Rating, Amenity, Dish, Hours and O.\nSentence: can you give me the phone number for the nearest mexican restaurant that is both affordable and has good quality food","prompt_labels":"can(O) you(O) give(O) me(O) the(O) phone(O) number(O) for(O) the(O) nearest(B-Location) mexican(B-Cuisine) restaurant(O) that(O) is(O) both(O) affordable(B-Price) and(O) has(O) good(B-Rating) quality(I-Rating) food(O)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Location","Amenity","Hours","Cuisine","Dish","Restaurant Name","Rating","Price"],"instance":{"id":"181","words":["can","you","help","me","find","a","fancy","restaurant","with","5","star","ratings"],"labels":["O","O","O","O","O","O","B-Amenity","O","O","B-Rating","I-Rating","I-Rating"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Location, Amenity, Hours, Cuisine, Dish, Restaurant Name, Rating, Price and O.\nSentence: can you help me find a fancy restaurant with 5 star ratings","prompt_labels":"can(O) you(O) help(O) me(O) find(O) a(O) fancy(B-Amenity) restaurant(O) with(O) 5(B-Rating) star(I-Rating) ratings(I-Rating)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Hours","Rating","Cuisine","Restaurant Name","Price","Dish","Amenity","Location"],"instance":{"id":"182","words":["can","you","help","me","find","a","high","end","restaurant","where","i","can","have","lunch"],"labels":["O","O","O","O","O","O","B-Price","I-Price","O","O","O","O","O","B-Amenity"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Rating, Cuisine, Restaurant Name, Price, Dish, Amenity, Location and O.\nSentence: can you help me find a high end restaurant where i can have lunch","prompt_labels":"can(O) you(O) help(O) me(O) find(O) a(O) high(B-Price) end(I-Price) restaurant(O) where(O) i(O) can(O) have(O) lunch(B-Amenity)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Restaurant Name","Dish","Price","Amenity","Location","Rating","Hours","Cuisine"],"instance":{"id":"183","words":["can","you","help","me","find","a","korean","restaurant","that","is","close","by"],"labels":["O","O","O","O","O","O","B-Cuisine","O","O","O","B-Location","I-Location"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Dish, Price, Amenity, Location, Rating, Hours, Cuisine and O.\nSentence: can you help me find a korean restaurant that is close by","prompt_labels":"can(O) you(O) help(O) me(O) find(O) a(O) korean(B-Cuisine) restaurant(O) that(O) is(O) close(B-Location) by(I-Location)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Amenity","Hours","Location","Cuisine","Rating","Price","Dish","Restaurant Name"],"instance":{"id":"184","words":["can","you","help","me","find","a","reasonably","priced","harvard","chinese","restaurant","that","lets","you","byob"],"labels":["O","O","O","O","O","O","B-Price","O","B-Location","B-Cuisine","O","O","O","O","B-Amenity"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Hours, Location, Cuisine, Rating, Price, Dish, Restaurant Name and O.\nSentence: can you help me find a reasonably priced harvard chinese restaurant that lets you byob","prompt_labels":"can(O) you(O) help(O) me(O) find(O) a(O) reasonably(B-Price) priced(O) harvard(B-Location) chinese(B-Cuisine) restaurant(O) that(O) lets(O) you(O) byob(B-Amenity)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Restaurant Name","Cuisine","Amenity","Hours","Location","Price","Rating","Dish"],"instance":{"id":"185","words":["can","you","help","me","find","a","restaurant","that","has","fast","service","and","is","open","before","11","am"],"labels":["O","O","O","O","O","O","O","O","O","B-Amenity","I-Amenity","O","O","B-Hours","I-Hours","I-Hours","I-Hours"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Cuisine, Amenity, Hours, Location, Price, Rating, Dish and O.\nSentence: can you help me find a restaurant that has fast service and is open before 11 am","prompt_labels":"can(O) you(O) help(O) me(O) find(O) a(O) restaurant(O) that(O) has(O) fast(B-Amenity) service(I-Amenity) and(O) is(O) open(B-Hours) before(I-Hours) 11(I-Hours) am(I-Hours)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Rating","Hours","Cuisine","Amenity","Location","Price","Dish","Restaurant Name"],"instance":{"id":"186","words":["can","you","help","me","find","a","tong","villa","that","serves","small","portions"],"labels":["O","O","O","O","O","O","B-Restaurant Name","I-Restaurant Name","O","O","B-Amenity","I-Amenity"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Rating, Hours, Cuisine, Amenity, Location, Price, Dish, Restaurant Name and O.\nSentence: can you help me find a tong villa that serves small portions","prompt_labels":"can(O) you(O) help(O) me(O) find(O) a(O) tong(B-Restaurant Name) villa(I-Restaurant Name) that(O) serves(O) small(B-Amenity) portions(I-Amenity)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Restaurant Name","Hours","Dish","Cuisine","Price","Rating","Amenity","Location"],"instance":{"id":"187","words":["can","you","help","me","find","inexpensive","dining","within","a","five","mile","radius","of","my","current","location"],"labels":["O","O","O","O","O","B-Price","O","B-Location","I-Location","I-Location","I-Location","I-Location","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Hours, Dish, Cuisine, Price, Rating, Amenity, Location and O.\nSentence: can you help me find inexpensive dining within a five mile radius of my current location","prompt_labels":"can(O) you(O) help(O) me(O) find(O) inexpensive(B-Price) dining(O) within(B-Location) a(I-Location) five(I-Location) mile(I-Location) radius(I-Location) of(O) my(O) current(O) location(O)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Amenity","Rating","Location","Hours","Dish","Price","Cuisine","Restaurant Name"],"instance":{"id":"188","words":["can","you","help","me","get","to","a","restaurant","where","i","can","get","lunch","for","under","10"],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","B-Hours","O","B-Price","I-Price"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Rating, Location, Hours, Dish, Price, Cuisine, Restaurant Name and O.\nSentence: can you help me get to a restaurant where i can get lunch for under 10","prompt_labels":"can(O) you(O) help(O) me(O) get(O) to(O) a(O) restaurant(O) where(O) i(O) can(O) get(O) lunch(B-Hours) for(O) under(B-Price) 10(I-Price)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Hours","Restaurant Name","Price","Amenity","Dish","Cuisine","Rating","Location"],"instance":{"id":"189","words":["can","you","locate","a","4","star","or","higher","restaurant","that","serves","italian","food"],"labels":["O","O","O","O","B-Rating","I-Rating","I-Rating","I-Rating","O","O","O","B-Cuisine","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Restaurant Name, Price, Amenity, Dish, Cuisine, Rating, Location and O.\nSentence: can you locate a 4 star or higher restaurant that serves italian food","prompt_labels":"can(O) you(O) locate(O) a(O) 4(B-Rating) star(I-Rating) or(I-Rating) higher(I-Rating) restaurant(O) that(O) serves(O) italian(B-Cuisine) food(O)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Hours","Amenity","Location","Restaurant Name","Cuisine","Dish","Price","Rating"],"instance":{"id":"190","words":["can","you","locate","a","chinese","buffet","for","under","12","within","a","five","minute","drive"],"labels":["O","O","O","O","B-Cuisine","B-Amenity","O","B-Price","I-Price","B-Location","I-Location","I-Location","I-Location","I-Location"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Amenity, Location, Restaurant Name, Cuisine, Dish, Price, Rating and O.\nSentence: can you locate a chinese buffet for under 12 within a five minute drive","prompt_labels":"can(O) you(O) locate(O) a(O) chinese(B-Cuisine) buffet(B-Amenity) for(O) under(B-Price) 12(I-Price) within(B-Location) a(I-Location) five(I-Location) minute(I-Location) drive(I-Location)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Price","Amenity","Hours","Rating","Location","Cuisine","Dish","Restaurant Name"],"instance":{"id":"191","words":["can","you","locate","a","diner","that","has","a","smoking","section","in","this","area"],"labels":["O","O","O","O","B-Cuisine","O","O","O","B-Amenity","I-Amenity","O","B-Location","I-Location"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Amenity, Hours, Rating, Location, Cuisine, Dish, Restaurant Name and O.\nSentence: can you locate a diner that has a smoking section in this area","prompt_labels":"can(O) you(O) locate(O) a(O) diner(B-Cuisine) that(O) has(O) a(O) smoking(B-Amenity) section(I-Amenity) in(O) this(B-Location) area(I-Location)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Rating","Amenity","Price","Dish","Cuisine","Hours","Location","Restaurant Name"],"instance":{"id":"192","words":["can","you","locate","a","restaurant","that","sell","burgers","after","12","00","am"],"labels":["O","O","O","O","O","O","O","B-Dish","O","B-Hours","I-Hours","I-Hours"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Rating, Amenity, Price, Dish, Cuisine, Hours, Location, Restaurant Name and O.\nSentence: can you locate a restaurant that sell burgers after 12 00 am","prompt_labels":"can(O) you(O) locate(O) a(O) restaurant(O) that(O) sell(O) burgers(B-Dish) after(O) 12(B-Hours) 00(I-Hours) am(I-Hours)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Amenity","Hours","Location","Price","Restaurant Name","Dish","Cuisine","Rating"],"instance":{"id":"193","words":["can","you","locate","the","business","hours","for","a","restaurant","that","serves","brunch"],"labels":["O","O","O","O","O","O","O","O","O","O","O","B-Hours"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Hours, Location, Price, Restaurant Name, Dish, Cuisine, Rating and O.\nSentence: can you locate the business hours for a restaurant that serves brunch","prompt_labels":"can(O) you(O) locate(O) the(O) business(O) hours(O) for(O) a(O) restaurant(O) that(O) serves(O) brunch(B-Hours)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Price","Location","Restaurant Name","Hours","Dish","Amenity","Rating","Cuisine"],"instance":{"id":"194","words":["can","you","make","a","reservation","at","pf","changs","for","tonight"],"labels":["O","O","O","O","O","O","B-Restaurant Name","I-Restaurant Name","O","B-Hours"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Location, Restaurant Name, Hours, Dish, Amenity, Rating, Cuisine and O.\nSentence: can you make a reservation at pf changs for tonight","prompt_labels":"can(O) you(O) make(O) a(O) reservation(O) at(O) pf(B-Restaurant Name) changs(I-Restaurant Name) for(O) tonight(B-Hours)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Amenity","Price","Cuisine","Rating","Restaurant Name","Location","Dish","Hours"],"instance":{"id":"195","words":["can","you","make","me","a","reservation","at","the","cheapest","restaurant","with","valet","parking"],"labels":["O","O","O","O","O","B-Amenity","O","O","B-Price","O","O","B-Amenity","I-Amenity"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Price, Cuisine, Rating, Restaurant Name, Location, Dish, Hours and O.\nSentence: can you make me a reservation at the cheapest restaurant with valet parking","prompt_labels":"can(O) you(O) make(O) me(O) a(O) reservation(B-Amenity) at(O) the(O) cheapest(B-Price) restaurant(O) with(O) valet(B-Amenity) parking(I-Amenity)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Hours","Rating","Restaurant Name","Amenity","Price","Location","Dish","Cuisine"],"instance":{"id":"196","words":["can","you","make","me","a","reservation","at","the","most","expensive","restaurant","within","15","miles"],"labels":["O","O","O","O","O","O","O","O","B-Price","I-Price","O","B-Location","I-Location","I-Location"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Rating, Restaurant Name, Amenity, Price, Location, Dish, Cuisine and O.\nSentence: can you make me a reservation at the most expensive restaurant within 15 miles","prompt_labels":"can(O) you(O) make(O) me(O) a(O) reservation(O) at(O) the(O) most(B-Price) expensive(I-Price) restaurant(O) within(B-Location) 15(I-Location) miles(I-Location)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Hours","Location","Price","Restaurant Name","Rating","Amenity","Dish","Cuisine"],"instance":{"id":"197","words":["can","you","make","me","a","reservation","for","4","at","the","nearest","upscale","steakhouse"],"labels":["O","O","O","O","O","O","O","O","O","O","B-Location","B-Price","B-Cuisine"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Location, Price, Restaurant Name, Rating, Amenity, Dish, Cuisine and O.\nSentence: can you make me a reservation for 4 at the nearest upscale steakhouse","prompt_labels":"can(O) you(O) make(O) me(O) a(O) reservation(O) for(O) 4(O) at(O) the(O) nearest(B-Location) upscale(B-Price) steakhouse(B-Cuisine)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Dish","Location","Cuisine","Rating","Amenity","Hours","Price","Restaurant Name"],"instance":{"id":"198","words":["can","you","make","me","a","reservation","for","todai","for","thursday","for","two","people"],"labels":["O","O","O","O","O","B-Cuisine","O","B-Cuisine","O","B-Restaurant Name","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Dish, Location, Cuisine, Rating, Amenity, Hours, Price, Restaurant Name and O.\nSentence: can you make me a reservation for todai for thursday for two people","prompt_labels":"can(O) you(O) make(O) me(O) a(O) reservation(B-Cuisine) for(O) todai(B-Cuisine) for(O) thursday(B-Restaurant Name) for(O) two(O) people(O)"}}
{"dataset":"mit-restaurant","split":"dev","label_list":["Price","Cuisine","Restaurant Name","Rating","Amenity","Location","Dish","Hours"],"instance":{"id":"199","words":["can","you","make","reservations","for","two","at","heartland","restaurant","for","tonight","at","7","30"],"labels":["O","O","O","O","O","O","O","B-Restaurant Name","I-Restaurant Name","O","B-Hours","I-Hours","I-Hours","I-Hours"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Cuisine, Restaurant Name, Rating, Amenity, Location, Dish, Hours and O.\nSentence: can you make reservations for two at heartland restaurant for tonight at 7 30","prompt_labels":"can(O) you(O) make(O) reservations(O) for(O) two(O) at(O) heartland(B-Restaurant Name) restaurant(I-Restaurant Name) for(O) tonight(B-Hours) at(I-Hours) 7(I-Hours) 30(I-Hours)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["researcher","product","task","university","field","country","location","algorithm","conference","organization","person","metric","programming language"],"instance":{"id":"0","words":["Here",",","accuracy","is","measured","by","error","rate",",","which","is","defined","as",":"],"labels":["O","O","B-metric","O","O","O","B-metric","I-metric","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: researcher, product, task, university, field, country, location, algorithm, conference, organization, person, metric, programming language and O.\nSentence: Here , accuracy is measured by error rate , which is defined as :","prompt_labels":"Here(O) ,(O) accuracy(B-metric) is(O) measured(O) by(O) error(B-metric) rate(I-metric) ,(O) which(O) is(O) defined(O) as(O) :(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["task","researcher","metric","programming language","person","conference","product","algorithm","organization","field","location","country","university"],"instance":{"id":"1","words":["From","this","perspective",",","SVM","is","closely","related","to","other","fundamental","classification","algorithms","such","as","regularized","least-squares","logistic","regression","."],"labels":["O","O","O","O","B-algorithm","O","O","O","O","O","O","O","O","O","O","B-algorithm","I-algorithm","B-algorithm","I-algorithm","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: task, researcher, metric, programming language, person, conference, product, algorithm, organization, field, location, country, university and O.\nSentence: From this perspective , SVM is closely related to other fundamental classification algorithms such as regularized least-squares logistic regression .","prompt_labels":"From(O) this(O) perspective(O) ,(O) SVM(B-algorithm) is(O) closely(O) related(O) to(O) other(O) fundamental(O) classification(O) algorithms(O) such(O) as(O) regularized(B-algorithm) least-squares(I-algorithm) logistic(B-algorithm) regression(I-algorithm) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["organization","country","programming language","metric","field","location","product","algorithm","task","conference","researcher","university","person"],"instance":{"id":"2","words":["Brion","James","portrays","Leon","Kowalski",",","a","combat","and","laborer","replicant",",","and","Joanna","Cassidy","portrays","Zhora",",","an","assassin","replicant","."],"labels":["B-person","I-person","O","B-person","I-person","O","O","O","O","O","O","O","O","B-person","I-person","O","B-person","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, country, programming language, metric, field, location, product, algorithm, task, conference, researcher, university, person and O.\nSentence: Brion James portrays Leon Kowalski , a combat and laborer replicant , and Joanna Cassidy portrays Zhora , an assassin replicant .","prompt_labels":"Brion(B-person) James(I-person) portrays(O) Leon(B-person) Kowalski(I-person) ,(O) a(O) combat(O) and(O) laborer(O) replicant(O) ,(O) and(O) Joanna(B-person) Cassidy(I-person) portrays(O) Zhora(B-person) ,(O) an(O) assassin(O) replicant(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["programming language","field","algorithm","task","country","university","product","researcher","location","person","organization","conference","metric"],"instance":{"id":"3","words":["The","first","picture","to","be","scanned",",","stored",",","and","recreated","in","digital","pixels","was","displayed","on","the","Standards","Eastern","Automatic","Computer","(","SEAC",")","at","NIST","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-product","I-product","I-product","I-product","O","B-product","O","O","B-organization","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: programming language, field, algorithm, task, country, university, product, researcher, location, person, organization, conference, metric and O.\nSentence: The first picture to be scanned , stored , and recreated in digital pixels was displayed on the Standards Eastern Automatic Computer ( SEAC ) at NIST .","prompt_labels":"The(O) first(O) picture(O) to(O) be(O) scanned(O) ,(O) stored(O) ,(O) and(O) recreated(O) in(O) digital(O) pixels(O) was(O) displayed(O) on(O) the(O) Standards(B-product) Eastern(I-product) Automatic(I-product) Computer(I-product) ((O) SEAC(B-product) )(O) at(O) NIST(B-organization) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["university","task","location","product","country","metric","researcher","person","conference","algorithm","field","programming language","organization"],"instance":{"id":"4","words":["Segmenting","the","text","into","topics","or","discourse","turns","might","be","useful","in","some","natural","processing","tasks",":","it","can","improve","information","retrieval","or","speech","recognition","significantly","(","by","indexing","\/","recognizing","documents","more","precisely","or","by","giving","the","specific","part","of","a","document","corresponding","to","the","query","as","a","result",")","."],"labels":["B-task","I-task","I-task","I-task","I-task","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-task","I-task","O","B-task","I-task","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: university, task, location, product, country, metric, researcher, person, conference, algorithm, field, programming language, organization and O.\nSentence: Segmenting the text into topics or discourse turns might be useful in some natural processing tasks : it can improve information retrieval or speech recognition significantly ( by indexing \/ recognizing documents more precisely or by giving the specific part of a document corresponding to the query as a result ) .","prompt_labels":"Segmenting(B-task) the(I-task) text(I-task) into(I-task) topics(I-task) or(O) discourse(O) turns(O) might(O) be(O) useful(O) in(O) some(O) natural(O) processing(O) tasks(O) :(O) it(O) can(O) improve(O) information(B-task) retrieval(I-task) or(O) speech(B-task) recognition(I-task) significantly(O) ((O) by(O) indexing(O) \/(O) recognizing(O) documents(O) more(O) precisely(O) or(O) by(O) giving(O) the(O) specific(O) part(O) of(O) a(O) document(O) corresponding(O) to(O) the(O) query(O) as(O) a(O) result(O) )(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["algorithm","country","university","location","product","conference","organization","metric","programming language","task","researcher","field","person"],"instance":{"id":"5","words":["At","Indiana","University","in","1999","he","organized","such","a","symposium",",","and","in","April","2000",",","he","organized","a","larger","symposium","entitled","Spiritual","Robots","at","Stanford","University",",","in","which","he","moderated","a","panel","consisting","of","Ray","Kurzweil",",","Hans","Moravec",",","Kevin","Kelly",",","Ralph","Merkle",",","Bill","Joy",",","Frank","Drake",",","John","Henry","Holland","and","John","Koza","."],"labels":["O","B-university","I-university","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-conference","I-conference","O","B-university","I-university","O","O","O","O","O","O","O","O","O","B-researcher","I-researcher","O","B-researcher","I-researcher","O","B-researcher","I-researcher","O","B-researcher","I-researcher","O","B-researcher","I-researcher","O","B-researcher","I-researcher","O","B-researcher","I-researcher","I-researcher","O","B-researcher","I-researcher","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: algorithm, country, university, location, product, conference, organization, metric, programming language, task, researcher, field, person and O.\nSentence: At Indiana University in 1999 he organized such a symposium , and in April 2000 , he organized a larger symposium entitled Spiritual Robots at Stanford University , in which he moderated a panel consisting of Ray Kurzweil , Hans Moravec , Kevin Kelly , Ralph Merkle , Bill Joy , Frank Drake , John Henry Holland and John Koza .","prompt_labels":"At(O) Indiana(B-university) University(I-university) in(O) 1999(O) he(O) organized(O) such(O) a(O) symposium(O) ,(O) and(O) in(O) April(O) 2000(O) ,(O) he(O) organized(O) a(O) larger(O) symposium(O) entitled(O) Spiritual(B-conference) Robots(I-conference) at(O) Stanford(B-university) University(I-university) ,(O) in(O) which(O) he(O) moderated(O) a(O) panel(O) consisting(O) of(O) Ray(B-researcher) Kurzweil(I-researcher) ,(O) Hans(B-researcher) Moravec(I-researcher) ,(O) Kevin(B-researcher) Kelly(I-researcher) ,(O) Ralph(B-researcher) Merkle(I-researcher) ,(O) Bill(B-researcher) Joy(I-researcher) ,(O) Frank(B-researcher) Drake(I-researcher) ,(O) John(B-researcher) Henry(I-researcher) Holland(I-researcher) and(O) John(B-researcher) Koza(I-researcher) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["programming language","country","conference","organization","task","metric","product","person","university","field","algorithm","researcher","location"],"instance":{"id":"6","words":["It","considers","both","the","precision","p","and","the","recall","r","of","the","test","to","compute","the","score",":","p","is","the","number","of","correct","positive","results","divided","by","the","number","of","all","positive","results","returned","by","the","classifier",",","and","r","is","the","number","of","correct","positive","results","divided","by","the","number","of","all","relevant","samples","(","all","samples","that","should","have","been","identified","as","positive",")","."],"labels":["O","O","O","O","B-metric","B-metric","O","O","B-metric","B-metric","O","O","O","O","O","O","O","O","B-metric","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-metric","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: programming language, country, conference, organization, task, metric, product, person, university, field, algorithm, researcher, location and O.\nSentence: It considers both the precision p and the recall r of the test to compute the score : p is the number of correct positive results divided by the number of all positive results returned by the classifier , and r is the number of correct positive results divided by the number of all relevant samples ( all samples that should have been identified as positive ) .","prompt_labels":"It(O) considers(O) both(O) the(O) precision(B-metric) p(B-metric) and(O) the(O) recall(B-metric) r(B-metric) of(O) the(O) test(O) to(O) compute(O) the(O) score(O) :(O) p(B-metric) is(O) the(O) number(O) of(O) correct(O) positive(O) results(O) divided(O) by(O) the(O) number(O) of(O) all(O) positive(O) results(O) returned(O) by(O) the(O) classifier(O) ,(O) and(O) r(B-metric) is(O) the(O) number(O) of(O) correct(O) positive(O) results(O) divided(O) by(O) the(O) number(O) of(O) all(O) relevant(O) samples(O) ((O) all(O) samples(O) that(O) should(O) have(O) been(O) identified(O) as(O) positive(O) )(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["organization","field","university","task","metric","algorithm","programming language","product","conference","person","researcher","location","country"],"instance":{"id":"7","words":["Since","the","Google","acquisition",",","the","company","has","notched","up","a","number","of","significant","achievements",",","perhaps","the","most","notable","being","the","creation","of","AlphaGo",",","a","program","that","defeated","world","champion","Lee","Sedol","at","the","complex","game","of","Go","."],"labels":["O","O","B-organization","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-product","O","O","O","O","O","O","O","B-person","I-person","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, field, university, task, metric, algorithm, programming language, product, conference, person, researcher, location, country and O.\nSentence: Since the Google acquisition , the company has notched up a number of significant achievements , perhaps the most notable being the creation of AlphaGo , a program that defeated world champion Lee Sedol at the complex game of Go .","prompt_labels":"Since(O) the(O) Google(B-organization) acquisition(O) ,(O) the(O) company(O) has(O) notched(O) up(O) a(O) number(O) of(O) significant(O) achievements(O) ,(O) perhaps(O) the(O) most(O) notable(O) being(O) the(O) creation(O) of(O) AlphaGo(B-product) ,(O) a(O) program(O) that(O) defeated(O) world(O) champion(O) Lee(B-person) Sedol(I-person) at(O) the(O) complex(O) game(O) of(O) Go(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["country","metric","researcher","university","organization","person","programming language","task","location","field","product","algorithm","conference"],"instance":{"id":"8","words":["Representing","words","considering","their","context","through","fixed","size","dense","vectors","(","word","embedding","s",")","has","become","one","the","most","fundamental","blocks","in","several","NLP","systems.","an","unsupervised","disambiguation","system","uses","the","similarity","between","word","senses","in","a","fixed","context","window","to","select","the","most","suitable","word","sense","using","a","pre-trained","word","embedding","model","and","WordNet","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-field","O","O","B-product","I-product","I-product","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-product","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, metric, researcher, university, organization, person, programming language, task, location, field, product, algorithm, conference and O.\nSentence: Representing words considering their context through fixed size dense vectors ( word embedding s ) has become one the most fundamental blocks in several NLP systems. an unsupervised disambiguation system uses the similarity between word senses in a fixed context window to select the most suitable word sense using a pre-trained word embedding model and WordNet .","prompt_labels":"Representing(O) words(O) considering(O) their(O) context(O) through(O) fixed(O) size(O) dense(O) vectors(O) ((O) word(O) embedding(O) s(O) )(O) has(O) become(O) one(O) the(O) most(O) fundamental(O) blocks(O) in(O) several(O) NLP(B-field) systems.(O) an(O) unsupervised(B-product) disambiguation(I-product) system(I-product) uses(O) the(O) similarity(O) between(O) word(O) senses(O) in(O) a(O) fixed(O) context(O) window(O) to(O) select(O) the(O) most(O) suitable(O) word(O) sense(O) using(O) a(O) pre-trained(O) word(O) embedding(O) model(O) and(O) WordNet(B-product) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["programming language","person","field","researcher","task","location","product","university","conference","metric","algorithm","organization","country"],"instance":{"id":"9","words":["Machine","learning","techniques",",","either","Supervised","learning","or","Unsupervised","learning",",","have","been","used","to","induce","such","rules","automatically","."],"labels":["B-field","I-field","O","O","O","B-field","I-field","O","B-field","I-field","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: programming language, person, field, researcher, task, location, product, university, conference, metric, algorithm, organization, country and O.\nSentence: Machine learning techniques , either Supervised learning or Unsupervised learning , have been used to induce such rules automatically .","prompt_labels":"Machine(B-field) learning(I-field) techniques(O) ,(O) either(O) Supervised(B-field) learning(I-field) or(O) Unsupervised(B-field) learning(I-field) ,(O) have(O) been(O) used(O) to(O) induce(O) such(O) rules(O) automatically(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["algorithm","product","person","country","researcher","field","metric","task","conference","university","programming language","organization","location"],"instance":{"id":"10","words":["In","1969",",","Scheinman","invented","the","Stanford","arm",","],"labels":["O","O","O","B-researcher","O","O","B-product","I-product","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: algorithm, product, person, country, researcher, field, metric, task, conference, university, programming language, organization, location and O.\nSentence: In 1969 , Scheinman invented the Stanford arm ,","prompt_labels":"In(O) 1969(O) ,(O) Scheinman(B-researcher) invented(O) the(O) Stanford(B-product) arm(I-product) ,(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["researcher","algorithm","organization","product","location","country","task","university","person","programming language","metric","conference","field"],"instance":{"id":"11","words":["Since","the","Log","loss","is","differentiable",",","a","gradient-based","method","can","be","used","to","optimize","the","model","."],"labels":["O","O","B-metric","I-metric","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: researcher, algorithm, organization, product, location, country, task, university, person, programming language, metric, conference, field and O.\nSentence: Since the Log loss is differentiable , a gradient-based method can be used to optimize the model .","prompt_labels":"Since(O) the(O) Log(B-metric) loss(I-metric) is(O) differentiable(O) ,(O) a(O) gradient-based(O) method(O) can(O) be(O) used(O) to(O) optimize(O) the(O) model(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["country","university","organization","conference","researcher","algorithm","metric","field","task","location","person","programming language","product"],"instance":{"id":"12","words":["In","machine","learning",",","support-vector","machines","(","SVMs",",","also","support-vector","networks",")","are","supervised","learning","models","with","learning","algorithm","s","that","analyze","data","used","for","classification","and","regression","analysis","."],"labels":["O","B-field","I-field","O","B-algorithm","I-algorithm","O","B-algorithm","O","O","B-algorithm","I-algorithm","O","O","B-field","I-field","O","O","O","O","O","O","O","O","O","O","B-task","O","B-task","I-task","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, university, organization, conference, researcher, algorithm, metric, field, task, location, person, programming language, product and O.\nSentence: In machine learning , support-vector machines ( SVMs , also support-vector networks ) are supervised learning models with learning algorithm s that analyze data used for classification and regression analysis .","prompt_labels":"In(O) machine(B-field) learning(I-field) ,(O) support-vector(B-algorithm) machines(I-algorithm) ((O) SVMs(B-algorithm) ,(O) also(O) support-vector(B-algorithm) networks(I-algorithm) )(O) are(O) supervised(B-field) learning(I-field) models(O) with(O) learning(O) algorithm(O) s(O) that(O) analyze(O) data(O) used(O) for(O) classification(B-task) and(O) regression(B-task) analysis(I-task) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["university","product","person","conference","organization","location","researcher","field","algorithm","task","metric","country","programming language"],"instance":{"id":"13","words":[",","(","2002",")","as","the","automatic","metric","for","Machine","translation","(","MT",")","evaluation",",","many","other","methods","have","been","proposed","to","revise","or","improve","it",",","such","as","TER",",","METEOR",",","Banerjee","and","Lavie",",","(","2005",")","etc","."],"labels":["O","O","O","O","O","O","O","O","O","B-task","I-task","O","B-task","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-metric","O","B-metric","O","B-researcher","O","B-researcher","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: university, product, person, conference, organization, location, researcher, field, algorithm, task, metric, country, programming language and O.\nSentence: , ( 2002 ) as the automatic metric for Machine translation ( MT ) evaluation , many other methods have been proposed to revise or improve it , such as TER , METEOR , Banerjee and Lavie , ( 2005 ) etc .","prompt_labels":",(O) ((O) 2002(O) )(O) as(O) the(O) automatic(O) metric(O) for(O) Machine(B-task) translation(I-task) ((O) MT(B-task) )(O) evaluation(O) ,(O) many(O) other(O) methods(O) have(O) been(O) proposed(O) to(O) revise(O) or(O) improve(O) it(O) ,(O) such(O) as(O) TER(B-metric) ,(O) METEOR(B-metric) ,(O) Banerjee(B-researcher) and(O) Lavie(B-researcher) ,(O) ((O) 2005(O) )(O) etc(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["university","task","person","product","conference","researcher","organization","location","algorithm","programming language","metric","country","field"],"instance":{"id":"14","words":["It","includes","an","upper","ontology",",","created","by","the","IEEE","working","group","P1600.1","(","originally","by","Ian","Niles","and","Adam","Pease",")","."],"labels":["O","O","O","O","O","O","O","O","O","B-organization","O","O","O","O","O","O","B-researcher","I-researcher","O","B-researcher","I-researcher","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: university, task, person, product, conference, researcher, organization, location, algorithm, programming language, metric, country, field and O.\nSentence: It includes an upper ontology , created by the IEEE working group P1600.1 ( originally by Ian Niles and Adam Pease ) .","prompt_labels":"It(O) includes(O) an(O) upper(O) ontology(O) ,(O) created(O) by(O) the(O) IEEE(B-organization) working(O) group(O) P1600.1(O) ((O) originally(O) by(O) Ian(B-researcher) Niles(I-researcher) and(O) Adam(B-researcher) Pease(I-researcher) )(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["metric","product","programming language","university","person","field","location","conference","algorithm","organization","task","country","researcher"],"instance":{"id":"15","words":["In","Cryo","Electron","Tomography",",","where","the","limited","number","of","projections","are","acquired","due","to","the","hardware","limitations","and","to","avoid","the","biological","specimen","damage",",","it","can","be","used","along","with","compressive","sensing","techniques","or","regularization","functions","(","e.g.","Huber","loss",")","to","improve","the","reconstruction","for","better","interpretation","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-algorithm","I-algorithm","I-algorithm","O","B-algorithm","I-algorithm","O","O","B-metric","I-metric","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: metric, product, programming language, university, person, field, location, conference, algorithm, organization, task, country, researcher and O.\nSentence: In Cryo Electron Tomography , where the limited number of projections are acquired due to the hardware limitations and to avoid the biological specimen damage , it can be used along with compressive sensing techniques or regularization functions ( e.g. Huber loss ) to improve the reconstruction for better interpretation .","prompt_labels":"In(O) Cryo(O) Electron(O) Tomography(O) ,(O) where(O) the(O) limited(O) number(O) of(O) projections(O) are(O) acquired(O) due(O) to(O) the(O) hardware(O) limitations(O) and(O) to(O) avoid(O) the(O) biological(O) specimen(O) damage(O) ,(O) it(O) can(O) be(O) used(O) along(O) with(O) compressive(B-algorithm) sensing(I-algorithm) techniques(I-algorithm) or(O) regularization(B-algorithm) functions(I-algorithm) ((O) e.g.(O) Huber(B-metric) loss(I-metric) )(O) to(O) improve(O) the(O) reconstruction(O) for(O) better(O) interpretation(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["university","location","programming language","metric","algorithm","product","task","researcher","field","conference","country","person","organization"],"instance":{"id":"16","words":["An","implementation","of","several","whitening","procedures","in","R",",","including","ZCA-whitening","and","PCA","whitening","but","also","CCA","whitening",",","is","available","in","the","whitening","R","package","published","on","CRAN","."],"labels":["O","O","O","O","O","O","O","B-programming language","O","O","B-algorithm","O","B-algorithm","I-algorithm","O","O","B-algorithm","I-algorithm","O","O","O","O","O","B-product","I-product","I-product","O","O","B-product","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: university, location, programming language, metric, algorithm, product, task, researcher, field, conference, country, person, organization and O.\nSentence: An implementation of several whitening procedures in R , including ZCA-whitening and PCA whitening but also CCA whitening , is available in the whitening R package published on CRAN .","prompt_labels":"An(O) implementation(O) of(O) several(O) whitening(O) procedures(O) in(O) R(B-programming language) ,(O) including(O) ZCA-whitening(B-algorithm) and(O) PCA(B-algorithm) whitening(I-algorithm) but(O) also(O) CCA(B-algorithm) whitening(I-algorithm) ,(O) is(O) available(O) in(O) the(O) whitening(B-product) R(I-product) package(I-product) published(O) on(O) CRAN(B-product) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["algorithm","conference","university","researcher","task","location","country","person","product","programming language","organization","metric","field"],"instance":{"id":"17","words":["Today",",","the","field","has","become","even","more","daunting","and","complex","with","the","addition","of","circuit",",","systems","and","signal","analysis","and","design","languages","and","software",",","from","MATLAB","and","Simulink","to","NumPy",",","VHDL",",","PSpice",",","Verilog","and","even","Assembly","language","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-product","O","B-product","O","B-product","O","B-product","O","B-product","O","B-product","O","O","B-programming language","I-programming language","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: algorithm, conference, university, researcher, task, location, country, person, product, programming language, organization, metric, field and O.\nSentence: Today , the field has become even more daunting and complex with the addition of circuit , systems and signal analysis and design languages and software , from MATLAB and Simulink to NumPy , VHDL , PSpice , Verilog and even Assembly language .","prompt_labels":"Today(O) ,(O) the(O) field(O) has(O) become(O) even(O) more(O) daunting(O) and(O) complex(O) with(O) the(O) addition(O) of(O) circuit(O) ,(O) systems(O) and(O) signal(O) analysis(O) and(O) design(O) languages(O) and(O) software(O) ,(O) from(O) MATLAB(B-product) and(O) Simulink(B-product) to(O) NumPy(B-product) ,(O) VHDL(B-product) ,(O) PSpice(B-product) ,(O) Verilog(B-product) and(O) even(O) Assembly(B-programming language) language(I-programming language) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["task","person","algorithm","researcher","university","organization","product","programming language","conference","metric","field","country","location"],"instance":{"id":"18","words":["The","company","was","founded","by","Kiichiro","Toyoda","in","1937",",","as","a","spinoff","from","Sakichi","Toyoda","company","Toyota","Industries","to","create","automobiles","."],"labels":["O","O","O","O","O","B-person","I-person","O","O","O","O","O","O","O","B-person","I-person","O","B-organization","I-organization","O","O","B-product","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: task, person, algorithm, researcher, university, organization, product, programming language, conference, metric, field, country, location and O.\nSentence: The company was founded by Kiichiro Toyoda in 1937 , as a spinoff from Sakichi Toyoda company Toyota Industries to create automobiles .","prompt_labels":"The(O) company(O) was(O) founded(O) by(O) Kiichiro(B-person) Toyoda(I-person) in(O) 1937(O) ,(O) as(O) a(O) spinoff(O) from(O) Sakichi(B-person) Toyoda(I-person) company(O) Toyota(B-organization) Industries(I-organization) to(O) create(O) automobiles(B-product) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["product","metric","person","researcher","algorithm","task","location","programming language","university","country","conference","field","organization"],"instance":{"id":"19","words":["Unsupervised","learning",",","on","the","other","hand",",","assumes","training","data","that","has","not","been","hand-labeled",",","and","attempts","to","find","inherent","patterns","in","the","data","that","can","then","be","used","to","determine","the","correct","output","value","for","new","data","instances","..","A","combination","of","the","two","that","has","recently","been","explored","is","semi-supervised","learning",",","which","uses","a","combination","of","labeled","and","unlabeled","data","(","typically","a","small","set","of","labeled","data","combined","with","a","large","amount","of","unlabeled","data",")","."],"labels":["B-field","I-field","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-field","I-field","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: product, metric, person, researcher, algorithm, task, location, programming language, university, country, conference, field, organization and O.\nSentence: Unsupervised learning , on the other hand , assumes training data that has not been hand-labeled , and attempts to find inherent patterns in the data that can then be used to determine the correct output value for new data instances .. A combination of the two that has recently been explored is semi-supervised learning , which uses a combination of labeled and unlabeled data ( typically a small set of labeled data combined with a large amount of unlabeled data ) .","prompt_labels":"Unsupervised(B-field) learning(I-field) ,(O) on(O) the(O) other(O) hand(O) ,(O) assumes(O) training(O) data(O) that(O) has(O) not(O) been(O) hand-labeled(O) ,(O) and(O) attempts(O) to(O) find(O) inherent(O) patterns(O) in(O) the(O) data(O) that(O) can(O) then(O) be(O) used(O) to(O) determine(O) the(O) correct(O) output(O) value(O) for(O) new(O) data(O) instances(O) ..(O) A(O) combination(O) of(O) the(O) two(O) that(O) has(O) recently(O) been(O) explored(O) is(O) semi-supervised(B-field) learning(I-field) ,(O) which(O) uses(O) a(O) combination(O) of(O) labeled(O) and(O) unlabeled(O) data(O) ((O) typically(O) a(O) small(O) set(O) of(O) labeled(O) data(O) combined(O) with(O) a(O) large(O) amount(O) of(O) unlabeled(O) data(O) )(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["researcher","location","algorithm","country","organization","task","product","university","person","conference","programming language","metric","field"],"instance":{"id":"20","words":["Despite","those","humanoid","robots","for","utilitarian","uses",",","there","are","some","humanoid","robots","which","aims","at","entertainment","uses",",","such","as","Sony","'","s","QRIO","and","Wow","Wee","'","s","RoboSapien","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-organization","O","O","B-product","O","B-organization","I-organization","O","O","B-product","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: researcher, location, algorithm, country, organization, task, product, university, person, conference, programming language, metric, field and O.\nSentence: Despite those humanoid robots for utilitarian uses , there are some humanoid robots which aims at entertainment uses , such as Sony ' s QRIO and Wow Wee ' s RoboSapien .","prompt_labels":"Despite(O) those(O) humanoid(O) robots(O) for(O) utilitarian(O) uses(O) ,(O) there(O) are(O) some(O) humanoid(O) robots(O) which(O) aims(O) at(O) entertainment(O) uses(O) ,(O) such(O) as(O) Sony(B-organization) '(O) s(O) QRIO(B-product) and(O) Wow(B-organization) Wee(I-organization) '(O) s(O) RoboSapien(B-product) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["country","field","algorithm","programming language","location","university","researcher","organization","product","metric","person","task","conference"],"instance":{"id":"21","words":["Webber","became","a","Fellow","of","the","Association","for","the","Advancement","of","Artificial","Intelligence","in","1991",","],"labels":["B-researcher","O","O","O","O","O","B-conference","I-conference","I-conference","I-conference","I-conference","I-conference","I-conference","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, field, algorithm, programming language, location, university, researcher, organization, product, metric, person, task, conference and O.\nSentence: Webber became a Fellow of the Association for the Advancement of Artificial Intelligence in 1991 ,","prompt_labels":"Webber(B-researcher) became(O) a(O) Fellow(O) of(O) the(O) Association(B-conference) for(I-conference) the(I-conference) Advancement(I-conference) of(I-conference) Artificial(I-conference) Intelligence(I-conference) in(O) 1991(O) ,(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["programming language","conference","organization","university","field","researcher","person","task","product","location","algorithm","metric","country"],"instance":{"id":"22","words":["With","this","company","he","was","developing","data-mining","and","database","technology",",","more","specific","high-level","ontologies","for","intelligence","and","automated","natural","language","understanding","."],"labels":["O","O","O","O","O","O","B-field","O","B-field","O","O","O","O","O","O","O","O","O","B-task","I-task","B-task","I-task","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: programming language, conference, organization, university, field, researcher, person, task, product, location, algorithm, metric, country and O.\nSentence: With this company he was developing data-mining and database technology , more specific high-level ontologies for intelligence and automated natural language understanding .","prompt_labels":"With(O) this(O) company(O) he(O) was(O) developing(O) data-mining(B-field) and(O) database(B-field) technology(O) ,(O) more(O) specific(O) high-level(O) ontologies(O) for(O) intelligence(O) and(O) automated(B-task) natural(I-task) language(B-task) understanding(I-task) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["person","location","programming language","researcher","field","metric","country","organization","university","conference","task","algorithm","product"],"instance":{"id":"23","words":["However",",","in","the","last","years",",","one","can","observe","appearing","of","different","e-services","and","related","initiatives","in","developing","countries","such","as","Project","Nemmadi",",","MCA21","Mission","Mode","Project","or","Digital","India","even","more",",","in","India",";","Electronic","Government","Directorate","in","Pakistan",";","etc","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-country","O","B-organization","I-organization","I-organization","O","B-country","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, location, programming language, researcher, field, metric, country, organization, university, conference, task, algorithm, product and O.\nSentence: However , in the last years , one can observe appearing of different e-services and related initiatives in developing countries such as Project Nemmadi , MCA21 Mission Mode Project or Digital India even more , in India ; Electronic Government Directorate in Pakistan ; etc .","prompt_labels":"However(O) ,(O) in(O) the(O) last(O) years(O) ,(O) one(O) can(O) observe(O) appearing(O) of(O) different(O) e-services(O) and(O) related(O) initiatives(O) in(O) developing(O) countries(O) such(O) as(O) Project(O) Nemmadi(O) ,(O) MCA21(O) Mission(O) Mode(O) Project(O) or(O) Digital(O) India(O) even(O) more(O) ,(O) in(O) India(B-country) ;(O) Electronic(B-organization) Government(I-organization) Directorate(I-organization) in(O) Pakistan(B-country) ;(O) etc(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["researcher","location","task","organization","programming language","conference","algorithm","university","product","field","person","metric","country"],"instance":{"id":"24","words":["He","received","a","PhD","in","Radio","Physics","and","Electronics","from","the","Rajabazar","Science","College","campus","of","University","of","Calcutta","in","1979","as","a","student","of","Indian","Statistical","Institute",",","and","another","PhD","in","Electrical","Engineering","along","with","Diploma","of","the","Imperial","College","from","Imperial","College",",","University","of","London",",","in","1982","."],"labels":["O","O","O","O","O","B-field","I-field","O","B-field","O","O","B-university","I-university","I-university","O","O","B-university","I-university","I-university","O","O","O","O","O","O","B-university","I-university","I-university","O","O","O","O","O","B-field","I-field","O","O","O","O","O","O","O","O","B-university","I-university","O","B-university","I-university","I-university","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: researcher, location, task, organization, programming language, conference, algorithm, university, product, field, person, metric, country and O.\nSentence: He received a PhD in Radio Physics and Electronics from the Rajabazar Science College campus of University of Calcutta in 1979 as a student of Indian Statistical Institute , and another PhD in Electrical Engineering along with Diploma of the Imperial College from Imperial College , University of London , in 1982 .","prompt_labels":"He(O) received(O) a(O) PhD(O) in(O) Radio(B-field) Physics(I-field) and(O) Electronics(B-field) from(O) the(O) Rajabazar(B-university) Science(I-university) College(I-university) campus(O) of(O) University(B-university) of(I-university) Calcutta(I-university) in(O) 1979(O) as(O) a(O) student(O) of(O) Indian(B-university) Statistical(I-university) Institute(I-university) ,(O) and(O) another(O) PhD(O) in(O) Electrical(B-field) Engineering(I-field) along(O) with(O) Diploma(O) of(O) the(O) Imperial(O) College(O) from(O) Imperial(B-university) College(I-university) ,(O) University(B-university) of(I-university) London(I-university) ,(O) in(O) 1982(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["programming language","algorithm","person","researcher","metric","university","product","location","conference","organization","country","task","field"],"instance":{"id":"25","words":["Expo","II","was","announced","as","being","the","locale","for","the","world","premiere","of","several","films","never","before","seen","in","3D",",","including","The","Diamond","Wizard","and","the","Universal","short",",","Hawaiian","Nights","with","Mamie","Van","Doren","and","Pinky","Lee","."],"labels":["B-location","I-location","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-person","I-person","I-person","O","B-person","I-person","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: programming language, algorithm, person, researcher, metric, university, product, location, conference, organization, country, task, field and O.\nSentence: Expo II was announced as being the locale for the world premiere of several films never before seen in 3D , including The Diamond Wizard and the Universal short , Hawaiian Nights with Mamie Van Doren and Pinky Lee .","prompt_labels":"Expo(B-location) II(I-location) was(O) announced(O) as(O) being(O) the(O) locale(O) for(O) the(O) world(O) premiere(O) of(O) several(O) films(O) never(O) before(O) seen(O) in(O) 3D(O) ,(O) including(O) The(O) Diamond(O) Wizard(O) and(O) the(O) Universal(O) short(O) ,(O) Hawaiian(O) Nights(O) with(O) Mamie(B-person) Van(I-person) Doren(I-person) and(O) Pinky(B-person) Lee(I-person) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["organization","person","algorithm","researcher","university","metric","country","programming language","location","task","conference","field","product"],"instance":{"id":"26","words":["The","maximum","subarray","problem","was","proposed","by","Ulf","Grenander","in","1977","as","a","simplified","model","for","maximum","likelihood","estimation","of","patterns","in","digitized","images","."],"labels":["O","O","O","O","O","O","O","B-researcher","I-researcher","O","O","O","O","O","O","O","B-metric","I-metric","I-metric","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, person, algorithm, researcher, university, metric, country, programming language, location, task, conference, field, product and O.\nSentence: The maximum subarray problem was proposed by Ulf Grenander in 1977 as a simplified model for maximum likelihood estimation of patterns in digitized images .","prompt_labels":"The(O) maximum(O) subarray(O) problem(O) was(O) proposed(O) by(O) Ulf(B-researcher) Grenander(I-researcher) in(O) 1977(O) as(O) a(O) simplified(O) model(O) for(O) maximum(B-metric) likelihood(I-metric) estimation(I-metric) of(O) patterns(O) in(O) digitized(O) images(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["metric","location","conference","organization","university","task","researcher","product","field","person","algorithm","programming language","country"],"instance":{"id":"27","words":["The","iPhone","4S",",","iPad","3",",","iPad","Mini","1G",",","iPad","Air",",","iPad","Pro","1G",",","iPod","Touch","5G","and","later",",","all","come","with","a","more","advanced","voice","assistant","called","Siri","."],"labels":["O","B-product","I-product","O","B-product","I-product","O","B-product","I-product","I-product","O","B-product","I-product","O","B-product","I-product","I-product","O","B-product","I-product","I-product","O","O","O","O","O","O","O","O","O","O","O","O","B-product","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: metric, location, conference, organization, university, task, researcher, product, field, person, algorithm, programming language, country and O.\nSentence: The iPhone 4S , iPad 3 , iPad Mini 1G , iPad Air , iPad Pro 1G , iPod Touch 5G and later , all come with a more advanced voice assistant called Siri .","prompt_labels":"The(O) iPhone(B-product) 4S(I-product) ,(O) iPad(B-product) 3(I-product) ,(O) iPad(B-product) Mini(I-product) 1G(I-product) ,(O) iPad(B-product) Air(I-product) ,(O) iPad(B-product) Pro(I-product) 1G(I-product) ,(O) iPod(B-product) Touch(I-product) 5G(I-product) and(O) later(O) ,(O) all(O) come(O) with(O) a(O) more(O) advanced(O) voice(O) assistant(O) called(O) Siri(B-product) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["location","task","person","algorithm","country","conference","product","university","metric","field","researcher","organization","programming language"],"instance":{"id":"28","words":["It","'s","easy","to","check","that","the","logistic","loss","and","binary","cross","entropy","loss","(","Log","loss",")","are","in","fact","the","same","(","up","to","a","multiplicative","constant","math","\\","frac","{","1","}","{","\\","log","(","2",")","}","\/","math",")",".The","cross","entropy","loss","is","closely","related","to","the","Kullback-Leibler","divergence","between","the","empirical","distribution","and","the","predicted","distribution","."],"labels":["O","O","O","O","O","O","O","B-metric","I-metric","O","B-metric","I-metric","I-metric","I-metric","O","B-metric","I-metric","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-metric","I-metric","I-metric","O","O","O","O","O","B-metric","I-metric","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, task, person, algorithm, country, conference, product, university, metric, field, researcher, organization, programming language and O.\nSentence: It 's easy to check that the logistic loss and binary cross entropy loss ( Log loss ) are in fact the same ( up to a multiplicative constant math \\ frac { 1 } { \\ log ( 2 ) } \/ math ) .The cross entropy loss is closely related to the Kullback-Leibler divergence between the empirical distribution and the predicted distribution .","prompt_labels":"It(O) 's(O) easy(O) to(O) check(O) that(O) the(O) logistic(B-metric) loss(I-metric) and(O) binary(B-metric) cross(I-metric) entropy(I-metric) loss(I-metric) ((O) Log(B-metric) loss(I-metric) )(O) are(O) in(O) fact(O) the(O) same(O) ((O) up(O) to(O) a(O) multiplicative(O) constant(O) math(O) \\(O) frac(O) {(O) 1(O) }(O) {(O) \\(O) log(O) ((O) 2(O) )(O) }(O) \/(O) math(O) )(O) .The(O) cross(B-metric) entropy(I-metric) loss(I-metric) is(O) closely(O) related(O) to(O) the(O) Kullback-Leibler(B-metric) divergence(I-metric) between(O) the(O) empirical(O) distribution(O) and(O) the(O) predicted(O) distribution(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["conference","person","product","programming language","country","metric","researcher","university","organization","location","field","task","algorithm"],"instance":{"id":"29","words":["The","EM","algorithm","is","used","to","find","(","local",")","maximum","likelihood","parameters","of","a","statistical","model","in","cases","where","the","equations","cannot","be","solved","directly","."],"labels":["O","B-algorithm","I-algorithm","O","O","O","O","O","O","O","B-metric","I-metric","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: conference, person, product, programming language, country, metric, researcher, university, organization, location, field, task, algorithm and O.\nSentence: The EM algorithm is used to find ( local ) maximum likelihood parameters of a statistical model in cases where the equations cannot be solved directly .","prompt_labels":"The(O) EM(B-algorithm) algorithm(I-algorithm) is(O) used(O) to(O) find(O) ((O) local(O) )(O) maximum(B-metric) likelihood(I-metric) parameters(O) of(O) a(O) statistical(O) model(O) in(O) cases(O) where(O) the(O) equations(O) cannot(O) be(O) solved(O) directly(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["algorithm","product","location","programming language","person","country","field","researcher","organization","conference","university","metric","task"],"instance":{"id":"30","words":["This","research","was","fundamental","to","the","development","of","modern","techniques","of","speech","synthesis",",","reading","machines","for","the","blind",",","the","study","of","speech","perception","and","speech","recognition",",","and","the","development","of","the","motor","theory","of","speech","perception","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","B-task","I-task","O","B-task","I-task","I-task","I-task","I-task","O","O","O","O","B-task","I-task","O","B-task","I-task","O","O","O","O","O","O","B-task","I-task","I-task","I-task","I-task","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: algorithm, product, location, programming language, person, country, field, researcher, organization, conference, university, metric, task and O.\nSentence: This research was fundamental to the development of modern techniques of speech synthesis , reading machines for the blind , the study of speech perception and speech recognition , and the development of the motor theory of speech perception .","prompt_labels":"This(O) research(O) was(O) fundamental(O) to(O) the(O) development(O) of(O) modern(O) techniques(O) of(O) speech(B-task) synthesis(I-task) ,(O) reading(B-task) machines(I-task) for(I-task) the(I-task) blind(I-task) ,(O) the(O) study(O) of(O) speech(B-task) perception(I-task) and(O) speech(B-task) recognition(I-task) ,(O) and(O) the(O) development(O) of(O) the(O) motor(B-task) theory(I-task) of(I-task) speech(I-task) perception(I-task) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["university","product","conference","metric","field","researcher","person","location","algorithm","organization","programming language","task","country"],"instance":{"id":"31","words":["The","Arduino","integrated","development","environment","(","IDE",")","is","a","cross-platform","application","(","for","Windows",",","macOS",",","and","Linux",")","that","is","written","in","the","programming","language","Java","."],"labels":["O","B-product","O","O","O","O","O","O","O","O","O","O","O","O","B-product","O","B-product","O","O","B-product","O","O","O","O","O","O","O","O","B-programming language","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: university, product, conference, metric, field, researcher, person, location, algorithm, organization, programming language, task, country and O.\nSentence: The Arduino integrated development environment ( IDE ) is a cross-platform application ( for Windows , macOS , and Linux ) that is written in the programming language Java .","prompt_labels":"The(O) Arduino(B-product) integrated(O) development(O) environment(O) ((O) IDE(O) )(O) is(O) a(O) cross-platform(O) application(O) ((O) for(O) Windows(B-product) ,(O) macOS(B-product) ,(O) and(O) Linux(B-product) )(O) that(O) is(O) written(O) in(O) the(O) programming(O) language(O) Java(B-programming language) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["researcher","location","product","conference","university","metric","organization","country","algorithm","task","programming language","field","person"],"instance":{"id":"32","words":["Neural","network","research","stagnated","after","the","publication","of","machine","learning","research","by","Marvin","Minsky","and","Seymour","Papert","(","1969",")","."],"labels":["B-algorithm","I-algorithm","O","O","O","O","O","O","B-field","I-field","O","O","B-researcher","I-researcher","O","B-researcher","I-researcher","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: researcher, location, product, conference, university, metric, organization, country, algorithm, task, programming language, field, person and O.\nSentence: Neural network research stagnated after the publication of machine learning research by Marvin Minsky and Seymour Papert ( 1969 ) .","prompt_labels":"Neural(B-algorithm) network(I-algorithm) research(O) stagnated(O) after(O) the(O) publication(O) of(O) machine(B-field) learning(I-field) research(O) by(O) Marvin(B-researcher) Minsky(I-researcher) and(O) Seymour(B-researcher) Papert(I-researcher) ((O) 1969(O) )(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["metric","country","programming language","product","field","researcher","location","conference","task","university","algorithm","person","organization"],"instance":{"id":"33","words":["Only","a","few","non-Japanese","companies","ultimately","managed","to","survive","in","this","market",",","the","major","ones","being",":","Adept","Technology",",","Stubli",",","the","Sweden","-","Switzerland","company","ABB","Asea","Brown","Boveri",",","the","Germany","company","KUKA","Robotics","and","the","Italy","company","Comau","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-organization","I-organization","O","B-organization","O","O","B-country","O","B-country","O","B-organization","I-organization","I-organization","I-organization","O","O","B-country","O","B-organization","I-organization","O","O","B-country","O","B-organization","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: metric, country, programming language, product, field, researcher, location, conference, task, university, algorithm, person, organization and O.\nSentence: Only a few non-Japanese companies ultimately managed to survive in this market , the major ones being : Adept Technology , Stubli , the Sweden - Switzerland company ABB Asea Brown Boveri , the Germany company KUKA Robotics and the Italy company Comau .","prompt_labels":"Only(O) a(O) few(O) non-Japanese(O) companies(O) ultimately(O) managed(O) to(O) survive(O) in(O) this(O) market(O) ,(O) the(O) major(O) ones(O) being(O) :(O) Adept(B-organization) Technology(I-organization) ,(O) Stubli(B-organization) ,(O) the(O) Sweden(B-country) -(O) Switzerland(B-country) company(O) ABB(B-organization) Asea(I-organization) Brown(I-organization) Boveri(I-organization) ,(O) the(O) Germany(B-country) company(O) KUKA(B-organization) Robotics(I-organization) and(O) the(O) Italy(B-country) company(O) Comau(B-organization) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["location","country","algorithm","metric","field","task","conference","product","organization","researcher","programming language","university","person"],"instance":{"id":"34","words":["The","research","activities","include","an","annual","research","conference",",","the","RuleML","Symposium",",","also","known","as","RuleML","for","short","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-conference","I-conference","O","O","O","O","B-conference","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, country, algorithm, metric, field, task, conference, product, organization, researcher, programming language, university, person and O.\nSentence: The research activities include an annual research conference , the RuleML Symposium , also known as RuleML for short .","prompt_labels":"The(O) research(O) activities(O) include(O) an(O) annual(O) research(O) conference(O) ,(O) the(O) RuleML(B-conference) Symposium(I-conference) ,(O) also(O) known(O) as(O) RuleML(B-conference) for(O) short(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["university","field","product","researcher","metric","programming language","algorithm","person","task","conference","country","organization","location"],"instance":{"id":"35","words":["Concepts","are","used","as","formal","tools","or","models","in","mathematics",",","computer","science",",","databases","and","artificial","intelligence","where","they","are","sometimes","called","classes",",","schema","or","categories","."],"labels":["O","O","O","O","O","O","O","O","O","B-field","O","B-field","I-field","O","B-field","O","B-field","I-field","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: university, field, product, researcher, metric, programming language, algorithm, person, task, conference, country, organization, location and O.\nSentence: Concepts are used as formal tools or models in mathematics , computer science , databases and artificial intelligence where they are sometimes called classes , schema or categories .","prompt_labels":"Concepts(O) are(O) used(O) as(O) formal(O) tools(O) or(O) models(O) in(O) mathematics(B-field) ,(O) computer(B-field) science(I-field) ,(O) databases(B-field) and(O) artificial(B-field) intelligence(I-field) where(O) they(O) are(O) sometimes(O) called(O) classes(O) ,(O) schema(O) or(O) categories(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["product","metric","researcher","programming language","university","task","field","country","algorithm","person","organization","conference","location"],"instance":{"id":"36","words":["He","has","won","awards","from","the","American","Psychological","Association",",","the","National","Academy","of","Sciences",",","the","Royal",",","the","Cognitive","Neuroscience","Society","and","the","American","Humanist","Association","."],"labels":["O","O","O","O","O","O","B-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","O","O","B-organization","O","O","B-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: product, metric, researcher, programming language, university, task, field, country, algorithm, person, organization, conference, location and O.\nSentence: He has won awards from the American Psychological Association , the National Academy of Sciences , the Royal , the Cognitive Neuroscience Society and the American Humanist Association .","prompt_labels":"He(O) has(O) won(O) awards(O) from(O) the(O) American(B-organization) Psychological(I-organization) Association(I-organization) ,(O) the(O) National(B-organization) Academy(I-organization) of(I-organization) Sciences(I-organization) ,(O) the(O) Royal(B-organization) ,(O) the(O) Cognitive(B-organization) Neuroscience(I-organization) Society(I-organization) and(O) the(O) American(B-organization) Humanist(I-organization) Association(I-organization) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["algorithm","field","programming language","organization","university","task","location","conference","country","person","metric","researcher","product"],"instance":{"id":"37","words":["Starring","Harrison","Ford",",","Rutger","Hauer","and","Sean","Young",",","it","is","loosely","based","on","Philip","K.","Dick","'","s","novel","Do","Androids","Dream","of","Electric","Sheep","?","(","1968",")","."],"labels":["O","B-person","I-person","O","B-person","I-person","O","B-person","I-person","O","O","O","O","O","O","B-person","I-person","I-person","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: algorithm, field, programming language, organization, university, task, location, conference, country, person, metric, researcher, product and O.\nSentence: Starring Harrison Ford , Rutger Hauer and Sean Young , it is loosely based on Philip K. Dick ' s novel Do Androids Dream of Electric Sheep ? ( 1968 ) .","prompt_labels":"Starring(O) Harrison(B-person) Ford(I-person) ,(O) Rutger(B-person) Hauer(I-person) and(O) Sean(B-person) Young(I-person) ,(O) it(O) is(O) loosely(O) based(O) on(O) Philip(B-person) K.(I-person) Dick(I-person) '(O) s(O) novel(O) Do(O) Androids(O) Dream(O) of(O) Electric(O) Sheep(O) ?(O) ((O) 1968(O) )(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["conference","country","person","algorithm","location","task","field","programming language","organization","university","product","researcher","metric"],"instance":{"id":"38","words":["Image","segmentation","using","k-means","clustering","algorithms","has","long","been","used","for","pattern","recognition",",","object","detection",",","and","medical","imaging","."],"labels":["B-task","I-task","O","B-algorithm","I-algorithm","I-algorithm","O","O","O","O","O","B-field","I-field","O","B-task","I-task","O","O","B-field","I-field","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: conference, country, person, algorithm, location, task, field, programming language, organization, university, product, researcher, metric and O.\nSentence: Image segmentation using k-means clustering algorithms has long been used for pattern recognition , object detection , and medical imaging .","prompt_labels":"Image(B-task) segmentation(I-task) using(O) k-means(B-algorithm) clustering(I-algorithm) algorithms(I-algorithm) has(O) long(O) been(O) used(O) for(O) pattern(B-field) recognition(I-field) ,(O) object(B-task) detection(I-task) ,(O) and(O) medical(B-field) imaging(I-field) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["programming language","person","product","researcher","university","organization","task","location","metric","field","conference","country","algorithm"],"instance":{"id":"39","words":["General","sampling","from","the","truncated","normal","can","be","achieved","using","approximations","to","the","normal","CDF","and","the","probit","function",",","and","R","has","a","function","codertnorm","(",")","\/","code","for","generating","truncated-normal","samples","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-algorithm","O","O","B-algorithm","I-algorithm","O","O","B-programming language","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: programming language, person, product, researcher, university, organization, task, location, metric, field, conference, country, algorithm and O.\nSentence: General sampling from the truncated normal can be achieved using approximations to the normal CDF and the probit function , and R has a function codertnorm ( ) \/ code for generating truncated-normal samples .","prompt_labels":"General(O) sampling(O) from(O) the(O) truncated(O) normal(O) can(O) be(O) achieved(O) using(O) approximations(O) to(O) the(O) normal(O) CDF(B-algorithm) and(O) the(O) probit(B-algorithm) function(I-algorithm) ,(O) and(O) R(B-programming language) has(O) a(O) function(O) codertnorm(O) ((O) )(O) \/(O) code(O) for(O) generating(O) truncated-normal(O) samples(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["algorithm","metric","task","country","person","field","conference","organization","researcher","university","location","product","programming language"],"instance":{"id":"40","words":["He","has","also","received","honorary","doctorates","from","the","universities","of","Newcastle",",","Surrey",",","Tel","Aviv","University",",",",","Simon","Fraser","University","and","the","University","of","Troms","."],"labels":["O","O","O","O","O","O","O","O","B-university","I-university","I-university","O","B-university","O","B-university","I-university","I-university","O","O","B-university","I-university","I-university","O","O","B-university","I-university","I-university","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: algorithm, metric, task, country, person, field, conference, organization, researcher, university, location, product, programming language and O.\nSentence: He has also received honorary doctorates from the universities of Newcastle , Surrey , Tel Aviv University , , Simon Fraser University and the University of Troms .","prompt_labels":"He(O) has(O) also(O) received(O) honorary(O) doctorates(O) from(O) the(O) universities(B-university) of(I-university) Newcastle(I-university) ,(O) Surrey(B-university) ,(O) Tel(B-university) Aviv(I-university) University(I-university) ,(O) ,(O) Simon(B-university) Fraser(I-university) University(I-university) and(O) the(O) University(B-university) of(I-university) Troms(I-university) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["person","field","organization","programming language","metric","university","location","algorithm","conference","product","task","country","researcher"],"instance":{"id":"41","words":["A","Java","implementation","using","zero","based","array","indexes","along","with","a","convenience","method","for","printing","the","solved","order","of","operations",":"],"labels":["O","B-programming language","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, field, organization, programming language, metric, university, location, algorithm, conference, product, task, country, researcher and O.\nSentence: A Java implementation using zero based array indexes along with a convenience method for printing the solved order of operations :","prompt_labels":"A(O) Java(B-programming language) implementation(O) using(O) zero(O) based(O) array(O) indexes(O) along(O) with(O) a(O) convenience(O) method(O) for(O) printing(O) the(O) solved(O) order(O) of(O) operations(O) :(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["product","conference","field","metric","person","researcher","country","university","location","task","organization","algorithm","programming language"],"instance":{"id":"42","words":["Such","networks","are","commonly","trained","under","a","Cross","entropy","(","or","cross-entropy",")","regime",",","giving","a","non-linear","variant","of","multinomial","logistic","regression","."],"labels":["O","O","O","O","O","O","O","B-metric","I-metric","O","O","B-metric","O","O","O","O","O","O","O","O","B-algorithm","I-algorithm","I-algorithm","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: product, conference, field, metric, person, researcher, country, university, location, task, organization, algorithm, programming language and O.\nSentence: Such networks are commonly trained under a Cross entropy ( or cross-entropy ) regime , giving a non-linear variant of multinomial logistic regression .","prompt_labels":"Such(O) networks(O) are(O) commonly(O) trained(O) under(O) a(O) Cross(B-metric) entropy(I-metric) ((O) or(O) cross-entropy(B-metric) )(O) regime(O) ,(O) giving(O) a(O) non-linear(O) variant(O) of(O) multinomial(B-algorithm) logistic(I-algorithm) regression(I-algorithm) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["person","researcher","university","product","country","algorithm","field","conference","task","location","programming language","metric","organization"],"instance":{"id":"43","words":["The","ACL","has","a","European","(","European","Chapter","of","the","Association","for","Computational","Linguistics",")"],"labels":["O","B-conference","O","O","O","O","B-conference","I-conference","I-conference","I-conference","I-conference","I-conference","I-conference","I-conference","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, researcher, university, product, country, algorithm, field, conference, task, location, programming language, metric, organization and O.\nSentence: The ACL has a European ( European Chapter of the Association for Computational Linguistics )","prompt_labels":"The(O) ACL(B-conference) has(O) a(O) European(O) ((O) European(B-conference) Chapter(I-conference) of(I-conference) the(I-conference) Association(I-conference) for(I-conference) Computational(I-conference) Linguistics(I-conference) )(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["location","algorithm","person","university","organization","field","metric","researcher","task","programming language","country","conference","product"],"instance":{"id":"44","words":["Two","professors",",","Hal","Abelson","and","Gerald","Jay","Sussman",",","chose","to","remain","neutral","-","their","group","was","referred","to","variously","as","Switzerland","and","Project","MAC","for","the","next","30","years","."],"labels":["O","O","O","B-researcher","I-researcher","O","B-researcher","I-researcher","I-researcher","O","O","O","O","O","O","O","O","O","O","O","O","O","B-country","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, algorithm, person, university, organization, field, metric, researcher, task, programming language, country, conference, product and O.\nSentence: Two professors , Hal Abelson and Gerald Jay Sussman , chose to remain neutral - their group was referred to variously as Switzerland and Project MAC for the next 30 years .","prompt_labels":"Two(O) professors(O) ,(O) Hal(B-researcher) Abelson(I-researcher) and(O) Gerald(B-researcher) Jay(I-researcher) Sussman(I-researcher) ,(O) chose(O) to(O) remain(O) neutral(O) -(O) their(O) group(O) was(O) referred(O) to(O) variously(O) as(O) Switzerland(B-country) and(O) Project(O) MAC(O) for(O) the(O) next(O) 30(O) years(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["organization","researcher","university","task","person","metric","country","field","product","algorithm","conference","programming language","location"],"instance":{"id":"45","words":["Following","his","PhD",",","Ghahramani","moved","to","the","University","of","Toronto","in","1995","as","an","ITRC","Postdoctoral","Fellow","in","the","Artificial","Intelligence","Lab",",","working","with","Geoffrey","Hinton","."],"labels":["O","O","O","O","B-researcher","O","O","O","B-university","I-university","I-university","O","O","O","O","B-organization","O","O","O","O","B-organization","I-organization","I-organization","O","O","O","B-researcher","I-researcher","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, researcher, university, task, person, metric, country, field, product, algorithm, conference, programming language, location and O.\nSentence: Following his PhD , Ghahramani moved to the University of Toronto in 1995 as an ITRC Postdoctoral Fellow in the Artificial Intelligence Lab , working with Geoffrey Hinton .","prompt_labels":"Following(O) his(O) PhD(O) ,(O) Ghahramani(B-researcher) moved(O) to(O) the(O) University(B-university) of(I-university) Toronto(I-university) in(O) 1995(O) as(O) an(O) ITRC(B-organization) Postdoctoral(O) Fellow(O) in(O) the(O) Artificial(B-organization) Intelligence(I-organization) Lab(I-organization) ,(O) working(O) with(O) Geoffrey(B-researcher) Hinton(I-researcher) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["algorithm","country","person","conference","university","organization","researcher","product","location","task","programming language","field","metric"],"instance":{"id":"46","words":["Subsequent","works","focused","on","addressing","these","problems",",","but","it","was","not","until","the","advent","of","the","modern","computer","and","the","popularisation","of","Maximum","Likelihood","(","MLE",")","parameterisation","techniques","that","research","really","took","off","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-metric","I-metric","O","B-metric","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: algorithm, country, person, conference, university, organization, researcher, product, location, task, programming language, field, metric and O.\nSentence: Subsequent works focused on addressing these problems , but it was not until the advent of the modern computer and the popularisation of Maximum Likelihood ( MLE ) parameterisation techniques that research really took off .","prompt_labels":"Subsequent(O) works(O) focused(O) on(O) addressing(O) these(O) problems(O) ,(O) but(O) it(O) was(O) not(O) until(O) the(O) advent(O) of(O) the(O) modern(O) computer(O) and(O) the(O) popularisation(O) of(O) Maximum(B-metric) Likelihood(I-metric) ((O) MLE(B-metric) )(O) parameterisation(O) techniques(O) that(O) research(O) really(O) took(O) off(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["task","product","programming language","university","organization","algorithm","conference","researcher","person","metric","location","field","country"],"instance":{"id":"47","words":["The","series","was","produced","by","David","Fincher",",","and","starred","Kevin","Spacey","."],"labels":["O","O","O","O","O","B-person","I-person","O","O","O","B-person","I-person","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: task, product, programming language, university, organization, algorithm, conference, researcher, person, metric, location, field, country and O.\nSentence: The series was produced by David Fincher , and starred Kevin Spacey .","prompt_labels":"The(O) series(O) was(O) produced(O) by(O) David(B-person) Fincher(I-person) ,(O) and(O) starred(O) Kevin(B-person) Spacey(I-person) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["organization","university","task","metric","researcher","person","field","product","algorithm","country","programming language","location","conference"],"instance":{"id":"48","words":["Due","to","limits","in","computing","power",",","current","in","silico","methods","usually","must","trade","speed","for","accuracy",";","e.g.",",","use","rapid","protein","docking","methods","instead","of","computationally","costly","free","energy","calculation","s","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-metric","O","O","O","O","O","B-algorithm","I-algorithm","O","O","O","O","O","B-algorithm","I-algorithm","I-algorithm","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, university, task, metric, researcher, person, field, product, algorithm, country, programming language, location, conference and O.\nSentence: Due to limits in computing power , current in silico methods usually must trade speed for accuracy ; e.g. , use rapid protein docking methods instead of computationally costly free energy calculation s .","prompt_labels":"Due(O) to(O) limits(O) in(O) computing(O) power(O) ,(O) current(O) in(O) silico(O) methods(O) usually(O) must(O) trade(O) speed(O) for(O) accuracy(B-metric) ;(O) e.g.(O) ,(O) use(O) rapid(O) protein(B-algorithm) docking(I-algorithm) methods(O) instead(O) of(O) computationally(O) costly(O) free(B-algorithm) energy(I-algorithm) calculation(I-algorithm) s(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["metric","field","algorithm","university","conference","location","country","task","researcher","product","programming language","organization","person"],"instance":{"id":"49","words":["It","had","over","30","locations","in","the","U.S.",",","Canada",",","Mexico",",","Brazil","and","Argentina","."],"labels":["O","O","O","O","O","O","O","B-country","O","B-country","O","B-country","O","B-country","O","B-country","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: metric, field, algorithm, university, conference, location, country, task, researcher, product, programming language, organization, person and O.\nSentence: It had over 30 locations in the U.S. , Canada , Mexico , Brazil and Argentina .","prompt_labels":"It(O) had(O) over(O) 30(O) locations(O) in(O) the(O) U.S.(B-country) ,(O) Canada(B-country) ,(O) Mexico(B-country) ,(O) Brazil(B-country) and(O) Argentina(B-country) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["country","organization","algorithm","metric","person","product","university","location","field","programming language","researcher","conference","task"],"instance":{"id":"50","words":["An","example","of","a","typical","computer","vision","computation","pipeline","for","Facial","recognition","system","using","k","-NN","including","feature","extraction","and","dimension","reduction","pre-processing","steps","(","usually","implemented","with","OpenCV",")",":"],"labels":["O","O","O","O","O","B-field","I-field","O","O","O","B-product","I-product","I-product","O","B-algorithm","I-algorithm","O","B-task","I-task","O","B-task","I-task","O","O","O","O","O","O","B-product","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, organization, algorithm, metric, person, product, university, location, field, programming language, researcher, conference, task and O.\nSentence: An example of a typical computer vision computation pipeline for Facial recognition system using k -NN including feature extraction and dimension reduction pre-processing steps ( usually implemented with OpenCV ) :","prompt_labels":"An(O) example(O) of(O) a(O) typical(O) computer(B-field) vision(I-field) computation(O) pipeline(O) for(O) Facial(B-product) recognition(I-product) system(I-product) using(O) k(B-algorithm) -NN(I-algorithm) including(O) feature(B-task) extraction(I-task) and(O) dimension(B-task) reduction(I-task) pre-processing(O) steps(O) ((O) usually(O) implemented(O) with(O) OpenCV(B-product) )(O) :(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["location","algorithm","country","task","researcher","programming language","organization","conference","field","university","person","metric","product"],"instance":{"id":"51","words":["It","has","a","rich","set","of","features",",","libraries","for","constraint","logic","programming",",","multithreading",",","unit","testing",",","GUI",",","interfacing","to","Java",",","ODBC","and","others",",","literate","programming",",","a","web","server",",","SGML",",","RDF",",","RDFS",",","developer","tools","(","including","an","IDE","with","a","GUI","debugger","and","GUI","profiler",")",",","and","extensive","documentation","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-algorithm","I-algorithm","I-algorithm","O","O","O","O","O","O","O","O","O","O","B-programming language","O","B-product","O","O","O","B-algorithm","I-algorithm","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, algorithm, country, task, researcher, programming language, organization, conference, field, university, person, metric, product and O.\nSentence: It has a rich set of features , libraries for constraint logic programming , multithreading , unit testing , GUI , interfacing to Java , ODBC and others , literate programming , a web server , SGML , RDF , RDFS , developer tools ( including an IDE with a GUI debugger and GUI profiler ) , and extensive documentation .","prompt_labels":"It(O) has(O) a(O) rich(O) set(O) of(O) features(O) ,(O) libraries(O) for(O) constraint(B-algorithm) logic(I-algorithm) programming(I-algorithm) ,(O) multithreading(O) ,(O) unit(O) testing(O) ,(O) GUI(O) ,(O) interfacing(O) to(O) Java(B-programming language) ,(O) ODBC(B-product) and(O) others(O) ,(O) literate(B-algorithm) programming(I-algorithm) ,(O) a(O) web(O) server(O) ,(O) SGML(O) ,(O) RDF(O) ,(O) RDFS(O) ,(O) developer(O) tools(O) ((O) including(O) an(O) IDE(O) with(O) a(O) GUI(O) debugger(O) and(O) GUI(O) profiler(O) )(O) ,(O) and(O) extensive(O) documentation(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["person","researcher","organization","country","programming language","product","metric","field","task","university","conference","location","algorithm"],"instance":{"id":"52","words":["In","computer","vision","and","image","processing",",","the","notion","of","scale","space","representation","and","Gaussian","derivative","operators","is","as","a","canonical","multi-scale","representation","."],"labels":["O","B-field","I-field","O","B-field","I-field","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, researcher, organization, country, programming language, product, metric, field, task, university, conference, location, algorithm and O.\nSentence: In computer vision and image processing , the notion of scale space representation and Gaussian derivative operators is as a canonical multi-scale representation .","prompt_labels":"In(O) computer(B-field) vision(I-field) and(O) image(B-field) processing(I-field) ,(O) the(O) notion(O) of(O) scale(O) space(O) representation(O) and(O) Gaussian(O) derivative(O) operators(O) is(O) as(O) a(O) canonical(O) multi-scale(O) representation(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["country","organization","algorithm","field","conference","product","person","location","programming language","researcher","task","university","metric"],"instance":{"id":"53","words":["He","is","also","the","President","of","the","Neural","Information","Processing","Systems","Foundation",",","a","non-profit","organization","that","oversees","the","annual","Conference","on","Neural","Information","Processing","Systems","Conference","."],"labels":["O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","O","O","O","O","O","O","O","B-conference","I-conference","I-conference","I-conference","I-conference","I-conference","I-conference","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, organization, algorithm, field, conference, product, person, location, programming language, researcher, task, university, metric and O.\nSentence: He is also the President of the Neural Information Processing Systems Foundation , a non-profit organization that oversees the annual Conference on Neural Information Processing Systems Conference .","prompt_labels":"He(O) is(O) also(O) the(O) President(O) of(O) the(O) Neural(B-organization) Information(I-organization) Processing(I-organization) Systems(I-organization) Foundation(I-organization) ,(O) a(O) non-profit(O) organization(O) that(O) oversees(O) the(O) annual(O) Conference(B-conference) on(I-conference) Neural(I-conference) Information(I-conference) Processing(I-conference) Systems(I-conference) Conference(I-conference) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["location","algorithm","metric","conference","university","person","task","product","organization","field","country","programming language","researcher"],"instance":{"id":"54","words":["For","regression","analysis","problems","the","squared","error","can","be","used","as","a","loss","function",",","for","classification","the","cross","entropy","can","be","used","."],"labels":["O","B-task","I-task","O","O","B-metric","I-metric","O","O","O","O","O","O","O","O","O","B-task","O","B-metric","I-metric","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, algorithm, metric, conference, university, person, task, product, organization, field, country, programming language, researcher and O.\nSentence: For regression analysis problems the squared error can be used as a loss function , for classification the cross entropy can be used .","prompt_labels":"For(O) regression(B-task) analysis(I-task) problems(O) the(O) squared(B-metric) error(I-metric) can(O) be(O) used(O) as(O) a(O) loss(O) function(O) ,(O) for(O) classification(B-task) the(O) cross(B-metric) entropy(I-metric) can(O) be(O) used(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["researcher","country","programming language","university","organization","task","conference","person","location","metric","field","product","algorithm"],"instance":{"id":"55","words":["Lafferty","served","many","prestigious","positions",",","including",":","1",")","program","co-chair","and","general","co-chair","of","the","Neural","Information","Processing","Systems","(","Conference","on","Neural","Information","Processing","Systems",")","Foundation","conferences",";","2",")","co-director","of","CMU","'s","new","Ph.D.","Machine","Learning","Ph.D.","Program",";","3",")","associate","editor","of","the","Journal","of","Machine","Learning","Research"],"labels":["B-researcher","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-conference","I-conference","I-conference","I-conference","O","B-conference","I-conference","I-conference","I-conference","I-conference","I-conference","O","O","O","O","O","O","O","O","B-university","O","O","O","B-field","I-field","O","O","O","O","O","O","O","O","O","B-conference","I-conference","I-conference","I-conference","I-conference"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: researcher, country, programming language, university, organization, task, conference, person, location, metric, field, product, algorithm and O.\nSentence: Lafferty served many prestigious positions , including : 1 ) program co-chair and general co-chair of the Neural Information Processing Systems ( Conference on Neural Information Processing Systems ) Foundation conferences ; 2 ) co-director of CMU 's new Ph.D. Machine Learning Ph.D. Program ; 3 ) associate editor of the Journal of Machine Learning Research","prompt_labels":"Lafferty(B-researcher) served(O) many(O) prestigious(O) positions(O) ,(O) including(O) :(O) 1(O) )(O) program(O) co-chair(O) and(O) general(O) co-chair(O) of(O) the(O) Neural(B-conference) Information(I-conference) Processing(I-conference) Systems(I-conference) ((O) Conference(B-conference) on(I-conference) Neural(I-conference) Information(I-conference) Processing(I-conference) Systems(I-conference) )(O) Foundation(O) conferences(O) ;(O) 2(O) )(O) co-director(O) of(O) CMU(B-university) 's(O) new(O) Ph.D.(O) Machine(B-field) Learning(I-field) Ph.D.(O) Program(O) ;(O) 3(O) )(O) associate(O) editor(O) of(O) the(O) Journal(B-conference) of(I-conference) Machine(I-conference) Learning(I-conference) Research(I-conference)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["algorithm","university","researcher","organization","person","country","conference","task","metric","programming language","field","location","product"],"instance":{"id":"56","words":["Convex","algorithms",",","such","as","AdaBoost","and","LogitBoost",",","can","be","defeated","by","random","noise","such","they","can","'t","learn","basic","and","learnable","combinations","of","weak","hypotheses","."],"labels":["O","O","O","O","O","B-algorithm","O","B-algorithm","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: algorithm, university, researcher, organization, person, country, conference, task, metric, programming language, field, location, product and O.\nSentence: Convex algorithms , such as AdaBoost and LogitBoost , can be defeated by random noise such they can 't learn basic and learnable combinations of weak hypotheses .","prompt_labels":"Convex(O) algorithms(O) ,(O) such(O) as(O) AdaBoost(B-algorithm) and(O) LogitBoost(B-algorithm) ,(O) can(O) be(O) defeated(O) by(O) random(O) noise(O) such(O) they(O) can(O) 't(O) learn(O) basic(O) and(O) learnable(O) combinations(O) of(O) weak(O) hypotheses(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["product","country","organization","conference","metric","researcher","person","programming language","field","task","algorithm","university","location"],"instance":{"id":"57","words":["Apertium","is","a","shallow-transfer","machine","translation","system",",","which","uses","finite","state","transducer","s","for","all","of","its","lexical","transformations",",","and","hidden","Markov","model","s","for","part-of-speech","tagging","or","word","category","disambiguation","."],"labels":["B-product","O","O","B-product","I-product","I-product","I-product","O","O","O","B-algorithm","I-algorithm","I-algorithm","O","O","O","O","O","O","O","O","O","B-algorithm","I-algorithm","I-algorithm","O","O","B-task","I-task","O","B-task","I-task","I-task","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: product, country, organization, conference, metric, researcher, person, programming language, field, task, algorithm, university, location and O.\nSentence: Apertium is a shallow-transfer machine translation system , which uses finite state transducer s for all of its lexical transformations , and hidden Markov model s for part-of-speech tagging or word category disambiguation .","prompt_labels":"Apertium(B-product) is(O) a(O) shallow-transfer(B-product) machine(I-product) translation(I-product) system(I-product) ,(O) which(O) uses(O) finite(B-algorithm) state(I-algorithm) transducer(I-algorithm) s(O) for(O) all(O) of(O) its(O) lexical(O) transformations(O) ,(O) and(O) hidden(B-algorithm) Markov(I-algorithm) model(I-algorithm) s(O) for(O) part-of-speech(B-task) tagging(I-task) or(O) word(B-task) category(I-task) disambiguation(I-task) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["product","field","metric","algorithm","conference","university","task","programming language","organization","location","country","person","researcher"],"instance":{"id":"58","words":["The","natural","gradient","of","mathE","f","(","x",")","\/","math",",","complying","with","the","Fisher","information","metric","(","an","informational","distance","measure","between","probability","distributions","and","the","curvature","of","the","relative","entropy",")",",","now","reads"],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-metric","I-metric","I-metric","O","O","O","O","O","O","O","O","O","O","O","O","O","B-metric","I-metric","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: product, field, metric, algorithm, conference, university, task, programming language, organization, location, country, person, researcher and O.\nSentence: The natural gradient of mathE f ( x ) \/ math , complying with the Fisher information metric ( an informational distance measure between probability distributions and the curvature of the relative entropy ) , now reads","prompt_labels":"The(O) natural(O) gradient(O) of(O) mathE(O) f(O) ((O) x(O) )(O) \/(O) math(O) ,(O) complying(O) with(O) the(O) Fisher(B-metric) information(I-metric) metric(I-metric) ((O) an(O) informational(O) distance(O) measure(O) between(O) probability(O) distributions(O) and(O) the(O) curvature(O) of(O) the(O) relative(B-metric) entropy(I-metric) )(O) ,(O) now(O) reads(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["field","researcher","country","organization","conference","university","algorithm","task","metric","location","programming language","person","product"],"instance":{"id":"59","words":["The","S","programming","language","inspired","the","systems","'","S","'","-PLUS","and","R","."],"labels":["O","B-programming language","I-programming language","I-programming language","O","O","O","B-product","I-product","I-product","I-product","O","B-programming language","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: field, researcher, country, organization, conference, university, algorithm, task, metric, location, programming language, person, product and O.\nSentence: The S programming language inspired the systems ' S ' -PLUS and R .","prompt_labels":"The(O) S(B-programming language) programming(I-programming language) language(I-programming language) inspired(O) the(O) systems(O) '(B-product) S(I-product) '(I-product) -PLUS(I-product) and(O) R(B-programming language) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["algorithm","country","university","field","metric","product","person","task","location","programming language","organization","conference","researcher"],"instance":{"id":"60","words":["The","most","influential","implementation","of","Planner","was","the","subset","of","Planner",",","called","Micro-Planner",",","implemented","by","Gerald","Jay","Sussman",",","Eugene","Charniak","and","Terry","Winograd","."],"labels":["O","O","O","O","O","B-product","O","O","O","O","B-product","O","O","B-product","O","O","O","B-researcher","I-researcher","I-researcher","O","B-researcher","I-researcher","O","B-researcher","I-researcher","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: algorithm, country, university, field, metric, product, person, task, location, programming language, organization, conference, researcher and O.\nSentence: The most influential implementation of Planner was the subset of Planner , called Micro-Planner , implemented by Gerald Jay Sussman , Eugene Charniak and Terry Winograd .","prompt_labels":"The(O) most(O) influential(O) implementation(O) of(O) Planner(B-product) was(O) the(O) subset(O) of(O) Planner(B-product) ,(O) called(O) Micro-Planner(B-product) ,(O) implemented(O) by(O) Gerald(B-researcher) Jay(I-researcher) Sussman(I-researcher) ,(O) Eugene(B-researcher) Charniak(I-researcher) and(O) Terry(B-researcher) Winograd(I-researcher) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["metric","task","programming language","field","university","country","algorithm","location","person","product","conference","organization","researcher"],"instance":{"id":"61","words":["In","1779","the","Germany","-","Denmark","scientist","Christian","Gottlieb","Kratzenstein","won","the","first","prize","in","a","competition","announced","the","Russian","Imperial","Academy","of","Sciences","and","Arts","for","models","he","built","of","the","human","vocal","tract","that","could","produce","the","five","long","vowel","sounds","(","in","International","Phonetic","Alphabet","notation",":"],"labels":["O","O","O","B-country","O","B-country","O","B-researcher","I-researcher","I-researcher","O","O","O","O","O","O","O","O","O","O","B-university","I-university","I-university","I-university","I-university","I-university","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: metric, task, programming language, field, university, country, algorithm, location, person, product, conference, organization, researcher and O.\nSentence: In 1779 the Germany - Denmark scientist Christian Gottlieb Kratzenstein won the first prize in a competition announced the Russian Imperial Academy of Sciences and Arts for models he built of the human vocal tract that could produce the five long vowel sounds ( in International Phonetic Alphabet notation :","prompt_labels":"In(O) 1779(O) the(O) Germany(B-country) -(O) Denmark(B-country) scientist(O) Christian(B-researcher) Gottlieb(I-researcher) Kratzenstein(I-researcher) won(O) the(O) first(O) prize(O) in(O) a(O) competition(O) announced(O) the(O) Russian(O) Imperial(B-university) Academy(I-university) of(I-university) Sciences(I-university) and(I-university) Arts(I-university) for(O) models(O) he(O) built(O) of(O) the(O) human(O) vocal(O) tract(O) that(O) could(O) produce(O) the(O) five(O) long(O) vowel(O) sounds(O) ((O) in(O) International(O) Phonetic(O) Alphabet(O) notation(O) :(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["country","conference","person","programming language","researcher","algorithm","field","organization","task","metric","product","location","university"],"instance":{"id":"62","words":["New","features","in","Office","XP","include","smart","tags",",","a","selection-based","search","feature","that","recognizes","different","types","of","text","in","a","document","so","that","users","can","perform","additional","actions",";","a","task","pane","interface","that","consolidates","popular","menu","bar","commands","on","the","right","side","of","the","screen","to","facilitate","quick","access","to","them",";","new","document","collaboration","capabilities",",","support","for","MSN","Groups","and","SharePoint",";","and","integrated","handwriting","recognition","and","speech","recognition","capabilities","."],"labels":["O","O","O","B-product","I-product","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-task","I-task","O","O","O","O","B-product","I-product","O","B-product","O","O","O","B-task","I-task","O","B-task","I-task","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, conference, person, programming language, researcher, algorithm, field, organization, task, metric, product, location, university and O.\nSentence: New features in Office XP include smart tags , a selection-based search feature that recognizes different types of text in a document so that users can perform additional actions ; a task pane interface that consolidates popular menu bar commands on the right side of the screen to facilitate quick access to them ; new document collaboration capabilities , support for MSN Groups and SharePoint ; and integrated handwriting recognition and speech recognition capabilities .","prompt_labels":"New(O) features(O) in(O) Office(B-product) XP(I-product) include(O) smart(O) tags(O) ,(O) a(O) selection-based(O) search(O) feature(O) that(O) recognizes(O) different(O) types(O) of(O) text(O) in(O) a(O) document(O) so(O) that(O) users(O) can(O) perform(O) additional(O) actions(O) ;(O) a(O) task(O) pane(O) interface(O) that(O) consolidates(O) popular(O) menu(O) bar(O) commands(O) on(O) the(O) right(O) side(O) of(O) the(O) screen(O) to(O) facilitate(O) quick(O) access(O) to(O) them(O) ;(O) new(O) document(B-task) collaboration(I-task) capabilities(O) ,(O) support(O) for(O) MSN(B-product) Groups(I-product) and(O) SharePoint(B-product) ;(O) and(O) integrated(O) handwriting(B-task) recognition(I-task) and(O) speech(B-task) recognition(I-task) capabilities(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["location","person","metric","country","researcher","product","organization","field","university","conference","programming language","task","algorithm"],"instance":{"id":"63","words":["In","many","applications","the","units","of","these","networks","apply","a","sigmoid","function","as","an","activation","function","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-algorithm","I-algorithm","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, person, metric, country, researcher, product, organization, field, university, conference, programming language, task, algorithm and O.\nSentence: In many applications the units of these networks apply a sigmoid function as an activation function .","prompt_labels":"In(O) many(O) applications(O) the(O) units(O) of(O) these(O) networks(O) apply(O) a(O) sigmoid(B-algorithm) function(I-algorithm) as(O) an(O) activation(O) function(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["programming language","product","task","conference","university","algorithm","location","country","organization","field","metric","researcher","person"],"instance":{"id":"64","words":["In","2001",",","Mehler","was","elected","a","foreign","honorary","member","of","the","American","Academy","of","Arts","and","Sciences",",","and","in","2003",",","he","was","elected","a","Fellow","of","the","American","Association","for","the","Advancement","of","Science","."],"labels":["O","O","O","B-researcher","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","O","O","O","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: programming language, product, task, conference, university, algorithm, location, country, organization, field, metric, researcher, person and O.\nSentence: In 2001 , Mehler was elected a foreign honorary member of the American Academy of Arts and Sciences , and in 2003 , he was elected a Fellow of the American Association for the Advancement of Science .","prompt_labels":"In(O) 2001(O) ,(O) Mehler(B-researcher) was(O) elected(O) a(O) foreign(O) honorary(O) member(O) of(O) the(O) American(B-organization) Academy(I-organization) of(I-organization) Arts(I-organization) and(I-organization) Sciences(I-organization) ,(O) and(O) in(O) 2003(O) ,(O) he(O) was(O) elected(O) a(O) Fellow(O) of(O) the(O) American(B-organization) Association(I-organization) for(I-organization) the(I-organization) Advancement(I-organization) of(I-organization) Science(I-organization) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["programming language","field","product","location","country","person","organization","conference","metric","researcher","task","algorithm","university"],"instance":{"id":"65","words":["The","extension","of","this","concept","to","non-binary","classifications","yields","the","confusion","matrix","."],"labels":["O","O","O","O","O","O","B-task","I-task","O","O","B-metric","I-metric","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: programming language, field, product, location, country, person, organization, conference, metric, researcher, task, algorithm, university and O.\nSentence: The extension of this concept to non-binary classifications yields the confusion matrix .","prompt_labels":"The(O) extension(O) of(O) this(O) concept(O) to(O) non-binary(B-task) classifications(I-task) yields(O) the(O) confusion(B-metric) matrix(I-metric) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["country","algorithm","task","person","university","field","conference","programming language","organization","product","location","researcher","metric"],"instance":{"id":"66","words":["An","updated","measurement","noise","variance","estimate","can","be","obtained","from","the","maximum","likelihood","calculation"],"labels":["O","O","O","O","O","O","O","O","O","O","O","B-algorithm","I-algorithm","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, algorithm, task, person, university, field, conference, programming language, organization, product, location, researcher, metric and O.\nSentence: An updated measurement noise variance estimate can be obtained from the maximum likelihood calculation","prompt_labels":"An(O) updated(O) measurement(O) noise(O) variance(O) estimate(O) can(O) be(O) obtained(O) from(O) the(O) maximum(B-algorithm) likelihood(I-algorithm) calculation(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["university","programming language","metric","country","person","task","product","conference","organization","algorithm","location","field","researcher"],"instance":{"id":"67","words":["In","machine","learning",",","the","perceptron","is","an","algorithm","for","supervised","learning","of","binary","classification","."],"labels":["O","B-field","I-field","O","O","B-algorithm","O","O","O","O","B-field","I-field","O","B-task","I-task","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: university, programming language, metric, country, person, task, product, conference, organization, algorithm, location, field, researcher and O.\nSentence: In machine learning , the perceptron is an algorithm for supervised learning of binary classification .","prompt_labels":"In(O) machine(B-field) learning(I-field) ,(O) the(O) perceptron(B-algorithm) is(O) an(O) algorithm(O) for(O) supervised(B-field) learning(I-field) of(O) binary(B-task) classification(I-task) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["researcher","metric","programming language","country","university","algorithm","organization","product","location","task","field","person","conference"],"instance":{"id":"68","words":["She","has","also","served","as","Area","Chair","of","several","machine","learning","and","vision","conferences","including","Conference","on","Neural","Information","Processing","Systems",",","International","Conference","on","Learning","Representations",",","Conference","on","Computer","Vision","and","Pattern","Recognition",",","International","Conference","on","Computer","Vision",",","and","European","Conference","on","Computer","Vision","."],"labels":["O","O","O","O","O","O","O","O","O","B-field","I-field","O","B-field","O","O","B-conference","I-conference","I-conference","I-conference","I-conference","I-conference","O","B-conference","I-conference","I-conference","I-conference","I-conference","O","B-conference","I-conference","I-conference","I-conference","I-conference","I-conference","I-conference","O","B-conference","I-conference","I-conference","I-conference","I-conference","O","O","B-conference","I-conference","I-conference","I-conference","I-conference","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: researcher, metric, programming language, country, university, algorithm, organization, product, location, task, field, person, conference and O.\nSentence: She has also served as Area Chair of several machine learning and vision conferences including Conference on Neural Information Processing Systems , International Conference on Learning Representations , Conference on Computer Vision and Pattern Recognition , International Conference on Computer Vision , and European Conference on Computer Vision .","prompt_labels":"She(O) has(O) also(O) served(O) as(O) Area(O) Chair(O) of(O) several(O) machine(B-field) learning(I-field) and(O) vision(B-field) conferences(O) including(O) Conference(B-conference) on(I-conference) Neural(I-conference) Information(I-conference) Processing(I-conference) Systems(I-conference) ,(O) International(B-conference) Conference(I-conference) on(I-conference) Learning(I-conference) Representations(I-conference) ,(O) Conference(B-conference) on(I-conference) Computer(I-conference) Vision(I-conference) and(I-conference) Pattern(I-conference) Recognition(I-conference) ,(O) International(B-conference) Conference(I-conference) on(I-conference) Computer(I-conference) Vision(I-conference) ,(O) and(O) European(B-conference) Conference(I-conference) on(I-conference) Computer(I-conference) Vision(I-conference) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["field","product","algorithm","task","university","programming language","country","organization","location","metric","conference","researcher","person"],"instance":{"id":"69","words":["The","condensation","algorithm","has","also","been","used","for","facial","recognition","system","in","a","video","sequence","."],"labels":["O","B-algorithm","I-algorithm","O","O","O","O","O","B-product","I-product","I-product","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: field, product, algorithm, task, university, programming language, country, organization, location, metric, conference, researcher, person and O.\nSentence: The condensation algorithm has also been used for facial recognition system in a video sequence .","prompt_labels":"The(O) condensation(B-algorithm) algorithm(I-algorithm) has(O) also(O) been(O) used(O) for(O) facial(B-product) recognition(I-product) system(I-product) in(O) a(O) video(O) sequence(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["metric","task","researcher","location","conference","country","product","university","person","algorithm","organization","programming language","field"],"instance":{"id":"70","words":["Information","Dissemination","is","also","part","of","ELRA","'s","missions","which","is","carried","through","both","the","organisation","of","the","conference","LREC","and","the","Language","Resources","and","Evaluation","Journal","edited","by","Springer","."],"labels":["B-task","I-task","O","O","O","O","B-conference","O","O","O","O","O","O","O","O","O","O","O","O","B-conference","O","O","B-conference","I-conference","I-conference","I-conference","I-conference","O","O","B-conference","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: metric, task, researcher, location, conference, country, product, university, person, algorithm, organization, programming language, field and O.\nSentence: Information Dissemination is also part of ELRA 's missions which is carried through both the organisation of the conference LREC and the Language Resources and Evaluation Journal edited by Springer .","prompt_labels":"Information(B-task) Dissemination(I-task) is(O) also(O) part(O) of(O) ELRA(B-conference) 's(O) missions(O) which(O) is(O) carried(O) through(O) both(O) the(O) organisation(O) of(O) the(O) conference(O) LREC(B-conference) and(O) the(O) Language(B-conference) Resources(I-conference) and(I-conference) Evaluation(I-conference) Journal(I-conference) edited(O) by(O) Springer(B-conference) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["country","task","researcher","person","metric","university","product","field","location","conference","organization","algorithm","programming language"],"instance":{"id":"71","words":["In","linear","time-invariant","(","LTI",")","system","theory",",","control","theory",",","and","in","digital","signal","processing","or","signal","processing",",","the","relationship","between","the","input","signal",",","math","\\","displaystyle","x","(","t",")","\/","math",",","to","output","signal",",","math","\\","displaystyle","y","(","t",")","\/","math",",","of","an","LTI","system","is","governed","by","a","convolution","operation",":"],"labels":["O","B-field","I-field","I-field","I-field","I-field","I-field","I-field","O","B-field","I-field","O","O","O","B-field","I-field","I-field","O","B-field","I-field","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-field","I-field","O","O","O","O","B-algorithm","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, task, researcher, person, metric, university, product, field, location, conference, organization, algorithm, programming language and O.\nSentence: In linear time-invariant ( LTI ) system theory , control theory , and in digital signal processing or signal processing , the relationship between the input signal , math \\ displaystyle x ( t ) \/ math , to output signal , math \\ displaystyle y ( t ) \/ math , of an LTI system is governed by a convolution operation :","prompt_labels":"In(O) linear(B-field) time-invariant(I-field) ((I-field) LTI(I-field) )(I-field) system(I-field) theory(I-field) ,(O) control(B-field) theory(I-field) ,(O) and(O) in(O) digital(B-field) signal(I-field) processing(I-field) or(O) signal(B-field) processing(I-field) ,(O) the(O) relationship(O) between(O) the(O) input(O) signal(O) ,(O) math(O) \\(O) displaystyle(O) x(O) ((O) t(O) )(O) \/(O) math(O) ,(O) to(O) output(O) signal(O) ,(O) math(O) \\(O) displaystyle(O) y(O) ((O) t(O) )(O) \/(O) math(O) ,(O) of(O) an(O) LTI(B-field) system(I-field) is(O) governed(O) by(O) a(O) convolution(B-algorithm) operation(O) :(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["country","person","metric","algorithm","conference","researcher","location","university","field","product","programming language","task","organization"],"instance":{"id":"72","words":["Due","to","its","generality",",","the","field","is","studied","in","many","other","disciplines",",","such","as","game","theory",",","control","theory",",","operations","research",",","information","theory",",","simulation-based","optimization",",","multi-agent","systems",",","swarm","intelligence",",","statistics","and","genetic","algorithm","s","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-field","I-field","O","B-field","I-field","O","B-field","I-field","O","B-field","I-field","O","B-field","I-field","O","B-product","I-product","O","B-field","I-field","O","B-field","O","B-algorithm","I-algorithm","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, person, metric, algorithm, conference, researcher, location, university, field, product, programming language, task, organization and O.\nSentence: Due to its generality , the field is studied in many other disciplines , such as game theory , control theory , operations research , information theory , simulation-based optimization , multi-agent systems , swarm intelligence , statistics and genetic algorithm s .","prompt_labels":"Due(O) to(O) its(O) generality(O) ,(O) the(O) field(O) is(O) studied(O) in(O) many(O) other(O) disciplines(O) ,(O) such(O) as(O) game(B-field) theory(I-field) ,(O) control(B-field) theory(I-field) ,(O) operations(B-field) research(I-field) ,(O) information(B-field) theory(I-field) ,(O) simulation-based(B-field) optimization(I-field) ,(O) multi-agent(B-product) systems(I-product) ,(O) swarm(B-field) intelligence(I-field) ,(O) statistics(B-field) and(O) genetic(B-algorithm) algorithm(I-algorithm) s(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["university","task","programming language","location","conference","product","person","organization","algorithm","metric","researcher","field","country"],"instance":{"id":"73","words":["Stochastic","gradient","descent","is","a","popular","algorithm","for","training","a","wide","range","of","models","in","machine","learning",",","including","(","linear",")","support","vector","machine","s",",","logistic","regression","(","see",",","e.g.",",","Vowpal","Wabbit",")","and","graphical","model","s.Jenny","Rose","Finkel",",","Alex","Kleeman",",","Christopher","D.","Manning","(","2008",")","."],"labels":["B-algorithm","I-algorithm","I-algorithm","O","O","O","O","O","O","O","O","O","O","O","O","B-field","I-field","O","O","O","O","O","B-algorithm","I-algorithm","I-algorithm","O","O","B-algorithm","I-algorithm","O","O","O","O","O","B-algorithm","I-algorithm","O","O","B-algorithm","I-algorithm","B-researcher","I-researcher","I-researcher","O","B-researcher","I-researcher","O","B-researcher","I-researcher","I-researcher","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: university, task, programming language, location, conference, product, person, organization, algorithm, metric, researcher, field, country and O.\nSentence: Stochastic gradient descent is a popular algorithm for training a wide range of models in machine learning , including ( linear ) support vector machine s , logistic regression ( see , e.g. , Vowpal Wabbit ) and graphical model s.Jenny Rose Finkel , Alex Kleeman , Christopher D. Manning ( 2008 ) .","prompt_labels":"Stochastic(B-algorithm) gradient(I-algorithm) descent(I-algorithm) is(O) a(O) popular(O) algorithm(O) for(O) training(O) a(O) wide(O) range(O) of(O) models(O) in(O) machine(B-field) learning(I-field) ,(O) including(O) ((O) linear(O) )(O) support(B-algorithm) vector(I-algorithm) machine(I-algorithm) s(O) ,(O) logistic(B-algorithm) regression(I-algorithm) ((O) see(O) ,(O) e.g.(O) ,(O) Vowpal(B-algorithm) Wabbit(I-algorithm) )(O) and(O) graphical(B-algorithm) model(I-algorithm) s.Jenny(B-researcher) Rose(I-researcher) Finkel(I-researcher) ,(O) Alex(B-researcher) Kleeman(I-researcher) ,(O) Christopher(B-researcher) D.(I-researcher) Manning(I-researcher) ((O) 2008(O) )(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["country","researcher","algorithm","task","location","field","organization","programming language","product","person","conference","metric","university"],"instance":{"id":"74","words":["In","August","2011",",","it","was","announced","that","Hitachi","would","donate","an","electron","microscope","to","each","of","five","universities","in","Indonesia","(","the","University","of","North","Sumatra","in","Medan",",","the","Indonesian","Christian","University","in","Jakarta",",","Padjadjaran","University","in","Bandung",",","Jenderal","Soedirman","University","in","Purwokerto","and","Muhammadiyah","University","in","Malang",")","."],"labels":["O","O","O","O","O","O","O","O","B-organization","O","O","O","B-product","I-product","O","O","O","O","O","O","B-country","O","O","B-university","I-university","I-university","I-university","O","B-location","O","O","B-university","I-university","I-university","O","B-location","O","B-university","I-university","O","B-location","O","B-university","I-university","I-university","O","B-location","O","B-university","I-university","O","B-location","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, researcher, algorithm, task, location, field, organization, programming language, product, person, conference, metric, university and O.\nSentence: In August 2011 , it was announced that Hitachi would donate an electron microscope to each of five universities in Indonesia ( the University of North Sumatra in Medan , the Indonesian Christian University in Jakarta , Padjadjaran University in Bandung , Jenderal Soedirman University in Purwokerto and Muhammadiyah University in Malang ) .","prompt_labels":"In(O) August(O) 2011(O) ,(O) it(O) was(O) announced(O) that(O) Hitachi(B-organization) would(O) donate(O) an(O) electron(B-product) microscope(I-product) to(O) each(O) of(O) five(O) universities(O) in(O) Indonesia(B-country) ((O) the(O) University(B-university) of(I-university) North(I-university) Sumatra(I-university) in(O) Medan(B-location) ,(O) the(O) Indonesian(B-university) Christian(I-university) University(I-university) in(O) Jakarta(B-location) ,(O) Padjadjaran(B-university) University(I-university) in(O) Bandung(B-location) ,(O) Jenderal(B-university) Soedirman(I-university) University(I-university) in(O) Purwokerto(B-location) and(O) Muhammadiyah(B-university) University(I-university) in(O) Malang(B-location) )(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["conference","person","country","university","product","task","algorithm","metric","field","location","researcher","organization","programming language"],"instance":{"id":"75","words":["Optimization","techniques","of","operations","research","such","as","linear","programming","or","dynamic","programming","are","often","impractical","for","large","scale","software","engineering","problems","because","of","their","computational","complexity","."],"labels":["B-field","O","O","B-field","I-field","O","O","B-algorithm","I-algorithm","O","B-algorithm","I-algorithm","O","O","O","O","O","O","B-field","I-field","O","O","O","O","B-metric","I-metric","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: conference, person, country, university, product, task, algorithm, metric, field, location, researcher, organization, programming language and O.\nSentence: Optimization techniques of operations research such as linear programming or dynamic programming are often impractical for large scale software engineering problems because of their computational complexity .","prompt_labels":"Optimization(B-field) techniques(O) of(O) operations(B-field) research(I-field) such(O) as(O) linear(B-algorithm) programming(I-algorithm) or(O) dynamic(B-algorithm) programming(I-algorithm) are(O) often(O) impractical(O) for(O) large(O) scale(O) software(B-field) engineering(I-field) problems(O) because(O) of(O) their(O) computational(B-metric) complexity(I-metric) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["programming language","organization","product","university","researcher","person","conference","task","country","algorithm","field","metric","location"],"instance":{"id":"76","words":["Sensitivity","is","not","the","same","as","the","precision","or","positive","predictive","value","(","ratio","of","TRUE","positives","to","combined","TRUE","and","FALSE","positives",")",",","which","is","as","much","a","statement","about","the","proportion","of","actual","positives","in","the","population","being","tested","as","it","is","about","the","test","."],"labels":["B-metric","O","O","O","O","O","O","B-metric","O","B-metric","I-metric","I-metric","O","O","O","B-metric","I-metric","O","O","B-metric","I-metric","I-metric","I-metric","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: programming language, organization, product, university, researcher, person, conference, task, country, algorithm, field, metric, location and O.\nSentence: Sensitivity is not the same as the precision or positive predictive value ( ratio of TRUE positives to combined TRUE and FALSE positives ) , which is as much a statement about the proportion of actual positives in the population being tested as it is about the test .","prompt_labels":"Sensitivity(B-metric) is(O) not(O) the(O) same(O) as(O) the(O) precision(B-metric) or(O) positive(B-metric) predictive(I-metric) value(I-metric) ((O) ratio(O) of(O) TRUE(B-metric) positives(I-metric) to(O) combined(O) TRUE(B-metric) and(I-metric) FALSE(I-metric) positives(I-metric) )(O) ,(O) which(O) is(O) as(O) much(O) a(O) statement(O) about(O) the(O) proportion(O) of(O) actual(O) positives(O) in(O) the(O) population(O) being(O) tested(O) as(O) it(O) is(O) about(O) the(O) test(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["university","task","metric","country","programming language","product","field","algorithm","person","conference","researcher","organization","location"],"instance":{"id":"77","words":["The","screenplay","by","Hampton","Fancher","!","--","Not","titled","Android","initially","-","See","Sammon",",","pp.","32","and","38","for","explanation","--","was","optioned","in","1977",".","Sammon",",","pp.","23-30","Producer","Michael","Deeley","became","interested","in","Fancher","'s","draft","and","convinced","director","Ridley","Scott","to","film","it","."],"labels":["O","O","O","B-person","I-person","O","O","O","O","B-product","O","O","O","B-person","O","O","O","O","O","O","O","O","O","O","O","O","O","B-person","O","O","O","O","B-person","I-person","O","O","O","B-person","O","O","O","O","O","B-person","I-person","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: university, task, metric, country, programming language, product, field, algorithm, person, conference, researcher, organization, location and O.\nSentence: The screenplay by Hampton Fancher ! -- Not titled Android initially - See Sammon , pp. 32 and 38 for explanation -- was optioned in 1977 . Sammon , pp. 23-30 Producer Michael Deeley became interested in Fancher 's draft and convinced director Ridley Scott to film it .","prompt_labels":"The(O) screenplay(O) by(O) Hampton(B-person) Fancher(I-person) !(O) --(O) Not(O) titled(O) Android(B-product) initially(O) -(O) See(O) Sammon(B-person) ,(O) pp.(O) 32(O) and(O) 38(O) for(O) explanation(O) --(O) was(O) optioned(O) in(O) 1977(O) .(O) Sammon(B-person) ,(O) pp.(O) 23-30(O) Producer(O) Michael(B-person) Deeley(I-person) became(O) interested(O) in(O) Fancher(B-person) 's(O) draft(O) and(O) convinced(O) director(O) Ridley(B-person) Scott(I-person) to(O) film(O) it(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["country","algorithm","field","researcher","location","task","metric","organization","product","programming language","conference","person","university"],"instance":{"id":"78","words":["Text","analysis","involves","information","retrieval",",","lexical","analysis","to","study","word","frequency","distributions",",","pattern","recognition",",","tagging","\/","annotation",",","information","extraction",",","data","mining","techniques","including","link","and","association","analysis",",","visualization",",","and","predictive","analytics","."],"labels":["B-field","I-field","O","B-task","I-task","O","B-task","I-task","O","O","O","O","O","O","B-field","I-field","O","B-task","I-task","I-task","O","B-task","I-task","O","B-field","I-field","O","O","B-task","I-task","I-task","I-task","O","B-task","O","O","B-task","I-task","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, algorithm, field, researcher, location, task, metric, organization, product, programming language, conference, person, university and O.\nSentence: Text analysis involves information retrieval , lexical analysis to study word frequency distributions , pattern recognition , tagging \/ annotation , information extraction , data mining techniques including link and association analysis , visualization , and predictive analytics .","prompt_labels":"Text(B-field) analysis(I-field) involves(O) information(B-task) retrieval(I-task) ,(O) lexical(B-task) analysis(I-task) to(O) study(O) word(O) frequency(O) distributions(O) ,(O) pattern(B-field) recognition(I-field) ,(O) tagging(B-task) \/(I-task) annotation(I-task) ,(O) information(B-task) extraction(I-task) ,(O) data(B-field) mining(I-field) techniques(O) including(O) link(B-task) and(I-task) association(I-task) analysis(I-task) ,(O) visualization(B-task) ,(O) and(O) predictive(B-task) analytics(I-task) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["programming language","organization","conference","researcher","country","metric","task","product","field","location","algorithm","person","university"],"instance":{"id":"79","words":["Several","metrics","use","WordNet",",","a","manually","constructed","lexical","database","of","English","words","."],"labels":["O","O","O","B-product","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: programming language, organization, conference, researcher, country, metric, task, product, field, location, algorithm, person, university and O.\nSentence: Several metrics use WordNet , a manually constructed lexical database of English words .","prompt_labels":"Several(O) metrics(O) use(O) WordNet(B-product) ,(O) a(O) manually(O) constructed(O) lexical(O) database(O) of(O) English(O) words(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["programming language","person","algorithm","researcher","country","organization","field","conference","location","metric","product","university","task"],"instance":{"id":"80","words":["The","system","uses","a","combination","of","techniques","from","computational","linguistics",",","information","retrieval","and","knowledge","representation","for","finding","answers","."],"labels":["O","O","O","O","O","O","O","O","B-field","I-field","O","B-task","I-task","O","B-task","I-task","I-task","I-task","I-task","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: programming language, person, algorithm, researcher, country, organization, field, conference, location, metric, product, university, task and O.\nSentence: The system uses a combination of techniques from computational linguistics , information retrieval and knowledge representation for finding answers .","prompt_labels":"The(O) system(O) uses(O) a(O) combination(O) of(O) techniques(O) from(O) computational(B-field) linguistics(I-field) ,(O) information(B-task) retrieval(I-task) and(O) knowledge(B-task) representation(I-task) for(I-task) finding(I-task) answers(I-task) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["product","university","task","conference","location","programming language","country","metric","field","person","organization","researcher","algorithm"],"instance":{"id":"81","words":["As","a","performance","metric",",","the","uncertainty","coefficient","has","the","advantage","over","simple","accuracy","in","that","it","is","not","affected","by","the","relative","sizes","of","the","different","classes","."],"labels":["O","O","O","O","O","O","B-metric","I-metric","O","O","O","O","O","B-metric","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: product, university, task, conference, location, programming language, country, metric, field, person, organization, researcher, algorithm and O.\nSentence: As a performance metric , the uncertainty coefficient has the advantage over simple accuracy in that it is not affected by the relative sizes of the different classes .","prompt_labels":"As(O) a(O) performance(O) metric(O) ,(O) the(O) uncertainty(B-metric) coefficient(I-metric) has(O) the(O) advantage(O) over(O) simple(O) accuracy(B-metric) in(O) that(O) it(O) is(O) not(O) affected(O) by(O) the(O) relative(O) sizes(O) of(O) the(O) different(O) classes(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["metric","researcher","organization","product","algorithm","programming language","university","field","task","location","person","conference","country"],"instance":{"id":"82","words":["Researchers","have","attempted","a","number","of","methods","such","as","optical","flow",",","Kalman","filtering",",","Hidden","Markov","model","s",",","etc","."],"labels":["O","O","O","O","O","O","O","O","O","B-algorithm","I-algorithm","O","B-algorithm","I-algorithm","O","B-algorithm","I-algorithm","I-algorithm","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: metric, researcher, organization, product, algorithm, programming language, university, field, task, location, person, conference, country and O.\nSentence: Researchers have attempted a number of methods such as optical flow , Kalman filtering , Hidden Markov model s , etc .","prompt_labels":"Researchers(O) have(O) attempted(O) a(O) number(O) of(O) methods(O) such(O) as(O) optical(B-algorithm) flow(I-algorithm) ,(O) Kalman(B-algorithm) filtering(I-algorithm) ,(O) Hidden(B-algorithm) Markov(I-algorithm) model(I-algorithm) s(O) ,(O) etc(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["researcher","field","product","programming language","metric","task","location","country","organization","algorithm","university","person","conference"],"instance":{"id":"83","words":["She","has","held","the","positions","of","President",",","Vice","President",",","and","Secretary-Treasurer","of","the","Association","for","Computational","Linguistics","and","has","been","a","board","member","and","secretary","of","the","board","of","the","Computing","Research","Association","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-conference","I-conference","I-conference","I-conference","O","O","O","O","O","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: researcher, field, product, programming language, metric, task, location, country, organization, algorithm, university, person, conference and O.\nSentence: She has held the positions of President , Vice President , and Secretary-Treasurer of the Association for Computational Linguistics and has been a board member and secretary of the board of the Computing Research Association .","prompt_labels":"She(O) has(O) held(O) the(O) positions(O) of(O) President(O) ,(O) Vice(O) President(O) ,(O) and(O) Secretary-Treasurer(O) of(O) the(O) Association(B-conference) for(I-conference) Computational(I-conference) Linguistics(I-conference) and(O) has(O) been(O) a(O) board(O) member(O) and(O) secretary(O) of(O) the(O) board(O) of(O) the(O) Computing(B-organization) Research(I-organization) Association(I-organization) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["product","organization","conference","location","person","country","researcher","algorithm","university","task","field","metric","programming language"],"instance":{"id":"84","words":["Like","other","similar","languages","such","as","APL","and","MATLAB",",","R","supports","matrix","arithmetic","."],"labels":["O","O","O","O","O","O","B-programming language","O","B-product","O","B-programming language","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: product, organization, conference, location, person, country, researcher, algorithm, university, task, field, metric, programming language and O.\nSentence: Like other similar languages such as APL and MATLAB , R supports matrix arithmetic .","prompt_labels":"Like(O) other(O) similar(O) languages(O) such(O) as(O) APL(B-programming language) and(O) MATLAB(B-product) ,(O) R(B-programming language) supports(O) matrix(O) arithmetic(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["task","organization","researcher","country","programming language","metric","university","person","field","conference","algorithm","product","location"],"instance":{"id":"85","words":["On","7","June","2014",",","in","a","Turing","test","competition","at","the","Royal","Society",",","organised","by","Kevin","Warwick","of","the","University","of","Reading","to","mark","the","60th","anniversary","of","Turing","'s","death",",","Goostman","won","after","33","%","of","the","judges","were","convinced","that","the","bot","was","human","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","B-organization","I-organization","O","O","O","B-researcher","I-researcher","O","O","B-university","I-university","I-university","O","O","O","O","O","O","O","O","O","O","B-researcher","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: task, organization, researcher, country, programming language, metric, university, person, field, conference, algorithm, product, location and O.\nSentence: On 7 June 2014 , in a Turing test competition at the Royal Society , organised by Kevin Warwick of the University of Reading to mark the 60th anniversary of Turing 's death , Goostman won after 33 % of the judges were convinced that the bot was human .","prompt_labels":"On(O) 7(O) June(O) 2014(O) ,(O) in(O) a(O) Turing(O) test(O) competition(O) at(O) the(O) Royal(B-organization) Society(I-organization) ,(O) organised(O) by(O) Kevin(B-researcher) Warwick(I-researcher) of(O) the(O) University(B-university) of(I-university) Reading(I-university) to(O) mark(O) the(O) 60th(O) anniversary(O) of(O) Turing(O) 's(O) death(O) ,(O) Goostman(B-researcher) won(O) after(O) 33(O) %(O) of(O) the(O) judges(O) were(O) convinced(O) that(O) the(O) bot(O) was(O) human(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["algorithm","task","researcher","product","location","university","conference","field","metric","programming language","country","person","organization"],"instance":{"id":"86","words":["A","collaborative","robot","or","cobot","is","a","robot","that","can","safely","and","effectively","interact","with","human","workers","while","performing","simple","industrial","tasks","."],"labels":["O","B-product","I-product","O","B-product","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: algorithm, task, researcher, product, location, university, conference, field, metric, programming language, country, person, organization and O.\nSentence: A collaborative robot or cobot is a robot that can safely and effectively interact with human workers while performing simple industrial tasks .","prompt_labels":"A(O) collaborative(B-product) robot(I-product) or(O) cobot(B-product) is(O) a(O) robot(O) that(O) can(O) safely(O) and(O) effectively(O) interact(O) with(O) human(O) workers(O) while(O) performing(O) simple(O) industrial(O) tasks(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["university","conference","task","country","field","organization","person","researcher","product","algorithm","metric","programming language","location"],"instance":{"id":"87","words":["This","overall","framework","has","been","applied","to","a","large","variety","of","problems","in","computer","vision",",","including","feature","detection",",","feature","classification",",","image","segmentation",",","image","matching",",","motion","estimation",",","computation","of","shape","cues","and","object","recognition","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","B-field","I-field","O","O","B-task","I-task","O","B-task","I-task","O","B-task","I-task","O","B-task","I-task","O","B-task","I-task","O","B-task","I-task","I-task","I-task","O","B-task","I-task","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: university, conference, task, country, field, organization, person, researcher, product, algorithm, metric, programming language, location and O.\nSentence: This overall framework has been applied to a large variety of problems in computer vision , including feature detection , feature classification , image segmentation , image matching , motion estimation , computation of shape cues and object recognition .","prompt_labels":"This(O) overall(O) framework(O) has(O) been(O) applied(O) to(O) a(O) large(O) variety(O) of(O) problems(O) in(O) computer(B-field) vision(I-field) ,(O) including(O) feature(B-task) detection(I-task) ,(O) feature(B-task) classification(I-task) ,(O) image(B-task) segmentation(I-task) ,(O) image(B-task) matching(I-task) ,(O) motion(B-task) estimation(I-task) ,(O) computation(B-task) of(I-task) shape(I-task) cues(I-task) and(O) object(B-task) recognition(I-task) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["product","task","university","researcher","organization","programming language","country","person","location","algorithm","conference","field","metric"],"instance":{"id":"88","words":["In","many","practical","applications",",","parameter","estimation","for","naive","Bayes","models","uses","the","method","of","maximum","likelihood",";","other","words",",","one","can","work","with","the","naive","Bayes","model","without","accepting","Bayesian","probability","or","using","any","Bayesian","methods","."],"labels":["O","O","O","O","O","B-task","I-task","O","B-algorithm","I-algorithm","I-algorithm","O","O","O","O","B-algorithm","I-algorithm","O","O","O","O","O","O","O","O","O","B-algorithm","I-algorithm","O","O","O","B-algorithm","I-algorithm","O","O","O","B-algorithm","I-algorithm","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: product, task, university, researcher, organization, programming language, country, person, location, algorithm, conference, field, metric and O.\nSentence: In many practical applications , parameter estimation for naive Bayes models uses the method of maximum likelihood ; other words , one can work with the naive Bayes model without accepting Bayesian probability or using any Bayesian methods .","prompt_labels":"In(O) many(O) practical(O) applications(O) ,(O) parameter(B-task) estimation(I-task) for(O) naive(B-algorithm) Bayes(I-algorithm) models(I-algorithm) uses(O) the(O) method(O) of(O) maximum(B-algorithm) likelihood(I-algorithm) ;(O) other(O) words(O) ,(O) one(O) can(O) work(O) with(O) the(O) naive(B-algorithm) Bayes(I-algorithm) model(O) without(O) accepting(O) Bayesian(B-algorithm) probability(I-algorithm) or(O) using(O) any(O) Bayesian(B-algorithm) methods(I-algorithm) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["product","university","country","person","conference","researcher","algorithm","task","organization","field","location","programming language","metric"],"instance":{"id":"89","words":["Brothers","-","Victor","Gershevich","Katz",",","American","mathematician",",","professor","at","the","Massachusetts","Institute","of","Technology",";","Mikhail","Gershevich","Katz",",","Israeli","mathematician",",","graduate","of","Harvard","and","Columbia","(","Ph.D.",",","1984",")","universities",",","professor","at","Bar-Ilan","University",",","author","of","the","monograph","Systolic","Geometry","and","Topology","(","Mathematical","Surveys","and","Monographs",",","vol","."],"labels":["O","O","B-researcher","I-researcher","I-researcher","O","O","O","O","O","O","O","B-university","I-university","I-university","I-university","O","B-researcher","I-researcher","I-researcher","O","O","O","O","O","O","B-university","O","B-university","O","O","O","O","O","O","O","O","O","B-university","I-university","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: product, university, country, person, conference, researcher, algorithm, task, organization, field, location, programming language, metric and O.\nSentence: Brothers - Victor Gershevich Katz , American mathematician , professor at the Massachusetts Institute of Technology ; Mikhail Gershevich Katz , Israeli mathematician , graduate of Harvard and Columbia ( Ph.D. , 1984 ) universities , professor at Bar-Ilan University , author of the monograph Systolic Geometry and Topology ( Mathematical Surveys and Monographs , vol .","prompt_labels":"Brothers(O) -(O) Victor(B-researcher) Gershevich(I-researcher) Katz(I-researcher) ,(O) American(O) mathematician(O) ,(O) professor(O) at(O) the(O) Massachusetts(B-university) Institute(I-university) of(I-university) Technology(I-university) ;(O) Mikhail(B-researcher) Gershevich(I-researcher) Katz(I-researcher) ,(O) Israeli(O) mathematician(O) ,(O) graduate(O) of(O) Harvard(B-university) and(O) Columbia(B-university) ((O) Ph.D.(O) ,(O) 1984(O) )(O) universities(O) ,(O) professor(O) at(O) Bar-Ilan(B-university) University(I-university) ,(O) author(O) of(O) the(O) monograph(O) Systolic(O) Geometry(O) and(O) Topology(O) ((O) Mathematical(O) Surveys(O) and(O) Monographs(O) ,(O) vol(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["country","metric","algorithm","organization","product","university","conference","researcher","person","task","field","programming language","location"],"instance":{"id":"90","words":["In","2000","Manuel","Toharia",",","a","speaker","at","previous","Campus","Parties",",","and","director","of","Prncipe","Felipe","'s","Museum","of","Sciences","in","Valencia","'s","City","of","arts","and","Sciences","suggested","that","Ragageles","expand","and","make","the","event","more","international","by","moving","it","to","the","famous","museum","."],"labels":["O","O","B-person","I-person","O","O","O","O","O","B-conference","I-conference","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","B-location","I-location","I-location","I-location","I-location","I-location","I-location","O","O","B-person","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, metric, algorithm, organization, product, university, conference, researcher, person, task, field, programming language, location and O.\nSentence: In 2000 Manuel Toharia , a speaker at previous Campus Parties , and director of Prncipe Felipe 's Museum of Sciences in Valencia 's City of arts and Sciences suggested that Ragageles expand and make the event more international by moving it to the famous museum .","prompt_labels":"In(O) 2000(O) Manuel(B-person) Toharia(I-person) ,(O) a(O) speaker(O) at(O) previous(O) Campus(B-conference) Parties(I-conference) ,(O) and(O) director(O) of(O) Prncipe(B-organization) Felipe(I-organization) 's(I-organization) Museum(I-organization) of(I-organization) Sciences(I-organization) in(O) Valencia(B-location) 's(I-location) City(I-location) of(I-location) arts(I-location) and(I-location) Sciences(I-location) suggested(O) that(O) Ragageles(B-person) expand(O) and(O) make(O) the(O) event(O) more(O) international(O) by(O) moving(O) it(O) to(O) the(O) famous(O) museum(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["programming language","product","task","algorithm","university","field","conference","researcher","country","person","metric","organization","location"],"instance":{"id":"91","words":["Within","20","minutes",",","a","facial","recognition","system","identifies","personal","information","including","family","name",",","ID","number","and","address","which","are","displayed","in","the","street","on","an","advertising","screen","."],"labels":["O","O","O","O","O","B-product","I-product","I-product","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: programming language, product, task, algorithm, university, field, conference, researcher, country, person, metric, organization, location and O.\nSentence: Within 20 minutes , a facial recognition system identifies personal information including family name , ID number and address which are displayed in the street on an advertising screen .","prompt_labels":"Within(O) 20(O) minutes(O) ,(O) a(O) facial(B-product) recognition(I-product) system(I-product) identifies(O) personal(O) information(O) including(O) family(O) name(O) ,(O) ID(O) number(O) and(O) address(O) which(O) are(O) displayed(O) in(O) the(O) street(O) on(O) an(O) advertising(O) screen(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["university","conference","researcher","task","metric","algorithm","country","field","product","location","person","programming language","organization"],"instance":{"id":"92","words":["Recent","research","has","increasingly","focused","on","unsupervised","learning","and","semi-supervised","learning","algorithms","."],"labels":["O","O","O","O","O","O","B-field","I-field","O","B-field","I-field","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: university, conference, researcher, task, metric, algorithm, country, field, product, location, person, programming language, organization and O.\nSentence: Recent research has increasingly focused on unsupervised learning and semi-supervised learning algorithms .","prompt_labels":"Recent(O) research(O) has(O) increasingly(O) focused(O) on(O) unsupervised(B-field) learning(I-field) and(O) semi-supervised(B-field) learning(I-field) algorithms(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["task","product","field","programming language","conference","country","university","metric","organization","algorithm","location","researcher","person"],"instance":{"id":"93","words":["Computation","of","this","example","using","Python","code",":"],"labels":["O","O","O","O","O","B-programming language","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: task, product, field, programming language, conference, country, university, metric, organization, algorithm, location, researcher, person and O.\nSentence: Computation of this example using Python code :","prompt_labels":"Computation(O) of(O) this(O) example(O) using(O) Python(B-programming language) code(O) :(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["conference","task","organization","programming language","field","location","university","algorithm","country","product","metric","researcher","person"],"instance":{"id":"94","words":["Today",",","however",",","many","aspects","of","speech","recognition","have","been","taken","over","by","a","deep","learning","method","called","Long","short-term","memory","(","LSTM",")",",","a","recurrent","neural","network","published","by","Sepp","Hochreiter","&","Jrgen","Schmidhuber","in","1997","."],"labels":["O","O","O","O","O","O","O","B-task","I-task","O","O","O","O","O","O","B-field","I-field","O","O","B-algorithm","I-algorithm","I-algorithm","O","B-algorithm","O","O","O","B-algorithm","I-algorithm","I-algorithm","O","O","B-researcher","I-researcher","O","B-researcher","I-researcher","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: conference, task, organization, programming language, field, location, university, algorithm, country, product, metric, researcher, person and O.\nSentence: Today , however , many aspects of speech recognition have been taken over by a deep learning method called Long short-term memory ( LSTM ) , a recurrent neural network published by Sepp Hochreiter & Jrgen Schmidhuber in 1997 .","prompt_labels":"Today(O) ,(O) however(O) ,(O) many(O) aspects(O) of(O) speech(B-task) recognition(I-task) have(O) been(O) taken(O) over(O) by(O) a(O) deep(B-field) learning(I-field) method(O) called(O) Long(B-algorithm) short-term(I-algorithm) memory(I-algorithm) ((O) LSTM(B-algorithm) )(O) ,(O) a(O) recurrent(B-algorithm) neural(I-algorithm) network(I-algorithm) published(O) by(O) Sepp(B-researcher) Hochreiter(I-researcher) &(O) Jrgen(B-researcher) Schmidhuber(I-researcher) in(O) 1997(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["researcher","conference","university","product","country","programming language","metric","field","task","organization","algorithm","person","location"],"instance":{"id":"95","words":["In","preliminary","experimental","results","with","noisy","datasets",",","BrownBoost","outperformed","AdaBoost","'","s","generalization","error",";","however",",","LogitBoost","performed","as","well","as","BrownBoost","."],"labels":["O","O","O","O","O","O","O","O","B-algorithm","O","B-algorithm","O","O","O","O","O","O","O","B-algorithm","O","O","O","O","B-algorithm","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: researcher, conference, university, product, country, programming language, metric, field, task, organization, algorithm, person, location and O.\nSentence: In preliminary experimental results with noisy datasets , BrownBoost outperformed AdaBoost ' s generalization error ; however , LogitBoost performed as well as BrownBoost .","prompt_labels":"In(O) preliminary(O) experimental(O) results(O) with(O) noisy(O) datasets(O) ,(O) BrownBoost(B-algorithm) outperformed(O) AdaBoost(B-algorithm) '(O) s(O) generalization(O) error(O) ;(O) however(O) ,(O) LogitBoost(B-algorithm) performed(O) as(O) well(O) as(O) BrownBoost(B-algorithm) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["programming language","university","researcher","algorithm","field","location","conference","organization","metric","task","country","person","product"],"instance":{"id":"96","words":["Evolutionary","programming","was","introduced","by","Lawrence","J.","Fogel","in","the","US",",","while","John","Henry","Holland","called","his","method","a","genetic","algorithm","."],"labels":["B-algorithm","I-algorithm","O","O","O","B-researcher","I-researcher","I-researcher","O","O","B-country","O","O","B-researcher","I-researcher","I-researcher","O","O","O","O","B-algorithm","I-algorithm","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: programming language, university, researcher, algorithm, field, location, conference, organization, metric, task, country, person, product and O.\nSentence: Evolutionary programming was introduced by Lawrence J. Fogel in the US , while John Henry Holland called his method a genetic algorithm .","prompt_labels":"Evolutionary(B-algorithm) programming(I-algorithm) was(O) introduced(O) by(O) Lawrence(B-researcher) J.(I-researcher) Fogel(I-researcher) in(O) the(O) US(B-country) ,(O) while(O) John(B-researcher) Henry(I-researcher) Holland(I-researcher) called(O) his(O) method(O) a(O) genetic(B-algorithm) algorithm(I-algorithm) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["university","researcher","field","location","product","country","organization","programming language","conference","metric","task","person","algorithm"],"instance":{"id":"97","words":["The","back-of-the-envelope","calculations","by","Doug",",","Alan",",","and","their","colleagues","(","including","Marvin","Minsky",",","Allen","Newell",",","Edward","Feigenbaum",",","and","John","McCarthy",")","indicated","that","that","effort","would","require","between","1000","and","3000","person-years","of","effort",",","far","beyond","the","standard","academic","project","model","."],"labels":["O","O","O","O","B-researcher","O","B-researcher","O","O","O","O","O","O","B-researcher","I-researcher","O","B-researcher","I-researcher","O","B-researcher","I-researcher","O","O","B-researcher","I-researcher","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: university, researcher, field, location, product, country, organization, programming language, conference, metric, task, person, algorithm and O.\nSentence: The back-of-the-envelope calculations by Doug , Alan , and their colleagues ( including Marvin Minsky , Allen Newell , Edward Feigenbaum , and John McCarthy ) indicated that that effort would require between 1000 and 3000 person-years of effort , far beyond the standard academic project model .","prompt_labels":"The(O) back-of-the-envelope(O) calculations(O) by(O) Doug(B-researcher) ,(O) Alan(B-researcher) ,(O) and(O) their(O) colleagues(O) ((O) including(O) Marvin(B-researcher) Minsky(I-researcher) ,(O) Allen(B-researcher) Newell(I-researcher) ,(O) Edward(B-researcher) Feigenbaum(I-researcher) ,(O) and(O) John(B-researcher) McCarthy(I-researcher) )(O) indicated(O) that(O) that(O) effort(O) would(O) require(O) between(O) 1000(O) and(O) 3000(O) person-years(O) of(O) effort(O) ,(O) far(O) beyond(O) the(O) standard(O) academic(O) project(O) model(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["product","field","location","university","researcher","person","organization","task","programming language","conference","metric","algorithm","country"],"instance":{"id":"98","words":["Common","criteria","are","the","Mean","Squared","Error","criterion","implemented","in","MSECriterion","and","the","cross-entropy","criterion","implemented","in","NLLCriterion","."],"labels":["O","O","O","O","B-metric","I-metric","I-metric","O","O","O","B-metric","O","O","B-metric","I-metric","O","O","B-metric","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: product, field, location, university, researcher, person, organization, task, programming language, conference, metric, algorithm, country and O.\nSentence: Common criteria are the Mean Squared Error criterion implemented in MSECriterion and the cross-entropy criterion implemented in NLLCriterion .","prompt_labels":"Common(O) criteria(O) are(O) the(O) Mean(B-metric) Squared(I-metric) Error(I-metric) criterion(O) implemented(O) in(O) MSECriterion(B-metric) and(O) the(O) cross-entropy(B-metric) criterion(I-metric) implemented(O) in(O) NLLCriterion(B-metric) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["conference","programming language","product","country","researcher","algorithm","task","university","location","metric","field","organization","person"],"instance":{"id":"99","words":["Zurada","has","served","the","engineering","profession","as","a","long-time","volunteer","of","IEEE",":","as","2014","IEEE","Vice-President-Technical","Activities","(","TAB","Chair",")",",","as","President","of","IEEE","Computational","Intelligence","Society","in","2004-05","and","the","ADCOM","member","in","2009-14",",","2016-18","and","earlier","years","."],"labels":["B-researcher","O","O","O","O","O","O","O","O","O","O","B-organization","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-conference","I-conference","I-conference","I-conference","O","O","O","O","B-conference","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: conference, programming language, product, country, researcher, algorithm, task, university, location, metric, field, organization, person and O.\nSentence: Zurada has served the engineering profession as a long-time volunteer of IEEE : as 2014 IEEE Vice-President-Technical Activities ( TAB Chair ) , as President of IEEE Computational Intelligence Society in 2004-05 and the ADCOM member in 2009-14 , 2016-18 and earlier years .","prompt_labels":"Zurada(B-researcher) has(O) served(O) the(O) engineering(O) profession(O) as(O) a(O) long-time(O) volunteer(O) of(O) IEEE(B-organization) :(O) as(O) 2014(O) IEEE(O) Vice-President-Technical(O) Activities(O) ((O) TAB(O) Chair(O) )(O) ,(O) as(O) President(O) of(O) IEEE(B-conference) Computational(I-conference) Intelligence(I-conference) Society(I-conference) in(O) 2004-05(O) and(O) the(O) ADCOM(B-conference) member(O) in(O) 2009-14(O) ,(O) 2016-18(O) and(O) earlier(O) years(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["field","algorithm","organization","metric","conference","programming language","researcher","location","person","country","task","product","university"],"instance":{"id":"100","words":["In","general",",","computational","linguistics","draws","upon","the","involvement","of","linguists",",","computer","science",",","experts","in","artificial","intelligence",",","mathematicians",",","logicians",",","philosophers",",","cognitive","scientists",",","cognitive","psychologists",",","psycholinguists",",","anthropologists","and","neuroscientists",",","among","others","."],"labels":["O","O","O","B-field","I-field","O","O","O","O","O","O","O","B-field","I-field","O","O","O","B-field","I-field","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: field, algorithm, organization, metric, conference, programming language, researcher, location, person, country, task, product, university and O.\nSentence: In general , computational linguistics draws upon the involvement of linguists , computer science , experts in artificial intelligence , mathematicians , logicians , philosophers , cognitive scientists , cognitive psychologists , psycholinguists , anthropologists and neuroscientists , among others .","prompt_labels":"In(O) general(O) ,(O) computational(B-field) linguistics(I-field) draws(O) upon(O) the(O) involvement(O) of(O) linguists(O) ,(O) computer(B-field) science(I-field) ,(O) experts(O) in(O) artificial(B-field) intelligence(I-field) ,(O) mathematicians(O) ,(O) logicians(O) ,(O) philosophers(O) ,(O) cognitive(O) scientists(O) ,(O) cognitive(O) psychologists(O) ,(O) psycholinguists(O) ,(O) anthropologists(O) and(O) neuroscientists(O) ,(O) among(O) others(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["location","organization","country","person","university","programming language","conference","researcher","field","task","metric","product","algorithm"],"instance":{"id":"101","words":["Techniques","such","as","dynamic","Markov","Networks",",","Convolutional","neural","network","and","Long","short-term","memory","are","often","employed","to","exploit","the","inter-frame","correlations","."],"labels":["O","O","O","B-algorithm","I-algorithm","I-algorithm","O","B-algorithm","I-algorithm","I-algorithm","O","B-algorithm","I-algorithm","I-algorithm","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, organization, country, person, university, programming language, conference, researcher, field, task, metric, product, algorithm and O.\nSentence: Techniques such as dynamic Markov Networks , Convolutional neural network and Long short-term memory are often employed to exploit the inter-frame correlations .","prompt_labels":"Techniques(O) such(O) as(O) dynamic(B-algorithm) Markov(I-algorithm) Networks(I-algorithm) ,(O) Convolutional(B-algorithm) neural(I-algorithm) network(I-algorithm) and(O) Long(B-algorithm) short-term(I-algorithm) memory(I-algorithm) are(O) often(O) employed(O) to(O) exploit(O) the(O) inter-frame(O) correlations(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["country","university","programming language","algorithm","field","task","organization","conference","metric","researcher","product","location","person"],"instance":{"id":"102","words":["Unimate","was","the","first","industrial","robot",","],"labels":["B-product","O","O","O","B-product","I-product","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, university, programming language, algorithm, field, task, organization, conference, metric, researcher, product, location, person and O.\nSentence: Unimate was the first industrial robot ,","prompt_labels":"Unimate(B-product) was(O) the(O) first(O) industrial(B-product) robot(I-product) ,(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["product","algorithm","person","task","field","organization","researcher","metric","university","location","country","conference","programming language"],"instance":{"id":"103","words":["Together","with","Geoffrey","Hinton","and","Yann","LeCun",",","Bengio","won","the","2018","Turing","Award","."],"labels":["O","O","B-researcher","I-researcher","O","B-researcher","I-researcher","O","B-researcher","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: product, algorithm, person, task, field, organization, researcher, metric, university, location, country, conference, programming language and O.\nSentence: Together with Geoffrey Hinton and Yann LeCun , Bengio won the 2018 Turing Award .","prompt_labels":"Together(O) with(O) Geoffrey(B-researcher) Hinton(I-researcher) and(O) Yann(B-researcher) LeCun(I-researcher) ,(O) Bengio(B-researcher) won(O) the(O) 2018(O) Turing(O) Award(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["conference","task","person","country","metric","organization","field","location","programming language","product","researcher","university","algorithm"],"instance":{"id":"104","words":["Additional","series","were","filmed","at","the","UK","venue","for","specific","sectors","of","the","global","market",",","including","two","series","of","Robot","Wars","Extreme","Warriors","with","United","States","competitors","for","the","TNN","network","(","hosted","by","Mick","Foley","with","Rebecca","Grant","serving","as","pit","reporter",")",",","two","of","Dutch","Robot","Wars","for","distribution","in","the","Netherlands","and","a","single","series","for","Germany","."],"labels":["O","O","O","O","O","O","B-country","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-country","I-country","O","O","O","B-organization","I-organization","O","O","O","B-person","I-person","O","B-person","I-person","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-country","O","O","O","O","O","B-country","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: conference, task, person, country, metric, organization, field, location, programming language, product, researcher, university, algorithm and O.\nSentence: Additional series were filmed at the UK venue for specific sectors of the global market , including two series of Robot Wars Extreme Warriors with United States competitors for the TNN network ( hosted by Mick Foley with Rebecca Grant serving as pit reporter ) , two of Dutch Robot Wars for distribution in the Netherlands and a single series for Germany .","prompt_labels":"Additional(O) series(O) were(O) filmed(O) at(O) the(O) UK(B-country) venue(O) for(O) specific(O) sectors(O) of(O) the(O) global(O) market(O) ,(O) including(O) two(O) series(O) of(O) Robot(O) Wars(O) Extreme(O) Warriors(O) with(O) United(B-country) States(I-country) competitors(O) for(O) the(O) TNN(B-organization) network(I-organization) ((O) hosted(O) by(O) Mick(B-person) Foley(I-person) with(O) Rebecca(B-person) Grant(I-person) serving(O) as(O) pit(O) reporter(O) )(O) ,(O) two(O) of(O) Dutch(O) Robot(O) Wars(O) for(O) distribution(O) in(O) the(O) Netherlands(B-country) and(O) a(O) single(O) series(O) for(O) Germany(B-country) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["country","person","university","task","algorithm","conference","organization","field","location","metric","product","programming language","researcher"],"instance":{"id":"105","words":["For","many","years","starting","from","1986",",","Miller","directed","the","development","of","WordNet",",","a","large","computer-readable","electronic","reference","usable","in","applications","such","as","search","engines","."],"labels":["O","O","O","O","O","O","O","B-researcher","O","O","O","O","B-product","O","O","O","O","O","O","O","O","O","O","O","B-product","I-product","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, person, university, task, algorithm, conference, organization, field, location, metric, product, programming language, researcher and O.\nSentence: For many years starting from 1986 , Miller directed the development of WordNet , a large computer-readable electronic reference usable in applications such as search engines .","prompt_labels":"For(O) many(O) years(O) starting(O) from(O) 1986(O) ,(O) Miller(B-researcher) directed(O) the(O) development(O) of(O) WordNet(B-product) ,(O) a(O) large(O) computer-readable(O) electronic(O) reference(O) usable(O) in(O) applications(O) such(O) as(O) search(B-product) engines(I-product) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["metric","conference","researcher","university","programming language","algorithm","country","organization","product","person","task","field","location"],"instance":{"id":"106","words":["Since","2009",",","the","recurrent","neural","network","s","and","deep","feedforward","neural","networks","developed","in","the","research","group","of","Jrgen","Schmidhuber","at","the","Swiss","AI","Lab","IDSIA","have","won","several","international","handwriting","competitions",".."],"labels":["O","O","O","O","B-algorithm","I-algorithm","I-algorithm","O","O","B-algorithm","I-algorithm","I-algorithm","I-algorithm","O","O","O","O","O","O","B-researcher","I-researcher","O","O","B-organization","I-organization","I-organization","I-organization","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: metric, conference, researcher, university, programming language, algorithm, country, organization, product, person, task, field, location and O.\nSentence: Since 2009 , the recurrent neural network s and deep feedforward neural networks developed in the research group of Jrgen Schmidhuber at the Swiss AI Lab IDSIA have won several international handwriting competitions ..","prompt_labels":"Since(O) 2009(O) ,(O) the(O) recurrent(B-algorithm) neural(I-algorithm) network(I-algorithm) s(O) and(O) deep(B-algorithm) feedforward(I-algorithm) neural(I-algorithm) networks(I-algorithm) developed(O) in(O) the(O) research(O) group(O) of(O) Jrgen(B-researcher) Schmidhuber(I-researcher) at(O) the(O) Swiss(B-organization) AI(I-organization) Lab(I-organization) IDSIA(I-organization) have(O) won(O) several(O) international(O) handwriting(O) competitions(O) ..(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["task","product","metric","programming language","organization","country","researcher","algorithm","person","location","university","field","conference"],"instance":{"id":"107","words":["The","software","is","implemented","in","C","+","+","and","it","is","wrapped","for","Python","."],"labels":["O","O","O","O","O","B-programming language","I-programming language","I-programming language","O","O","O","O","O","B-programming language","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: task, product, metric, programming language, organization, country, researcher, algorithm, person, location, university, field, conference and O.\nSentence: The software is implemented in C + + and it is wrapped for Python .","prompt_labels":"The(O) software(O) is(O) implemented(O) in(O) C(B-programming language) +(I-programming language) +(I-programming language) and(O) it(O) is(O) wrapped(O) for(O) Python(B-programming language) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["organization","field","metric","algorithm","university","researcher","person","product","task","programming language","country","conference","location"],"instance":{"id":"108","words":["In","1857",",","at","the","request","of","the","Tokugawa","Shogunate",",","a","group","of","Dutch","engineers","began","work","on","the","Nagasaki","Yotetsusho",",","a","modern",",","Western-style","foundry","and","shipyard","near","the","Dutch","settlement","of","Dejima",",","at","Nagasaki","."],"labels":["O","O","O","O","O","O","O","O","B-country","I-country","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, field, metric, algorithm, university, researcher, person, product, task, programming language, country, conference, location and O.\nSentence: In 1857 , at the request of the Tokugawa Shogunate , a group of Dutch engineers began work on the Nagasaki Yotetsusho , a modern , Western-style foundry and shipyard near the Dutch settlement of Dejima , at Nagasaki .","prompt_labels":"In(O) 1857(O) ,(O) at(O) the(O) request(O) of(O) the(O) Tokugawa(B-country) Shogunate(I-country) ,(O) a(O) group(O) of(O) Dutch(O) engineers(O) began(O) work(O) on(O) the(O) Nagasaki(O) Yotetsusho(O) ,(O) a(O) modern(O) ,(O) Western-style(O) foundry(O) and(O) shipyard(O) near(O) the(O) Dutch(O) settlement(O) of(O) Dejima(O) ,(O) at(O) Nagasaki(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["metric","university","task","location","researcher","conference","organization","field","algorithm","country","programming language","person","product"],"instance":{"id":"109","words":["We","make","as","well","as","possible","precise","by","measuring","the","mean","squared","error","between","mathy","\/","math","and","math","\\","hat","{","f","}","(","x",";","D",")","\/","math",":","we","want","math","(","y","-","\\","hat","{","f","}","(","x",";","D",")",")","^","2","\/","math","to","be","minimal",",","both","for","mathx","_","1",",","\\","dots",",","x","_","n","\/","math","and","for","points","outside","of","our","sample","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-metric","I-metric","I-metric","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: metric, university, task, location, researcher, conference, organization, field, algorithm, country, programming language, person, product and O.\nSentence: We make as well as possible precise by measuring the mean squared error between mathy \/ math and math \\ hat { f } ( x ; D ) \/ math : we want math ( y - \\ hat { f } ( x ; D ) ) ^ 2 \/ math to be minimal , both for mathx _ 1 , \\ dots , x _ n \/ math and for points outside of our sample .","prompt_labels":"We(O) make(O) as(O) well(O) as(O) possible(O) precise(O) by(O) measuring(O) the(O) mean(B-metric) squared(I-metric) error(I-metric) between(O) mathy(O) \/(O) math(O) and(O) math(O) \\(O) hat(O) {(O) f(O) }(O) ((O) x(O) ;(O) D(O) )(O) \/(O) math(O) :(O) we(O) want(O) math(O) ((O) y(O) -(O) \\(O) hat(O) {(O) f(O) }(O) ((O) x(O) ;(O) D(O) )(O) )(O) ^(O) 2(O) \/(O) math(O) to(O) be(O) minimal(O) ,(O) both(O) for(O) mathx(O) _(O) 1(O) ,(O) \\(O) dots(O) ,(O) x(O) _(O) n(O) \/(O) math(O) and(O) for(O) points(O) outside(O) of(O) our(O) sample(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["location","algorithm","university","metric","conference","organization","person","product","programming language","field","researcher","country","task"],"instance":{"id":"110","words":["He","subsequently","extended","an","invitation","for","Wydner","to","attend","the","annual","meeting","of","the","American","Translators","Association","that","following","October","where","the","Weidner","Machine","Translation","System","hailed","a","hoped-for","breakthrough","in","machine","translation","."],"labels":["O","O","O","O","O","O","B-researcher","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","O","O","O","O","O","B-product","I-product","I-product","I-product","O","O","O","O","O","B-task","I-task","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, algorithm, university, metric, conference, organization, person, product, programming language, field, researcher, country, task and O.\nSentence: He subsequently extended an invitation for Wydner to attend the annual meeting of the American Translators Association that following October where the Weidner Machine Translation System hailed a hoped-for breakthrough in machine translation .","prompt_labels":"He(O) subsequently(O) extended(O) an(O) invitation(O) for(O) Wydner(B-researcher) to(O) attend(O) the(O) annual(O) meeting(O) of(O) the(O) American(B-organization) Translators(I-organization) Association(I-organization) that(O) following(O) October(O) where(O) the(O) Weidner(B-product) Machine(I-product) Translation(I-product) System(I-product) hailed(O) a(O) hoped-for(O) breakthrough(O) in(O) machine(B-task) translation(I-task) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["programming language","conference","person","metric","location","task","field","organization","researcher","country","product","university","algorithm"],"instance":{"id":"111","words":["At","the","2018","Conference","on","Neural","Information","Processing","Systems","(","NeurIPS",")","researchers","from","Google","presented","the","work","."],"labels":["O","O","B-conference","I-conference","I-conference","I-conference","I-conference","I-conference","I-conference","O","B-conference","O","O","O","B-organization","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: programming language, conference, person, metric, location, task, field, organization, researcher, country, product, university, algorithm and O.\nSentence: At the 2018 Conference on Neural Information Processing Systems ( NeurIPS ) researchers from Google presented the work .","prompt_labels":"At(O) the(O) 2018(B-conference) Conference(I-conference) on(I-conference) Neural(I-conference) Information(I-conference) Processing(I-conference) Systems(I-conference) ((O) NeurIPS(B-conference) )(O) researchers(O) from(O) Google(B-organization) presented(O) the(O) work(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["product","university","location","organization","person","conference","field","programming language","country","algorithm","researcher","metric","task"],"instance":{"id":"112","words":["The","Baum-Welch","algorithm","uses","the","well","known","EM","algorithm","to","find","the","maximum","likelihood","estimate","of","the","parameters","of","a","hidden","Markov","model","given","a","set","of","observed","feature","vectors","."],"labels":["O","B-algorithm","I-algorithm","O","O","O","O","B-algorithm","I-algorithm","O","O","O","B-metric","I-metric","I-metric","O","O","O","O","O","B-algorithm","I-algorithm","I-algorithm","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: product, university, location, organization, person, conference, field, programming language, country, algorithm, researcher, metric, task and O.\nSentence: The Baum-Welch algorithm uses the well known EM algorithm to find the maximum likelihood estimate of the parameters of a hidden Markov model given a set of observed feature vectors .","prompt_labels":"The(O) Baum-Welch(B-algorithm) algorithm(I-algorithm) uses(O) the(O) well(O) known(O) EM(B-algorithm) algorithm(I-algorithm) to(O) find(O) the(O) maximum(B-metric) likelihood(I-metric) estimate(I-metric) of(O) the(O) parameters(O) of(O) a(O) hidden(B-algorithm) Markov(I-algorithm) model(I-algorithm) given(O) a(O) set(O) of(O) observed(O) feature(O) vectors(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["task","location","programming language","organization","algorithm","person","metric","country","researcher","field","conference","product","university"],"instance":{"id":"113","words":[")","In","addition","to","the","taxonomic","information","contained","in","OpenCyc",",","ResearchCyc","includes","significantly","more","semantic","knowledge","(","i.e.",",","additional","facts","and","rules","of","thumb",")","involving","the","concepts","in","its","knowledge","base",";","it","also","includes","a","large","lexicon",",","English","parsing","and","generation","tools",",","and","Java","based","interfaces","for","knowledge","editing","and","querying","."],"labels":["O","O","O","O","O","O","O","O","O","B-product","O","B-product","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-product","I-product","I-product","I-product","I-product","I-product","I-product","I-product","O","O","B-programming language","O","B-product","I-product","I-product","I-product","I-product","I-product","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: task, location, programming language, organization, algorithm, person, metric, country, researcher, field, conference, product, university and O.\nSentence: ) In addition to the taxonomic information contained in OpenCyc , ResearchCyc includes significantly more semantic knowledge ( i.e. , additional facts and rules of thumb ) involving the concepts in its knowledge base ; it also includes a large lexicon , English parsing and generation tools , and Java based interfaces for knowledge editing and querying .","prompt_labels":")(O) In(O) addition(O) to(O) the(O) taxonomic(O) information(O) contained(O) in(O) OpenCyc(B-product) ,(O) ResearchCyc(B-product) includes(O) significantly(O) more(O) semantic(O) knowledge(O) ((O) i.e.(O) ,(O) additional(O) facts(O) and(O) rules(O) of(O) thumb(O) )(O) involving(O) the(O) concepts(O) in(O) its(O) knowledge(O) base(O) ;(O) it(O) also(O) includes(O) a(O) large(B-product) lexicon(I-product) ,(I-product) English(I-product) parsing(I-product) and(I-product) generation(I-product) tools(I-product) ,(O) and(O) Java(B-programming language) based(O) interfaces(B-product) for(I-product) knowledge(I-product) editing(I-product) and(I-product) querying(I-product) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["programming language","field","country","location","product","person","algorithm","metric","organization","university","conference","task","researcher"],"instance":{"id":"114","words":["The","Hough","transform","is","a","feature","extraction","technique","used","in","image","analysis",",","computer","vision",",","and","digital","image","processing","."],"labels":["O","B-algorithm","I-algorithm","O","O","B-task","I-task","O","O","O","B-field","I-field","O","B-field","I-field","O","O","B-field","I-field","I-field","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: programming language, field, country, location, product, person, algorithm, metric, organization, university, conference, task, researcher and O.\nSentence: The Hough transform is a feature extraction technique used in image analysis , computer vision , and digital image processing .","prompt_labels":"The(O) Hough(B-algorithm) transform(I-algorithm) is(O) a(O) feature(B-task) extraction(I-task) technique(O) used(O) in(O) image(B-field) analysis(I-field) ,(O) computer(B-field) vision(I-field) ,(O) and(O) digital(B-field) image(I-field) processing(I-field) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["task","person","metric","organization","university","location","conference","country","field","algorithm","product","programming language","researcher"],"instance":{"id":"115","words":["In","1978",",","the","PUMA","(","Programmable","Universal","Machine","for","Assembly",")","robot","was","developed","by","Unimation","from","Vicarm","(","Victor","Scheinman",")","and","with","support","from","General","Motors","."],"labels":["O","O","O","O","B-product","O","B-product","I-product","I-product","I-product","I-product","O","O","O","O","O","B-organization","O","B-organization","O","B-researcher","I-researcher","O","O","O","O","O","B-organization","I-organization","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: task, person, metric, organization, university, location, conference, country, field, algorithm, product, programming language, researcher and O.\nSentence: In 1978 , the PUMA ( Programmable Universal Machine for Assembly ) robot was developed by Unimation from Vicarm ( Victor Scheinman ) and with support from General Motors .","prompt_labels":"In(O) 1978(O) ,(O) the(O) PUMA(B-product) ((O) Programmable(B-product) Universal(I-product) Machine(I-product) for(I-product) Assembly(I-product) )(O) robot(O) was(O) developed(O) by(O) Unimation(B-organization) from(O) Vicarm(B-organization) ((O) Victor(B-researcher) Scheinman(I-researcher) )(O) and(O) with(O) support(O) from(O) General(B-organization) Motors(I-organization) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["field","programming language","product","metric","person","algorithm","country","task","university","location","organization","conference","researcher"],"instance":{"id":"116","words":["LSTM","was","proposed","in","1997","by","Sepp","Hochreiter","and","Jrgen","Schmidhuber","."],"labels":["B-algorithm","O","O","O","O","O","B-researcher","I-researcher","O","B-researcher","I-researcher","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: field, programming language, product, metric, person, algorithm, country, task, university, location, organization, conference, researcher and O.\nSentence: LSTM was proposed in 1997 by Sepp Hochreiter and Jrgen Schmidhuber .","prompt_labels":"LSTM(B-algorithm) was(O) proposed(O) in(O) 1997(O) by(O) Sepp(B-researcher) Hochreiter(I-researcher) and(O) Jrgen(B-researcher) Schmidhuber(I-researcher) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["product","researcher","metric","task","algorithm","university","field","person","country","conference","location","programming language","organization"],"instance":{"id":"117","words":["The","four","outcomes","can","be","formulated","in","a","2","","2","contingency","table","or","confusion","matrix",",","as","follows",":"],"labels":["O","O","O","O","O","O","O","O","O","O","O","B-metric","I-metric","O","B-metric","I-metric","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: product, researcher, metric, task, algorithm, university, field, person, country, conference, location, programming language, organization and O.\nSentence: The four outcomes can be formulated in a 2  2 contingency table or confusion matrix , as follows :","prompt_labels":"The(O) four(O) outcomes(O) can(O) be(O) formulated(O) in(O) a(O) 2(O) (O) 2(O) contingency(B-metric) table(I-metric) or(O) confusion(B-metric) matrix(I-metric) ,(O) as(O) follows(O) :(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["university","programming language","location","product","conference","task","field","algorithm","person","organization","country","metric","researcher"],"instance":{"id":"118","words":["He","also","contributed","much","through","the","establishment","of","ELRA","and","the","LREC","conference","."],"labels":["O","O","O","O","O","O","O","O","B-conference","O","O","B-conference","I-conference","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: university, programming language, location, product, conference, task, field, algorithm, person, organization, country, metric, researcher and O.\nSentence: He also contributed much through the establishment of ELRA and the LREC conference .","prompt_labels":"He(O) also(O) contributed(O) much(O) through(O) the(O) establishment(O) of(O) ELRA(B-conference) and(O) the(O) LREC(B-conference) conference(I-conference) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["task","product","conference","university","person","metric","country","organization","programming language","algorithm","location","researcher","field"],"instance":{"id":"119","words":["A","popular","application","for","serial","robots","in","today","'s","industry","is","the","pick-and-place","assembly","robot",",","called","a","SCARA","robot",",","which","has","four","degrees","of","freedom","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","B-programming language","O","O","O","O","B-product","I-product","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: task, product, conference, university, person, metric, country, organization, programming language, algorithm, location, researcher, field and O.\nSentence: A popular application for serial robots in today 's industry is the pick-and-place assembly robot , called a SCARA robot , which has four degrees of freedom .","prompt_labels":"A(O) popular(O) application(O) for(O) serial(O) robots(O) in(O) today(O) 's(O) industry(O) is(O) the(O) pick-and-place(O) assembly(B-programming language) robot(O) ,(O) called(O) a(O) SCARA(B-product) robot(I-product) ,(O) which(O) has(O) four(O) degrees(O) of(O) freedom(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["conference","algorithm","researcher","programming language","organization","field","country","task","person","location","metric","university","product"],"instance":{"id":"120","words":["He","was","one","of","the","founding","members","and","former","chair","(","2006-2008",")","of","the","Special","Interest","Group","on","Web","as","Corpus","(","SIGWAC",")","of","the","Association","for","Computational","Linguistics","and","also","one","of","the","founding","organizers","of","SENSEVAL","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-conference","I-conference","I-conference","I-conference","I-conference","I-conference","I-conference","O","B-conference","O","O","O","B-conference","I-conference","I-conference","I-conference","O","O","O","O","O","O","O","O","B-conference","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: conference, algorithm, researcher, programming language, organization, field, country, task, person, location, metric, university, product and O.\nSentence: He was one of the founding members and former chair ( 2006-2008 ) of the Special Interest Group on Web as Corpus ( SIGWAC ) of the Association for Computational Linguistics and also one of the founding organizers of SENSEVAL .","prompt_labels":"He(O) was(O) one(O) of(O) the(O) founding(O) members(O) and(O) former(O) chair(O) ((O) 2006-2008(O) )(O) of(O) the(O) Special(B-conference) Interest(I-conference) Group(I-conference) on(I-conference) Web(I-conference) as(I-conference) Corpus(I-conference) ((O) SIGWAC(B-conference) )(O) of(O) the(O) Association(B-conference) for(I-conference) Computational(I-conference) Linguistics(I-conference) and(O) also(O) one(O) of(O) the(O) founding(O) organizers(O) of(O) SENSEVAL(B-conference) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["algorithm","field","university","person","programming language","country","location","task","product","conference","researcher","organization","metric"],"instance":{"id":"121","words":["As","a","platform",",","LinguaStream","provides","an","extensive","Java","API","."],"labels":["O","O","O","O","B-product","O","O","O","B-product","I-product","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: algorithm, field, university, person, programming language, country, location, task, product, conference, researcher, organization, metric and O.\nSentence: As a platform , LinguaStream provides an extensive Java API .","prompt_labels":"As(O) a(O) platform(O) ,(O) LinguaStream(B-product) provides(O) an(O) extensive(O) Java(B-product) API(I-product) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["researcher","location","task","country","product","university","organization","programming language","field","algorithm","person","metric","conference"],"instance":{"id":"122","words":["The","robot","kit","is","Android-based",",","and","it","is","programmed","using","Java",",","the","Blocks","programming","interface",",","or","other","Android","programming","systems","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","B-programming language","O","O","O","O","O","O","O","O","B-product","I-product","I-product","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: researcher, location, task, country, product, university, organization, programming language, field, algorithm, person, metric, conference and O.\nSentence: The robot kit is Android-based , and it is programmed using Java , the Blocks programming interface , or other Android programming systems .","prompt_labels":"The(O) robot(O) kit(O) is(O) Android-based(O) ,(O) and(O) it(O) is(O) programmed(O) using(O) Java(B-programming language) ,(O) the(O) Blocks(O) programming(O) interface(O) ,(O) or(O) other(O) Android(B-product) programming(I-product) systems(I-product) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["programming language","country","organization","location","researcher","field","person","conference","algorithm","metric","product","university","task"],"instance":{"id":"123","words":["The","method","of","defining","the","linked","list","specifies","the","use","of","a","depth-first","search","or","a","breadth-first","search","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","B-algorithm","I-algorithm","O","O","B-algorithm","I-algorithm","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: programming language, country, organization, location, researcher, field, person, conference, algorithm, metric, product, university, task and O.\nSentence: The method of defining the linked list specifies the use of a depth-first search or a breadth-first search .","prompt_labels":"The(O) method(O) of(O) defining(O) the(O) linked(O) list(O) specifies(O) the(O) use(O) of(O) a(O) depth-first(B-algorithm) search(I-algorithm) or(O) a(O) breadth-first(B-algorithm) search(I-algorithm) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["product","field","researcher","country","organization","conference","university","algorithm","metric","location","programming language","person","task"],"instance":{"id":"124","words":["These","regions","could","signal","the","presence","of","objects","or","parts","of","objects","in","the","image","domain","with","application","to","object","recognition","and","\/","or","object","video","tracking","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-task","I-task","O","O","O","B-task","I-task","I-task","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: product, field, researcher, country, organization, conference, university, algorithm, metric, location, programming language, person, task and O.\nSentence: These regions could signal the presence of objects or parts of objects in the image domain with application to object recognition and \/ or object video tracking .","prompt_labels":"These(O) regions(O) could(O) signal(O) the(O) presence(O) of(O) objects(O) or(O) parts(O) of(O) objects(O) in(O) the(O) image(O) domain(O) with(O) application(O) to(O) object(B-task) recognition(I-task) and(O) \/(O) or(O) object(B-task) video(I-task) tracking(I-task) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["task","algorithm","metric","country","programming language","researcher","location","conference","university","field","person","product","organization"],"instance":{"id":"125","words":["An","example","of","a","semantic","network","is","WordNet",",","a","lexical","database","of","English","."],"labels":["O","O","O","O","B-algorithm","I-algorithm","O","B-product","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: task, algorithm, metric, country, programming language, researcher, location, conference, university, field, person, product, organization and O.\nSentence: An example of a semantic network is WordNet , a lexical database of English .","prompt_labels":"An(O) example(O) of(O) a(O) semantic(B-algorithm) network(I-algorithm) is(O) WordNet(B-product) ,(O) a(O) lexical(O) database(O) of(O) English(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["field","metric","researcher","programming language","location","task","country","product","person","university","conference","organization","algorithm"],"instance":{"id":"126","words":["Speech","recognition","is","an","interdisciplinary","subfield","of","computer","science","and","computational","linguistics","that","develops","methodologies","and","technologies","that","enable","the","recognition","and","translation","of","spoken","language","into","text","by","computers","."],"labels":["B-task","I-task","O","O","O","O","O","B-field","I-field","O","B-field","I-field","O","O","O","O","O","O","O","O","B-task","I-task","I-task","I-task","I-task","I-task","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: field, metric, researcher, programming language, location, task, country, product, person, university, conference, organization, algorithm and O.\nSentence: Speech recognition is an interdisciplinary subfield of computer science and computational linguistics that develops methodologies and technologies that enable the recognition and translation of spoken language into text by computers .","prompt_labels":"Speech(B-task) recognition(I-task) is(O) an(O) interdisciplinary(O) subfield(O) of(O) computer(B-field) science(I-field) and(O) computational(B-field) linguistics(I-field) that(O) develops(O) methodologies(O) and(O) technologies(O) that(O) enable(O) the(O) recognition(B-task) and(I-task) translation(I-task) of(I-task) spoken(I-task) language(I-task) into(O) text(O) by(O) computers(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["task","organization","conference","location","person","algorithm","researcher","university","programming language","metric","field","product","country"],"instance":{"id":"127","words":["Artificial","intelligence","has","retained","the","most","attention","regarding","applied","ontology","in","subfields","like","natural","language","processing","within","machine","and","knowledge","representation",",","but","ontology","editors","are","being","used","often","in","a","range","of","fields","like","education","without","the","intent","to","contribute","to","AI","."],"labels":["B-field","I-field","O","O","O","O","O","O","O","O","O","O","O","B-field","I-field","I-field","O","B-task","O","B-task","I-task","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-field","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: task, organization, conference, location, person, algorithm, researcher, university, programming language, metric, field, product, country and O.\nSentence: Artificial intelligence has retained the most attention regarding applied ontology in subfields like natural language processing within machine and knowledge representation , but ontology editors are being used often in a range of fields like education without the intent to contribute to AI .","prompt_labels":"Artificial(B-field) intelligence(I-field) has(O) retained(O) the(O) most(O) attention(O) regarding(O) applied(O) ontology(O) in(O) subfields(O) like(O) natural(B-field) language(I-field) processing(I-field) within(O) machine(B-task) and(O) knowledge(B-task) representation(I-task) ,(O) but(O) ontology(O) editors(O) are(O) being(O) used(O) often(O) in(O) a(O) range(O) of(O) fields(O) like(O) education(O) without(O) the(O) intent(O) to(O) contribute(O) to(O) AI(B-field) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["researcher","conference","product","metric","person","field","algorithm","university","location","country","organization","task","programming language"],"instance":{"id":"128","words":["This","update","rule","is","in","fact","the","stochastic","gradient","descent","update","for","linear","regression","."],"labels":["O","O","O","O","O","O","O","B-algorithm","I-algorithm","I-algorithm","O","O","B-algorithm","I-algorithm","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: researcher, conference, product, metric, person, field, algorithm, university, location, country, organization, task, programming language and O.\nSentence: This update rule is in fact the stochastic gradient descent update for linear regression .","prompt_labels":"This(O) update(O) rule(O) is(O) in(O) fact(O) the(O) stochastic(B-algorithm) gradient(I-algorithm) descent(I-algorithm) update(O) for(O) linear(B-algorithm) regression(I-algorithm) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["field","programming language","country","organization","conference","university","person","product","task","metric","researcher","location","algorithm"],"instance":{"id":"129","words":["He","was","elected","to","the","American","Academy","of","Arts","and","Sciences","and","the","National","Academy","of","Sciences","and","has","received","a","series","of","awards",":"],"labels":["O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: field, programming language, country, organization, conference, university, person, product, task, metric, researcher, location, algorithm and O.\nSentence: He was elected to the American Academy of Arts and Sciences and the National Academy of Sciences and has received a series of awards :","prompt_labels":"He(O) was(O) elected(O) to(O) the(O) American(B-organization) Academy(I-organization) of(I-organization) Arts(I-organization) and(I-organization) Sciences(I-organization) and(O) the(O) National(B-organization) Academy(I-organization) of(I-organization) Sciences(I-organization) and(O) has(O) received(O) a(O) series(O) of(O) awards(O) :(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["algorithm","person","organization","task","field","metric","university","researcher","programming language","country","location","product","conference"],"instance":{"id":"130","words":["The","most","recent","school","of","thought","on","Honda","'s","strategy","was","put","forward","by","Gary","Hamel","and","C.","K.","Prahalad","in","1989","."],"labels":["O","O","O","O","O","O","O","B-organization","O","O","O","O","O","O","B-person","I-person","O","B-person","I-person","I-person","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: algorithm, person, organization, task, field, metric, university, researcher, programming language, country, location, product, conference and O.\nSentence: The most recent school of thought on Honda 's strategy was put forward by Gary Hamel and C. K. Prahalad in 1989 .","prompt_labels":"The(O) most(O) recent(O) school(O) of(O) thought(O) on(O) Honda(B-organization) 's(O) strategy(O) was(O) put(O) forward(O) by(O) Gary(B-person) Hamel(I-person) and(O) C.(B-person) K.(I-person) Prahalad(I-person) in(O) 1989(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["task","product","country","metric","university","algorithm","programming language","organization","field","location","researcher","conference","person"],"instance":{"id":"131","words":["Where","BLEU","simply","calculates","n-gram","precision","adding","equal","weight","to","each","one",",","NIST","also","calculates","how","informative","a","particular","n-gram","is","."],"labels":["O","B-metric","O","O","B-metric","I-metric","O","O","O","O","O","O","O","B-metric","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: task, product, country, metric, university, algorithm, programming language, organization, field, location, researcher, conference, person and O.\nSentence: Where BLEU simply calculates n-gram precision adding equal weight to each one , NIST also calculates how informative a particular n-gram is .","prompt_labels":"Where(O) BLEU(B-metric) simply(O) calculates(O) n-gram(B-metric) precision(I-metric) adding(O) equal(O) weight(O) to(O) each(O) one(O) ,(O) NIST(B-metric) also(O) calculates(O) how(O) informative(O) a(O) particular(O) n-gram(O) is(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["location","programming language","person","country","product","university","algorithm","organization","metric","field","task","conference","researcher"],"instance":{"id":"132","words":["He","was","honored","with","the","2019","Lifetime","Achievement","Award","from","the","Association","for","Computational","Linguistics","(","ACL",")","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","B-conference","I-conference","I-conference","I-conference","O","B-conference","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, programming language, person, country, product, university, algorithm, organization, metric, field, task, conference, researcher and O.\nSentence: He was honored with the 2019 Lifetime Achievement Award from the Association for Computational Linguistics ( ACL ) .","prompt_labels":"He(O) was(O) honored(O) with(O) the(O) 2019(O) Lifetime(O) Achievement(O) Award(O) from(O) the(O) Association(B-conference) for(I-conference) Computational(I-conference) Linguistics(I-conference) ((O) ACL(B-conference) )(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["metric","field","programming language","algorithm","organization","product","task","country","person","conference","location","university","researcher"],"instance":{"id":"133","words":["Sycara","is","a","Fellow","of","Institute","of","Electrical","and","Electronics","Engineers","(","IEEE",")",",","and","a","Fellow","of","American","Association","for","Artificial","Intelligence","(","AAAI",")","."],"labels":["B-researcher","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","B-organization","O","O","O","O","O","O","B-conference","I-conference","I-conference","I-conference","I-conference","O","B-conference","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: metric, field, programming language, algorithm, organization, product, task, country, person, conference, location, university, researcher and O.\nSentence: Sycara is a Fellow of Institute of Electrical and Electronics Engineers ( IEEE ) , and a Fellow of American Association for Artificial Intelligence ( AAAI ) .","prompt_labels":"Sycara(B-researcher) is(O) a(O) Fellow(O) of(O) Institute(B-organization) of(I-organization) Electrical(I-organization) and(I-organization) Electronics(I-organization) Engineers(I-organization) ((O) IEEE(B-organization) )(O) ,(O) and(O) a(O) Fellow(O) of(O) American(B-conference) Association(I-conference) for(I-conference) Artificial(I-conference) Intelligence(I-conference) ((O) AAAI(B-conference) )(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["task","person","researcher","field","location","conference","product","university","algorithm","programming language","country","organization","metric"],"instance":{"id":"134","words":["The","following","MATLAB","code","demonstrates","a","concrete","solution","for","solving","the","non-linear","system","of","equations","presented","in","the","previous","section",":","See","also"],"labels":["O","O","B-product","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: task, person, researcher, field, location, conference, product, university, algorithm, programming language, country, organization, metric and O.\nSentence: The following MATLAB code demonstrates a concrete solution for solving the non-linear system of equations presented in the previous section : See also","prompt_labels":"The(O) following(O) MATLAB(B-product) code(O) demonstrates(O) a(O) concrete(O) solution(O) for(O) solving(O) the(O) non-linear(O) system(O) of(O) equations(O) presented(O) in(O) the(O) previous(O) section(O) :(O) See(O) also(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["algorithm","product","location","organization","field","programming language","person","university","conference","metric","researcher","country","task"],"instance":{"id":"135","words":["Pattern","recognition","systems","are","in","many","cases","trained","from","labeled","training","data","(","supervised","learning",")","but","when","no","labeled","data","are","available","other","algorithms","can","be","used","to","discover","previously","unknown","patterns","(","unsupervised","learning",")","."],"labels":["B-product","I-product","I-product","O","O","O","O","O","O","O","O","O","O","B-field","I-field","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-field","I-field","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: algorithm, product, location, organization, field, programming language, person, university, conference, metric, researcher, country, task and O.\nSentence: Pattern recognition systems are in many cases trained from labeled training data ( supervised learning ) but when no labeled data are available other algorithms can be used to discover previously unknown patterns ( unsupervised learning ) .","prompt_labels":"Pattern(B-product) recognition(I-product) systems(I-product) are(O) in(O) many(O) cases(O) trained(O) from(O) labeled(O) training(O) data(O) ((O) supervised(B-field) learning(I-field) )(O) but(O) when(O) no(O) labeled(O) data(O) are(O) available(O) other(O) algorithms(O) can(O) be(O) used(O) to(O) discover(O) previously(O) unknown(O) patterns(O) ((O) unsupervised(B-field) learning(I-field) )(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["field","person","algorithm","programming language","conference","location","product","university","task","country","metric","organization","researcher"],"instance":{"id":"136","words":["It","was","first","used","by","Lawrence","J.","Fogel","in","the","US","in","1960","in","order","to","use","simulated","evolution","as","a","learning","process","aiming","to","generate","artificial","intelligence","."],"labels":["O","O","O","O","O","B-researcher","I-researcher","I-researcher","O","O","B-country","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-field","I-field","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: field, person, algorithm, programming language, conference, location, product, university, task, country, metric, organization, researcher and O.\nSentence: It was first used by Lawrence J. Fogel in the US in 1960 in order to use simulated evolution as a learning process aiming to generate artificial intelligence .","prompt_labels":"It(O) was(O) first(O) used(O) by(O) Lawrence(B-researcher) J.(I-researcher) Fogel(I-researcher) in(O) the(O) US(B-country) in(O) 1960(O) in(O) order(O) to(O) use(O) simulated(O) evolution(O) as(O) a(O) learning(O) process(O) aiming(O) to(O) generate(O) artificial(B-field) intelligence(I-field) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["programming language","country","university","task","person","metric","conference","researcher","organization","location","algorithm","product","field"],"instance":{"id":"137","words":["Reinforcement","learning","is","one","of","three","basic","machine","learning","paradigms",",","alongside","supervised","learning","and","unsupervised","learning","."],"labels":["B-field","I-field","O","O","O","O","O","B-field","I-field","O","O","O","B-field","I-field","O","B-field","I-field","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: programming language, country, university, task, person, metric, conference, researcher, organization, location, algorithm, product, field and O.\nSentence: Reinforcement learning is one of three basic machine learning paradigms , alongside supervised learning and unsupervised learning .","prompt_labels":"Reinforcement(B-field) learning(I-field) is(O) one(O) of(O) three(O) basic(O) machine(B-field) learning(I-field) paradigms(O) ,(O) alongside(O) supervised(B-field) learning(I-field) and(O) unsupervised(B-field) learning(I-field) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["task","metric","product","programming language","organization","university","country","conference","algorithm","researcher","field","person","location"],"instance":{"id":"138","words":["In","such","cases",",","cloud","computing","and","open","source","programming","language","R","can","help","smaller","banks","to","adopt","risk","analytics","and","support","branch","level","monitoring","by","applying","predictive","analytics","."],"labels":["O","O","O","O","B-field","I-field","O","O","O","O","O","B-programming language","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-field","I-field","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: task, metric, product, programming language, organization, university, country, conference, algorithm, researcher, field, person, location and O.\nSentence: In such cases , cloud computing and open source programming language R can help smaller banks to adopt risk analytics and support branch level monitoring by applying predictive analytics .","prompt_labels":"In(O) such(O) cases(O) ,(O) cloud(B-field) computing(I-field) and(O) open(O) source(O) programming(O) language(O) R(B-programming language) can(O) help(O) smaller(O) banks(O) to(O) adopt(O) risk(O) analytics(O) and(O) support(O) branch(O) level(O) monitoring(O) by(O) applying(O) predictive(B-field) analytics(I-field) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["researcher","organization","conference","field","programming language","country","metric","task","university","person","algorithm","location","product"],"instance":{"id":"139","words":["One","of","the","first","versions","of","the","theorem","was","proved","by","George","Cybenko","in","1989","for","sigmoid","function","activation","functions.","Cybenko","G.","(","1989",")",",","2","(","4",")",",","303-314","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","B-researcher","I-researcher","O","O","O","B-algorithm","I-algorithm","O","O","B-researcher","I-researcher","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: researcher, organization, conference, field, programming language, country, metric, task, university, person, algorithm, location, product and O.\nSentence: One of the first versions of the theorem was proved by George Cybenko in 1989 for sigmoid function activation functions. Cybenko G. ( 1989 ) , 2 ( 4 ) , 303-314 .","prompt_labels":"One(O) of(O) the(O) first(O) versions(O) of(O) the(O) theorem(O) was(O) proved(O) by(O) George(B-researcher) Cybenko(I-researcher) in(O) 1989(O) for(O) sigmoid(B-algorithm) function(I-algorithm) activation(O) functions.(O) Cybenko(B-researcher) G.(I-researcher) ((O) 1989(O) )(O) ,(O) 2(O) ((O) 4(O) )(O) ,(O) 303-314(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["location","organization","algorithm","researcher","university","task","country","conference","field","person","programming language","metric","product"],"instance":{"id":"140","words":["In","this","process",",","which","is","known","as","cross-validation",",","the","MSE","is","often","called","the","mean","squared","prediction","error",",","and","is","computed","as"],"labels":["O","O","O","O","O","O","O","O","B-algorithm","O","O","B-metric","O","O","O","O","B-metric","I-metric","I-metric","I-metric","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, organization, algorithm, researcher, university, task, country, conference, field, person, programming language, metric, product and O.\nSentence: In this process , which is known as cross-validation , the MSE is often called the mean squared prediction error , and is computed as","prompt_labels":"In(O) this(O) process(O) ,(O) which(O) is(O) known(O) as(O) cross-validation(B-algorithm) ,(O) the(O) MSE(B-metric) is(O) often(O) called(O) the(O) mean(B-metric) squared(I-metric) prediction(I-metric) error(I-metric) ,(O) and(O) is(O) computed(O) as(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["field","task","conference","metric","researcher","person","country","algorithm","programming language","product","university","location","organization"],"instance":{"id":"141","words":["OMR","is","generally","distinguished","from","optical","character","recognition","(","OCR",")","by","the","fact","that","a","complicated","pattern","recognition","engine","is","not","required","."],"labels":["B-task","O","O","O","O","B-task","I-task","I-task","O","B-task","O","O","O","O","O","O","O","B-field","I-field","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: field, task, conference, metric, researcher, person, country, algorithm, programming language, product, university, location, organization and O.\nSentence: OMR is generally distinguished from optical character recognition ( OCR ) by the fact that a complicated pattern recognition engine is not required .","prompt_labels":"OMR(B-task) is(O) generally(O) distinguished(O) from(O) optical(B-task) character(I-task) recognition(I-task) ((O) OCR(B-task) )(O) by(O) the(O) fact(O) that(O) a(O) complicated(O) pattern(B-field) recognition(I-field) engine(O) is(O) not(O) required(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["country","field","person","conference","organization","metric","product","algorithm","task","programming language","location","university","researcher"],"instance":{"id":"142","words":["In","2018","and","2019",",","the","Championship","was","be","held","in","Houston","and","Detroit",",","Michigan","at","the","TCF","Center","and","Ford","Field","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","B-location","O","B-location","O","B-location","O","O","B-location","I-location","O","B-location","I-location","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, field, person, conference, organization, metric, product, algorithm, task, programming language, location, university, researcher and O.\nSentence: In 2018 and 2019 , the Championship was be held in Houston and Detroit , Michigan at the TCF Center and Ford Field .","prompt_labels":"In(O) 2018(O) and(O) 2019(O) ,(O) the(O) Championship(O) was(O) be(O) held(O) in(O) Houston(B-location) and(O) Detroit(B-location) ,(O) Michigan(B-location) at(O) the(O) TCF(B-location) Center(I-location) and(O) Ford(B-location) Field(I-location) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["country","location","conference","university","algorithm","metric","task","person","researcher","organization","programming language","field","product"],"instance":{"id":"143","words":["Classification","can","be","thought","of","as","two","separate","problems","-","binary","classification","and","multiclass","classification","."],"labels":["B-task","O","O","O","O","O","O","O","O","O","B-task","I-task","O","B-task","I-task","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, location, conference, university, algorithm, metric, task, person, researcher, organization, programming language, field, product and O.\nSentence: Classification can be thought of as two separate problems - binary classification and multiclass classification .","prompt_labels":"Classification(B-task) can(O) be(O) thought(O) of(O) as(O) two(O) separate(O) problems(O) -(O) binary(B-task) classification(I-task) and(O) multiclass(B-task) classification(I-task) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["university","field","task","product","conference","metric","organization","person","country","location","programming language","algorithm","researcher"],"instance":{"id":"144","words":["Two","examples","of","popular","parallel","robots","are","the","Stewart","platform","and","the","Delta","robot","."],"labels":["O","O","O","O","B-product","I-product","O","O","B-product","I-product","O","O","B-product","I-product","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: university, field, task, product, conference, metric, organization, person, country, location, programming language, algorithm, researcher and O.\nSentence: Two examples of popular parallel robots are the Stewart platform and the Delta robot .","prompt_labels":"Two(O) examples(O) of(O) popular(O) parallel(B-product) robots(I-product) are(O) the(O) Stewart(B-product) platform(I-product) and(O) the(O) Delta(B-product) robot(I-product) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["location","country","conference","university","product","field","organization","researcher","person","task","algorithm","programming language","metric"],"instance":{"id":"145","words":["(","Nevertheless",",","the","ReLU","activation","function",",","which","is","non-differentiable","at","0",",","has","become","quite","popular",",","e.g.","in","AlexNet",")"],"labels":["O","O","O","O","B-algorithm","I-algorithm","I-algorithm","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-algorithm","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, country, conference, university, product, field, organization, researcher, person, task, algorithm, programming language, metric and O.\nSentence: ( Nevertheless , the ReLU activation function , which is non-differentiable at 0 , has become quite popular , e.g. in AlexNet )","prompt_labels":"((O) Nevertheless(O) ,(O) the(O) ReLU(B-algorithm) activation(I-algorithm) function(I-algorithm) ,(O) which(O) is(O) non-differentiable(O) at(O) 0(O) ,(O) has(O) become(O) quite(O) popular(O) ,(O) e.g.(O) in(O) AlexNet(B-algorithm) )(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["researcher","product","location","country","programming language","algorithm","person","metric","task","field","university","conference","organization"],"instance":{"id":"146","words":["The","F-score","is","often","used","in","the","field","of","information","retrieval","for","measuring","search",",","document","classification",",","and","query","classification","performance.","and","so","F_beta","is","seen","in","wide","application","."],"labels":["O","B-metric","O","O","O","O","O","O","O","B-task","I-task","O","O","B-task","O","B-task","I-task","O","O","B-task","I-task","O","O","O","B-metric","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: researcher, product, location, country, programming language, algorithm, person, metric, task, field, university, conference, organization and O.\nSentence: The F-score is often used in the field of information retrieval for measuring search , document classification , and query classification performance. and so F_beta is seen in wide application .","prompt_labels":"The(O) F-score(B-metric) is(O) often(O) used(O) in(O) the(O) field(O) of(O) information(B-task) retrieval(I-task) for(O) measuring(O) search(B-task) ,(O) document(B-task) classification(I-task) ,(O) and(O) query(B-task) classification(I-task) performance.(O) and(O) so(O) F_beta(B-metric) is(O) seen(O) in(O) wide(O) application(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["metric","conference","field","algorithm","university","country","organization","person","location","task","researcher","product","programming language"],"instance":{"id":"147","words":["This","is","done","by","modeling","the","received","signal","then","using","a","statistical","estimation","method","such","as","maximum","likelihood","(","ML",")",",","majority","voting","(","MV",")","or","maximum","a","posteriori","(","MAP",")","to","make","a","decision","about","which","target","in","the","library","best","fits","the","model","built","using","the","received","signal","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-algorithm","I-algorithm","O","B-algorithm","O","O","B-algorithm","I-algorithm","O","B-algorithm","O","O","B-algorithm","I-algorithm","I-algorithm","O","B-algorithm","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: metric, conference, field, algorithm, university, country, organization, person, location, task, researcher, product, programming language and O.\nSentence: This is done by modeling the received signal then using a statistical estimation method such as maximum likelihood ( ML ) , majority voting ( MV ) or maximum a posteriori ( MAP ) to make a decision about which target in the library best fits the model built using the received signal .","prompt_labels":"This(O) is(O) done(O) by(O) modeling(O) the(O) received(O) signal(O) then(O) using(O) a(O) statistical(O) estimation(O) method(O) such(O) as(O) maximum(B-algorithm) likelihood(I-algorithm) ((O) ML(B-algorithm) )(O) ,(O) majority(B-algorithm) voting(I-algorithm) ((O) MV(B-algorithm) )(O) or(O) maximum(B-algorithm) a(I-algorithm) posteriori(I-algorithm) ((O) MAP(B-algorithm) )(O) to(O) make(O) a(O) decision(O) about(O) which(O) target(O) in(O) the(O) library(O) best(O) fits(O) the(O) model(O) built(O) using(O) the(O) received(O) signal(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["researcher","university","person","metric","algorithm","conference","field","organization","product","programming language","location","task","country"],"instance":{"id":"148","words":["Sowa","received","a","BS","in","mathematics","from","Massachusetts","Institute","of","Technology","in","1962",",","an","MA","in","applied","from","Harvard","University","in","1966",",","and","a","PhD","in","computer","science","from","the","Vrije","Universiteit","Brussel","in","1999","on","a","dissertation","titled","Knowledge","Representation",":","Logical",",","Philosophical",",","and","Computational","Foundations","."],"labels":["B-researcher","O","O","O","O","B-field","O","B-university","I-university","I-university","I-university","O","O","O","O","O","O","B-field","O","B-university","I-university","O","O","O","O","O","O","O","B-field","I-field","O","O","B-university","I-university","I-university","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: researcher, university, person, metric, algorithm, conference, field, organization, product, programming language, location, task, country and O.\nSentence: Sowa received a BS in mathematics from Massachusetts Institute of Technology in 1962 , an MA in applied from Harvard University in 1966 , and a PhD in computer science from the Vrije Universiteit Brussel in 1999 on a dissertation titled Knowledge Representation : Logical , Philosophical , and Computational Foundations .","prompt_labels":"Sowa(B-researcher) received(O) a(O) BS(O) in(O) mathematics(B-field) from(O) Massachusetts(B-university) Institute(I-university) of(I-university) Technology(I-university) in(O) 1962(O) ,(O) an(O) MA(O) in(O) applied(B-field) from(O) Harvard(B-university) University(I-university) in(O) 1966(O) ,(O) and(O) a(O) PhD(O) in(O) computer(B-field) science(I-field) from(O) the(O) Vrije(B-university) Universiteit(I-university) Brussel(I-university) in(O) 1999(O) on(O) a(O) dissertation(O) titled(O) Knowledge(O) Representation(O) :(O) Logical(O) ,(O) Philosophical(O) ,(O) and(O) Computational(O) Foundations(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["researcher","person","organization","country","programming language","location","task","metric","product","algorithm","university","conference","field"],"instance":{"id":"149","words":["Since","paraphrase","recognition","can","be","posed","as","a","classification","problem",",","most","standard","evaluations","metrics","such","as","accuracy",",","f1","score",",","or","an","ROC","curve","do","relatively","well","."],"labels":["O","B-task","I-task","O","O","O","O","O","B-task","O","O","O","O","O","O","O","O","B-metric","O","B-metric","I-metric","O","O","O","B-metric","I-metric","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: researcher, person, organization, country, programming language, location, task, metric, product, algorithm, university, conference, field and O.\nSentence: Since paraphrase recognition can be posed as a classification problem , most standard evaluations metrics such as accuracy , f1 score , or an ROC curve do relatively well .","prompt_labels":"Since(O) paraphrase(B-task) recognition(I-task) can(O) be(O) posed(O) as(O) a(O) classification(B-task) problem(O) ,(O) most(O) standard(O) evaluations(O) metrics(O) such(O) as(O) accuracy(B-metric) ,(O) f1(B-metric) score(I-metric) ,(O) or(O) an(O) ROC(B-metric) curve(I-metric) do(O) relatively(O) well(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["location","task","field","country","conference","product","algorithm","researcher","metric","person","organization","programming language","university"],"instance":{"id":"150","words":["This","makes","it","practical","for","analyzing","large","data","sets","(","hundreds","or","thousands","of","taxa",")","and","for","bootstrapping",",","for","which","purposes","other","means","of","analysis","(","e.g.","maximum","parsimony",",","maximum","likelihood",")","may","be","computation","ally","prohibitive","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-algorithm","O","O","O","O","O","O","O","O","O","O","B-algorithm","I-algorithm","O","B-algorithm","I-algorithm","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, task, field, country, conference, product, algorithm, researcher, metric, person, organization, programming language, university and O.\nSentence: This makes it practical for analyzing large data sets ( hundreds or thousands of taxa ) and for bootstrapping , for which purposes other means of analysis ( e.g. maximum parsimony , maximum likelihood ) may be computation ally prohibitive .","prompt_labels":"This(O) makes(O) it(O) practical(O) for(O) analyzing(O) large(O) data(O) sets(O) ((O) hundreds(O) or(O) thousands(O) of(O) taxa(O) )(O) and(O) for(O) bootstrapping(B-algorithm) ,(O) for(O) which(O) purposes(O) other(O) means(O) of(O) analysis(O) ((O) e.g.(O) maximum(B-algorithm) parsimony(I-algorithm) ,(O) maximum(B-algorithm) likelihood(I-algorithm) )(O) may(O) be(O) computation(O) ally(O) prohibitive(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["person","algorithm","researcher","conference","product","metric","organization","country","programming language","field","university","task","location"],"instance":{"id":"151","words":["The","2002","submission","of","the","DAML","+","OIL","language","to","the","World","Wide","Web","Consortium","(","W3C",")","the","work","done","by","DAML","contractors","and","the","European","Union","\/","United","States","ad","hoc","Joint","Committee","on","Markup","Languages","."],"labels":["O","O","O","O","O","B-programming language","O","B-programming language","O","O","O","B-organization","I-organization","I-organization","I-organization","O","B-organization","O","O","O","O","O","B-programming language","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","I-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, algorithm, researcher, conference, product, metric, organization, country, programming language, field, university, task, location and O.\nSentence: The 2002 submission of the DAML + OIL language to the World Wide Web Consortium ( W3C ) the work done by DAML contractors and the European Union \/ United States ad hoc Joint Committee on Markup Languages .","prompt_labels":"The(O) 2002(O) submission(O) of(O) the(O) DAML(B-programming language) +(O) OIL(B-programming language) language(O) to(O) the(O) World(B-organization) Wide(I-organization) Web(I-organization) Consortium(I-organization) ((O) W3C(B-organization) )(O) the(O) work(O) done(O) by(O) DAML(B-programming language) contractors(O) and(O) the(O) European(B-organization) Union(I-organization) \/(I-organization) United(I-organization) States(I-organization) ad(I-organization) hoc(I-organization) Joint(I-organization) Committee(I-organization) on(I-organization) Markup(I-organization) Languages(I-organization) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["metric","organization","product","task","researcher","country","programming language","conference","field","university","algorithm","location","person"],"instance":{"id":"152","words":["An","example","of","non-linear","normalization","is","when","the","normalization","follows","a","sigmoid","function",",","in","that","case",",","the","normalized","image","is","computed","according","to","the","formula"],"labels":["O","O","O","O","O","O","O","O","O","O","O","B-algorithm","I-algorithm","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: metric, organization, product, task, researcher, country, programming language, conference, field, university, algorithm, location, person and O.\nSentence: An example of non-linear normalization is when the normalization follows a sigmoid function , in that case , the normalized image is computed according to the formula","prompt_labels":"An(O) example(O) of(O) non-linear(O) normalization(O) is(O) when(O) the(O) normalization(O) follows(O) a(O) sigmoid(B-algorithm) function(I-algorithm) ,(O) in(O) that(O) case(O) ,(O) the(O) normalized(O) image(O) is(O) computed(O) according(O) to(O) the(O) formula(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["field","university","task","organization","product","algorithm","metric","person","location","conference","programming language","researcher","country"],"instance":{"id":"153","words":["It","has","been","pointed","out","that","precision","is","usually","twinned","with","recall","to","overcome","this","problem"],"labels":["O","O","O","O","O","O","B-metric","O","O","O","O","B-metric","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: field, university, task, organization, product, algorithm, metric, person, location, conference, programming language, researcher, country and O.\nSentence: It has been pointed out that precision is usually twinned with recall to overcome this problem","prompt_labels":"It(O) has(O) been(O) pointed(O) out(O) that(O) precision(B-metric) is(O) usually(O) twinned(O) with(O) recall(B-metric) to(O) overcome(O) this(O) problem(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["person","metric","programming language","country","organization","researcher","location","algorithm","task","product","field","conference","university"],"instance":{"id":"154","words":["The","commonly","used","metrics","are","the","mean","squared","error","and","root","mean","squared","error",",","the","latter","having","been","used","in","the","Netflix","Prize","."],"labels":["O","O","O","O","O","O","B-metric","I-metric","I-metric","O","B-metric","I-metric","I-metric","I-metric","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, metric, programming language, country, organization, researcher, location, algorithm, task, product, field, conference, university and O.\nSentence: The commonly used metrics are the mean squared error and root mean squared error , the latter having been used in the Netflix Prize .","prompt_labels":"The(O) commonly(O) used(O) metrics(O) are(O) the(O) mean(B-metric) squared(I-metric) error(I-metric) and(O) root(B-metric) mean(I-metric) squared(I-metric) error(I-metric) ,(O) the(O) latter(O) having(O) been(O) used(O) in(O) the(O) Netflix(O) Prize(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["product","researcher","task","country","algorithm","conference","metric","person","organization","field","location","programming language","university"],"instance":{"id":"155","words":["In","August","2016",",","a","research","programme","with","University","College","Hospital","was","announced","with","the","aim","of","developing","an","algorithm","that","can","automatically","differentiate","between","healthy","and","cancerous","tissues","in","head","and","neck","areas","."],"labels":["O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: product, researcher, task, country, algorithm, conference, metric, person, organization, field, location, programming language, university and O.\nSentence: In August 2016 , a research programme with University College Hospital was announced with the aim of developing an algorithm that can automatically differentiate between healthy and cancerous tissues in head and neck areas .","prompt_labels":"In(O) August(O) 2016(O) ,(O) a(O) research(O) programme(O) with(O) University(B-organization) College(I-organization) Hospital(I-organization) was(O) announced(O) with(O) the(O) aim(O) of(O) developing(O) an(O) algorithm(O) that(O) can(O) automatically(O) differentiate(O) between(O) healthy(O) and(O) cancerous(O) tissues(O) in(O) head(O) and(O) neck(O) areas(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["researcher","programming language","conference","metric","organization","product","algorithm","location","university","person","country","task","field"],"instance":{"id":"156","words":["The","impact","of","Posner","'s","theoretical","and","empirical","contributions","has","been","recognized","through","fellowship","in","the","American","Psychological","Association",",","the","Association","for","Psychological","Science",",","the","Society","of","Experimental","Psychologists",",","the","American","Academy","of","Arts","and","Sciences",",","the","American","Association","for","the","Advancement","of","Science",",","and","the","National","Academy","of","Sciences","."],"labels":["O","O","O","B-researcher","O","O","O","O","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","O","O","B-organization","I-organization","I-organization","I-organization","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: researcher, programming language, conference, metric, organization, product, algorithm, location, university, person, country, task, field and O.\nSentence: The impact of Posner 's theoretical and empirical contributions has been recognized through fellowship in the American Psychological Association , the Association for Psychological Science , the Society of Experimental Psychologists , the American Academy of Arts and Sciences , the American Association for the Advancement of Science , and the National Academy of Sciences .","prompt_labels":"The(O) impact(O) of(O) Posner(B-researcher) 's(O) theoretical(O) and(O) empirical(O) contributions(O) has(O) been(O) recognized(O) through(O) fellowship(O) in(O) the(O) American(B-organization) Psychological(I-organization) Association(I-organization) ,(O) the(O) Association(B-organization) for(I-organization) Psychological(I-organization) Science(I-organization) ,(O) the(O) Society(B-organization) of(I-organization) Experimental(I-organization) Psychologists(I-organization) ,(O) the(O) American(B-organization) Academy(I-organization) of(I-organization) Arts(I-organization) and(I-organization) Sciences(I-organization) ,(O) the(O) American(B-organization) Association(I-organization) for(I-organization) the(I-organization) Advancement(I-organization) of(I-organization) Science(I-organization) ,(O) and(O) the(O) National(B-organization) Academy(I-organization) of(I-organization) Sciences(I-organization) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["researcher","task","product","university","organization","conference","algorithm","country","location","programming language","field","person","metric"],"instance":{"id":"157","words":["These","Intelligent","Chatbots","make","use","of","all","kinds","of","artificial","intelligence","like","image","moderation","and","natural","language","understanding","(","NLU",")",",","natural","language","generation","(","NLG",")",",","machine","learning","and","deep","learning","."],"labels":["O","O","B-product","O","O","O","O","O","O","B-field","I-field","O","B-task","I-task","O","B-task","I-task","I-task","O","B-task","O","O","B-task","I-task","I-task","O","B-task","O","O","B-field","I-field","O","B-field","I-field","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: researcher, task, product, university, organization, conference, algorithm, country, location, programming language, field, person, metric and O.\nSentence: These Intelligent Chatbots make use of all kinds of artificial intelligence like image moderation and natural language understanding ( NLU ) , natural language generation ( NLG ) , machine learning and deep learning .","prompt_labels":"These(O) Intelligent(O) Chatbots(B-product) make(O) use(O) of(O) all(O) kinds(O) of(O) artificial(B-field) intelligence(I-field) like(O) image(B-task) moderation(I-task) and(O) natural(B-task) language(I-task) understanding(I-task) ((O) NLU(B-task) )(O) ,(O) natural(B-task) language(I-task) generation(I-task) ((O) NLG(B-task) )(O) ,(O) machine(B-field) learning(I-field) and(O) deep(B-field) learning(I-field) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["algorithm","location","conference","country","task","product","organization","programming language","field","university","metric","researcher","person"],"instance":{"id":"158","words":["The","row","ratios","are","Positive","Predictive","Value","(","PPV",",","aka","precision",")","(","TP","\/","(","TP","+","FP",")",")",",","with","complement","the","FALSE","Discovery","Rate","(","FDR",")","(","FP","\/","(","TP","+","FP",")",")",";","and","Negative","Predictive","Value","(","NPV",")","(","TN","\/","(","TN","+","FN",")",")",",","with","complement","the","FALSE","Omission","Rate","(","FOR",")","(","FN","\/","(","TN","+","FN",")",")","."],"labels":["O","O","O","O","B-metric","I-metric","I-metric","O","B-metric","O","O","B-metric","O","O","B-metric","I-metric","I-metric","I-metric","I-metric","I-metric","I-metric","O","O","O","O","O","B-metric","I-metric","I-metric","O","B-metric","O","O","B-metric","I-metric","I-metric","I-metric","I-metric","I-metric","I-metric","O","O","O","B-metric","I-metric","I-metric","O","B-metric","O","O","B-metric","I-metric","I-metric","I-metric","I-metric","I-metric","I-metric","O","O","O","O","O","B-metric","I-metric","I-metric","O","B-metric","O","O","B-metric","I-metric","I-metric","I-metric","I-metric","I-metric","I-metric","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: algorithm, location, conference, country, task, product, organization, programming language, field, university, metric, researcher, person and O.\nSentence: The row ratios are Positive Predictive Value ( PPV , aka precision ) ( TP \/ ( TP + FP ) ) , with complement the FALSE Discovery Rate ( FDR ) ( FP \/ ( TP + FP ) ) ; and Negative Predictive Value ( NPV ) ( TN \/ ( TN + FN ) ) , with complement the FALSE Omission Rate ( FOR ) ( FN \/ ( TN + FN ) ) .","prompt_labels":"The(O) row(O) ratios(O) are(O) Positive(B-metric) Predictive(I-metric) Value(I-metric) ((O) PPV(B-metric) ,(O) aka(O) precision(B-metric) )(O) ((O) TP(B-metric) \/(I-metric) ((I-metric) TP(I-metric) +(I-metric) FP(I-metric) )(I-metric) )(O) ,(O) with(O) complement(O) the(O) FALSE(B-metric) Discovery(I-metric) Rate(I-metric) ((O) FDR(B-metric) )(O) ((O) FP(B-metric) \/(I-metric) ((I-metric) TP(I-metric) +(I-metric) FP(I-metric) )(I-metric) )(O) ;(O) and(O) Negative(B-metric) Predictive(I-metric) Value(I-metric) ((O) NPV(B-metric) )(O) ((O) TN(B-metric) \/(I-metric) ((I-metric) TN(I-metric) +(I-metric) FN(I-metric) )(I-metric) )(O) ,(O) with(O) complement(O) the(O) FALSE(B-metric) Omission(I-metric) Rate(I-metric) ((O) FOR(B-metric) )(O) ((O) FN(B-metric) \/(I-metric) ((I-metric) TN(I-metric) +(I-metric) FN(I-metric) )(I-metric) )(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["organization","product","university","programming language","researcher","location","algorithm","field","person","metric","task","country","conference"],"instance":{"id":"159","words":["The","information","is","a","blend","of","sitemaps","and","RSS","and","is","created","using","the","Information","Model","(","IM",")","and","Biomedical","Resource","Ontology","(","BRO",")","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-algorithm","I-algorithm","O","B-algorithm","O","O","B-algorithm","I-algorithm","I-algorithm","O","B-algorithm","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, product, university, programming language, researcher, location, algorithm, field, person, metric, task, country, conference and O.\nSentence: The information is a blend of sitemaps and RSS and is created using the Information Model ( IM ) and Biomedical Resource Ontology ( BRO ) .","prompt_labels":"The(O) information(O) is(O) a(O) blend(O) of(O) sitemaps(O) and(O) RSS(O) and(O) is(O) created(O) using(O) the(O) Information(B-algorithm) Model(I-algorithm) ((O) IM(B-algorithm) )(O) and(O) Biomedical(B-algorithm) Resource(I-algorithm) Ontology(I-algorithm) ((O) BRO(B-algorithm) )(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["product","metric","programming language","field","conference","university","task","country","organization","researcher","person","location","algorithm"],"instance":{"id":"160","words":["Recent","text","recognition","is","based","on","Recurrent","neural","network","(","Long","short-term","memory",")","and","does","not","require","a","language","model","."],"labels":["O","B-task","I-task","O","O","O","B-algorithm","I-algorithm","I-algorithm","O","B-algorithm","I-algorithm","I-algorithm","O","O","O","O","O","O","B-algorithm","I-algorithm","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: product, metric, programming language, field, conference, university, task, country, organization, researcher, person, location, algorithm and O.\nSentence: Recent text recognition is based on Recurrent neural network ( Long short-term memory ) and does not require a language model .","prompt_labels":"Recent(O) text(B-task) recognition(I-task) is(O) based(O) on(O) Recurrent(B-algorithm) neural(I-algorithm) network(I-algorithm) ((O) Long(B-algorithm) short-term(I-algorithm) memory(I-algorithm) )(O) and(O) does(O) not(O) require(O) a(O) language(B-algorithm) model(I-algorithm) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["conference","task","researcher","university","organization","location","metric","product","country","field","person","algorithm","programming language"],"instance":{"id":"161","words":["Popular","loss","functions","include","the","hinge","loss","(","for","linear","SVMs",")","and","the","log","loss","(","for","logistic","regression",")","."],"labels":["O","O","O","O","O","B-metric","I-metric","O","O","B-algorithm","I-algorithm","O","O","O","B-metric","I-metric","O","O","B-algorithm","I-algorithm","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: conference, task, researcher, university, organization, location, metric, product, country, field, person, algorithm, programming language and O.\nSentence: Popular loss functions include the hinge loss ( for linear SVMs ) and the log loss ( for logistic regression ) .","prompt_labels":"Popular(O) loss(O) functions(O) include(O) the(O) hinge(B-metric) loss(I-metric) ((O) for(O) linear(B-algorithm) SVMs(I-algorithm) )(O) and(O) the(O) log(B-metric) loss(I-metric) ((O) for(O) logistic(B-algorithm) regression(I-algorithm) )(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["programming language","algorithm","location","researcher","conference","product","university","metric","field","person","task","organization","country"],"instance":{"id":"162","words":["SSIM","is","designed","to","improve","on","traditional","methods","such","as","peak","signal-to-noise","ratio","(","PSNR",")","and","mean","squared","error","(","MSE",")","."],"labels":["B-metric","O","O","O","O","O","O","O","O","O","B-metric","I-metric","I-metric","O","B-metric","O","O","B-metric","I-metric","I-metric","O","B-metric","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: programming language, algorithm, location, researcher, conference, product, university, metric, field, person, task, organization, country and O.\nSentence: SSIM is designed to improve on traditional methods such as peak signal-to-noise ratio ( PSNR ) and mean squared error ( MSE ) .","prompt_labels":"SSIM(B-metric) is(O) designed(O) to(O) improve(O) on(O) traditional(O) methods(O) such(O) as(O) peak(B-metric) signal-to-noise(I-metric) ratio(I-metric) ((O) PSNR(B-metric) )(O) and(O) mean(B-metric) squared(I-metric) error(I-metric) ((O) MSE(B-metric) )(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["conference","algorithm","researcher","programming language","location","field","person","task","organization","university","country","product","metric"],"instance":{"id":"163","words":["His","work","inspired","subsequent","generations","of","robotics","researchers","such","as","Rodney","Brooks",",","Hans","Moravec","and","Mark","Tilden","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-researcher","I-researcher","O","B-researcher","I-researcher","O","B-researcher","I-researcher","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: conference, algorithm, researcher, programming language, location, field, person, task, organization, university, country, product, metric and O.\nSentence: His work inspired subsequent generations of robotics researchers such as Rodney Brooks , Hans Moravec and Mark Tilden .","prompt_labels":"His(O) work(O) inspired(O) subsequent(O) generations(O) of(O) robotics(O) researchers(O) such(O) as(O) Rodney(B-researcher) Brooks(I-researcher) ,(O) Hans(B-researcher) Moravec(I-researcher) and(O) Mark(B-researcher) Tilden(I-researcher) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["task","field","metric","person","product","programming language","organization","university","conference","researcher","location","country","algorithm"],"instance":{"id":"164","words":["Further","pulse","training","is","not","differentiable",",","eliminating","backpropagation","-based","training","methods","like","gradient","descent","."],"labels":["O","O","O","O","O","O","O","O","B-algorithm","O","O","O","O","B-algorithm","I-algorithm","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: task, field, metric, person, product, programming language, organization, university, conference, researcher, location, country, algorithm and O.\nSentence: Further pulse training is not differentiable , eliminating backpropagation -based training methods like gradient descent .","prompt_labels":"Further(O) pulse(O) training(O) is(O) not(O) differentiable(O) ,(O) eliminating(O) backpropagation(B-algorithm) -based(O) training(O) methods(O) like(O) gradient(B-algorithm) descent(I-algorithm) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["metric","researcher","country","product","task","person","university","field","conference","organization","programming language","location","algorithm"],"instance":{"id":"165","words":["This","relations","can","be","easily","represented","with","a","confusion","matrix",",","a","table","which","describes","the","accuracy","of","a","classification","model","."],"labels":["O","O","O","O","O","O","O","O","B-metric","I-metric","O","O","O","O","O","O","B-metric","O","O","B-task","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: metric, researcher, country, product, task, person, university, field, conference, organization, programming language, location, algorithm and O.\nSentence: This relations can be easily represented with a confusion matrix , a table which describes the accuracy of a classification model .","prompt_labels":"This(O) relations(O) can(O) be(O) easily(O) represented(O) with(O) a(O) confusion(B-metric) matrix(I-metric) ,(O) a(O) table(O) which(O) describes(O) the(O) accuracy(B-metric) of(O) a(O) classification(B-task) model(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["person","university","metric","product","task","field","location","organization","researcher","conference","country","programming language","algorithm"],"instance":{"id":"166","words":["At","the","2018","Conference","on","Neural","Information","Processing","Systems","(","NeurIPS",")","researchers","from","Google","presented","the","work"],"labels":["O","O","B-conference","I-conference","I-conference","I-conference","I-conference","I-conference","I-conference","O","B-conference","O","O","O","B-organization","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, university, metric, product, task, field, location, organization, researcher, conference, country, programming language, algorithm and O.\nSentence: At the 2018 Conference on Neural Information Processing Systems ( NeurIPS ) researchers from Google presented the work","prompt_labels":"At(O) the(O) 2018(B-conference) Conference(I-conference) on(I-conference) Neural(I-conference) Information(I-conference) Processing(I-conference) Systems(I-conference) ((O) NeurIPS(B-conference) )(O) researchers(O) from(O) Google(B-organization) presented(O) the(O) work(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["algorithm","country","researcher","person","task","product","organization","university","conference","field","programming language","location","metric"],"instance":{"id":"167","words":["During","his","time","at","Duke",",","he","worked","on","an","automated","crossword","solver","PROVERB",",","which","won","an","Outstanding","Paper","Award","in","1999","from","AAAI","and","competed","in","the","American","Crossword","Puzzle","Tournament","."],"labels":["O","O","O","O","B-university","O","O","O","O","O","O","O","O","B-product","O","O","O","O","O","O","O","O","O","O","B-conference","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: algorithm, country, researcher, person, task, product, organization, university, conference, field, programming language, location, metric and O.\nSentence: During his time at Duke , he worked on an automated crossword solver PROVERB , which won an Outstanding Paper Award in 1999 from AAAI and competed in the American Crossword Puzzle Tournament .","prompt_labels":"During(O) his(O) time(O) at(O) Duke(B-university) ,(O) he(O) worked(O) on(O) an(O) automated(O) crossword(O) solver(O) PROVERB(B-product) ,(O) which(O) won(O) an(O) Outstanding(O) Paper(O) Award(O) in(O) 1999(O) from(O) AAAI(B-conference) and(O) competed(O) in(O) the(O) American(O) Crossword(O) Puzzle(O) Tournament(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["country","algorithm","product","programming language","conference","field","task","researcher","person","university","organization","metric","location"],"instance":{"id":"168","words":["Headquartered","in","Rochester","Hills",",","Michigan",",","the","company","had","10","regional","locations","in","the","U.S.",",","Canada",",","Mexico","and","Brazil","."],"labels":["O","O","B-location","I-location","O","B-location","O","O","O","O","O","O","O","O","B-country","I-country","O","B-country","O","B-country","O","B-country","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, algorithm, product, programming language, conference, field, task, researcher, person, university, organization, metric, location and O.\nSentence: Headquartered in Rochester Hills , Michigan , the company had 10 regional locations in the U.S. , Canada , Mexico and Brazil .","prompt_labels":"Headquartered(O) in(O) Rochester(B-location) Hills(I-location) ,(O) Michigan(B-location) ,(O) the(O) company(O) had(O) 10(O) regional(O) locations(O) in(O) the(B-country) U.S.(I-country) ,(O) Canada(B-country) ,(O) Mexico(B-country) and(O) Brazil(B-country) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["conference","university","organization","location","country","person","task","field","algorithm","researcher","programming language","product","metric"],"instance":{"id":"169","words":["It","joins","a","collection","of","historically","important","robots","that","includes","an","early","Unimate","and","the","Odetics","Odex","1","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","B-product","O","O","B-product","I-product","I-product","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: conference, university, organization, location, country, person, task, field, algorithm, researcher, programming language, product, metric and O.\nSentence: It joins a collection of historically important robots that includes an early Unimate and the Odetics Odex 1 .","prompt_labels":"It(O) joins(O) a(O) collection(O) of(O) historically(O) important(O) robots(O) that(O) includes(O) an(O) early(O) Unimate(B-product) and(O) the(O) Odetics(B-product) Odex(I-product) 1(I-product) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["conference","location","country","university","field","task","algorithm","metric","programming language","person","researcher","organization","product"],"instance":{"id":"170","words":["A","guest","editor","for","that","issue","will","be","David","'s","former","colleague","at","NIST",",","Judah","Levine","who","is","the","most","recent","recipient","of","the","I.","I.","Rabi","Award","."],"labels":["O","O","O","O","O","O","O","O","B-researcher","O","O","O","O","B-organization","O","B-researcher","I-researcher","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: conference, location, country, university, field, task, algorithm, metric, programming language, person, researcher, organization, product and O.\nSentence: A guest editor for that issue will be David 's former colleague at NIST , Judah Levine who is the most recent recipient of the I. I. Rabi Award .","prompt_labels":"A(O) guest(O) editor(O) for(O) that(O) issue(O) will(O) be(O) David(B-researcher) 's(O) former(O) colleague(O) at(O) NIST(B-organization) ,(O) Judah(B-researcher) Levine(I-researcher) who(O) is(O) the(O) most(O) recent(O) recipient(O) of(O) the(O) I.(O) I.(O) Rabi(O) Award(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["programming language","location","researcher","metric","field","country","algorithm","organization","task","person","university","product","conference"],"instance":{"id":"171","words":["These","can","be","arranged","into","a","2","","2","contingency","table","(","confusion","matrix",")",",","conventionally","with","the","test","result","on","the","vertical","axis","and","the","actual","condition","on","the","horizontal","axis","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","B-metric","I-metric","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: programming language, location, researcher, metric, field, country, algorithm, organization, task, person, university, product, conference and O.\nSentence: These can be arranged into a 2  2 contingency table ( confusion matrix ) , conventionally with the test result on the vertical axis and the actual condition on the horizontal axis .","prompt_labels":"These(O) can(O) be(O) arranged(O) into(O) a(O) 2(O) (O) 2(O) contingency(O) table(O) ((O) confusion(B-metric) matrix(I-metric) )(O) ,(O) conventionally(O) with(O) the(O) test(O) result(O) on(O) the(O) vertical(O) axis(O) and(O) the(O) actual(O) condition(O) on(O) the(O) horizontal(O) axis(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["organization","programming language","location","algorithm","conference","researcher","task","person","university","product","field","country","metric"],"instance":{"id":"172","words":["The","Apple","iOS","operating","system","used","on","the","iPhone",",","iPad","and","iPod","Touch","uses","VoiceOver","speech","synthesis","accessibility","."],"labels":["O","B-product","I-product","I-product","I-product","O","O","O","B-product","O","B-product","O","B-product","I-product","O","B-product","I-product","I-product","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, programming language, location, algorithm, conference, researcher, task, person, university, product, field, country, metric and O.\nSentence: The Apple iOS operating system used on the iPhone , iPad and iPod Touch uses VoiceOver speech synthesis accessibility .","prompt_labels":"The(O) Apple(B-product) iOS(I-product) operating(I-product) system(I-product) used(O) on(O) the(O) iPhone(B-product) ,(O) iPad(B-product) and(O) iPod(B-product) Touch(I-product) uses(O) VoiceOver(B-product) speech(I-product) synthesis(I-product) accessibility(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["person","university","conference","location","product","programming language","researcher","country","metric","task","field","organization","algorithm"],"instance":{"id":"173","words":["For","example",",","the","best","system","entering","MUC-7","scored","93.39","%","of","F-measure","while","human","annotators","scored","97.6","%","and","96.95","%","."],"labels":["O","O","O","O","O","O","O","B-conference","O","O","O","O","B-metric","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, university, conference, location, product, programming language, researcher, country, metric, task, field, organization, algorithm and O.\nSentence: For example , the best system entering MUC-7 scored 93.39 % of F-measure while human annotators scored 97.6 % and 96.95 % .","prompt_labels":"For(O) example(O) ,(O) the(O) best(O) system(O) entering(O) MUC-7(B-conference) scored(O) 93.39(O) %(O) of(O) F-measure(B-metric) while(O) human(O) annotators(O) scored(O) 97.6(O) %(O) and(O) 96.95(O) %(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["field","organization","metric","university","task","person","country","programming language","location","conference","product","algorithm","researcher"],"instance":{"id":"174","words":["This","is","done","using","standard","neural","net","training","algorithms","such","as","stochastic","gradient","descent","with","backpropagation","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","B-algorithm","I-algorithm","I-algorithm","O","B-algorithm","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: field, organization, metric, university, task, person, country, programming language, location, conference, product, algorithm, researcher and O.\nSentence: This is done using standard neural net training algorithms such as stochastic gradient descent with backpropagation .","prompt_labels":"This(O) is(O) done(O) using(O) standard(O) neural(O) net(O) training(O) algorithms(O) such(O) as(O) stochastic(B-algorithm) gradient(I-algorithm) descent(I-algorithm) with(O) backpropagation(B-algorithm) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["conference","task","country","organization","person","university","metric","programming language","researcher","field","location","product","algorithm"],"instance":{"id":"175","words":["Rotten","Tomatoes","is","a","top","1000","site",",","placing","around","#","400","globally","and","top","150","for","the","US","only",",","according","to","website","ranker","Alexa","."],"labels":["B-organization","I-organization","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-country","O","O","O","O","O","O","B-product","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: conference, task, country, organization, person, university, metric, programming language, researcher, field, location, product, algorithm and O.\nSentence: Rotten Tomatoes is a top 1000 site , placing around # 400 globally and top 150 for the US only , according to website ranker Alexa .","prompt_labels":"Rotten(B-organization) Tomatoes(I-organization) is(O) a(O) top(O) 1000(O) site(O) ,(O) placing(O) around(O) #(O) 400(O) globally(O) and(O) top(O) 150(O) for(O) the(O) US(B-country) only(O) ,(O) according(O) to(O) website(O) ranker(O) Alexa(B-product) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["person","product","programming language","country","researcher","metric","conference","algorithm","field","location","task","organization","university"],"instance":{"id":"176","words":["Generally","speaking","all","learning","displays","incremental","change","over","time",",","but","describes","an","Sigmoid","function","which","has","different","appearances","depending","on","the","time","scale","of","observation","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","B-algorithm","I-algorithm","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, product, programming language, country, researcher, metric, conference, algorithm, field, location, task, organization, university and O.\nSentence: Generally speaking all learning displays incremental change over time , but describes an Sigmoid function which has different appearances depending on the time scale of observation .","prompt_labels":"Generally(O) speaking(O) all(O) learning(O) displays(O) incremental(O) change(O) over(O) time(O) ,(O) but(O) describes(O) an(O) Sigmoid(B-algorithm) function(I-algorithm) which(O) has(O) different(O) appearances(O) depending(O) on(O) the(O) time(O) scale(O) of(O) observation(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["task","product","researcher","field","metric","location","programming language","conference","university","country","person","organization","algorithm"],"instance":{"id":"177","words":["The","SSD","is","also","known","as","mean","squared","error","."],"labels":["O","B-metric","O","O","O","O","B-metric","I-metric","I-metric","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: task, product, researcher, field, metric, location, programming language, conference, university, country, person, organization, algorithm and O.\nSentence: The SSD is also known as mean squared error .","prompt_labels":"The(O) SSD(B-metric) is(O) also(O) known(O) as(O) mean(B-metric) squared(I-metric) error(I-metric) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["conference","person","researcher","task","country","programming language","field","university","product","organization","metric","algorithm","location"],"instance":{"id":"178","words":["Decision","tree","learning",",","neural","networks",",","or","a","naive","Bayes","classifier","could","be","used","in","combination","with","measures","of","model","quality","such","as","balanced","accuracy"],"labels":["B-algorithm","I-algorithm","I-algorithm","O","B-algorithm","I-algorithm","O","O","O","B-algorithm","I-algorithm","I-algorithm","O","O","O","O","O","O","O","O","O","O","O","O","B-metric","I-metric"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: conference, person, researcher, task, country, programming language, field, university, product, organization, metric, algorithm, location and O.\nSentence: Decision tree learning , neural networks , or a naive Bayes classifier could be used in combination with measures of model quality such as balanced accuracy","prompt_labels":"Decision(B-algorithm) tree(I-algorithm) learning(I-algorithm) ,(O) neural(B-algorithm) networks(I-algorithm) ,(O) or(O) a(O) naive(B-algorithm) Bayes(I-algorithm) classifier(I-algorithm) could(O) be(O) used(O) in(O) combination(O) with(O) measures(O) of(O) model(O) quality(O) such(O) as(O) balanced(B-metric) accuracy(I-metric)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["field","university","researcher","algorithm","conference","country","organization","person","metric","product","programming language","location","task"],"instance":{"id":"179","words":["He","is","a","past","President","(","1979",")","and","an","inaugural","Fellow","(","2011",")","of","the","ACL",",","a","co-recipient","of","the","1992","Association","for","Computing","Machinery","Software","Systems","Award","for","his","contribution","to","the","Interlisp","programming","system",",","and","a","Fellow","of","the","Association","for","Computing","Machinery","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-conference","O","O","O","O","O","B-conference","I-conference","I-conference","I-conference","I-conference","O","O","O","O","O","O","O","O","B-product","I-product","I-product","O","O","O","O","O","O","B-conference","I-conference","I-conference","I-conference","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: field, university, researcher, algorithm, conference, country, organization, person, metric, product, programming language, location, task and O.\nSentence: He is a past President ( 1979 ) and an inaugural Fellow ( 2011 ) of the ACL , a co-recipient of the 1992 Association for Computing Machinery Software Systems Award for his contribution to the Interlisp programming system , and a Fellow of the Association for Computing Machinery .","prompt_labels":"He(O) is(O) a(O) past(O) President(O) ((O) 1979(O) )(O) and(O) an(O) inaugural(O) Fellow(O) ((O) 2011(O) )(O) of(O) the(O) ACL(B-conference) ,(O) a(O) co-recipient(O) of(O) the(O) 1992(B-conference) Association(I-conference) for(I-conference) Computing(I-conference) Machinery(I-conference) Software(O) Systems(O) Award(O) for(O) his(O) contribution(O) to(O) the(O) Interlisp(B-product) programming(I-product) system(I-product) ,(O) and(O) a(O) Fellow(O) of(O) the(O) Association(B-conference) for(I-conference) Computing(I-conference) Machinery(I-conference) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["metric","algorithm","task","country","product","person","conference","programming language","university","organization","researcher","location","field"],"instance":{"id":"180","words":["Along","with","Geoffrey","Hinton","and","Yann","LeCun",",","Bengio","is","considered","by","Cade","Metz","as","one","of","the","three","people","most","responsible","for","the","advancement","of","deep","learning","during","the","1990s","and","2000s","."],"labels":["O","O","B-researcher","I-researcher","O","B-researcher","I-researcher","O","B-researcher","O","O","O","B-researcher","I-researcher","O","O","O","O","O","O","O","O","O","O","O","O","B-field","I-field","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: metric, algorithm, task, country, product, person, conference, programming language, university, organization, researcher, location, field and O.\nSentence: Along with Geoffrey Hinton and Yann LeCun , Bengio is considered by Cade Metz as one of the three people most responsible for the advancement of deep learning during the 1990s and 2000s .","prompt_labels":"Along(O) with(O) Geoffrey(B-researcher) Hinton(I-researcher) and(O) Yann(B-researcher) LeCun(I-researcher) ,(O) Bengio(B-researcher) is(O) considered(O) by(O) Cade(B-researcher) Metz(I-researcher) as(O) one(O) of(O) the(O) three(O) people(O) most(O) responsible(O) for(O) the(O) advancement(O) of(O) deep(B-field) learning(I-field) during(O) the(O) 1990s(O) and(O) 2000s(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["product","researcher","task","conference","algorithm","university","programming language","person","country","metric","organization","location","field"],"instance":{"id":"181","words":["In","information","theory","and","computer","science",",","a","code","is","usually","considered","as","an","algorithm","that","uniquely","represents","symbols","from","some","source","alphabet",",","by","encoded","strings",",","which","may","be","in","some","other","target","alphabet","."],"labels":["O","B-field","I-field","O","B-field","I-field","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: product, researcher, task, conference, algorithm, university, programming language, person, country, metric, organization, location, field and O.\nSentence: In information theory and computer science , a code is usually considered as an algorithm that uniquely represents symbols from some source alphabet , by encoded strings , which may be in some other target alphabet .","prompt_labels":"In(O) information(B-field) theory(I-field) and(O) computer(B-field) science(I-field) ,(O) a(O) code(O) is(O) usually(O) considered(O) as(O) an(O) algorithm(O) that(O) uniquely(O) represents(O) symbols(O) from(O) some(O) source(O) alphabet(O) ,(O) by(O) encoded(O) strings(O) ,(O) which(O) may(O) be(O) in(O) some(O) other(O) target(O) alphabet(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["researcher","field","person","product","country","metric","location","task","organization","algorithm","university","conference","programming language"],"instance":{"id":"182","words":["A","fairly","simple","non-linear","function",",","the","sigmoid","function","such","as","the","logistic","function","also","has","an","easily","calculated","derivative",",","which","can","be","important","when","calculating","the","weight","updates","in","the","network","."],"labels":["O","O","O","O","O","O","O","B-algorithm","I-algorithm","O","O","O","B-algorithm","I-algorithm","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: researcher, field, person, product, country, metric, location, task, organization, algorithm, university, conference, programming language and O.\nSentence: A fairly simple non-linear function , the sigmoid function such as the logistic function also has an easily calculated derivative , which can be important when calculating the weight updates in the network .","prompt_labels":"A(O) fairly(O) simple(O) non-linear(O) function(O) ,(O) the(O) sigmoid(B-algorithm) function(I-algorithm) such(O) as(O) the(O) logistic(B-algorithm) function(I-algorithm) also(O) has(O) an(O) easily(O) calculated(O) derivative(O) ,(O) which(O) can(O) be(O) important(O) when(O) calculating(O) the(O) weight(O) updates(O) in(O) the(O) network(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["field","product","conference","university","task","country","metric","researcher","programming language","person","organization","location","algorithm"],"instance":{"id":"183","words":["apek","was","born","in","Hronov",",","Bohemia","(","Austria-Hungary",",","later","Czechoslovakia",",","now","the","Czech","Republic",")","in","1887","."],"labels":["B-person","O","O","O","B-location","O","B-location","O","B-country","O","O","B-country","O","O","O","B-country","I-country","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: field, product, conference, university, task, country, metric, researcher, programming language, person, organization, location, algorithm and O.\nSentence: apek was born in Hronov , Bohemia ( Austria-Hungary , later Czechoslovakia , now the Czech Republic ) in 1887 .","prompt_labels":"apek(B-person) was(O) born(O) in(O) Hronov(B-location) ,(O) Bohemia(B-location) ((O) Austria-Hungary(B-country) ,(O) later(O) Czechoslovakia(B-country) ,(O) now(O) the(O) Czech(B-country) Republic(I-country) )(O) in(O) 1887(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["conference","person","organization","country","metric","task","product","researcher","algorithm","location","field","programming language","university"],"instance":{"id":"184","words":["Some","specialized","software","can","narrate","RSS","."],"labels":["O","O","O","O","O","B-product","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: conference, person, organization, country, metric, task, product, researcher, algorithm, location, field, programming language, university and O.\nSentence: Some specialized software can narrate RSS .","prompt_labels":"Some(O) specialized(O) software(O) can(O) narrate(O) RSS(B-product) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["researcher","location","programming language","task","field","country","person","algorithm","metric","organization","product","conference","university"],"instance":{"id":"185","words":["Aspects","of","ontology","editors","include",":","visual","navigation","possibilities","within","the","knowledge","model",",","inference","engine","s","and","extraction",";","support","for","modules",";","the","import","and","export","of","foreign","knowledge","representation","languages","for","ontology","matching",";","and","the","support","of","meta-ontologies","such","as","OWL-S",",","Dublin","Core",",","etc","."],"labels":["O","O","O","O","O","O","B-task","I-task","O","O","O","B-task","I-task","O","B-task","I-task","O","O","B-task","O","B-task","I-task","I-task","O","O","O","O","O","O","O","B-task","I-task","O","O","B-task","I-task","O","O","O","O","O","B-task","O","O","B-product","O","B-product","I-product","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: researcher, location, programming language, task, field, country, person, algorithm, metric, organization, product, conference, university and O.\nSentence: Aspects of ontology editors include : visual navigation possibilities within the knowledge model , inference engine s and extraction ; support for modules ; the import and export of foreign knowledge representation languages for ontology matching ; and the support of meta-ontologies such as OWL-S , Dublin Core , etc .","prompt_labels":"Aspects(O) of(O) ontology(O) editors(O) include(O) :(O) visual(B-task) navigation(I-task) possibilities(O) within(O) the(O) knowledge(B-task) model(I-task) ,(O) inference(B-task) engine(I-task) s(O) and(O) extraction(B-task) ;(O) support(B-task) for(I-task) modules(I-task) ;(O) the(O) import(O) and(O) export(O) of(O) foreign(O) knowledge(B-task) representation(I-task) languages(O) for(O) ontology(B-task) matching(I-task) ;(O) and(O) the(O) support(O) of(O) meta-ontologies(B-task) such(O) as(O) OWL-S(B-product) ,(O) Dublin(B-product) Core(I-product) ,(O) etc(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["metric","conference","organization","product","person","algorithm","location","field","task","programming language","country","researcher","university"],"instance":{"id":"186","words":["The","FBI","has","also","instituted","its","Next","Generation","Identification","program","to","include","face","recognition",",","as","well","as","more","traditional","biometrics","like","fingerprints","and","iris","scans",",","which","can","pull","from","both","criminal","and","civil","databases","."],"labels":["O","B-organization","O","O","O","O","O","O","O","O","O","O","B-task","I-task","O","O","O","O","O","O","B-field","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: metric, conference, organization, product, person, algorithm, location, field, task, programming language, country, researcher, university and O.\nSentence: The FBI has also instituted its Next Generation Identification program to include face recognition , as well as more traditional biometrics like fingerprints and iris scans , which can pull from both criminal and civil databases .","prompt_labels":"The(O) FBI(B-organization) has(O) also(O) instituted(O) its(O) Next(O) Generation(O) Identification(O) program(O) to(O) include(O) face(B-task) recognition(I-task) ,(O) as(O) well(O) as(O) more(O) traditional(O) biometrics(B-field) like(O) fingerprints(O) and(O) iris(O) scans(O) ,(O) which(O) can(O) pull(O) from(O) both(O) criminal(O) and(O) civil(O) databases(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["organization","algorithm","country","metric","researcher","task","location","person","university","field","conference","programming language","product"],"instance":{"id":"187","words":["For","the","2016","season",",","Samantha","Ponder","was","added","as","host",",","replacing","Molly","McGrath","."],"labels":["O","O","O","O","O","B-person","I-person","O","O","O","O","O","O","B-person","I-person","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, algorithm, country, metric, researcher, task, location, person, university, field, conference, programming language, product and O.\nSentence: For the 2016 season , Samantha Ponder was added as host , replacing Molly McGrath .","prompt_labels":"For(O) the(O) 2016(O) season(O) ,(O) Samantha(B-person) Ponder(I-person) was(O) added(O) as(O) host(O) ,(O) replacing(O) Molly(B-person) McGrath(I-person) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["organization","task","field","researcher","conference","metric","product","country","location","university","programming language","algorithm","person"],"instance":{"id":"188","words":["It","is","an","adversarial","search","algorithm","used","commonly","for","machine","playing","of","two-player","games","(","Tic-tac-toe",",","Chess",",","Go",",","etc","."],"labels":["O","O","O","B-algorithm","I-algorithm","I-algorithm","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, task, field, researcher, conference, metric, product, country, location, university, programming language, algorithm, person and O.\nSentence: It is an adversarial search algorithm used commonly for machine playing of two-player games ( Tic-tac-toe , Chess , Go , etc .","prompt_labels":"It(O) is(O) an(O) adversarial(B-algorithm) search(I-algorithm) algorithm(I-algorithm) used(O) commonly(O) for(O) machine(O) playing(O) of(O) two-player(O) games(O) ((O) Tic-tac-toe(O) ,(O) Chess(O) ,(O) Go(O) ,(O) etc(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["organization","conference","task","metric","country","location","person","field","university","programming language","researcher","algorithm","product"],"instance":{"id":"189","words":["It","involves","the","fields","of","computer","vision","or","machine","vision",",","and","medical","imaging",",","and","makes","heavy","use","of","pattern","recognition",",","digital","geometry",",","and","signal","processing","."],"labels":["O","O","O","O","O","B-field","I-field","O","B-field","I-field","O","O","B-field","I-field","O","O","O","O","O","O","B-field","I-field","O","B-field","I-field","O","O","B-field","I-field","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, conference, task, metric, country, location, person, field, university, programming language, researcher, algorithm, product and O.\nSentence: It involves the fields of computer vision or machine vision , and medical imaging , and makes heavy use of pattern recognition , digital geometry , and signal processing .","prompt_labels":"It(O) involves(O) the(O) fields(O) of(O) computer(B-field) vision(I-field) or(O) machine(B-field) vision(I-field) ,(O) and(O) medical(B-field) imaging(I-field) ,(O) and(O) makes(O) heavy(O) use(O) of(O) pattern(B-field) recognition(I-field) ,(O) digital(B-field) geometry(I-field) ,(O) and(O) signal(B-field) processing(I-field) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["algorithm","person","location","organization","programming language","country","university","product","conference","field","metric","researcher","task"],"instance":{"id":"190","words":["In","facial","recognition","system",",","for","instance",",","a","picture","of","a","person","'s","face","would","be","the","input",",","and","the","output","label","would","be","that","person","'s","name","."],"labels":["O","B-product","I-product","I-product","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: algorithm, person, location, organization, programming language, country, university, product, conference, field, metric, researcher, task and O.\nSentence: In facial recognition system , for instance , a picture of a person 's face would be the input , and the output label would be that person 's name .","prompt_labels":"In(O) facial(B-product) recognition(I-product) system(I-product) ,(O) for(O) instance(O) ,(O) a(O) picture(O) of(O) a(O) person(O) 's(O) face(O) would(O) be(O) the(O) input(O) ,(O) and(O) the(O) output(O) label(O) would(O) be(O) that(O) person(O) 's(O) name(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["researcher","algorithm","country","person","programming language","organization","task","conference","field","metric","product","university","location"],"instance":{"id":"191","words":["Apple","Inc","introduced","Face","ID","on","the","flagship","iPhone","X","as","a","biometric","authentication","successor","to","the","Touch","ID",",","a","fingerprint","based","system","."],"labels":["B-organization","I-organization","O","B-product","I-product","O","O","O","B-product","I-product","O","O","O","O","O","O","O","B-product","I-product","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: researcher, algorithm, country, person, programming language, organization, task, conference, field, metric, product, university, location and O.\nSentence: Apple Inc introduced Face ID on the flagship iPhone X as a biometric authentication successor to the Touch ID , a fingerprint based system .","prompt_labels":"Apple(B-organization) Inc(I-organization) introduced(O) Face(B-product) ID(I-product) on(O) the(O) flagship(O) iPhone(B-product) X(I-product) as(O) a(O) biometric(O) authentication(O) successor(O) to(O) the(O) Touch(B-product) ID(I-product) ,(O) a(O) fingerprint(O) based(O) system(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["programming language","metric","location","university","conference","product","researcher","task","organization","algorithm","person","country","field"],"instance":{"id":"192","words":["Or","combine","the","F-measure","with","the","R-square","evaluated","for","the","raw","model","output","and","the","target",";","or","the","cost","\/","gain","matrix","with","the","correlation","coefficient",",","and","so","on","."],"labels":["O","O","O","B-metric","O","O","B-metric","O","O","O","O","O","O","O","O","O","O","O","O","B-metric","I-metric","I-metric","I-metric","O","O","B-metric","I-metric","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: programming language, metric, location, university, conference, product, researcher, task, organization, algorithm, person, country, field and O.\nSentence: Or combine the F-measure with the R-square evaluated for the raw model output and the target ; or the cost \/ gain matrix with the correlation coefficient , and so on .","prompt_labels":"Or(O) combine(O) the(O) F-measure(B-metric) with(O) the(O) R-square(B-metric) evaluated(O) for(O) the(O) raw(O) model(O) output(O) and(O) the(O) target(O) ;(O) or(O) the(O) cost(B-metric) \/(I-metric) gain(I-metric) matrix(I-metric) with(O) the(O) correlation(B-metric) coefficient(I-metric) ,(O) and(O) so(O) on(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["person","metric","conference","algorithm","university","country","organization","programming language","task","location","researcher","field","product"],"instance":{"id":"193","words":["The","Spanish","edition","of","Campus","Party","has","been","held","at","the","Colegio","Miguel","Hernndez",",","Ceulaj",",","and","the","Municipal","Sport","Arena","of","Benalmdena","in","Mlaga",",","Spain",";","and","at","both","the","Valencia","County","Fair","and","the","City","of","Arts","and","Sciences","in","Valencia","over","the","past","15","years","."],"labels":["O","B-conference","I-conference","I-conference","I-conference","I-conference","O","O","O","O","O","B-location","I-location","I-location","O","B-location","O","O","O","B-location","I-location","I-location","I-location","I-location","O","B-location","O","B-country","O","O","O","O","O","B-location","I-location","I-location","O","O","B-location","I-location","I-location","I-location","I-location","O","B-location","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, metric, conference, algorithm, university, country, organization, programming language, task, location, researcher, field, product and O.\nSentence: The Spanish edition of Campus Party has been held at the Colegio Miguel Hernndez , Ceulaj , and the Municipal Sport Arena of Benalmdena in Mlaga , Spain ; and at both the Valencia County Fair and the City of Arts and Sciences in Valencia over the past 15 years .","prompt_labels":"The(O) Spanish(B-conference) edition(I-conference) of(I-conference) Campus(I-conference) Party(I-conference) has(O) been(O) held(O) at(O) the(O) Colegio(B-location) Miguel(I-location) Hernndez(I-location) ,(O) Ceulaj(B-location) ,(O) and(O) the(O) Municipal(B-location) Sport(I-location) Arena(I-location) of(I-location) Benalmdena(I-location) in(O) Mlaga(B-location) ,(O) Spain(B-country) ;(O) and(O) at(O) both(O) the(O) Valencia(B-location) County(I-location) Fair(I-location) and(O) the(O) City(B-location) of(I-location) Arts(I-location) and(I-location) Sciences(I-location) in(O) Valencia(B-location) over(O) the(O) past(O) 15(O) years(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["researcher","programming language","product","algorithm","field","metric","country","person","task","conference","university","location","organization"],"instance":{"id":"194","words":["gnuplot","can","be","used","from","various","programming","languages","to","graph","data",",","including","Perl","(","via","PDL","and","CPAN","packages",")",",","Python","(","via",")","."],"labels":["B-product","O","O","O","O","O","O","O","O","O","O","O","O","B-programming language","O","O","B-product","O","B-product","O","O","O","B-programming language","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: researcher, programming language, product, algorithm, field, metric, country, person, task, conference, university, location, organization and O.\nSentence: gnuplot can be used from various programming languages to graph data , including Perl ( via PDL and CPAN packages ) , Python ( via ) .","prompt_labels":"gnuplot(B-product) can(O) be(O) used(O) from(O) various(O) programming(O) languages(O) to(O) graph(O) data(O) ,(O) including(O) Perl(B-programming language) ((O) via(O) PDL(B-product) and(O) CPAN(B-product) packages(O) )(O) ,(O) Python(B-programming language) ((O) via(O) )(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["algorithm","field","conference","organization","programming language","researcher","person","location","country","university","task","product","metric"],"instance":{"id":"195","words":["The","field","of","spoken","dialog","systems","is","quite","large","and","includes","research","(","featured","at","scientific","conferences","such","as","SIGdial","and","Interspeech",")","and","a","large","industrial","sector","(","with","its","own","meetings","such","as","SpeechTek","and","AVIOS",")","."],"labels":["O","O","O","B-product","I-product","I-product","O","O","O","O","O","O","O","O","O","O","O","O","O","B-conference","O","B-conference","O","O","O","O","O","O","O","O","O","O","O","O","O","B-conference","O","B-conference","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: algorithm, field, conference, organization, programming language, researcher, person, location, country, university, task, product, metric and O.\nSentence: The field of spoken dialog systems is quite large and includes research ( featured at scientific conferences such as SIGdial and Interspeech ) and a large industrial sector ( with its own meetings such as SpeechTek and AVIOS ) .","prompt_labels":"The(O) field(O) of(O) spoken(B-product) dialog(I-product) systems(I-product) is(O) quite(O) large(O) and(O) includes(O) research(O) ((O) featured(O) at(O) scientific(O) conferences(O) such(O) as(O) SIGdial(B-conference) and(O) Interspeech(B-conference) )(O) and(O) a(O) large(O) industrial(O) sector(O) ((O) with(O) its(O) own(O) meetings(O) such(O) as(O) SpeechTek(B-conference) and(O) AVIOS(B-conference) )(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["university","field","organization","person","conference","algorithm","country","researcher","programming language","task","product","location","metric"],"instance":{"id":"196","words":["Challenges","in","natural","language","processing","frequently","involve","speech","recognition",",","natural","language","understanding",",","and","natural","language","generation","."],"labels":["O","O","B-field","I-field","I-field","O","O","B-task","I-task","O","B-task","I-task","I-task","O","O","B-task","I-task","I-task","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: university, field, organization, person, conference, algorithm, country, researcher, programming language, task, product, location, metric and O.\nSentence: Challenges in natural language processing frequently involve speech recognition , natural language understanding , and natural language generation .","prompt_labels":"Challenges(O) in(O) natural(B-field) language(I-field) processing(I-field) frequently(O) involve(O) speech(B-task) recognition(I-task) ,(O) natural(B-task) language(I-task) understanding(I-task) ,(O) and(O) natural(B-task) language(I-task) generation(I-task) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["metric","programming language","location","task","researcher","person","organization","university","product","country","conference","algorithm","field"],"instance":{"id":"197","words":["These","systems",",","such","as","Siri","of","the","iOS","operating","system",",","operate","on","a","similar","pattern-recognizing","technique","as","that","of","text-based","systems",",","but","with","the","former",",","the","user","input","is","conducted","through","speech","recognition","."],"labels":["O","O","O","O","O","B-product","O","O","B-product","I-product","I-product","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-task","I-task","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: metric, programming language, location, task, researcher, person, organization, university, product, country, conference, algorithm, field and O.\nSentence: These systems , such as Siri of the iOS operating system , operate on a similar pattern-recognizing technique as that of text-based systems , but with the former , the user input is conducted through speech recognition .","prompt_labels":"These(O) systems(O) ,(O) such(O) as(O) Siri(B-product) of(O) the(O) iOS(B-product) operating(I-product) system(I-product) ,(O) operate(O) on(O) a(O) similar(O) pattern-recognizing(O) technique(O) as(O) that(O) of(O) text-based(O) systems(O) ,(O) but(O) with(O) the(O) former(O) ,(O) the(O) user(O) input(O) is(O) conducted(O) through(O) speech(B-task) recognition(I-task) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["task","product","algorithm","conference","programming language","country","metric","organization","location","university","field","person","researcher"],"instance":{"id":"198","words":["More","exotic","fitness","functions","that","explore","model","granularity","include","the","area","under","the","ROC","curve","and","rank","measure","."],"labels":["O","B-algorithm","I-algorithm","I-algorithm","O","O","O","O","O","O","O","O","O","B-metric","I-metric","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: task, product, algorithm, conference, programming language, country, metric, organization, location, university, field, person, researcher and O.\nSentence: More exotic fitness functions that explore model granularity include the area under the ROC curve and rank measure .","prompt_labels":"More(O) exotic(B-algorithm) fitness(I-algorithm) functions(I-algorithm) that(O) explore(O) model(O) granularity(O) include(O) the(O) area(O) under(O) the(O) ROC(B-metric) curve(I-metric) and(O) rank(O) measure(O) .(O)"}}
{"dataset":"crossner_ai","split":"dev","label_list":["university","person","organization","product","country","location","researcher","metric","task","field","conference","programming language","algorithm"],"instance":{"id":"199","words":["The","term","Semantic","Web","was","coined","by","Tim","Berners-Lee",",","the","inventor","of","the","World","Wide","Web","and","director","of","the","World","Wide","Web","Consortium","(","W3C",")",",","which","oversees","the","development","of","proposed","Semantic","Web","standards","."],"labels":["O","O","B-product","I-product","O","O","O","B-researcher","I-researcher","O","O","O","O","O","B-product","I-product","I-product","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O","B-organization","O","O","O","O","O","O","O","O","B-product","I-product","I-product","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: university, person, organization, product, country, location, researcher, metric, task, field, conference, programming language, algorithm and O.\nSentence: The term Semantic Web was coined by Tim Berners-Lee , the inventor of the World Wide Web and director of the World Wide Web Consortium ( W3C ) , which oversees the development of proposed Semantic Web standards .","prompt_labels":"The(O) term(O) Semantic(B-product) Web(I-product) was(O) coined(O) by(O) Tim(B-researcher) Berners-Lee(I-researcher) ,(O) the(O) inventor(O) of(O) the(O) World(B-product) Wide(I-product) Web(I-product) and(O) director(O) of(O) the(O) World(B-organization) Wide(I-organization) Web(I-organization) Consortium(I-organization) ((O) W3C(B-organization) )(O) ,(O) which(O) oversees(O) the(O) development(O) of(O) proposed(O) Semantic(B-product) Web(I-product) standards(I-product) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["book","location","writer","organization","country","person","literary genre","poem","event","magazine","award"],"instance":{"id":"0","words":["In","1982",",","she","wrote","the","novel","The","Color","Purple",",","for","which","she","won","the","National","Book","Award","for","hardcover","fiction",",","and","the","Pulitzer","Prize","for","Fiction","."],"labels":["O","O","O","O","O","O","B-literary genre","B-book","I-book","I-book","O","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","I-award","O","O","O","B-award","I-award","I-award","I-award","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: book, location, writer, organization, country, person, literary genre, poem, event, magazine, award and O.\nSentence: In 1982 , she wrote the novel The Color Purple , for which she won the National Book Award for hardcover fiction , and the Pulitzer Prize for Fiction .","prompt_labels":"In(O) 1982(O) ,(O) she(O) wrote(O) the(O) novel(B-literary genre) The(B-book) Color(I-book) Purple(I-book) ,(O) for(O) which(O) she(O) won(O) the(O) National(B-award) Book(I-award) Award(I-award) for(I-award) hardcover(I-award) fiction(I-award) ,(O) and(O) the(O) Pulitzer(B-award) Prize(I-award) for(I-award) Fiction(I-award) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["event","award","organization","person","location","literary genre","poem","book","country","writer","magazine"],"instance":{"id":"1","words":["His","most","famous","work","is","the","versified","topographical","description","of","northern","Norway",",","Nordlands","Trompet","(","The","Trumpet","of","Nordland",")",",","and","some","psalms","still","in","use",",","most","prominently","Herre","Gud",",","ditt","dyre","navn","og","re","(","Good","Lord",",","thy","precious","name","and","glory",")","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-location","I-location","O","B-poem","I-poem","O","B-poem","I-poem","I-poem","I-poem","O","O","O","O","O","O","O","O","O","O","O","B-poem","I-poem","I-poem","I-poem","I-poem","I-poem","I-poem","I-poem","O","B-poem","I-poem","I-poem","I-poem","I-poem","I-poem","I-poem","I-poem","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, award, organization, person, location, literary genre, poem, book, country, writer, magazine and O.\nSentence: His most famous work is the versified topographical description of northern Norway , Nordlands Trompet ( The Trumpet of Nordland ) , and some psalms still in use , most prominently Herre Gud , ditt dyre navn og re ( Good Lord , thy precious name and glory ) .","prompt_labels":"His(O) most(O) famous(O) work(O) is(O) the(O) versified(O) topographical(O) description(O) of(O) northern(B-location) Norway(I-location) ,(O) Nordlands(B-poem) Trompet(I-poem) ((O) The(B-poem) Trumpet(I-poem) of(I-poem) Nordland(I-poem) )(O) ,(O) and(O) some(O) psalms(O) still(O) in(O) use(O) ,(O) most(O) prominently(O) Herre(B-poem) Gud(I-poem) ,(I-poem) ditt(I-poem) dyre(I-poem) navn(I-poem) og(I-poem) re(I-poem) ((O) Good(B-poem) Lord(I-poem) ,(I-poem) thy(I-poem) precious(I-poem) name(I-poem) and(I-poem) glory(I-poem) )(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["magazine","person","writer","location","poem","event","country","book","award","organization","literary genre"],"instance":{"id":"2","words":["The","fantasy","critic","L.","Sprague","de","Camp","said","of","him","that","nobody","since","Edgar","Allan","Poe","has","so","loved","a","well-rotted","corpse","."],"labels":["O","O","O","B-writer","I-writer","I-writer","I-writer","O","O","O","O","O","O","B-writer","I-writer","I-writer","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: magazine, person, writer, location, poem, event, country, book, award, organization, literary genre and O.\nSentence: The fantasy critic L. Sprague de Camp said of him that nobody since Edgar Allan Poe has so loved a well-rotted corpse .","prompt_labels":"The(O) fantasy(O) critic(O) L.(B-writer) Sprague(I-writer) de(I-writer) Camp(I-writer) said(O) of(O) him(O) that(O) nobody(O) since(O) Edgar(B-writer) Allan(I-writer) Poe(I-writer) has(O) so(O) loved(O) a(O) well-rotted(O) corpse(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["magazine","poem","book","award","writer","organization","country","person","event","location","literary genre"],"instance":{"id":"3","words":["Atwood","has","strong","views","on","environmental","issues",",","and","she","and","Graeme","Gibson","were","the","joint","honorary","presidents","of","the","Rare","Bird","Club","within","BirdLife","International","."],"labels":["B-writer","O","O","O","O","O","O","O","O","O","O","B-writer","I-writer","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","O","B-organization","I-organization","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: magazine, poem, book, award, writer, organization, country, person, event, location, literary genre and O.\nSentence: Atwood has strong views on environmental issues , and she and Graeme Gibson were the joint honorary presidents of the Rare Bird Club within BirdLife International .","prompt_labels":"Atwood(B-writer) has(O) strong(O) views(O) on(O) environmental(O) issues(O) ,(O) and(O) she(O) and(O) Graeme(B-writer) Gibson(I-writer) were(O) the(O) joint(O) honorary(O) presidents(O) of(O) the(O) Rare(B-organization) Bird(I-organization) Club(I-organization) within(O) BirdLife(B-organization) International(I-organization) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["location","book","event","writer","poem","country","organization","magazine","literary genre","award","person"],"instance":{"id":"4","words":["In","1998",",","Oldman","was","honored","at","the","Camerimage","Film","Festival",",","where","he","was","awarded","the","Krzysztof","Kielowski","Award","for","Acting",",","the","first","recipient","of","the","award","."],"labels":["O","O","O","B-person","O","O","O","O","B-event","I-event","I-event","O","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, book, event, writer, poem, country, organization, magazine, literary genre, award, person and O.\nSentence: In 1998 , Oldman was honored at the Camerimage Film Festival , where he was awarded the Krzysztof Kielowski Award for Acting , the first recipient of the award .","prompt_labels":"In(O) 1998(O) ,(O) Oldman(B-person) was(O) honored(O) at(O) the(O) Camerimage(B-event) Film(I-event) Festival(I-event) ,(O) where(O) he(O) was(O) awarded(O) the(O) Krzysztof(B-award) Kielowski(I-award) Award(I-award) for(I-award) Acting(I-award) ,(O) the(O) first(O) recipient(O) of(O) the(O) award(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["person","event","book","literary genre","poem","writer","organization","award","magazine","location","country"],"instance":{"id":"5","words":["The","poor","conditions","of","the","hospital","in","Lambarn","were","also","famously","criticized","by","Nigerian","professor","and","novelist","Chinua","Achebe","in","his","essay","on","Joseph","Conrad","'","s","novel","Heart","of","Darkness",":","In","a","comment","which","has","often","been","quoted","Schweitzer","says",":","'","The","African","is","indeed","my","brother","but","my","junior","brother","."],"labels":["O","O","O","O","O","O","O","B-location","O","O","O","O","O","O","O","O","O","B-writer","I-writer","O","O","O","O","B-person","I-person","O","O","B-literary genre","B-book","I-book","I-book","O","O","O","O","O","O","O","O","O","B-writer","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, event, book, literary genre, poem, writer, organization, award, magazine, location, country and O.\nSentence: The poor conditions of the hospital in Lambarn were also famously criticized by Nigerian professor and novelist Chinua Achebe in his essay on Joseph Conrad ' s novel Heart of Darkness : In a comment which has often been quoted Schweitzer says : ' The African is indeed my brother but my junior brother .","prompt_labels":"The(O) poor(O) conditions(O) of(O) the(O) hospital(O) in(O) Lambarn(B-location) were(O) also(O) famously(O) criticized(O) by(O) Nigerian(O) professor(O) and(O) novelist(O) Chinua(B-writer) Achebe(I-writer) in(O) his(O) essay(O) on(O) Joseph(B-person) Conrad(I-person) '(O) s(O) novel(B-literary genre) Heart(B-book) of(I-book) Darkness(I-book) :(O) In(O) a(O) comment(O) which(O) has(O) often(O) been(O) quoted(O) Schweitzer(B-writer) says(O) :(O) '(O) The(O) African(O) is(O) indeed(O) my(O) brother(O) but(O) my(O) junior(O) brother(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["book","award","literary genre","magazine","country","event","poem","organization","writer","location","person"],"instance":{"id":"6","words":["His","main","work","was","the","libretto","for","The","Veiled","Prophet",",","a","Romantic","Opera","in","3","acts","composed","by","Charles","Villiers","Stanford",",","adapted","from","the","homonymous","ballad","in","Thomas","Moore","oriental","romance","Lalla-Rookh",",","published","1890","."],"labels":["O","O","O","O","O","B-literary genre","O","O","O","O","O","O","B-literary genre","I-literary genre","O","O","O","O","O","B-person","I-person","I-person","O","O","O","O","O","O","O","B-writer","I-writer","O","O","B-poem","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: book, award, literary genre, magazine, country, event, poem, organization, writer, location, person and O.\nSentence: His main work was the libretto for The Veiled Prophet , a Romantic Opera in 3 acts composed by Charles Villiers Stanford , adapted from the homonymous ballad in Thomas Moore oriental romance Lalla-Rookh , published 1890 .","prompt_labels":"His(O) main(O) work(O) was(O) the(O) libretto(B-literary genre) for(O) The(O) Veiled(O) Prophet(O) ,(O) a(O) Romantic(B-literary genre) Opera(I-literary genre) in(O) 3(O) acts(O) composed(O) by(O) Charles(B-person) Villiers(I-person) Stanford(I-person) ,(O) adapted(O) from(O) the(O) homonymous(O) ballad(O) in(O) Thomas(B-writer) Moore(I-writer) oriental(O) romance(O) Lalla-Rookh(B-poem) ,(O) published(O) 1890(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["organization","country","event","award","magazine","location","person","writer","book","literary genre","poem"],"instance":{"id":"7","words":["It","won","the","Critics","Award","at","the","Deauville","American","Film","Festival","and","shared","the","Sundance","Film","Festival","'","s","Grand","Jury","Prize","."],"labels":["O","O","O","B-award","I-award","O","O","B-event","I-event","I-event","I-event","O","O","O","B-event","I-event","I-event","O","O","B-award","I-award","I-award","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, country, event, award, magazine, location, person, writer, book, literary genre, poem and O.\nSentence: It won the Critics Award at the Deauville American Film Festival and shared the Sundance Film Festival ' s Grand Jury Prize .","prompt_labels":"It(O) won(O) the(O) Critics(B-award) Award(I-award) at(O) the(O) Deauville(B-event) American(I-event) Film(I-event) Festival(I-event) and(O) shared(O) the(O) Sundance(B-event) Film(I-event) Festival(I-event) '(O) s(O) Grand(B-award) Jury(I-award) Prize(I-award) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["award","organization","book","event","country","literary genre","magazine","writer","location","person","poem"],"instance":{"id":"8","words":["In","1829","he","was","publicly","crowned","with","laurel","as","the","king","of","Nordic","countries","poetry","and","the","Scandinavian","King","of","Song","(","by","Bishop","Esaias","Tegnr",",","who","would","be","his","Swedish","parallel",")","in","the","cathedral","of","Lund",",","Sweden",",","based","on","a","vast","production","of","poetry",",","theatre","plays","and","prose",",","inspired","by","Johann","Wolfgang","von","Goethe",",","Gottlieb","Fichte",",","and","Friedrich","von","Schelling","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","B-literary genre","I-literary genre","I-literary genre","O","O","O","O","O","O","O","O","O","B-writer","I-writer","O","O","O","O","O","O","O","O","O","O","B-location","I-location","I-location","O","B-country","O","O","O","O","O","O","O","B-literary genre","O","B-literary genre","I-literary genre","O","B-literary genre","O","O","O","B-writer","I-writer","I-writer","I-writer","O","B-writer","I-writer","O","O","B-writer","I-writer","I-writer","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, organization, book, event, country, literary genre, magazine, writer, location, person, poem and O.\nSentence: In 1829 he was publicly crowned with laurel as the king of Nordic countries poetry and the Scandinavian King of Song ( by Bishop Esaias Tegnr , who would be his Swedish parallel ) in the cathedral of Lund , Sweden , based on a vast production of poetry , theatre plays and prose , inspired by Johann Wolfgang von Goethe , Gottlieb Fichte , and Friedrich von Schelling .","prompt_labels":"In(O) 1829(O) he(O) was(O) publicly(O) crowned(O) with(O) laurel(O) as(O) the(O) king(O) of(O) Nordic(B-literary genre) countries(I-literary genre) poetry(I-literary genre) and(O) the(O) Scandinavian(O) King(O) of(O) Song(O) ((O) by(O) Bishop(O) Esaias(B-writer) Tegnr(I-writer) ,(O) who(O) would(O) be(O) his(O) Swedish(O) parallel(O) )(O) in(O) the(O) cathedral(B-location) of(I-location) Lund(I-location) ,(O) Sweden(B-country) ,(O) based(O) on(O) a(O) vast(O) production(O) of(O) poetry(B-literary genre) ,(O) theatre(B-literary genre) plays(I-literary genre) and(O) prose(B-literary genre) ,(O) inspired(O) by(O) Johann(B-writer) Wolfgang(I-writer) von(I-writer) Goethe(I-writer) ,(O) Gottlieb(B-writer) Fichte(I-writer) ,(O) and(O) Friedrich(B-writer) von(I-writer) Schelling(I-writer) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["location","organization","person","magazine","poem","writer","book","literary genre","award","event","country"],"instance":{"id":"9","words":["In","2012",",","the","Nobel","Records","were","opened","after","50","years","and","it","was","revealed","that","Anouilh","was","among","a","shortlist","of","authors","considered","for","the","1962","Nobel","Prize","in","Literature",",","along","with","John","Steinbeck","(","winner",")",",","Robert","Graves",",","Lawrence","Durrell","and","Karen","Blixen","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-writer","O","O","O","O","O","O","O","O","O","O","B-award","I-award","I-award","I-award","O","O","O","B-writer","I-writer","O","O","O","O","B-writer","I-writer","O","B-writer","I-writer","O","B-writer","I-writer","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, organization, person, magazine, poem, writer, book, literary genre, award, event, country and O.\nSentence: In 2012 , the Nobel Records were opened after 50 years and it was revealed that Anouilh was among a shortlist of authors considered for the 1962 Nobel Prize in Literature , along with John Steinbeck ( winner ) , Robert Graves , Lawrence Durrell and Karen Blixen .","prompt_labels":"In(O) 2012(O) ,(O) the(O) Nobel(O) Records(O) were(O) opened(O) after(O) 50(O) years(O) and(O) it(O) was(O) revealed(O) that(O) Anouilh(B-writer) was(O) among(O) a(O) shortlist(O) of(O) authors(O) considered(O) for(O) the(O) 1962(O) Nobel(B-award) Prize(I-award) in(I-award) Literature(I-award) ,(O) along(O) with(O) John(B-writer) Steinbeck(I-writer) ((O) winner(O) )(O) ,(O) Robert(B-writer) Graves(I-writer) ,(O) Lawrence(B-writer) Durrell(I-writer) and(O) Karen(B-writer) Blixen(I-writer) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["book","organization","poem","writer","magazine","location","country","literary genre","award","event","person"],"instance":{"id":"10","words":["Some","critics",",","among","them","William","Veeder",",","suggest","that","Carmilla",",","notably","in","its","outlandish","use","of","narrative","frames",",","was","an","important","influence","on","Henry","James","'","The","Turn","of","the","Screw","(","1898",")","."],"labels":["O","O","O","O","O","B-writer","I-writer","O","O","O","B-book","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-writer","I-writer","O","B-book","I-book","I-book","I-book","I-book","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: book, organization, poem, writer, magazine, location, country, literary genre, award, event, person and O.\nSentence: Some critics , among them William Veeder , suggest that Carmilla , notably in its outlandish use of narrative frames , was an important influence on Henry James ' The Turn of the Screw ( 1898 ) .","prompt_labels":"Some(O) critics(O) ,(O) among(O) them(O) William(B-writer) Veeder(I-writer) ,(O) suggest(O) that(O) Carmilla(B-book) ,(O) notably(O) in(O) its(O) outlandish(O) use(O) of(O) narrative(O) frames(O) ,(O) was(O) an(O) important(O) influence(O) on(O) Henry(B-writer) James(I-writer) '(O) The(B-book) Turn(I-book) of(I-book) the(I-book) Screw(I-book) ((O) 1898(O) )(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["person","poem","location","book","writer","award","literary genre","magazine","country","event","organization"],"instance":{"id":"11","words":["The","Lancer","\/","Ace","editions","(","1966-1977",")",",","under","the","direction","of","L.","Sprague","de","Camp","and","Lin","Carter",",","were","the","first","comprehensive","paperbacks",",","compiling","the","material","from","the","Gnome","Press","series","together","in","chronological","order","with","all","the","remaining","original","Howard","material",",","including","that","left","unpublished","in","his","lifetime","and","fragments","and","outlines","."],"labels":["B-book","I-book","I-book","I-book","I-book","O","O","O","O","O","O","O","O","B-writer","I-writer","I-writer","I-writer","O","B-writer","I-writer","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-writer","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, poem, location, book, writer, award, literary genre, magazine, country, event, organization and O.\nSentence: The Lancer \/ Ace editions ( 1966-1977 ) , under the direction of L. Sprague de Camp and Lin Carter , were the first comprehensive paperbacks , compiling the material from the Gnome Press series together in chronological order with all the remaining original Howard material , including that left unpublished in his lifetime and fragments and outlines .","prompt_labels":"The(B-book) Lancer(I-book) \/(I-book) Ace(I-book) editions(I-book) ((O) 1966-1977(O) )(O) ,(O) under(O) the(O) direction(O) of(O) L.(B-writer) Sprague(I-writer) de(I-writer) Camp(I-writer) and(O) Lin(B-writer) Carter(I-writer) ,(O) were(O) the(O) first(O) comprehensive(O) paperbacks(O) ,(O) compiling(O) the(O) material(O) from(O) the(O) Gnome(O) Press(O) series(O) together(O) in(O) chronological(O) order(O) with(O) all(O) the(O) remaining(O) original(O) Howard(B-writer) material(O) ,(O) including(O) that(O) left(O) unpublished(O) in(O) his(O) lifetime(O) and(O) fragments(O) and(O) outlines(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["event","magazine","person","location","award","book","country","organization","writer","literary genre","poem"],"instance":{"id":"12","words":["Later","in","his","life",",","Ginsberg","formed","a","bridge","between","the","beat","movement","of","the","1950s","and","the","hippie","s","of","the","1960s",",","befriending",",","among","others",",","Timothy","Leary",",","Ken","Kesey",",","Hunter","S.","Thompson",",","and","Bob","Dylan","."],"labels":["O","O","O","O","O","B-writer","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-writer","I-writer","O","B-writer","I-writer","O","B-writer","I-writer","I-writer","O","O","B-writer","I-writer","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, magazine, person, location, award, book, country, organization, writer, literary genre, poem and O.\nSentence: Later in his life , Ginsberg formed a bridge between the beat movement of the 1950s and the hippie s of the 1960s , befriending , among others , Timothy Leary , Ken Kesey , Hunter S. Thompson , and Bob Dylan .","prompt_labels":"Later(O) in(O) his(O) life(O) ,(O) Ginsberg(B-writer) formed(O) a(O) bridge(O) between(O) the(O) beat(O) movement(O) of(O) the(O) 1950s(O) and(O) the(O) hippie(O) s(O) of(O) the(O) 1960s(O) ,(O) befriending(O) ,(O) among(O) others(O) ,(O) Timothy(B-writer) Leary(I-writer) ,(O) Ken(B-writer) Kesey(I-writer) ,(O) Hunter(B-writer) S.(I-writer) Thompson(I-writer) ,(O) and(O) Bob(B-writer) Dylan(I-writer) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["award","country","organization","writer","person","literary genre","location","event","magazine","book","poem"],"instance":{"id":"13","words":["During","this","period",",","he","covered","Timothy","Leary","and","Richard","Alpert","'","s","Millbrook",",","New","York","-based","Castalia","Foundation","at","the","instigation","of","Alan","Watts","in","The","Realist",",","cultivated","important","friendships","with","William","S.","Burroughs","and","Allen","Ginsberg",",","and","lectured","at","the","Free","University","of","New","York","on","'","Anarchist","and","Synergetic","Politics","'","in","1965","."],"labels":["O","O","O","O","O","O","B-person","I-person","O","B-person","I-person","O","O","B-location","O","B-location","I-location","O","B-organization","I-organization","O","O","O","O","B-writer","I-writer","O","B-magazine","I-magazine","O","O","O","O","O","B-writer","I-writer","I-writer","O","B-writer","I-writer","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, country, organization, writer, person, literary genre, location, event, magazine, book, poem and O.\nSentence: During this period , he covered Timothy Leary and Richard Alpert ' s Millbrook , New York -based Castalia Foundation at the instigation of Alan Watts in The Realist , cultivated important friendships with William S. Burroughs and Allen Ginsberg , and lectured at the Free University of New York on ' Anarchist and Synergetic Politics ' in 1965 .","prompt_labels":"During(O) this(O) period(O) ,(O) he(O) covered(O) Timothy(B-person) Leary(I-person) and(O) Richard(B-person) Alpert(I-person) '(O) s(O) Millbrook(B-location) ,(O) New(B-location) York(I-location) -based(O) Castalia(B-organization) Foundation(I-organization) at(O) the(O) instigation(O) of(O) Alan(B-writer) Watts(I-writer) in(O) The(B-magazine) Realist(I-magazine) ,(O) cultivated(O) important(O) friendships(O) with(O) William(B-writer) S.(I-writer) Burroughs(I-writer) and(O) Allen(B-writer) Ginsberg(I-writer) ,(O) and(O) lectured(O) at(O) the(O) Free(B-organization) University(I-organization) of(I-organization) New(I-organization) York(I-organization) on(O) '(O) Anarchist(O) and(O) Synergetic(O) Politics(O) '(O) in(O) 1965(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["award","country","book","magazine","organization","poem","event","location","writer","literary genre","person"],"instance":{"id":"14","words":["He","is","the","protagonist","of","Robert","Coover","'","s","short","story","Charlie","in","the","House","of","Rue","(","1980",";","reprinted","in","Coover","'s","1987","collection","A","Night","at","the","Movies",")",",","and","of","Glen","David","Gold","'","s","Sunnyside","(","2009",")",",","a","historical","novel","set","in","the","First","World","War","period","."],"labels":["O","O","O","O","O","B-book","I-book","O","O","B-literary genre","I-literary genre","B-book","I-book","I-book","I-book","I-book","I-book","O","O","O","O","O","B-writer","O","O","O","B-book","I-book","I-book","I-book","I-book","O","O","O","O","B-writer","I-writer","I-writer","O","O","B-book","O","O","O","O","O","B-literary genre","I-literary genre","O","O","O","B-event","I-event","I-event","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, country, book, magazine, organization, poem, event, location, writer, literary genre, person and O.\nSentence: He is the protagonist of Robert Coover ' s short story Charlie in the House of Rue ( 1980 ; reprinted in Coover 's 1987 collection A Night at the Movies ) , and of Glen David Gold ' s Sunnyside ( 2009 ) , a historical novel set in the First World War period .","prompt_labels":"He(O) is(O) the(O) protagonist(O) of(O) Robert(B-book) Coover(I-book) '(O) s(O) short(B-literary genre) story(I-literary genre) Charlie(B-book) in(I-book) the(I-book) House(I-book) of(I-book) Rue(I-book) ((O) 1980(O) ;(O) reprinted(O) in(O) Coover(B-writer) 's(O) 1987(O) collection(O) A(B-book) Night(I-book) at(I-book) the(I-book) Movies(I-book) )(O) ,(O) and(O) of(O) Glen(B-writer) David(I-writer) Gold(I-writer) '(O) s(O) Sunnyside(B-book) ((O) 2009(O) )(O) ,(O) a(O) historical(B-literary genre) novel(I-literary genre) set(O) in(O) the(O) First(B-event) World(I-event) War(I-event) period(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["person","magazine","organization","literary genre","book","writer","poem","award","country","location","event"],"instance":{"id":"15","words":["The","story","has","appeared","with","other","works","by","Tolkien","in","omnibus","editions",",","including","The","Tolkien","Reader","and","Tales","from","the","Perilous","Realm","."],"labels":["O","O","O","O","O","O","O","O","B-writer","O","O","O","O","O","B-book","I-book","I-book","O","B-book","I-book","I-book","I-book","I-book","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, magazine, organization, literary genre, book, writer, poem, award, country, location, event and O.\nSentence: The story has appeared with other works by Tolkien in omnibus editions , including The Tolkien Reader and Tales from the Perilous Realm .","prompt_labels":"The(O) story(O) has(O) appeared(O) with(O) other(O) works(O) by(O) Tolkien(B-writer) in(O) omnibus(O) editions(O) ,(O) including(O) The(B-book) Tolkien(I-book) Reader(I-book) and(O) Tales(B-book) from(I-book) the(I-book) Perilous(I-book) Realm(I-book) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["organization","event","magazine","country","person","award","location","book","literary genre","poem","writer"],"instance":{"id":"16","words":["His","works","include","not","only","science","fiction",",","but","also","articles","for","Playboy","and","Family","Circle","magazines","and","nonfiction","books","."],"labels":["O","O","O","O","O","B-literary genre","I-literary genre","O","O","O","O","O","B-magazine","O","B-magazine","I-magazine","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, event, magazine, country, person, award, location, book, literary genre, poem, writer and O.\nSentence: His works include not only science fiction , but also articles for Playboy and Family Circle magazines and nonfiction books .","prompt_labels":"His(O) works(O) include(O) not(O) only(O) science(B-literary genre) fiction(I-literary genre) ,(O) but(O) also(O) articles(O) for(O) Playboy(B-magazine) and(O) Family(B-magazine) Circle(I-magazine) magazines(O) and(O) nonfiction(O) books(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["award","poem","magazine","literary genre","location","person","book","country","organization","writer","event"],"instance":{"id":"17","words":["Silas","Marner","(","1861",")","and","Romola","(","1863",")","soon","followed",",","and","later","Felix","Holt",",","the","Radical","(","1866",")","and","her","most","acclaimed","novel",",","Middlemarch","(","1871-1872",")","."],"labels":["B-book","I-book","O","O","O","O","B-book","O","O","O","O","O","O","O","O","B-book","I-book","I-book","I-book","I-book","O","O","O","O","O","O","O","B-literary genre","O","B-book","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, poem, magazine, literary genre, location, person, book, country, organization, writer, event and O.\nSentence: Silas Marner ( 1861 ) and Romola ( 1863 ) soon followed , and later Felix Holt , the Radical ( 1866 ) and her most acclaimed novel , Middlemarch ( 1871-1872 ) .","prompt_labels":"Silas(B-book) Marner(I-book) ((O) 1861(O) )(O) and(O) Romola(B-book) ((O) 1863(O) )(O) soon(O) followed(O) ,(O) and(O) later(O) Felix(B-book) Holt(I-book) ,(I-book) the(I-book) Radical(I-book) ((O) 1866(O) )(O) and(O) her(O) most(O) acclaimed(O) novel(B-literary genre) ,(O) Middlemarch(B-book) ((O) 1871-1872(O) )(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["literary genre","book","location","country","poem","award","event","organization","magazine","writer","person"],"instance":{"id":"18","words":["His","most","famous","work","is","The","Chronicles","of","Prydain",",","a","series","of","five","high","fantasy","novels","whose","conclusion",",","The","High","King",",","was","awarded","the","1969","Newbery","Medal","for","excellence","in","American","children","'s","literature","."],"labels":["O","O","O","O","O","B-book","I-book","I-book","I-book","O","O","O","O","O","B-literary genre","I-literary genre","I-literary genre","O","O","O","B-book","I-book","I-book","O","O","O","O","O","B-award","I-award","O","O","O","B-literary genre","I-literary genre","I-literary genre","I-literary genre","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: literary genre, book, location, country, poem, award, event, organization, magazine, writer, person and O.\nSentence: His most famous work is The Chronicles of Prydain , a series of five high fantasy novels whose conclusion , The High King , was awarded the 1969 Newbery Medal for excellence in American children 's literature .","prompt_labels":"His(O) most(O) famous(O) work(O) is(O) The(B-book) Chronicles(I-book) of(I-book) Prydain(I-book) ,(O) a(O) series(O) of(O) five(O) high(B-literary genre) fantasy(I-literary genre) novels(I-literary genre) whose(O) conclusion(O) ,(O) The(B-book) High(I-book) King(I-book) ,(O) was(O) awarded(O) the(O) 1969(O) Newbery(B-award) Medal(I-award) for(O) excellence(O) in(O) American(B-literary genre) children(I-literary genre) 's(I-literary genre) literature(I-literary genre) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["award","magazine","poem","book","literary genre","event","person","writer","organization","country","location"],"instance":{"id":"19","words":["When","Davies","retired","from","his","position","at","the","university",",","his","seventh","novel",",","a","satire","of","academic","life",",","The","Rebel","Angels","(","1981",")",",","was","published",",","followed","by","What","'s","Bred","in","the","Bone","(","1985",")","which","was","short-listed","for","the","Booker","Prize","for","fiction","in","1986","."],"labels":["O","B-writer","O","O","O","O","O","O","O","O","O","O","B-literary genre","O","O","B-literary genre","O","O","O","O","B-book","I-book","I-book","O","O","O","O","O","O","O","O","O","B-book","I-book","I-book","I-book","I-book","I-book","O","O","O","O","O","O","O","O","B-award","I-award","I-award","I-award","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, magazine, poem, book, literary genre, event, person, writer, organization, country, location and O.\nSentence: When Davies retired from his position at the university , his seventh novel , a satire of academic life , The Rebel Angels ( 1981 ) , was published , followed by What 's Bred in the Bone ( 1985 ) which was short-listed for the Booker Prize for fiction in 1986 .","prompt_labels":"When(O) Davies(B-writer) retired(O) from(O) his(O) position(O) at(O) the(O) university(O) ,(O) his(O) seventh(O) novel(B-literary genre) ,(O) a(O) satire(B-literary genre) of(O) academic(O) life(O) ,(O) The(B-book) Rebel(I-book) Angels(I-book) ((O) 1981(O) )(O) ,(O) was(O) published(O) ,(O) followed(O) by(O) What(B-book) 's(I-book) Bred(I-book) in(I-book) the(I-book) Bone(I-book) ((O) 1985(O) )(O) which(O) was(O) short-listed(O) for(O) the(O) Booker(B-award) Prize(I-award) for(I-award) fiction(I-award) in(O) 1986(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["poem","event","country","literary genre","book","award","location","writer","organization","person","magazine"],"instance":{"id":"20","words":["The","film","is","based","on","The","Caine","Mutiny",",","the","1951","Pulitzer","Prize","-winning","novel","written","by","Herman","Wouk","."],"labels":["O","O","O","O","O","B-book","I-book","I-book","O","O","O","B-award","I-award","O","B-literary genre","O","O","B-writer","I-writer","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: poem, event, country, literary genre, book, award, location, writer, organization, person, magazine and O.\nSentence: The film is based on The Caine Mutiny , the 1951 Pulitzer Prize -winning novel written by Herman Wouk .","prompt_labels":"The(O) film(O) is(O) based(O) on(O) The(B-book) Caine(I-book) Mutiny(I-book) ,(O) the(O) 1951(O) Pulitzer(B-award) Prize(I-award) -winning(O) novel(B-literary genre) written(O) by(O) Herman(B-writer) Wouk(I-writer) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["award","person","poem","country","event","book","magazine","organization","writer","literary genre","location"],"instance":{"id":"21","words":["W.","H.","Auden","(","1907-1973",")","wrote","a","number","of","poems",",","including","The","Age","of","Anxiety",",","in","a","type","of","alliterative","verse","modified","for","modern","English","."],"labels":["B-writer","I-writer","I-writer","O","O","O","O","O","O","O","O","O","O","B-poem","I-poem","I-poem","I-poem","O","O","O","O","O","O","B-literary genre","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, person, poem, country, event, book, magazine, organization, writer, literary genre, location and O.\nSentence: W. H. Auden ( 1907-1973 ) wrote a number of poems , including The Age of Anxiety , in a type of alliterative verse modified for modern English .","prompt_labels":"W.(B-writer) H.(I-writer) Auden(I-writer) ((O) 1907-1973(O) )(O) wrote(O) a(O) number(O) of(O) poems(O) ,(O) including(O) The(B-poem) Age(I-poem) of(I-poem) Anxiety(I-poem) ,(O) in(O) a(O) type(O) of(O) alliterative(O) verse(B-literary genre) modified(O) for(O) modern(O) English(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["award","organization","location","event","literary genre","country","person","poem","magazine","book","writer"],"instance":{"id":"22","words":["In","October","1946",",","the","twice","married","Pasternak","met","Olga","Ivinskaya",",","a","34","year","old","single","mother","employed","by","Novy","Mir","."],"labels":["O","O","O","O","O","O","O","B-writer","O","B-writer","I-writer","O","O","O","O","O","O","O","O","O","B-magazine","I-magazine","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, organization, location, event, literary genre, country, person, poem, magazine, book, writer and O.\nSentence: In October 1946 , the twice married Pasternak met Olga Ivinskaya , a 34 year old single mother employed by Novy Mir .","prompt_labels":"In(O) October(O) 1946(O) ,(O) the(O) twice(O) married(O) Pasternak(B-writer) met(O) Olga(B-writer) Ivinskaya(I-writer) ,(O) a(O) 34(O) year(O) old(O) single(O) mother(O) employed(O) by(O) Novy(B-magazine) Mir(I-magazine) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["event","literary genre","person","book","award","location","writer","country","poem","magazine","organization"],"instance":{"id":"23","words":["The","remainder","were","distributed","off","a","ferry","near","Hong","Kong",",","the","ferry","between","Hainan","Island","and","the","Chinese","mainland",",","a","ferry","in","Vietnam",",","White","'s","Ferry","on","the","Potomac","River","in","Virginia","on","Father","'s","Day","2007",",","and","on","author","H.","P.","Lovecraft","'","s","grave","in","Providence",",","Rhode","Island","on","December","17",",","2005","."],"labels":["O","O","O","O","O","O","O","O","B-location","I-location","O","O","O","O","B-location","I-location","O","O","B-location","I-location","O","O","O","O","B-country","O","O","O","O","O","O","B-location","I-location","O","B-location","O","B-event","I-event","I-event","O","O","O","O","O","B-writer","I-writer","I-writer","O","O","O","O","B-location","O","B-location","I-location","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, literary genre, person, book, award, location, writer, country, poem, magazine, organization and O.\nSentence: The remainder were distributed off a ferry near Hong Kong , the ferry between Hainan Island and the Chinese mainland , a ferry in Vietnam , White 's Ferry on the Potomac River in Virginia on Father 's Day 2007 , and on author H. P. Lovecraft ' s grave in Providence , Rhode Island on December 17 , 2005 .","prompt_labels":"The(O) remainder(O) were(O) distributed(O) off(O) a(O) ferry(O) near(O) Hong(B-location) Kong(I-location) ,(O) the(O) ferry(O) between(O) Hainan(B-location) Island(I-location) and(O) the(O) Chinese(B-location) mainland(I-location) ,(O) a(O) ferry(O) in(O) Vietnam(B-country) ,(O) White(O) 's(O) Ferry(O) on(O) the(O) Potomac(B-location) River(I-location) in(O) Virginia(B-location) on(O) Father(B-event) 's(I-event) Day(I-event) 2007(O) ,(O) and(O) on(O) author(O) H.(B-writer) P.(I-writer) Lovecraft(I-writer) '(O) s(O) grave(O) in(O) Providence(B-location) ,(O) Rhode(B-location) Island(I-location) on(O) December(O) 17(O) ,(O) 2005(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["organization","event","writer","literary genre","magazine","poem","book","location","award","country","person"],"instance":{"id":"24","words":["He","reprised","the","role","in","Evil","Under","the","Sun","(","1982",")","and","Appointment","with","Death","(","1988",")","."],"labels":["O","O","O","O","O","B-book","I-book","I-book","I-book","O","O","O","O","B-book","I-book","I-book","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, event, writer, literary genre, magazine, poem, book, location, award, country, person and O.\nSentence: He reprised the role in Evil Under the Sun ( 1982 ) and Appointment with Death ( 1988 ) .","prompt_labels":"He(O) reprised(O) the(O) role(O) in(O) Evil(B-book) Under(I-book) the(I-book) Sun(I-book) ((O) 1982(O) )(O) and(O) Appointment(B-book) with(I-book) Death(I-book) ((O) 1988(O) )(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["person","organization","award","magazine","book","country","writer","event","location","literary genre","poem"],"instance":{"id":"25","words":["Russell","was","asked","by","The","New","Republic",",","a","liberal","American","magazine",",","to","elaborate","his","views","on","world","peace","."],"labels":["B-writer","O","O","O","B-magazine","I-magazine","I-magazine","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, organization, award, magazine, book, country, writer, event, location, literary genre, poem and O.\nSentence: Russell was asked by The New Republic , a liberal American magazine , to elaborate his views on world peace .","prompt_labels":"Russell(B-writer) was(O) asked(O) by(O) The(B-magazine) New(I-magazine) Republic(I-magazine) ,(O) a(O) liberal(O) American(O) magazine(O) ,(O) to(O) elaborate(O) his(O) views(O) on(O) world(O) peace(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["poem","person","event","writer","literary genre","organization","book","magazine","country","award","location"],"instance":{"id":"26","words":["His","father","Noah","Webster","Sr.","(","1722-1813",")","was","a","descendant","of","Connecticut","Governor","John","Webster",";","his","mother","Mercy","(","Steele",")","Webster","(","1727-1794",")","was","a","descendant","of","Governor","William","Bradford","of","Plymouth","Colony",".","Noah","had","two","brothers",",","Abraham","(","1751-1831",")","and","Charles","(","b","."],"labels":["O","O","B-person","I-person","I-person","O","O","O","O","O","O","O","B-location","O","B-writer","I-writer","O","O","O","B-person","I-person","I-person","I-person","I-person","O","O","O","O","O","O","O","O","B-person","I-person","O","B-country","I-country","O","B-person","O","O","O","O","B-person","O","O","O","O","B-person","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: poem, person, event, writer, literary genre, organization, book, magazine, country, award, location and O.\nSentence: His father Noah Webster Sr. ( 1722-1813 ) was a descendant of Connecticut Governor John Webster ; his mother Mercy ( Steele ) Webster ( 1727-1794 ) was a descendant of Governor William Bradford of Plymouth Colony . Noah had two brothers , Abraham ( 1751-1831 ) and Charles ( b .","prompt_labels":"His(O) father(O) Noah(B-person) Webster(I-person) Sr.(I-person) ((O) 1722-1813(O) )(O) was(O) a(O) descendant(O) of(O) Connecticut(B-location) Governor(O) John(B-writer) Webster(I-writer) ;(O) his(O) mother(O) Mercy(B-person) ((I-person) Steele(I-person) )(I-person) Webster(I-person) ((O) 1727-1794(O) )(O) was(O) a(O) descendant(O) of(O) Governor(O) William(B-person) Bradford(I-person) of(O) Plymouth(B-country) Colony(I-country) .(O) Noah(B-person) had(O) two(O) brothers(O) ,(O) Abraham(B-person) ((O) 1751-1831(O) )(O) and(O) Charles(B-person) ((O) b(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["writer","organization","event","country","magazine","literary genre","location","poem","book","person","award"],"instance":{"id":"27","words":["It","was","a","finalist","for","the","National","Book","Award","for","Fiction","!","--","National","Book","Awards","were","called","American","for","several","years","from","1980",",","but","must","not","be","confused","with","American","Book","Awards","--","in","1979","(","which","ultimately","went","to","Tim","O","'Brien","for","Going","After","Cacciato",")","in","the","film","as","an","official","in","one","of","Garp","'s","high","school","wrestling","matches","."],"labels":["O","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","O","O","B-award","I-award","I-award","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-award","I-award","I-award","O","O","O","O","O","O","O","O","B-writer","I-writer","I-writer","O","B-book","I-book","I-book","O","O","O","O","O","O","O","O","O","O","B-person","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: writer, organization, event, country, magazine, literary genre, location, poem, book, person, award and O.\nSentence: It was a finalist for the National Book Award for Fiction ! -- National Book Awards were called American for several years from 1980 , but must not be confused with American Book Awards -- in 1979 ( which ultimately went to Tim O 'Brien for Going After Cacciato ) in the film as an official in one of Garp 's high school wrestling matches .","prompt_labels":"It(O) was(O) a(O) finalist(O) for(O) the(O) National(B-award) Book(I-award) Award(I-award) for(I-award) Fiction(I-award) !(O) --(O) National(B-award) Book(I-award) Awards(I-award) were(O) called(O) American(O) for(O) several(O) years(O) from(O) 1980(O) ,(O) but(O) must(O) not(O) be(O) confused(O) with(O) American(B-award) Book(I-award) Awards(I-award) --(O) in(O) 1979(O) ((O) which(O) ultimately(O) went(O) to(O) Tim(B-writer) O(I-writer) 'Brien(I-writer) for(O) Going(B-book) After(I-book) Cacciato(I-book) )(O) in(O) the(O) film(O) as(O) an(O) official(O) in(O) one(O) of(O) Garp(B-person) 's(O) high(O) school(O) wrestling(O) matches(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["event","award","location","writer","book","literary genre","poem","person","magazine","organization","country"],"instance":{"id":"28","words":["Skarma",",","Bjarkarmur",",","and","Lokrur","are","other","examples","of","early","rmur","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, award, location, writer, book, literary genre, poem, person, magazine, organization, country and O.\nSentence: Skarma , Bjarkarmur , and Lokrur are other examples of early rmur .","prompt_labels":"Skarma(O) ,(O) Bjarkarmur(O) ,(O) and(O) Lokrur(O) are(O) other(O) examples(O) of(O) early(O) rmur(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["location","country","organization","writer","event","person","magazine","literary genre","book","award","poem"],"instance":{"id":"29","words":["Other","figures","in","literature","who","were","strongly","influenced","by","Schopenhauer","were","Thomas","Mann",",","Afanasy","Fet",",","Joris-Karl","Huysmans","and","George","Santayana","."],"labels":["O","O","O","O","O","O","O","O","O","B-writer","O","B-writer","I-writer","O","B-writer","I-writer","O","B-writer","I-writer","O","B-writer","I-writer","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, country, organization, writer, event, person, magazine, literary genre, book, award, poem and O.\nSentence: Other figures in literature who were strongly influenced by Schopenhauer were Thomas Mann , Afanasy Fet , Joris-Karl Huysmans and George Santayana .","prompt_labels":"Other(O) figures(O) in(O) literature(O) who(O) were(O) strongly(O) influenced(O) by(O) Schopenhauer(B-writer) were(O) Thomas(B-writer) Mann(I-writer) ,(O) Afanasy(B-writer) Fet(I-writer) ,(O) Joris-Karl(B-writer) Huysmans(I-writer) and(O) George(B-writer) Santayana(I-writer) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["literary genre","book","event","person","poem","country","magazine","organization","writer","award","location"],"instance":{"id":"30","words":["In","addition",",","Dogpatch","characters","were","used","in","national","campaigns","for","the","U.S.","Treasury",",","the","Cancer","Foundation",",","the","March","of","Dimes",",","the","National","Heart","Fund",",","the","Sister","Kenny","Foundation",",","the","Boy","Scouts","of","America",",","Community","Chest",",","the","National","Reading","Council",",","Minnesota","Tuberculosis","and","Health","Association",",","Christmas","Seals",",","the","National","Amputation","Foundation",",","and","Disabled","American","Veterans",",","among","others","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","B-organization","I-organization","O","O","B-organization","I-organization","O","O","B-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","O","B-organization","I-organization","O","O","B-organization","I-organization","I-organization","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","B-organization","I-organization","O","O","B-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: literary genre, book, event, person, poem, country, magazine, organization, writer, award, location and O.\nSentence: In addition , Dogpatch characters were used in national campaigns for the U.S. Treasury , the Cancer Foundation , the March of Dimes , the National Heart Fund , the Sister Kenny Foundation , the Boy Scouts of America , Community Chest , the National Reading Council , Minnesota Tuberculosis and Health Association , Christmas Seals , the National Amputation Foundation , and Disabled American Veterans , among others .","prompt_labels":"In(O) addition(O) ,(O) Dogpatch(O) characters(O) were(O) used(O) in(O) national(O) campaigns(O) for(O) the(O) U.S.(B-organization) Treasury(I-organization) ,(O) the(O) Cancer(B-organization) Foundation(I-organization) ,(O) the(O) March(B-organization) of(I-organization) Dimes(I-organization) ,(O) the(O) National(B-organization) Heart(I-organization) Fund(I-organization) ,(O) the(O) Sister(B-organization) Kenny(I-organization) Foundation(I-organization) ,(O) the(O) Boy(B-organization) Scouts(I-organization) of(I-organization) America(I-organization) ,(O) Community(B-organization) Chest(I-organization) ,(O) the(O) National(B-organization) Reading(I-organization) Council(I-organization) ,(O) Minnesota(B-organization) Tuberculosis(I-organization) and(I-organization) Health(I-organization) Association(I-organization) ,(O) Christmas(B-organization) Seals(I-organization) ,(O) the(O) National(B-organization) Amputation(I-organization) Foundation(I-organization) ,(O) and(O) Disabled(B-organization) American(I-organization) Veterans(I-organization) ,(O) among(O) others(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["organization","book","event","poem","literary genre","location","person","magazine","country","writer","award"],"instance":{"id":"31","words":["According","to","Entertainment","Weekly",",","Raimi","had","expressed","an","interest","in","directing","a","film","version","of","The","Hobbit",",","the","prequel","to","the","Lord","of","the","Rings","trilogy","."],"labels":["O","O","B-magazine","I-magazine","O","B-person","O","O","O","O","O","O","O","O","O","O","B-book","I-book","O","O","O","O","O","B-book","I-book","I-book","I-book","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, book, event, poem, literary genre, location, person, magazine, country, writer, award and O.\nSentence: According to Entertainment Weekly , Raimi had expressed an interest in directing a film version of The Hobbit , the prequel to the Lord of the Rings trilogy .","prompt_labels":"According(O) to(O) Entertainment(B-magazine) Weekly(I-magazine) ,(O) Raimi(B-person) had(O) expressed(O) an(O) interest(O) in(O) directing(O) a(O) film(O) version(O) of(O) The(B-book) Hobbit(I-book) ,(O) the(O) prequel(O) to(O) the(O) Lord(B-book) of(I-book) the(I-book) Rings(I-book) trilogy(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["location","award","person","writer","organization","magazine","poem","event","country","literary genre","book"],"instance":{"id":"32","words":["Ansgar","received","the","mission","of","evangelizing","pagan","Denmark",",","Norway","and","Sweden","."],"labels":["B-writer","O","O","O","O","O","O","B-country","O","B-country","O","B-country","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, award, person, writer, organization, magazine, poem, event, country, literary genre, book and O.\nSentence: Ansgar received the mission of evangelizing pagan Denmark , Norway and Sweden .","prompt_labels":"Ansgar(B-writer) received(O) the(O) mission(O) of(O) evangelizing(O) pagan(O) Denmark(B-country) ,(O) Norway(B-country) and(O) Sweden(B-country) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["location","organization","writer","award","book","magazine","event","person","poem","country","literary genre"],"instance":{"id":"33","words":["The","poem","is","quoted","by","Sue","Bridehead","in","Thomas","Hardy","'","s","1895","novel",",","Jude","the","Obscure","and","also","by","Edward","Ashburnham","in","Ford","Madox",".","Ford","'","s","The","Good","Soldier","."],"labels":["O","B-literary genre","O","O","O","B-writer","I-writer","O","B-writer","I-writer","O","O","O","B-literary genre","O","B-book","I-book","I-book","O","O","O","B-writer","I-writer","O","B-writer","I-writer","O","B-writer","O","O","B-book","I-book","I-book","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, organization, writer, award, book, magazine, event, person, poem, country, literary genre and O.\nSentence: The poem is quoted by Sue Bridehead in Thomas Hardy ' s 1895 novel , Jude the Obscure and also by Edward Ashburnham in Ford Madox . Ford ' s The Good Soldier .","prompt_labels":"The(O) poem(B-literary genre) is(O) quoted(O) by(O) Sue(B-writer) Bridehead(I-writer) in(O) Thomas(B-writer) Hardy(I-writer) '(O) s(O) 1895(O) novel(B-literary genre) ,(O) Jude(B-book) the(I-book) Obscure(I-book) and(O) also(O) by(O) Edward(B-writer) Ashburnham(I-writer) in(O) Ford(B-writer) Madox(I-writer) .(O) Ford(B-writer) '(O) s(O) The(B-book) Good(I-book) Soldier(I-book) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["literary genre","award","person","location","magazine","event","organization","country","writer","poem","book"],"instance":{"id":"34","words":["In","a","1971","interview","with","The","London","Magazine",",","Hughes","cited","his","main","influences","as","including","William","Blake",",","John","Donne",",","Hopkins","and","T.","S.","Eliot","."],"labels":["O","O","O","O","O","B-magazine","I-magazine","I-magazine","O","B-writer","O","O","O","O","O","O","B-writer","I-writer","O","B-writer","I-writer","O","B-writer","O","B-writer","I-writer","I-writer","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: literary genre, award, person, location, magazine, event, organization, country, writer, poem, book and O.\nSentence: In a 1971 interview with The London Magazine , Hughes cited his main influences as including William Blake , John Donne , Hopkins and T. S. Eliot .","prompt_labels":"In(O) a(O) 1971(O) interview(O) with(O) The(B-magazine) London(I-magazine) Magazine(I-magazine) ,(O) Hughes(B-writer) cited(O) his(O) main(O) influences(O) as(O) including(O) William(B-writer) Blake(I-writer) ,(O) John(B-writer) Donne(I-writer) ,(O) Hopkins(B-writer) and(O) T.(B-writer) S.(I-writer) Eliot(I-writer) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["country","literary genre","book","organization","event","location","poem","award","writer","magazine","person"],"instance":{"id":"35","words":["Dune","tied","with","Roger","Zelazny","'","s","This","Immortal","for","the","Hugo","Award","in","1966",","],"labels":["B-book","O","O","B-writer","I-writer","O","O","B-book","I-book","O","O","B-award","I-award","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, literary genre, book, organization, event, location, poem, award, writer, magazine, person and O.\nSentence: Dune tied with Roger Zelazny ' s This Immortal for the Hugo Award in 1966 ,","prompt_labels":"Dune(B-book) tied(O) with(O) Roger(B-writer) Zelazny(I-writer) '(O) s(O) This(B-book) Immortal(I-book) for(O) the(O) Hugo(B-award) Award(I-award) in(O) 1966(O) ,(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["event","magazine","location","award","writer","person","literary genre","book","poem","organization","country"],"instance":{"id":"36","words":["In","1973",",","Sakharov","was","nominated","for","the","Nobel","Peace","Prize","and","in","1974","was","awarded","the","Prix","mondial","Cino","Del","Duca","."],"labels":["O","O","O","B-person","O","O","O","O","B-award","I-award","I-award","O","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, magazine, location, award, writer, person, literary genre, book, poem, organization, country and O.\nSentence: In 1973 , Sakharov was nominated for the Nobel Peace Prize and in 1974 was awarded the Prix mondial Cino Del Duca .","prompt_labels":"In(O) 1973(O) ,(O) Sakharov(B-person) was(O) nominated(O) for(O) the(O) Nobel(B-award) Peace(I-award) Prize(I-award) and(O) in(O) 1974(O) was(O) awarded(O) the(O) Prix(B-award) mondial(I-award) Cino(I-award) Del(I-award) Duca(I-award) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["person","writer","country","magazine","event","award","location","poem","literary genre","organization","book"],"instance":{"id":"37","words":["James","herself","used","phrases","from","the","Book","of","Common","Prayer","and","made","them","into","bestselling","titles","-","Devices","and","Desires","and","The","Children","of","Men","-","while","Alfonso","Cuarn","'","s","2006","film","Children","of","Men","placed","the","phrase","onto","cinema","marquees","worldwide","."],"labels":["B-writer","O","O","O","O","O","B-book","I-book","I-book","I-book","O","O","O","O","O","O","O","B-book","I-book","I-book","O","B-book","I-book","I-book","I-book","O","O","B-person","I-person","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, writer, country, magazine, event, award, location, poem, literary genre, organization, book and O.\nSentence: James herself used phrases from the Book of Common Prayer and made them into bestselling titles - Devices and Desires and The Children of Men - while Alfonso Cuarn ' s 2006 film Children of Men placed the phrase onto cinema marquees worldwide .","prompt_labels":"James(B-writer) herself(O) used(O) phrases(O) from(O) the(O) Book(B-book) of(I-book) Common(I-book) Prayer(I-book) and(O) made(O) them(O) into(O) bestselling(O) titles(O) -(O) Devices(B-book) and(I-book) Desires(I-book) and(O) The(B-book) Children(I-book) of(I-book) Men(I-book) -(O) while(O) Alfonso(B-person) Cuarn(I-person) '(O) s(O) 2006(O) film(O) Children(O) of(O) Men(O) placed(O) the(O) phrase(O) onto(O) cinema(O) marquees(O) worldwide(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["country","organization","location","book","award","writer","event","person","magazine","literary genre","poem"],"instance":{"id":"38","words":["Marsters","moved","to","Chicago",",","where","his","first","professional","acting","role","was","Ferdinand","in","The","Tempest","at","the","Goodman","Theatre","in","1987","."],"labels":["B-person","O","O","B-location","O","O","O","O","O","O","O","O","O","O","B-book","I-book","O","O","B-location","I-location","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, organization, location, book, award, writer, event, person, magazine, literary genre, poem and O.\nSentence: Marsters moved to Chicago , where his first professional acting role was Ferdinand in The Tempest at the Goodman Theatre in 1987 .","prompt_labels":"Marsters(B-person) moved(O) to(O) Chicago(B-location) ,(O) where(O) his(O) first(O) professional(O) acting(O) role(O) was(O) Ferdinand(O) in(O) The(B-book) Tempest(I-book) at(O) the(O) Goodman(B-location) Theatre(I-location) in(O) 1987(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["person","magazine","award","event","country","location","book","literary genre","poem","organization","writer"],"instance":{"id":"39","words":["In","an","autobiographical","essay","published","in","the","1950s",",","Pasternak","described","the","execution","of","Tabidze","and","the","suicides","of","Marina","Tsvetaeva","and","Paolo","Iashvili","as","the","greatest","heartbreaks","of","his","life","."],"labels":["O","O","B-literary genre","I-literary genre","O","O","O","O","O","B-writer","O","O","O","O","B-writer","O","O","O","O","B-writer","I-writer","O","B-writer","I-writer","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, magazine, award, event, country, location, book, literary genre, poem, organization, writer and O.\nSentence: In an autobiographical essay published in the 1950s , Pasternak described the execution of Tabidze and the suicides of Marina Tsvetaeva and Paolo Iashvili as the greatest heartbreaks of his life .","prompt_labels":"In(O) an(O) autobiographical(B-literary genre) essay(I-literary genre) published(O) in(O) the(O) 1950s(O) ,(O) Pasternak(B-writer) described(O) the(O) execution(O) of(O) Tabidze(B-writer) and(O) the(O) suicides(O) of(O) Marina(B-writer) Tsvetaeva(I-writer) and(O) Paolo(B-writer) Iashvili(I-writer) as(O) the(O) greatest(O) heartbreaks(O) of(O) his(O) life(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["magazine","writer","poem","event","organization","literary genre","person","location","book","country","award"],"instance":{"id":"40","words":["Milestone","won","his","second","Academy","Awards","for","All","Quiet","on","the","Western","Front",",","a","harrowing","screen","adaptation","of","the","antiwar","novel","by","Erich","Maria","Remarque","."],"labels":["B-writer","O","O","O","B-award","I-award","O","B-book","I-book","I-book","I-book","I-book","I-book","O","O","O","O","O","O","O","O","B-literary genre","O","B-writer","I-writer","I-writer","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: magazine, writer, poem, event, organization, literary genre, person, location, book, country, award and O.\nSentence: Milestone won his second Academy Awards for All Quiet on the Western Front , a harrowing screen adaptation of the antiwar novel by Erich Maria Remarque .","prompt_labels":"Milestone(B-writer) won(O) his(O) second(O) Academy(B-award) Awards(I-award) for(O) All(B-book) Quiet(I-book) on(I-book) the(I-book) Western(I-book) Front(I-book) ,(O) a(O) harrowing(O) screen(O) adaptation(O) of(O) the(O) antiwar(O) novel(B-literary genre) by(O) Erich(B-writer) Maria(I-writer) Remarque(I-writer) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["country","event","literary genre","person","award","organization","book","magazine","poem","writer","location"],"instance":{"id":"41","words":["He","studied","Platonism","in","Athens",",","travelled","to","Roman","Italy",",","Asia","Minor",",","and","Egypt",",","and","was","an","initiate","in","several","cults","or","mysteries","."],"labels":["O","O","O","O","B-location","O","O","O","B-location","I-location","O","B-location","I-location","O","O","B-country","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, event, literary genre, person, award, organization, book, magazine, poem, writer, location and O.\nSentence: He studied Platonism in Athens , travelled to Roman Italy , Asia Minor , and Egypt , and was an initiate in several cults or mysteries .","prompt_labels":"He(O) studied(O) Platonism(O) in(O) Athens(B-location) ,(O) travelled(O) to(O) Roman(B-location) Italy(I-location) ,(O) Asia(B-location) Minor(I-location) ,(O) and(O) Egypt(B-country) ,(O) and(O) was(O) an(O) initiate(O) in(O) several(O) cults(O) or(O) mysteries(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["country","literary genre","award","writer","organization","magazine","event","book","location","person","poem"],"instance":{"id":"42","words":["She","was","appointed","Burmese","ambassador","to","India","and","Nepal","in","1960",",","and","Aung","San","Suu","Kyi","followed","her","there","."],"labels":["O","O","O","O","O","O","B-country","O","B-country","O","O","O","O","B-writer","I-writer","I-writer","I-writer","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, literary genre, award, writer, organization, magazine, event, book, location, person, poem and O.\nSentence: She was appointed Burmese ambassador to India and Nepal in 1960 , and Aung San Suu Kyi followed her there .","prompt_labels":"She(O) was(O) appointed(O) Burmese(O) ambassador(O) to(O) India(B-country) and(O) Nepal(B-country) in(O) 1960(O) ,(O) and(O) Aung(B-writer) San(I-writer) Suu(I-writer) Kyi(I-writer) followed(O) her(O) there(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["award","event","organization","location","person","poem","magazine","country","book","writer","literary genre"],"instance":{"id":"43","words":["Although","the","reforms","brought","by","Nikita","Khrushchev","freed","him","from","exile","in","1956",",","the","publication","of","Cancer","Ward","(","1968",")",",","August","1914","(","1971",")",",","and","The","Gulag","Archipelago","(","1973",")","beyond","the","Soviet","Union","angered","authorities",",","and","Solzhenitsyn","lost","his","Soviet","citizenship","in","1974","."],"labels":["O","O","O","O","O","B-person","I-person","O","O","O","O","O","O","O","O","O","O","B-book","I-book","O","O","O","O","B-book","I-book","O","O","O","O","O","B-book","I-book","I-book","O","O","O","O","O","B-country","I-country","O","O","O","O","B-writer","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, event, organization, location, person, poem, magazine, country, book, writer, literary genre and O.\nSentence: Although the reforms brought by Nikita Khrushchev freed him from exile in 1956 , the publication of Cancer Ward ( 1968 ) , August 1914 ( 1971 ) , and The Gulag Archipelago ( 1973 ) beyond the Soviet Union angered authorities , and Solzhenitsyn lost his Soviet citizenship in 1974 .","prompt_labels":"Although(O) the(O) reforms(O) brought(O) by(O) Nikita(B-person) Khrushchev(I-person) freed(O) him(O) from(O) exile(O) in(O) 1956(O) ,(O) the(O) publication(O) of(O) Cancer(B-book) Ward(I-book) ((O) 1968(O) )(O) ,(O) August(B-book) 1914(I-book) ((O) 1971(O) )(O) ,(O) and(O) The(B-book) Gulag(I-book) Archipelago(I-book) ((O) 1973(O) )(O) beyond(O) the(O) Soviet(B-country) Union(I-country) angered(O) authorities(O) ,(O) and(O) Solzhenitsyn(B-writer) lost(O) his(O) Soviet(O) citizenship(O) in(O) 1974(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["country","location","award","writer","magazine","literary genre","organization","poem","person","book","event"],"instance":{"id":"44","words":["Hesser","lives","in","Brooklyn","Heights","with","her","husband",",","Tad","Friend",",","a","staff","writer","for","The","New","Yorker",",","and","their","two","children","."],"labels":["B-writer","O","O","B-location","I-location","O","O","O","O","B-writer","I-writer","O","O","O","O","O","B-magazine","I-magazine","I-magazine","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, location, award, writer, magazine, literary genre, organization, poem, person, book, event and O.\nSentence: Hesser lives in Brooklyn Heights with her husband , Tad Friend , a staff writer for The New Yorker , and their two children .","prompt_labels":"Hesser(B-writer) lives(O) in(O) Brooklyn(B-location) Heights(I-location) with(O) her(O) husband(O) ,(O) Tad(B-writer) Friend(I-writer) ,(O) a(O) staff(O) writer(O) for(O) The(B-magazine) New(I-magazine) Yorker(I-magazine) ,(O) and(O) their(O) two(O) children(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["person","writer","award","magazine","literary genre","country","poem","location","book","event","organization"],"instance":{"id":"45","words":["He","dedicated","his","poem","Fragments","of","Olympian","Gossip","to","Viereck",",","a","work","in","which","Tesla","ridiculed","the","scientific","establishment","of","the","day","."],"labels":["O","O","O","B-literary genre","B-poem","I-poem","I-poem","I-poem","O","B-location","O","O","O","O","O","B-organization","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, writer, award, magazine, literary genre, country, poem, location, book, event, organization and O.\nSentence: He dedicated his poem Fragments of Olympian Gossip to Viereck , a work in which Tesla ridiculed the scientific establishment of the day .","prompt_labels":"He(O) dedicated(O) his(O) poem(B-literary genre) Fragments(B-poem) of(I-poem) Olympian(I-poem) Gossip(I-poem) to(O) Viereck(B-location) ,(O) a(O) work(O) in(O) which(O) Tesla(B-organization) ridiculed(O) the(O) scientific(O) establishment(O) of(O) the(O) day(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["organization","country","book","magazine","person","event","award","location","poem","writer","literary genre"],"instance":{"id":"46","words":["Those","two","men","either","together","or","singly","also","appear","in","so","called","Catullus","'","Furius","and","Aurelius","cycle",",","in","poems","Catullus","11",",","15",",","21",",","23",",","24","and","26","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","B-poem","I-poem","I-poem","I-poem","I-poem","O","O","O","B-literary genre","B-poem","I-poem","O","B-poem","O","B-poem","O","B-poem","O","B-poem","O","B-poem","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, country, book, magazine, person, event, award, location, poem, writer, literary genre and O.\nSentence: Those two men either together or singly also appear in so called Catullus ' Furius and Aurelius cycle , in poems Catullus 11 , 15 , 21 , 23 , 24 and 26 .","prompt_labels":"Those(O) two(O) men(O) either(O) together(O) or(O) singly(O) also(O) appear(O) in(O) so(O) called(O) Catullus(B-poem) '(I-poem) Furius(I-poem) and(I-poem) Aurelius(I-poem) cycle(O) ,(O) in(O) poems(B-literary genre) Catullus(B-poem) 11(I-poem) ,(O) 15(B-poem) ,(O) 21(B-poem) ,(O) 23(B-poem) ,(O) 24(B-poem) and(O) 26(B-poem) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["award","poem","event","literary genre","magazine","organization","writer","book","location","country","person"],"instance":{"id":"47","words":["In","March","2020",",","a","third","season","of","Cosmos","named","Cosmos",":","Possible","Worlds",",","for","which","Druyan","was","executive","producer",",","writer",",","and","director","premiered","on","National","Geographic","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-writer","O","O","O","O","O","O","O","O","O","O","B-magazine","I-magazine","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, poem, event, literary genre, magazine, organization, writer, book, location, country, person and O.\nSentence: In March 2020 , a third season of Cosmos named Cosmos : Possible Worlds , for which Druyan was executive producer , writer , and director premiered on National Geographic .","prompt_labels":"In(O) March(O) 2020(O) ,(O) a(O) third(O) season(O) of(O) Cosmos(O) named(O) Cosmos(O) :(O) Possible(O) Worlds(O) ,(O) for(O) which(O) Druyan(B-writer) was(O) executive(O) producer(O) ,(O) writer(O) ,(O) and(O) director(O) premiered(O) on(O) National(B-magazine) Geographic(I-magazine) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["organization","magazine","literary genre","writer","book","person","location","poem","award","country","event"],"instance":{"id":"48","words":["He","spent","most","of","the","war","flying","between","the","U.S.","and","India",",","via","the","Azores","and","North","Africa","or","South","America",",","Nigeria",",","and","Central","Africa","."],"labels":["O","O","O","O","O","O","O","O","O","B-country","O","B-country","O","O","O","B-location","O","B-location","I-location","O","B-location","I-location","O","B-country","O","O","B-location","I-location","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, magazine, literary genre, writer, book, person, location, poem, award, country, event and O.\nSentence: He spent most of the war flying between the U.S. and India , via the Azores and North Africa or South America , Nigeria , and Central Africa .","prompt_labels":"He(O) spent(O) most(O) of(O) the(O) war(O) flying(O) between(O) the(O) U.S.(B-country) and(O) India(B-country) ,(O) via(O) the(O) Azores(B-location) and(O) North(B-location) Africa(I-location) or(O) South(B-location) America(I-location) ,(O) Nigeria(B-country) ,(O) and(O) Central(B-location) Africa(I-location) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["poem","organization","book","writer","magazine","country","award","location","event","literary genre","person"],"instance":{"id":"49","words":["1933",")",",","and","by","Random","House","in","1934",",","which","also","included","The","Orators","and","The","Dance","of","Death","."],"labels":["O","O","O","O","O","B-organization","I-organization","O","O","O","O","O","O","B-poem","I-poem","O","B-poem","I-poem","I-poem","I-poem","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: poem, organization, book, writer, magazine, country, award, location, event, literary genre, person and O.\nSentence: 1933 ) , and by Random House in 1934 , which also included The Orators and The Dance of Death .","prompt_labels":"1933(O) )(O) ,(O) and(O) by(O) Random(B-organization) House(I-organization) in(O) 1934(O) ,(O) which(O) also(O) included(O) The(B-poem) Orators(I-poem) and(O) The(B-poem) Dance(I-poem) of(I-poem) Death(I-poem) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["magazine","person","writer","literary genre","country","event","location","award","organization","book","poem"],"instance":{"id":"50","words":["Kirkus","Reviews","described","it","as","Predictable",",","certainly",",","and","less","imaginative","than","Consider","Phlebas","Consider","Phlebas",",","but","technically","much","more","solid",":","honorably","crafted","work",",","often","engrossing","despite","some","sluggish","patches","."],"labels":["B-magazine","I-magazine","O","O","O","O","O","O","O","O","O","O","O","B-book","I-book","B-book","I-book","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: magazine, person, writer, literary genre, country, event, location, award, organization, book, poem and O.\nSentence: Kirkus Reviews described it as Predictable , certainly , and less imaginative than Consider Phlebas Consider Phlebas , but technically much more solid : honorably crafted work , often engrossing despite some sluggish patches .","prompt_labels":"Kirkus(B-magazine) Reviews(I-magazine) described(O) it(O) as(O) Predictable(O) ,(O) certainly(O) ,(O) and(O) less(O) imaginative(O) than(O) Consider(B-book) Phlebas(I-book) Consider(B-book) Phlebas(I-book) ,(O) but(O) technically(O) much(O) more(O) solid(O) :(O) honorably(O) crafted(O) work(O) ,(O) often(O) engrossing(O) despite(O) some(O) sluggish(O) patches(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["award","event","country","writer","book","organization","magazine","literary genre","poem","location","person"],"instance":{"id":"51","words":["Moreover",",","he","planned","the","publication","of","the","compilation","Nietzsche","contra","Wagner","and","of","the","poems","that","made","up","his","collection","Dionysian-Dithyrambs","."],"labels":["O","O","O","O","O","O","O","O","O","B-book","I-book","I-book","O","O","O","O","O","O","O","O","O","B-book","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, event, country, writer, book, organization, magazine, literary genre, poem, location, person and O.\nSentence: Moreover , he planned the publication of the compilation Nietzsche contra Wagner and of the poems that made up his collection Dionysian-Dithyrambs .","prompt_labels":"Moreover(O) ,(O) he(O) planned(O) the(O) publication(O) of(O) the(O) compilation(O) Nietzsche(B-book) contra(I-book) Wagner(I-book) and(O) of(O) the(O) poems(O) that(O) made(O) up(O) his(O) collection(O) Dionysian-Dithyrambs(B-book) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["country","award","writer","event","magazine","book","person","literary genre","poem","organization","location"],"instance":{"id":"52","words":["Vladimir","Nabokov","'","s","novel",",","Ada","or","Ardor",":","A","Family","Chronicle","(","1969",")",",","is","a","story","of","incest","that","takes","place","within","an","alternate","North","America","settled","in","part","by","Russian","Empire","and","that","borrows","from","Dick","'s","idea","of","alternate-alternate","history","(","the","world","of","Nabokov","'s","hero","is","wracked","by","rumors","of","a","counter-earth","that","apparently","is","ours",")","."],"labels":["B-writer","I-writer","O","O","B-literary genre","O","B-book","I-book","I-book","I-book","I-book","I-book","I-book","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-location","I-location","O","O","O","O","B-country","I-country","O","O","O","O","B-writer","O","O","O","B-literary genre","I-literary genre","O","O","O","O","B-writer","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, award, writer, event, magazine, book, person, literary genre, poem, organization, location and O.\nSentence: Vladimir Nabokov ' s novel , Ada or Ardor : A Family Chronicle ( 1969 ) , is a story of incest that takes place within an alternate North America settled in part by Russian Empire and that borrows from Dick 's idea of alternate-alternate history ( the world of Nabokov 's hero is wracked by rumors of a counter-earth that apparently is ours ) .","prompt_labels":"Vladimir(B-writer) Nabokov(I-writer) '(O) s(O) novel(B-literary genre) ,(O) Ada(B-book) or(I-book) Ardor(I-book) :(I-book) A(I-book) Family(I-book) Chronicle(I-book) ((O) 1969(O) )(O) ,(O) is(O) a(O) story(O) of(O) incest(O) that(O) takes(O) place(O) within(O) an(O) alternate(O) North(B-location) America(I-location) settled(O) in(O) part(O) by(O) Russian(B-country) Empire(I-country) and(O) that(O) borrows(O) from(O) Dick(B-writer) 's(O) idea(O) of(O) alternate-alternate(B-literary genre) history(I-literary genre) ((O) the(O) world(O) of(O) Nabokov(B-writer) 's(O) hero(O) is(O) wracked(O) by(O) rumors(O) of(O) a(O) counter-earth(O) that(O) apparently(O) is(O) ours(O) )(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["country","event","person","award","location","magazine","poem","organization","writer","book","literary genre"],"instance":{"id":"53","words":["Rolling","Stone","magazine","ranked","him","number","13","in","its","list","of","100","Greatest","Artists","."],"labels":["B-magazine","I-magazine","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, event, person, award, location, magazine, poem, organization, writer, book, literary genre and O.\nSentence: Rolling Stone magazine ranked him number 13 in its list of 100 Greatest Artists .","prompt_labels":"Rolling(B-magazine) Stone(I-magazine) magazine(O) ranked(O) him(O) number(O) 13(O) in(O) its(O) list(O) of(O) 100(O) Greatest(O) Artists(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["book","magazine","organization","event","location","poem","award","country","person","writer","literary genre"],"instance":{"id":"54","words":["He","was","a","member","of","the","National","Academy","of","Sciences",",","the","National","Academy","of","Engineering",",","and","the","American","Academy","of","Arts","and","Sciences","."],"labels":["O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: book, magazine, organization, event, location, poem, award, country, person, writer, literary genre and O.\nSentence: He was a member of the National Academy of Sciences , the National Academy of Engineering , and the American Academy of Arts and Sciences .","prompt_labels":"He(O) was(O) a(O) member(O) of(O) the(O) National(B-organization) Academy(I-organization) of(I-organization) Sciences(I-organization) ,(O) the(O) National(B-organization) Academy(I-organization) of(I-organization) Engineering(I-organization) ,(O) and(O) the(O) American(B-organization) Academy(I-organization) of(I-organization) Arts(I-organization) and(I-organization) Sciences(I-organization) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["book","award","organization","person","writer","event","literary genre","poem","country","magazine","location"],"instance":{"id":"55","words":["Mere","Christianity","was","voted","best","book","of","the","20th","century","by","Christianity","Today","in","2000","."],"labels":["B-book","I-book","O","O","O","O","O","O","O","O","O","B-magazine","I-magazine","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: book, award, organization, person, writer, event, literary genre, poem, country, magazine, location and O.\nSentence: Mere Christianity was voted best book of the 20th century by Christianity Today in 2000 .","prompt_labels":"Mere(B-book) Christianity(I-book) was(O) voted(O) best(O) book(O) of(O) the(O) 20th(O) century(O) by(O) Christianity(B-magazine) Today(I-magazine) in(O) 2000(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["country","event","poem","magazine","award","organization","person","location","book","literary genre","writer"],"instance":{"id":"56","words":["Snyder","'s","interest","in","things","Chinese","and","Japanese","stemmed","from","his","early","reading","of","Pound","'s","writings.","and","his","long","poem","Mountains","and","Rivers","Without","End","(","1965-1996",")","reflects","his","reading","of","The","Cantos","in","many","of","the","formal","devices","used","."],"labels":["B-writer","O","O","O","O","O","O","O","O","O","O","O","O","O","B-writer","O","O","O","O","B-literary genre","I-literary genre","B-poem","I-poem","I-poem","I-poem","I-poem","O","O","O","O","O","O","O","B-poem","I-poem","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, event, poem, magazine, award, organization, person, location, book, literary genre, writer and O.\nSentence: Snyder 's interest in things Chinese and Japanese stemmed from his early reading of Pound 's writings. and his long poem Mountains and Rivers Without End ( 1965-1996 ) reflects his reading of The Cantos in many of the formal devices used .","prompt_labels":"Snyder(B-writer) 's(O) interest(O) in(O) things(O) Chinese(O) and(O) Japanese(O) stemmed(O) from(O) his(O) early(O) reading(O) of(O) Pound(B-writer) 's(O) writings.(O) and(O) his(O) long(B-literary genre) poem(I-literary genre) Mountains(B-poem) and(I-poem) Rivers(I-poem) Without(I-poem) End(I-poem) ((O) 1965-1996(O) )(O) reflects(O) his(O) reading(O) of(O) The(B-poem) Cantos(I-poem) in(O) many(O) of(O) the(O) formal(O) devices(O) used(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["country","poem","magazine","award","book","person","writer","literary genre","event","organization","location"],"instance":{"id":"57","words":["Although","Nietzsche","had","previously","announced","at","the","end","of","On","the","Genealogy","of","Morality","a","new","work","with","the","title","The","Will","to","Power",":","Attempt","at","a","Revaluation","of","All","Values",",","he","eventually","seems","to","have","abandoned","this","idea","and","instead","used","some","of","the","draft","passages","to","compose","Twilight","of","the","Idols","and","The","Antichrist","in","1888","."],"labels":["O","B-writer","O","O","O","O","O","O","O","B-book","I-book","I-book","I-book","I-book","O","O","O","O","O","O","B-book","I-book","I-book","I-book","I-book","I-book","I-book","I-book","I-book","I-book","I-book","I-book","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-book","I-book","I-book","I-book","O","B-book","I-book","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, poem, magazine, award, book, person, writer, literary genre, event, organization, location and O.\nSentence: Although Nietzsche had previously announced at the end of On the Genealogy of Morality a new work with the title The Will to Power : Attempt at a Revaluation of All Values , he eventually seems to have abandoned this idea and instead used some of the draft passages to compose Twilight of the Idols and The Antichrist in 1888 .","prompt_labels":"Although(O) Nietzsche(B-writer) had(O) previously(O) announced(O) at(O) the(O) end(O) of(O) On(B-book) the(I-book) Genealogy(I-book) of(I-book) Morality(I-book) a(O) new(O) work(O) with(O) the(O) title(O) The(B-book) Will(I-book) to(I-book) Power(I-book) :(I-book) Attempt(I-book) at(I-book) a(I-book) Revaluation(I-book) of(I-book) All(I-book) Values(I-book) ,(O) he(O) eventually(O) seems(O) to(O) have(O) abandoned(O) this(O) idea(O) and(O) instead(O) used(O) some(O) of(O) the(O) draft(O) passages(O) to(O) compose(O) Twilight(B-book) of(I-book) the(I-book) Idols(I-book) and(O) The(B-book) Antichrist(I-book) in(O) 1888(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["award","organization","poem","writer","magazine","event","literary genre","book","country","person","location"],"instance":{"id":"58","words":["It","was","praised","by","scientists","such","as","Darwin","(","to","whom","the","book","was","dedicated",")",",","and","Charles","Lyell",",","and","by","non-scientists","such","as","the","novelist","Joseph","Conrad",",","who","called","it","his","favorite","bedside","companion","and","used","it","as","source","of","information","for","several","of","his","novels",",","especially","Lord","Jim","."],"labels":["O","O","O","O","O","O","O","B-person","O","O","O","O","O","O","O","O","O","O","B-person","I-person","O","O","O","O","O","O","O","O","B-writer","I-writer","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-writer","I-writer","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, organization, poem, writer, magazine, event, literary genre, book, country, person, location and O.\nSentence: It was praised by scientists such as Darwin ( to whom the book was dedicated ) , and Charles Lyell , and by non-scientists such as the novelist Joseph Conrad , who called it his favorite bedside companion and used it as source of information for several of his novels , especially Lord Jim .","prompt_labels":"It(O) was(O) praised(O) by(O) scientists(O) such(O) as(O) Darwin(B-person) ((O) to(O) whom(O) the(O) book(O) was(O) dedicated(O) )(O) ,(O) and(O) Charles(B-person) Lyell(I-person) ,(O) and(O) by(O) non-scientists(O) such(O) as(O) the(O) novelist(O) Joseph(B-writer) Conrad(I-writer) ,(O) who(O) called(O) it(O) his(O) favorite(O) bedside(O) companion(O) and(O) used(O) it(O) as(O) source(O) of(O) information(O) for(O) several(O) of(O) his(O) novels(O) ,(O) especially(O) Lord(B-writer) Jim(I-writer) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["writer","award","event","book","poem","organization","location","magazine","country","person","literary genre"],"instance":{"id":"59","words":["He","received","an","Academy","Awards","nomination","for","Academy","Award","for","Best","Supporting","Actor","for","1987","'s","Broadcast","News","and","was","widely","praised","for","his","performance","in","the","2011","film","Drive","."],"labels":["O","O","O","B-award","I-award","O","O","B-award","I-award","I-award","I-award","I-award","I-award","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: writer, award, event, book, poem, organization, location, magazine, country, person, literary genre and O.\nSentence: He received an Academy Awards nomination for Academy Award for Best Supporting Actor for 1987 's Broadcast News and was widely praised for his performance in the 2011 film Drive .","prompt_labels":"He(O) received(O) an(O) Academy(B-award) Awards(I-award) nomination(O) for(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Supporting(I-award) Actor(I-award) for(O) 1987(O) 's(O) Broadcast(O) News(O) and(O) was(O) widely(O) praised(O) for(O) his(O) performance(O) in(O) the(O) 2011(O) film(O) Drive(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["location","poem","person","writer","book","literary genre","country","organization","award","magazine","event"],"instance":{"id":"60","words":["Catullus","twice","used","a","meter","that","Sappho","developed",",","called","the","Sapphic","strophe",",","in","poems","Catullus","11","and","51",",","perhaps","prompting","his","successor","Horace","'s","interest","in","the","form","."],"labels":["B-writer","O","O","O","O","O","B-writer","O","O","O","O","O","O","O","O","O","B-poem","I-poem","I-poem","I-poem","O","O","O","O","O","B-writer","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, poem, person, writer, book, literary genre, country, organization, award, magazine, event and O.\nSentence: Catullus twice used a meter that Sappho developed , called the Sapphic strophe , in poems Catullus 11 and 51 , perhaps prompting his successor Horace 's interest in the form .","prompt_labels":"Catullus(B-writer) twice(O) used(O) a(O) meter(O) that(O) Sappho(B-writer) developed(O) ,(O) called(O) the(O) Sapphic(O) strophe(O) ,(O) in(O) poems(O) Catullus(B-poem) 11(I-poem) and(I-poem) 51(I-poem) ,(O) perhaps(O) prompting(O) his(O) successor(O) Horace(B-writer) 's(O) interest(O) in(O) the(O) form(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["magazine","location","award","event","person","poem","writer","book","organization","country","literary genre"],"instance":{"id":"61","words":["Bernard","Miles","gave","Milligan","his","first","straight","acting","role",",","as","Ben","Gunn",",","in","the","Mermaid","Theatre","production","of","Treasure","Island","."],"labels":["B-person","I-person","O","B-person","O","O","O","O","O","O","O","B-person","I-person","O","O","O","B-location","I-location","O","O","B-book","I-book","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: magazine, location, award, event, person, poem, writer, book, organization, country, literary genre and O.\nSentence: Bernard Miles gave Milligan his first straight acting role , as Ben Gunn , in the Mermaid Theatre production of Treasure Island .","prompt_labels":"Bernard(B-person) Miles(I-person) gave(O) Milligan(B-person) his(O) first(O) straight(O) acting(O) role(O) ,(O) as(O) Ben(B-person) Gunn(I-person) ,(O) in(O) the(O) Mermaid(B-location) Theatre(I-location) production(O) of(O) Treasure(B-book) Island(I-book) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["writer","organization","event","book","literary genre","location","country","magazine","person","poem","award"],"instance":{"id":"62","words":["In","1979","a","cartoon","based","on","Seton","'s","1922","book","Bannertail","was","produced","in","Japan","."],"labels":["O","O","O","O","O","O","B-writer","O","O","O","B-book","O","O","O","B-country","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: writer, organization, event, book, literary genre, location, country, magazine, person, poem, award and O.\nSentence: In 1979 a cartoon based on Seton 's 1922 book Bannertail was produced in Japan .","prompt_labels":"In(O) 1979(O) a(O) cartoon(O) based(O) on(O) Seton(B-writer) 's(O) 1922(O) book(O) Bannertail(B-book) was(O) produced(O) in(O) Japan(B-country) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["location","organization","person","writer","literary genre","magazine","poem","event","book","award","country"],"instance":{"id":"63","words":["In","1930","he","was","nominated","for","the","Nobel","Prize","in","Literature","by","Swedish","author","Anders","sterling",",","but","was","passed","over","in","favor","of","Sinclair","Lewis","."],"labels":["O","O","O","O","O","O","O","B-award","I-award","I-award","I-award","O","O","O","B-writer","I-writer","O","O","O","O","O","O","O","O","B-writer","I-writer","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, organization, person, writer, literary genre, magazine, poem, event, book, award, country and O.\nSentence: In 1930 he was nominated for the Nobel Prize in Literature by Swedish author Anders sterling , but was passed over in favor of Sinclair Lewis .","prompt_labels":"In(O) 1930(O) he(O) was(O) nominated(O) for(O) the(O) Nobel(B-award) Prize(I-award) in(I-award) Literature(I-award) by(O) Swedish(O) author(O) Anders(B-writer) sterling(I-writer) ,(O) but(O) was(O) passed(O) over(O) in(O) favor(O) of(O) Sinclair(B-writer) Lewis(I-writer) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["person","award","country","organization","magazine","writer","location","literary genre","poem","book","event"],"instance":{"id":"64","words":["Among","his","childhood","favorites","were","Charles","Dickens",",","Tobias","Smollett",",","Mark","Twain",",","Booth","Tarkington",",","and","later",",","Robert","Benchley","and","S.","J.","Perelman","."],"labels":["O","O","O","O","O","B-writer","I-writer","O","B-writer","I-writer","O","B-writer","I-writer","O","B-writer","I-writer","O","O","O","O","B-writer","I-writer","O","B-writer","I-writer","I-writer","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, award, country, organization, magazine, writer, location, literary genre, poem, book, event and O.\nSentence: Among his childhood favorites were Charles Dickens , Tobias Smollett , Mark Twain , Booth Tarkington , and later , Robert Benchley and S. J. Perelman .","prompt_labels":"Among(O) his(O) childhood(O) favorites(O) were(O) Charles(B-writer) Dickens(I-writer) ,(O) Tobias(B-writer) Smollett(I-writer) ,(O) Mark(B-writer) Twain(I-writer) ,(O) Booth(B-writer) Tarkington(I-writer) ,(O) and(O) later(O) ,(O) Robert(B-writer) Benchley(I-writer) and(O) S.(B-writer) J.(I-writer) Perelman(I-writer) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["organization","country","magazine","location","person","literary genre","book","poem","event","award","writer"],"instance":{"id":"65","words":["Among","the","books","found","in","his","library","(","as","evidenced","in","Lovecraft","'s","Library","by","S.","T.","Joshi",")","was","The","Seven","Who","Were","Hanged","by","Leonid","Andreyev","and","A","Strange","Manuscript","Found","in","a","Copper","Cylinder","by","James","De","Mille","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","B-book","I-book","I-book","O","B-writer","I-writer","I-writer","O","O","B-book","I-book","I-book","I-book","I-book","O","B-writer","I-writer","O","B-book","I-book","I-book","I-book","I-book","I-book","I-book","I-book","O","B-writer","I-writer","I-writer","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, country, magazine, location, person, literary genre, book, poem, event, award, writer and O.\nSentence: Among the books found in his library ( as evidenced in Lovecraft 's Library by S. T. Joshi ) was The Seven Who Were Hanged by Leonid Andreyev and A Strange Manuscript Found in a Copper Cylinder by James De Mille .","prompt_labels":"Among(O) the(O) books(O) found(O) in(O) his(O) library(O) ((O) as(O) evidenced(O) in(O) Lovecraft(B-book) 's(I-book) Library(I-book) by(O) S.(B-writer) T.(I-writer) Joshi(I-writer) )(O) was(O) The(B-book) Seven(I-book) Who(I-book) Were(I-book) Hanged(I-book) by(O) Leonid(B-writer) Andreyev(I-writer) and(O) A(B-book) Strange(I-book) Manuscript(I-book) Found(I-book) in(I-book) a(I-book) Copper(I-book) Cylinder(I-book) by(O) James(B-writer) De(I-writer) Mille(I-writer) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["book","magazine","event","poem","literary genre","country","organization","person","location","writer","award"],"instance":{"id":"66","words":["He","soon","produced","acclaimed","translations","of","Sndor","Petfi",",","Johann","Wolfgang","von","Goethe",",","Rainer","Maria","Rilke",",","Paul","Verlaine",",","Taras","Shevchenko",",","and","Nikoloz","Baratashvili","."],"labels":["O","O","O","O","O","O","B-writer","I-writer","O","B-writer","I-writer","I-writer","I-writer","O","B-writer","I-writer","I-writer","O","B-writer","I-writer","O","B-writer","I-writer","O","O","B-writer","I-writer","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: book, magazine, event, poem, literary genre, country, organization, person, location, writer, award and O.\nSentence: He soon produced acclaimed translations of Sndor Petfi , Johann Wolfgang von Goethe , Rainer Maria Rilke , Paul Verlaine , Taras Shevchenko , and Nikoloz Baratashvili .","prompt_labels":"He(O) soon(O) produced(O) acclaimed(O) translations(O) of(O) Sndor(B-writer) Petfi(I-writer) ,(O) Johann(B-writer) Wolfgang(I-writer) von(I-writer) Goethe(I-writer) ,(O) Rainer(B-writer) Maria(I-writer) Rilke(I-writer) ,(O) Paul(B-writer) Verlaine(I-writer) ,(O) Taras(B-writer) Shevchenko(I-writer) ,(O) and(O) Nikoloz(B-writer) Baratashvili(I-writer) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["event","location","organization","person","writer","poem","literary genre","award","country","book","magazine"],"instance":{"id":"67","words":["This","aversion","to","war","also","led","Einstein","to","befriend","author","Upton","Sinclair","and","film","star","Charlie","Chaplin",",","both","noted","for","their","pacifism","."],"labels":["O","O","O","O","O","O","B-person","O","O","O","B-writer","I-writer","O","O","O","B-person","I-person","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, location, organization, person, writer, poem, literary genre, award, country, book, magazine and O.\nSentence: This aversion to war also led Einstein to befriend author Upton Sinclair and film star Charlie Chaplin , both noted for their pacifism .","prompt_labels":"This(O) aversion(O) to(O) war(O) also(O) led(O) Einstein(B-person) to(O) befriend(O) author(O) Upton(B-writer) Sinclair(I-writer) and(O) film(O) star(O) Charlie(B-person) Chaplin(I-person) ,(O) both(O) noted(O) for(O) their(O) pacifism(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["magazine","book","country","person","organization","award","location","event","poem","literary genre","writer"],"instance":{"id":"68","words":["The","scholar","and","translator","David","Hawkes","divides","the","verses","of","what","seem","to","be","of","the","earlier","(","pre-Han","era",")",",","into","two","types",",","each","type","being","characterized","by","one","of","two","characteristic","metrical","forms","(","with","the","exception","of","the","mixed","poetry","and","prose","narratives","of","the","Bu","Ju","and","of","The","Fisherman",")","."],"labels":["O","O","O","O","B-writer","I-writer","O","O","B-literary genre","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-literary genre","O","B-literary genre","O","O","O","B-poem","I-poem","O","O","B-poem","I-poem","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: magazine, book, country, person, organization, award, location, event, poem, literary genre, writer and O.\nSentence: The scholar and translator David Hawkes divides the verses of what seem to be of the earlier ( pre-Han era ) , into two types , each type being characterized by one of two characteristic metrical forms ( with the exception of the mixed poetry and prose narratives of the Bu Ju and of The Fisherman ) .","prompt_labels":"The(O) scholar(O) and(O) translator(O) David(B-writer) Hawkes(I-writer) divides(O) the(O) verses(B-literary genre) of(O) what(O) seem(O) to(O) be(O) of(O) the(O) earlier(O) ((O) pre-Han(O) era(O) )(O) ,(O) into(O) two(O) types(O) ,(O) each(O) type(O) being(O) characterized(O) by(O) one(O) of(O) two(O) characteristic(O) metrical(O) forms(O) ((O) with(O) the(O) exception(O) of(O) the(O) mixed(O) poetry(B-literary genre) and(O) prose(B-literary genre) narratives(O) of(O) the(O) Bu(B-poem) Ju(I-poem) and(O) of(O) The(B-poem) Fisherman(I-poem) )(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["event","poem","book","country","organization","magazine","literary genre","location","writer","award","person"],"instance":{"id":"69","words":["Since","release",",","the","film","has","divided","critics","but","generally","received","praise",";","initial","reviews","ranged","from","Melody","Maker","calling","it","the","greatest","horror","film","made","in","Britain",",","to","Roger","Ebert","decrying","its","bankruptcy","of","imagination","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-magazine","I-magazine","O","O","O","O","O","O","O","O","B-country","O","O","B-writer","I-writer","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, poem, book, country, organization, magazine, literary genre, location, writer, award, person and O.\nSentence: Since release , the film has divided critics but generally received praise ; initial reviews ranged from Melody Maker calling it the greatest horror film made in Britain , to Roger Ebert decrying its bankruptcy of imagination .","prompt_labels":"Since(O) release(O) ,(O) the(O) film(O) has(O) divided(O) critics(O) but(O) generally(O) received(O) praise(O) ;(O) initial(O) reviews(O) ranged(O) from(O) Melody(B-magazine) Maker(I-magazine) calling(O) it(O) the(O) greatest(O) horror(O) film(O) made(O) in(O) Britain(B-country) ,(O) to(O) Roger(B-writer) Ebert(I-writer) decrying(O) its(O) bankruptcy(O) of(O) imagination(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["organization","award","book","poem","literary genre","country","magazine","writer","event","person","location"],"instance":{"id":"70","words":["Tarkovsky","was","the","recipient","of","several","awards","at","the","Cannes","Film","Festival","throughout","his","career","(","including","the","FIPRESCI","prize",",","the","Prize","of","the","Ecumenical","Jury",",","and","the","Grand","Prix","Spcial","du","Jury",")","and","winner","of","the","Golden","Lion","award","at","the","Venice","Film","Festival","for","his","debut","film","Ivan","'s","Childhood","."],"labels":["B-writer","O","O","O","O","O","O","O","O","B-event","I-event","I-event","O","O","O","O","O","O","B-award","I-award","O","O","B-award","I-award","I-award","I-award","I-award","O","O","O","B-award","I-award","I-award","I-award","I-award","O","O","O","O","O","B-award","I-award","I-award","O","O","B-event","I-event","I-event","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, award, book, poem, literary genre, country, magazine, writer, event, person, location and O.\nSentence: Tarkovsky was the recipient of several awards at the Cannes Film Festival throughout his career ( including the FIPRESCI prize , the Prize of the Ecumenical Jury , and the Grand Prix Spcial du Jury ) and winner of the Golden Lion award at the Venice Film Festival for his debut film Ivan 's Childhood .","prompt_labels":"Tarkovsky(B-writer) was(O) the(O) recipient(O) of(O) several(O) awards(O) at(O) the(O) Cannes(B-event) Film(I-event) Festival(I-event) throughout(O) his(O) career(O) ((O) including(O) the(O) FIPRESCI(B-award) prize(I-award) ,(O) the(O) Prize(B-award) of(I-award) the(I-award) Ecumenical(I-award) Jury(I-award) ,(O) and(O) the(O) Grand(B-award) Prix(I-award) Spcial(I-award) du(I-award) Jury(I-award) )(O) and(O) winner(O) of(O) the(O) Golden(B-award) Lion(I-award) award(I-award) at(O) the(O) Venice(B-event) Film(I-event) Festival(I-event) for(O) his(O) debut(O) film(O) Ivan(O) 's(O) Childhood(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["literary genre","location","country","poem","book","organization","award","magazine","event","writer","person"],"instance":{"id":"71","words":["The","first","global","recognition","came","in","1950","when","Gwendolyn","Brooks","was","the","first","black","American","to","win","a","Pulitzer","Prize","for","Literature","."],"labels":["O","O","O","O","O","O","O","O","B-writer","I-writer","O","O","O","O","O","O","O","O","B-award","I-award","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: literary genre, location, country, poem, book, organization, award, magazine, event, writer, person and O.\nSentence: The first global recognition came in 1950 when Gwendolyn Brooks was the first black American to win a Pulitzer Prize for Literature .","prompt_labels":"The(O) first(O) global(O) recognition(O) came(O) in(O) 1950(O) when(O) Gwendolyn(B-writer) Brooks(I-writer) was(O) the(O) first(O) black(O) American(O) to(O) win(O) a(O) Pulitzer(B-award) Prize(I-award) for(O) Literature(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["writer","book","organization","country","person","award","event","location","literary genre","poem","magazine"],"instance":{"id":"72","words":["Modern","children","'s","literature","has","been","more","or","less","influenced","by","Lewis","'s","series",",","such","as","Daniel","Handler","'","s","A","Series","of","Unfortunate","Events",",","Eoin","Colfer","'","s","Artemis","Fowl",",","Philip","Pullman","'","s","His","Dark","Materials",",","and","J.","K.","Rowling","'","s","Harry","Potter","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","B-writer","O","O","O","O","O","B-writer","I-writer","O","O","B-book","I-book","I-book","I-book","I-book","O","B-writer","I-writer","O","O","B-book","I-book","O","B-writer","I-writer","O","O","B-book","I-book","I-book","O","O","B-writer","I-writer","I-writer","O","O","B-book","I-book","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: writer, book, organization, country, person, award, event, location, literary genre, poem, magazine and O.\nSentence: Modern children 's literature has been more or less influenced by Lewis 's series , such as Daniel Handler ' s A Series of Unfortunate Events , Eoin Colfer ' s Artemis Fowl , Philip Pullman ' s His Dark Materials , and J. K. Rowling ' s Harry Potter .","prompt_labels":"Modern(O) children(O) 's(O) literature(O) has(O) been(O) more(O) or(O) less(O) influenced(O) by(O) Lewis(B-writer) 's(O) series(O) ,(O) such(O) as(O) Daniel(B-writer) Handler(I-writer) '(O) s(O) A(B-book) Series(I-book) of(I-book) Unfortunate(I-book) Events(I-book) ,(O) Eoin(B-writer) Colfer(I-writer) '(O) s(O) Artemis(B-book) Fowl(I-book) ,(O) Philip(B-writer) Pullman(I-writer) '(O) s(O) His(B-book) Dark(I-book) Materials(I-book) ,(O) and(O) J.(B-writer) K.(I-writer) Rowling(I-writer) '(O) s(O) Harry(B-book) Potter(I-book) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["book","writer","country","magazine","poem","organization","award","person","location","literary genre","event"],"instance":{"id":"73","words":["Orwell","wrote","the","book","between","November","1943","and","February","1944",",","when","the","UK","was","in","its","Allies","of","World","War","II","with","the","Soviet","Union","against","Nazi","Germany",",","and","the","British","people","and","intelligentsia","held","Stalin","in","high","esteem",",","a","phenomenon","Orwell","hated","."],"labels":["B-writer","O","O","O","O","O","O","O","O","O","O","O","O","B-country","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","O","B-country","I-country","O","B-country","I-country","O","O","O","O","O","O","O","O","B-person","O","O","O","O","O","O","B-writer","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: book, writer, country, magazine, poem, organization, award, person, location, literary genre, event and O.\nSentence: Orwell wrote the book between November 1943 and February 1944 , when the UK was in its Allies of World War II with the Soviet Union against Nazi Germany , and the British people and intelligentsia held Stalin in high esteem , a phenomenon Orwell hated .","prompt_labels":"Orwell(B-writer) wrote(O) the(O) book(O) between(O) November(O) 1943(O) and(O) February(O) 1944(O) ,(O) when(O) the(O) UK(B-country) was(O) in(O) its(O) Allies(B-organization) of(I-organization) World(I-organization) War(I-organization) II(I-organization) with(O) the(O) Soviet(B-country) Union(I-country) against(O) Nazi(B-country) Germany(I-country) ,(O) and(O) the(O) British(O) people(O) and(O) intelligentsia(O) held(O) Stalin(B-person) in(O) high(O) esteem(O) ,(O) a(O) phenomenon(O) Orwell(B-writer) hated(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["poem","magazine","award","event","organization","country","book","person","literary genre","location","writer"],"instance":{"id":"74","words":["He","is","best","remembered","for","his","science","fiction",",","including","The","Demolished","Man",",","winner","of","the","inaugural","Hugo","Award","in","1953","."],"labels":["O","O","O","O","O","O","B-literary genre","I-literary genre","O","O","B-book","I-book","I-book","O","O","O","O","O","B-award","I-award","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: poem, magazine, award, event, organization, country, book, person, literary genre, location, writer and O.\nSentence: He is best remembered for his science fiction , including The Demolished Man , winner of the inaugural Hugo Award in 1953 .","prompt_labels":"He(O) is(O) best(O) remembered(O) for(O) his(O) science(B-literary genre) fiction(I-literary genre) ,(O) including(O) The(B-book) Demolished(I-book) Man(I-book) ,(O) winner(O) of(O) the(O) inaugural(O) Hugo(B-award) Award(I-award) in(O) 1953(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["event","magazine","location","book","person","poem","award","organization","literary genre","writer","country"],"instance":{"id":"75","words":["Amos","prophesied","during","the","reign","of","Jeroboam","II",",","King","of","Israel",",","and","of","Uzziah","of","Kingdom","of","Judah",",","which","places","him","in","the","first","half","of","the","8th","century","BC","."],"labels":["B-writer","O","O","O","O","O","B-person","I-person","O","O","O","B-country","O","O","O","B-person","O","B-country","I-country","I-country","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, magazine, location, book, person, poem, award, organization, literary genre, writer, country and O.\nSentence: Amos prophesied during the reign of Jeroboam II , King of Israel , and of Uzziah of Kingdom of Judah , which places him in the first half of the 8th century BC .","prompt_labels":"Amos(B-writer) prophesied(O) during(O) the(O) reign(O) of(O) Jeroboam(B-person) II(I-person) ,(O) King(O) of(O) Israel(B-country) ,(O) and(O) of(O) Uzziah(B-person) of(O) Kingdom(B-country) of(I-country) Judah(I-country) ,(O) which(O) places(O) him(O) in(O) the(O) first(O) half(O) of(O) the(O) 8th(O) century(O) BC(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["book","magazine","person","award","event","writer","organization","location","poem","literary genre","country"],"instance":{"id":"76","words":["Jorge","Luis","Borges","wrote","a","contemporary","bestiary","of","sorts",",","the","Book","of","Imaginary","Beings",",","which","collects","imaginary","beasts","from","bestiaries","and","fiction","."],"labels":["B-writer","I-writer","I-writer","O","O","O","O","O","O","O","O","B-book","I-book","I-book","I-book","O","O","O","O","O","O","O","O","B-literary genre","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: book, magazine, person, award, event, writer, organization, location, poem, literary genre, country and O.\nSentence: Jorge Luis Borges wrote a contemporary bestiary of sorts , the Book of Imaginary Beings , which collects imaginary beasts from bestiaries and fiction .","prompt_labels":"Jorge(B-writer) Luis(I-writer) Borges(I-writer) wrote(O) a(O) contemporary(O) bestiary(O) of(O) sorts(O) ,(O) the(O) Book(B-book) of(I-book) Imaginary(I-book) Beings(I-book) ,(O) which(O) collects(O) imaginary(O) beasts(O) from(O) bestiaries(O) and(O) fiction(B-literary genre) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["location","person","event","poem","literary genre","magazine","country","organization","award","writer","book"],"instance":{"id":"77","words":["The","Australia","n","composer","Peter","Sculthorpe","quoted","parts","of","it","in","his","opera","or","music","theatre","work","Rites","of","Passage","(","1972-73",")",",","which","was","commissioned","for","the","opening","of","the","Sydney","Opera","House","but","was","not","ready","in","time","."],"labels":["O","B-country","O","O","B-writer","I-writer","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-location","I-location","I-location","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, person, event, poem, literary genre, magazine, country, organization, award, writer, book and O.\nSentence: The Australia n composer Peter Sculthorpe quoted parts of it in his opera or music theatre work Rites of Passage ( 1972-73 ) , which was commissioned for the opening of the Sydney Opera House but was not ready in time .","prompt_labels":"The(O) Australia(B-country) n(O) composer(O) Peter(B-writer) Sculthorpe(I-writer) quoted(O) parts(O) of(O) it(O) in(O) his(O) opera(O) or(O) music(O) theatre(O) work(O) Rites(O) of(O) Passage(O) ((O) 1972-73(O) )(O) ,(O) which(O) was(O) commissioned(O) for(O) the(O) opening(O) of(O) the(O) Sydney(B-location) Opera(I-location) House(I-location) but(O) was(O) not(O) ready(O) in(O) time(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["magazine","writer","country","book","location","award","person","organization","event","poem","literary genre"],"instance":{"id":"78","words":["She","especially","enjoyed","the","St.","Nicholas","Magazine","(","which","carried","her","first","published","stories",")",",","the","works","of","Beatrix","Potter",",","and","the","novels","of","Gene","Stratton-Porter",",","and","in","her","teen","years",",","Herman","Melville",",","Joseph","Conrad","and","Robert","Louis","Stevenson","."],"labels":["O","O","O","O","B-magazine","I-magazine","I-magazine","O","O","O","O","O","O","O","O","O","O","O","O","B-writer","I-writer","O","O","O","B-literary genre","O","B-writer","I-writer","O","O","O","O","O","O","O","B-writer","I-writer","O","B-writer","I-writer","O","B-writer","I-writer","I-writer","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: magazine, writer, country, book, location, award, person, organization, event, poem, literary genre and O.\nSentence: She especially enjoyed the St. Nicholas Magazine ( which carried her first published stories ) , the works of Beatrix Potter , and the novels of Gene Stratton-Porter , and in her teen years , Herman Melville , Joseph Conrad and Robert Louis Stevenson .","prompt_labels":"She(O) especially(O) enjoyed(O) the(O) St.(B-magazine) Nicholas(I-magazine) Magazine(I-magazine) ((O) which(O) carried(O) her(O) first(O) published(O) stories(O) )(O) ,(O) the(O) works(O) of(O) Beatrix(B-writer) Potter(I-writer) ,(O) and(O) the(O) novels(B-literary genre) of(O) Gene(B-writer) Stratton-Porter(I-writer) ,(O) and(O) in(O) her(O) teen(O) years(O) ,(O) Herman(B-writer) Melville(I-writer) ,(O) Joseph(B-writer) Conrad(I-writer) and(O) Robert(B-writer) Louis(I-writer) Stevenson(I-writer) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["literary genre","country","event","poem","writer","book","location","organization","magazine","person","award"],"instance":{"id":"79","words":["He","came","to","wide","public","attention","with","his","first","book","Poems","at","the","age","of","twenty-three","in","1930",";","it","was","followed","in","1932","by","The","Orators","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-poem","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-poem","I-poem","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: literary genre, country, event, poem, writer, book, location, organization, magazine, person, award and O.\nSentence: He came to wide public attention with his first book Poems at the age of twenty-three in 1930 ; it was followed in 1932 by The Orators .","prompt_labels":"He(O) came(O) to(O) wide(O) public(O) attention(O) with(O) his(O) first(O) book(O) Poems(B-poem) at(O) the(O) age(O) of(O) twenty-three(O) in(O) 1930(O) ;(O) it(O) was(O) followed(O) in(O) 1932(O) by(O) The(B-poem) Orators(I-poem) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["poem","literary genre","location","organization","country","person","book","award","magazine","writer","event"],"instance":{"id":"80","words":["Julia","was","the","niece","of","poet","and","critic","Matthew","Arnold","and","the","sister","of","Mary","Augusta","Ward","."],"labels":["B-writer","O","O","O","O","O","O","O","B-writer","I-writer","O","O","O","O","B-writer","I-writer","I-writer","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: poem, literary genre, location, organization, country, person, book, award, magazine, writer, event and O.\nSentence: Julia was the niece of poet and critic Matthew Arnold and the sister of Mary Augusta Ward .","prompt_labels":"Julia(B-writer) was(O) the(O) niece(O) of(O) poet(O) and(O) critic(O) Matthew(B-writer) Arnold(I-writer) and(O) the(O) sister(O) of(O) Mary(B-writer) Augusta(I-writer) Ward(I-writer) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["organization","poem","country","magazine","person","book","event","location","literary genre","writer","award"],"instance":{"id":"81","words":["It","was","adapted","by","Talbot","Jennings",",","Tess","Slesinger",",","and","Claudine","West","from","the","play","by","Owen","Davis","and","Donald","Davis",",","which","was","in","itself","based","on","the","1931","The","Good","Earth","by","Nobel","Prize","-winning","author","Pearl","S.","Buck","."],"labels":["O","O","O","O","B-writer","I-writer","O","B-writer","I-writer","O","O","B-writer","I-writer","O","O","O","O","B-writer","I-writer","O","B-writer","I-writer","O","O","O","O","O","O","O","O","O","B-book","I-book","I-book","O","B-award","I-award","O","O","B-writer","I-writer","I-writer","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, poem, country, magazine, person, book, event, location, literary genre, writer, award and O.\nSentence: It was adapted by Talbot Jennings , Tess Slesinger , and Claudine West from the play by Owen Davis and Donald Davis , which was in itself based on the 1931 The Good Earth by Nobel Prize -winning author Pearl S. Buck .","prompt_labels":"It(O) was(O) adapted(O) by(O) Talbot(B-writer) Jennings(I-writer) ,(O) Tess(B-writer) Slesinger(I-writer) ,(O) and(O) Claudine(B-writer) West(I-writer) from(O) the(O) play(O) by(O) Owen(B-writer) Davis(I-writer) and(O) Donald(B-writer) Davis(I-writer) ,(O) which(O) was(O) in(O) itself(O) based(O) on(O) the(O) 1931(O) The(B-book) Good(I-book) Earth(I-book) by(O) Nobel(B-award) Prize(I-award) -winning(O) author(O) Pearl(B-writer) S.(I-writer) Buck(I-writer) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["poem","organization","literary genre","person","magazine","writer","event","country","book","location","award"],"instance":{"id":"82","words":["His","best-known","works","include","Demian",",","Steppenwolf",",","Siddhartha",",","and","The","Glass","Bead","Game",",","each","of","which","explores","an","individual","'s","search","for","authenticity",",","self-knowledge","and","spirituality","."],"labels":["O","O","O","O","B-book","O","B-book","O","B-book","O","O","B-book","I-book","I-book","I-book","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: poem, organization, literary genre, person, magazine, writer, event, country, book, location, award and O.\nSentence: His best-known works include Demian , Steppenwolf , Siddhartha , and The Glass Bead Game , each of which explores an individual 's search for authenticity , self-knowledge and spirituality .","prompt_labels":"His(O) best-known(O) works(O) include(O) Demian(B-book) ,(O) Steppenwolf(B-book) ,(O) Siddhartha(B-book) ,(O) and(O) The(B-book) Glass(I-book) Bead(I-book) Game(I-book) ,(O) each(O) of(O) which(O) explores(O) an(O) individual(O) 's(O) search(O) for(O) authenticity(O) ,(O) self-knowledge(O) and(O) spirituality(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["literary genre","country","person","book","event","writer","magazine","award","location","organization","poem"],"instance":{"id":"83","words":[")","Huxley","received","screen","credit","for","Pride","and","Prejudice","(","1940",")","and","was","paid","for","his","work","on","a","number","of","other","films",",","including","Jane","Eyre","(","1944",")","."],"labels":["O","B-writer","O","B-award","I-award","O","B-book","I-book","I-book","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: literary genre, country, person, book, event, writer, magazine, award, location, organization, poem and O.\nSentence: ) Huxley received screen credit for Pride and Prejudice ( 1940 ) and was paid for his work on a number of other films , including Jane Eyre ( 1944 ) .","prompt_labels":")(O) Huxley(B-writer) received(O) screen(B-award) credit(I-award) for(O) Pride(B-book) and(I-book) Prejudice(I-book) ((O) 1940(O) )(O) and(O) was(O) paid(O) for(O) his(O) work(O) on(O) a(O) number(O) of(O) other(O) films(O) ,(O) including(O) Jane(O) Eyre(O) ((O) 1944(O) )(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["magazine","writer","poem","award","book","country","event","organization","literary genre","location","person"],"instance":{"id":"84","words":["In","New","York",",","he","socialized","at","the","Hydra","Club",",","an","organization","of","New","York","'s","science","fiction","writers",",","including","such","luminaries","as","Isaac","Asimov",",","James","Blish",",","Anthony","Boucher",",","Avram","Davidson",",","Judith","Merril",",","and","Theodore","Sturgeon","."],"labels":["O","B-location","I-location","O","O","O","O","O","B-organization","I-organization","O","O","O","O","B-location","I-location","O","B-literary genre","I-literary genre","O","O","O","O","O","O","B-writer","I-writer","O","B-writer","I-writer","O","B-writer","I-writer","O","B-writer","I-writer","O","B-writer","I-writer","O","O","B-writer","I-writer","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: magazine, writer, poem, award, book, country, event, organization, literary genre, location, person and O.\nSentence: In New York , he socialized at the Hydra Club , an organization of New York 's science fiction writers , including such luminaries as Isaac Asimov , James Blish , Anthony Boucher , Avram Davidson , Judith Merril , and Theodore Sturgeon .","prompt_labels":"In(O) New(B-location) York(I-location) ,(O) he(O) socialized(O) at(O) the(O) Hydra(B-organization) Club(I-organization) ,(O) an(O) organization(O) of(O) New(B-location) York(I-location) 's(O) science(B-literary genre) fiction(I-literary genre) writers(O) ,(O) including(O) such(O) luminaries(O) as(O) Isaac(B-writer) Asimov(I-writer) ,(O) James(B-writer) Blish(I-writer) ,(O) Anthony(B-writer) Boucher(I-writer) ,(O) Avram(B-writer) Davidson(I-writer) ,(O) Judith(B-writer) Merril(I-writer) ,(O) and(O) Theodore(B-writer) Sturgeon(I-writer) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["book","writer","organization","magazine","event","country","person","location","poem","award","literary genre"],"instance":{"id":"85","words":["Wajda","made","two","more","increasingly","accomplished","films",",","which","developed","further","the","anti-war","theme","of","A","Generation",":","Kana","(","1956",")","(","Special","Jury","Prize","at","Cannes","Film","Festival","in","1957",",","shared","with","Bergman","'s","The","Seventh","Seal",")","and","Ashes","and","Diamonds","(","1958",")","with","Zbigniew","Cybulski","."],"labels":["B-person","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-award","I-award","I-award","O","B-event","I-event","I-event","O","O","O","O","O","B-person","O","O","O","O","O","O","O","O","O","O","O","O","O","B-person","I-person","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: book, writer, organization, magazine, event, country, person, location, poem, award, literary genre and O.\nSentence: Wajda made two more increasingly accomplished films , which developed further the anti-war theme of A Generation : Kana ( 1956 ) ( Special Jury Prize at Cannes Film Festival in 1957 , shared with Bergman 's The Seventh Seal ) and Ashes and Diamonds ( 1958 ) with Zbigniew Cybulski .","prompt_labels":"Wajda(B-person) made(O) two(O) more(O) increasingly(O) accomplished(O) films(O) ,(O) which(O) developed(O) further(O) the(O) anti-war(O) theme(O) of(O) A(O) Generation(O) :(O) Kana(O) ((O) 1956(O) )(O) ((O) Special(B-award) Jury(I-award) Prize(I-award) at(O) Cannes(B-event) Film(I-event) Festival(I-event) in(O) 1957(O) ,(O) shared(O) with(O) Bergman(B-person) 's(O) The(O) Seventh(O) Seal(O) )(O) and(O) Ashes(O) and(O) Diamonds(O) ((O) 1958(O) )(O) with(O) Zbigniew(B-person) Cybulski(I-person) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["organization","poem","magazine","person","location","literary genre","event","book","award","writer","country"],"instance":{"id":"86","words":["His","feature","film","debut","came","in","1992","when","he","starred","alongside","Sandrine","Bonnaire","and","Bruno","Ganz","in","Ian","Sellar","'","s","Prague",",","which","premiered","at","the","Cannes","Film","Festival","and","earned","him","the","Best","Actor","award","at","the","Atlantic","Film","Festival","and","a","Scottish","BAFTA","Best","Actor","nomination","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","B-person","I-person","O","B-person","I-person","O","B-writer","I-writer","O","O","B-book","O","O","O","O","O","B-event","I-event","I-event","O","O","O","O","B-award","I-award","I-award","O","O","B-event","I-event","I-event","O","O","B-organization","I-organization","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, poem, magazine, person, location, literary genre, event, book, award, writer, country and O.\nSentence: His feature film debut came in 1992 when he starred alongside Sandrine Bonnaire and Bruno Ganz in Ian Sellar ' s Prague , which premiered at the Cannes Film Festival and earned him the Best Actor award at the Atlantic Film Festival and a Scottish BAFTA Best Actor nomination .","prompt_labels":"His(O) feature(O) film(O) debut(O) came(O) in(O) 1992(O) when(O) he(O) starred(O) alongside(O) Sandrine(B-person) Bonnaire(I-person) and(O) Bruno(B-person) Ganz(I-person) in(O) Ian(B-writer) Sellar(I-writer) '(O) s(O) Prague(B-book) ,(O) which(O) premiered(O) at(O) the(O) Cannes(B-event) Film(I-event) Festival(I-event) and(O) earned(O) him(O) the(O) Best(B-award) Actor(I-award) award(I-award) at(O) the(O) Atlantic(B-event) Film(I-event) Festival(I-event) and(O) a(O) Scottish(B-organization) BAFTA(I-organization) Best(O) Actor(O) nomination(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["literary genre","organization","award","magazine","person","book","event","poem","writer","location","country"],"instance":{"id":"87","words":["The","Great","Hunt","is","a","fantasy","novel","by","United","States","author","Robert","Jordan",",","the","second","book","of","The","Wheel","of","Time","series","."],"labels":["B-book","I-book","I-book","O","O","B-literary genre","I-literary genre","O","B-country","I-country","O","B-writer","I-writer","O","O","O","O","O","B-book","I-book","I-book","I-book","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: literary genre, organization, award, magazine, person, book, event, poem, writer, location, country and O.\nSentence: The Great Hunt is a fantasy novel by United States author Robert Jordan , the second book of The Wheel of Time series .","prompt_labels":"The(B-book) Great(I-book) Hunt(I-book) is(O) a(O) fantasy(B-literary genre) novel(I-literary genre) by(O) United(B-country) States(I-country) author(O) Robert(B-writer) Jordan(I-writer) ,(O) the(O) second(O) book(O) of(O) The(B-book) Wheel(I-book) of(I-book) Time(I-book) series(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["organization","event","award","writer","poem","book","country","location","magazine","person","literary genre"],"instance":{"id":"88","words":["The","Man","in","the","High","Castle","(","1962",")","is","set","in","an","alternate","history","in","which","the","United","States","is","ruled","by","the","victorious","Axis","powers","."],"labels":["B-book","I-book","I-book","I-book","I-book","I-book","O","O","O","O","O","O","O","B-literary genre","I-literary genre","O","O","O","B-country","I-country","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, event, award, writer, poem, book, country, location, magazine, person, literary genre and O.\nSentence: The Man in the High Castle ( 1962 ) is set in an alternate history in which the United States is ruled by the victorious Axis powers .","prompt_labels":"The(B-book) Man(I-book) in(I-book) the(I-book) High(I-book) Castle(I-book) ((O) 1962(O) )(O) is(O) set(O) in(O) an(O) alternate(B-literary genre) history(I-literary genre) in(O) which(O) the(O) United(B-country) States(I-country) is(O) ruled(O) by(O) the(O) victorious(O) Axis(O) powers(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["organization","award","book","poem","event","writer","person","literary genre","location","magazine","country"],"instance":{"id":"89","words":["Powers","has","won","the","World","Fantasy","Award","twice","for","his","critically","acclaimed","novels","Last","Call","and","Declare","."],"labels":["B-writer","O","O","O","B-award","I-award","I-award","O","O","O","O","O","B-literary genre","B-book","I-book","O","B-book","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, award, book, poem, event, writer, person, literary genre, location, magazine, country and O.\nSentence: Powers has won the World Fantasy Award twice for his critically acclaimed novels Last Call and Declare .","prompt_labels":"Powers(B-writer) has(O) won(O) the(O) World(B-award) Fantasy(I-award) Award(I-award) twice(O) for(O) his(O) critically(O) acclaimed(O) novels(B-literary genre) Last(B-book) Call(I-book) and(O) Declare(B-book) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["country","literary genre","person","writer","award","organization","magazine","event","book","poem","location"],"instance":{"id":"90","words":["Confucianism","reached","its","peak","of","influence","during","the","Tang","dynasty","and","Song","dynasty","Dynasties","under","a","rebranded","Confucianism","called","Neo-Confucianism","."],"labels":["O","O","O","O","O","O","O","O","B-country","I-country","O","B-country","I-country","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, literary genre, person, writer, award, organization, magazine, event, book, poem, location and O.\nSentence: Confucianism reached its peak of influence during the Tang dynasty and Song dynasty Dynasties under a rebranded Confucianism called Neo-Confucianism .","prompt_labels":"Confucianism(O) reached(O) its(O) peak(O) of(O) influence(O) during(O) the(O) Tang(B-country) dynasty(I-country) and(O) Song(B-country) dynasty(I-country) Dynasties(O) under(O) a(O) rebranded(O) Confucianism(O) called(O) Neo-Confucianism(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["poem","magazine","literary genre","person","country","writer","award","location","book","event","organization"],"instance":{"id":"91","words":["The","concept","of","a","cross-time","version","of","a","world","war",",","involving","rival","paratime","empires",",","was","developed","in","Fritz","Leiber","'","s","Change","War","series",",","starting","with","the","Hugo","Award","winning","The","Big","Time","(","1958",")",";","followed","by","Richard","C.","Meredith","'","s","Timeliner","trilogy","in","the","1970s",",","Michael","McCollum","'","s","A","Greater","Infinity","(","1982",")","and","John","Barnes","'","Timeline","Wars","trilogy","in","the","1990s","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-writer","I-writer","O","O","B-book","I-book","I-book","O","O","O","O","B-award","I-award","O","B-book","I-book","I-book","O","O","O","O","O","O","B-writer","I-writer","I-writer","O","O","B-book","O","O","O","O","O","B-writer","I-writer","O","O","B-book","I-book","I-book","O","O","O","O","B-writer","I-writer","O","B-book","I-book","I-book","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: poem, magazine, literary genre, person, country, writer, award, location, book, event, organization and O.\nSentence: The concept of a cross-time version of a world war , involving rival paratime empires , was developed in Fritz Leiber ' s Change War series , starting with the Hugo Award winning The Big Time ( 1958 ) ; followed by Richard C. Meredith ' s Timeliner trilogy in the 1970s , Michael McCollum ' s A Greater Infinity ( 1982 ) and John Barnes ' Timeline Wars trilogy in the 1990s .","prompt_labels":"The(O) concept(O) of(O) a(O) cross-time(O) version(O) of(O) a(O) world(O) war(O) ,(O) involving(O) rival(O) paratime(O) empires(O) ,(O) was(O) developed(O) in(O) Fritz(B-writer) Leiber(I-writer) '(O) s(O) Change(B-book) War(I-book) series(I-book) ,(O) starting(O) with(O) the(O) Hugo(B-award) Award(I-award) winning(O) The(B-book) Big(I-book) Time(I-book) ((O) 1958(O) )(O) ;(O) followed(O) by(O) Richard(B-writer) C.(I-writer) Meredith(I-writer) '(O) s(O) Timeliner(B-book) trilogy(O) in(O) the(O) 1970s(O) ,(O) Michael(B-writer) McCollum(I-writer) '(O) s(O) A(B-book) Greater(I-book) Infinity(I-book) ((O) 1982(O) )(O) and(O) John(B-writer) Barnes(I-writer) '(O) Timeline(B-book) Wars(I-book) trilogy(I-book) in(O) the(O) 1990s(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["organization","event","poem","person","book","country","magazine","award","location","writer","literary genre"],"instance":{"id":"92","words":["Before","writing","Dracula",",","Stoker","met","rmin","Vmbry",",","a","Hungarian-Jewish","writer","and","traveller","(","born","in","Szent-Gyrgy",",","Kingdom","of","Hungary","now","Svt","Jur",",","Slovakia",")","."],"labels":["O","O","B-book","O","B-writer","O","B-writer","I-writer","O","O","O","O","O","O","O","O","O","B-location","O","B-country","I-country","I-country","O","B-location","I-location","O","B-country","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, event, poem, person, book, country, magazine, award, location, writer, literary genre and O.\nSentence: Before writing Dracula , Stoker met rmin Vmbry , a Hungarian-Jewish writer and traveller ( born in Szent-Gyrgy , Kingdom of Hungary now Svt Jur , Slovakia ) .","prompt_labels":"Before(O) writing(O) Dracula(B-book) ,(O) Stoker(B-writer) met(O) rmin(B-writer) Vmbry(I-writer) ,(O) a(O) Hungarian-Jewish(O) writer(O) and(O) traveller(O) ((O) born(O) in(O) Szent-Gyrgy(B-location) ,(O) Kingdom(B-country) of(I-country) Hungary(I-country) now(O) Svt(B-location) Jur(I-location) ,(O) Slovakia(B-country) )(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["country","award","event","magazine","organization","book","poem","literary genre","writer","person","location"],"instance":{"id":"93","words":["The","crowds","were","delighted","with","the","stories","of","romances",",","the","wickedness","of","Macaire",",","and","the","misfortunes","of","Blanziflor",",","the","terrors","of","the","Babilonia","Infernale","and","the","blessedness","of","the","Gerusalemme","celeste",",","and","the","singers","of","religious","poetry","vied","with","those","of","the","chansons","de","geste","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","B-poem","O","O","O","O","O","B-poem","O","O","O","O","O","B-poem","I-poem","O","O","O","O","O","B-poem","I-poem","O","O","O","O","O","O","B-literary genre","O","O","O","O","O","B-poem","I-poem","I-poem","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, award, event, magazine, organization, book, poem, literary genre, writer, person, location and O.\nSentence: The crowds were delighted with the stories of romances , the wickedness of Macaire , and the misfortunes of Blanziflor , the terrors of the Babilonia Infernale and the blessedness of the Gerusalemme celeste , and the singers of religious poetry vied with those of the chansons de geste .","prompt_labels":"The(O) crowds(O) were(O) delighted(O) with(O) the(O) stories(O) of(O) romances(O) ,(O) the(O) wickedness(O) of(O) Macaire(B-poem) ,(O) and(O) the(O) misfortunes(O) of(O) Blanziflor(B-poem) ,(O) the(O) terrors(O) of(O) the(O) Babilonia(B-poem) Infernale(I-poem) and(O) the(O) blessedness(O) of(O) the(O) Gerusalemme(B-poem) celeste(I-poem) ,(O) and(O) the(O) singers(O) of(O) religious(O) poetry(B-literary genre) vied(O) with(O) those(O) of(O) the(O) chansons(B-poem) de(I-poem) geste(I-poem) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["country","event","poem","person","book","writer","magazine","organization","literary genre","award","location"],"instance":{"id":"94","words":["Michael","Wigglesworth","(","1631-1705",")","was","a","Puritan","minister",",","doctor","and","poet","whose","poem","The","Day","of","Doom","was","a","bestseller","in","early","New","England","."],"labels":["B-writer","I-writer","O","O","O","O","O","O","O","O","O","O","O","O","B-literary genre","B-poem","I-poem","I-poem","I-poem","O","O","O","O","O","B-location","I-location","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, event, poem, person, book, writer, magazine, organization, literary genre, award, location and O.\nSentence: Michael Wigglesworth ( 1631-1705 ) was a Puritan minister , doctor and poet whose poem The Day of Doom was a bestseller in early New England .","prompt_labels":"Michael(B-writer) Wigglesworth(I-writer) ((O) 1631-1705(O) )(O) was(O) a(O) Puritan(O) minister(O) ,(O) doctor(O) and(O) poet(O) whose(O) poem(B-literary genre) The(B-poem) Day(I-poem) of(I-poem) Doom(I-poem) was(O) a(O) bestseller(O) in(O) early(O) New(B-location) England(I-location) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["person","location","organization","event","writer","magazine","literary genre","poem","award","book","country"],"instance":{"id":"95","words":["In","1991",",","Puzo","'s","speculative","fiction","The","Fourth","K","was","published",";","it","hypothesizes","a","member","of","the","Kennedy","family","who","becomes","President","of","the","United","States","early","in","the","2000s","."],"labels":["O","O","O","B-writer","O","B-literary genre","I-literary genre","B-book","I-book","I-book","O","O","O","O","O","O","O","O","O","B-person","O","O","O","O","O","O","B-country","I-country","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, location, organization, event, writer, magazine, literary genre, poem, award, book, country and O.\nSentence: In 1991 , Puzo 's speculative fiction The Fourth K was published ; it hypothesizes a member of the Kennedy family who becomes President of the United States early in the 2000s .","prompt_labels":"In(O) 1991(O) ,(O) Puzo(B-writer) 's(O) speculative(B-literary genre) fiction(I-literary genre) The(B-book) Fourth(I-book) K(I-book) was(O) published(O) ;(O) it(O) hypothesizes(O) a(O) member(O) of(O) the(O) Kennedy(B-person) family(O) who(O) becomes(O) President(O) of(O) the(O) United(B-country) States(I-country) early(O) in(O) the(O) 2000s(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["country","organization","person","book","award","magazine","event","poem","literary genre","location","writer"],"instance":{"id":"96","words":["The","friends","joined","in","keeping","up","the","delusion","that","Erskine","and","not","Scott","was","the","author","of","the","portions","of","The","Bridal","of","Triermain",",","and","wrote","a","preface","intended","to","throw","out","the","knowing","ones","."],"labels":["O","O","O","O","O","O","O","O","O","B-location","O","O","B-location","O","O","O","O","O","O","O","B-poem","I-poem","I-poem","I-poem","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, organization, person, book, award, magazine, event, poem, literary genre, location, writer and O.\nSentence: The friends joined in keeping up the delusion that Erskine and not Scott was the author of the portions of The Bridal of Triermain , and wrote a preface intended to throw out the knowing ones .","prompt_labels":"The(O) friends(O) joined(O) in(O) keeping(O) up(O) the(O) delusion(O) that(O) Erskine(B-location) and(O) not(O) Scott(B-location) was(O) the(O) author(O) of(O) the(O) portions(O) of(O) The(B-poem) Bridal(I-poem) of(I-poem) Triermain(I-poem) ,(O) and(O) wrote(O) a(O) preface(O) intended(O) to(O) throw(O) out(O) the(O) knowing(O) ones(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["writer","country","magazine","award","book","organization","poem","location","literary genre","person","event"],"instance":{"id":"97","words":["She","wrote","several","popular","comedies",",","of","which","Das","Testament","is","the","best",",","and","translated","The","Spectator","(","9","volumes",",","1739-1743",")",",","Alexander","Pope","'","s","Rape","of","the","Lock","(","1744",")","and","other","English","and","French","works","."],"labels":["O","O","O","O","B-literary genre","O","O","O","B-book","I-book","O","O","O","O","O","O","B-magazine","I-magazine","O","O","O","O","O","O","O","B-writer","I-writer","O","O","B-book","I-book","I-book","I-book","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: writer, country, magazine, award, book, organization, poem, location, literary genre, person, event and O.\nSentence: She wrote several popular comedies , of which Das Testament is the best , and translated The Spectator ( 9 volumes , 1739-1743 ) , Alexander Pope ' s Rape of the Lock ( 1744 ) and other English and French works .","prompt_labels":"She(O) wrote(O) several(O) popular(O) comedies(B-literary genre) ,(O) of(O) which(O) Das(B-book) Testament(I-book) is(O) the(O) best(O) ,(O) and(O) translated(O) The(B-magazine) Spectator(I-magazine) ((O) 9(O) volumes(O) ,(O) 1739-1743(O) )(O) ,(O) Alexander(B-writer) Pope(I-writer) '(O) s(O) Rape(B-book) of(I-book) the(I-book) Lock(I-book) ((O) 1744(O) )(O) and(O) other(O) English(O) and(O) French(O) works(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["writer","location","poem","event","organization","book","literary genre","person","award","magazine","country"],"instance":{"id":"98","words":["The","title","page","of","the","collection","Cathay","(","1915",")",",","refers","to","the","poet","Rihaku",",","the","pronunciation","in","Japanese","of","the","Tang","dynasty","Chinese","poet",",","Li","Bai",",","whose","poems","were","much","beloved","in","China","and","Japan","for","their","technical","mastery","and","much","translated","in","the","West","because","of","their","seeming","simplicity","."],"labels":["O","O","O","O","O","O","B-book","O","O","O","O","O","O","O","O","B-writer","O","O","O","O","O","O","O","B-country","I-country","O","O","O","B-writer","I-writer","O","O","B-literary genre","O","O","O","O","B-country","O","B-country","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: writer, location, poem, event, organization, book, literary genre, person, award, magazine, country and O.\nSentence: The title page of the collection Cathay ( 1915 ) , refers to the poet Rihaku , the pronunciation in Japanese of the Tang dynasty Chinese poet , Li Bai , whose poems were much beloved in China and Japan for their technical mastery and much translated in the West because of their seeming simplicity .","prompt_labels":"The(O) title(O) page(O) of(O) the(O) collection(O) Cathay(B-book) ((O) 1915(O) )(O) ,(O) refers(O) to(O) the(O) poet(O) Rihaku(B-writer) ,(O) the(O) pronunciation(O) in(O) Japanese(O) of(O) the(O) Tang(B-country) dynasty(I-country) Chinese(O) poet(O) ,(O) Li(B-writer) Bai(I-writer) ,(O) whose(O) poems(B-literary genre) were(O) much(O) beloved(O) in(O) China(B-country) and(O) Japan(B-country) for(O) their(O) technical(O) mastery(O) and(O) much(O) translated(O) in(O) the(O) West(O) because(O) of(O) their(O) seeming(O) simplicity(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["award","country","poem","literary genre","organization","book","magazine","person","event","writer","location"],"instance":{"id":"99","words":["Davy","was","a","baronet",",","President","of","the","Royal","Society","(","PRS",")",",","Royal","Irish","Academy",",","and","Geological","Society","of","London","."],"labels":["B-person","O","O","O","O","O","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, country, poem, literary genre, organization, book, magazine, person, event, writer, location and O.\nSentence: Davy was a baronet , President of the Royal Society ( PRS ) , Royal Irish Academy , and Geological Society of London .","prompt_labels":"Davy(B-person) was(O) a(O) baronet(O) ,(O) President(O) of(O) the(O) Royal(O) Society(O) ((O) PRS(O) )(O) ,(O) Royal(B-organization) Irish(I-organization) Academy(I-organization) ,(O) and(O) Geological(B-organization) Society(I-organization) of(I-organization) London(I-organization) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["writer","event","country","award","magazine","person","book","poem","location","organization","literary genre"],"instance":{"id":"100","words":["During","his","first","years","as","bishop",",","Athanasius","visited","the","churches","of","his","territory",",","which","at","that","time","included","all","of","Egypt","and","Libya","."],"labels":["O","O","O","O","O","O","O","B-writer","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-country","O","B-country","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: writer, event, country, award, magazine, person, book, poem, location, organization, literary genre and O.\nSentence: During his first years as bishop , Athanasius visited the churches of his territory , which at that time included all of Egypt and Libya .","prompt_labels":"During(O) his(O) first(O) years(O) as(O) bishop(O) ,(O) Athanasius(B-writer) visited(O) the(O) churches(O) of(O) his(O) territory(O) ,(O) which(O) at(O) that(O) time(O) included(O) all(O) of(O) Egypt(B-country) and(O) Libya(B-country) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["event","award","book","person","writer","location","poem","organization","magazine","country","literary genre"],"instance":{"id":"101","words":["Nimzowitsch","'s","vanity","and","faith","in","his","ideas","of","overprotection","provoked","Hans","Kmoch","to","write","a","parody","about","him","in","February","1928","in","the","Wiener","Schachzeitung","."],"labels":["B-person","O","O","O","O","O","O","O","O","O","O","B-person","I-person","O","O","O","O","O","O","O","O","O","O","O","B-magazine","I-magazine","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, award, book, person, writer, location, poem, organization, magazine, country, literary genre and O.\nSentence: Nimzowitsch 's vanity and faith in his ideas of overprotection provoked Hans Kmoch to write a parody about him in February 1928 in the Wiener Schachzeitung .","prompt_labels":"Nimzowitsch(B-person) 's(O) vanity(O) and(O) faith(O) in(O) his(O) ideas(O) of(O) overprotection(O) provoked(O) Hans(B-person) Kmoch(I-person) to(O) write(O) a(O) parody(O) about(O) him(O) in(O) February(O) 1928(O) in(O) the(O) Wiener(B-magazine) Schachzeitung(I-magazine) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["magazine","writer","organization","location","event","poem","book","award","country","literary genre","person"],"instance":{"id":"102","words":["He","liked","Pedro","Caldern","de","la","Barca",",","Lope","de","Vega",",","Miguel","de","Cervantes",",","and","especially","Baltasar","Gracin","."],"labels":["O","O","B-writer","I-writer","I-writer","I-writer","I-writer","O","B-writer","I-writer","I-writer","O","B-writer","I-writer","I-writer","O","O","O","B-writer","I-writer","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: magazine, writer, organization, location, event, poem, book, award, country, literary genre, person and O.\nSentence: He liked Pedro Caldern de la Barca , Lope de Vega , Miguel de Cervantes , and especially Baltasar Gracin .","prompt_labels":"He(O) liked(O) Pedro(B-writer) Caldern(I-writer) de(I-writer) la(I-writer) Barca(I-writer) ,(O) Lope(B-writer) de(I-writer) Vega(I-writer) ,(O) Miguel(B-writer) de(I-writer) Cervantes(I-writer) ,(O) and(O) especially(O) Baltasar(B-writer) Gracin(I-writer) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["country","poem","literary genre","location","book","organization","writer","award","person","magazine","event"],"instance":{"id":"103","words":["Shortly","after",",","he","signed","a","contract","with","RCA","Victor","and","one","of","his","early","singles",",","Trouble","in","the","Amen","Corner","reached","the","1960","country","music","Top","25","."],"labels":["O","O","O","O","O","O","O","O","B-organization","I-organization","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, poem, literary genre, location, book, organization, writer, award, person, magazine, event and O.\nSentence: Shortly after , he signed a contract with RCA Victor and one of his early singles , Trouble in the Amen Corner reached the 1960 country music Top 25 .","prompt_labels":"Shortly(O) after(O) ,(O) he(O) signed(O) a(O) contract(O) with(O) RCA(B-organization) Victor(I-organization) and(O) one(O) of(O) his(O) early(O) singles(O) ,(O) Trouble(O) in(O) the(O) Amen(O) Corner(O) reached(O) the(O) 1960(O) country(O) music(O) Top(O) 25(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["award","literary genre","book","event","writer","person","location","magazine","organization","poem","country"],"instance":{"id":"104","words":["Examples","include","the","chansons","de","geste",",","Macaire",",","the","Entre","en","Espagne","written","by","Niccola","of","Padua",",","the","Prise","de","Pampelune",",","and","others","."],"labels":["O","O","O","B-poem","I-poem","I-poem","O","B-poem","O","O","B-poem","I-poem","I-poem","O","O","B-writer","I-writer","I-writer","O","O","B-poem","I-poem","I-poem","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, literary genre, book, event, writer, person, location, magazine, organization, poem, country and O.\nSentence: Examples include the chansons de geste , Macaire , the Entre en Espagne written by Niccola of Padua , the Prise de Pampelune , and others .","prompt_labels":"Examples(O) include(O) the(O) chansons(B-poem) de(I-poem) geste(I-poem) ,(O) Macaire(B-poem) ,(O) the(O) Entre(B-poem) en(I-poem) Espagne(I-poem) written(O) by(O) Niccola(B-writer) of(I-writer) Padua(I-writer) ,(O) the(O) Prise(B-poem) de(I-poem) Pampelune(I-poem) ,(O) and(O) others(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["book","literary genre","poem","magazine","writer","organization","event","location","country","award","person"],"instance":{"id":"105","words":["In","2000","Atwood","published","her","tenth","novel",",","The","Blind","Assassin",",","to","critical","acclaim",",","winning","both","the","Booker","Prize"],"labels":["O","O","B-writer","O","O","O","B-literary genre","O","B-book","I-book","I-book","O","O","O","O","O","O","O","O","B-award","I-award"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: book, literary genre, poem, magazine, writer, organization, event, location, country, award, person and O.\nSentence: In 2000 Atwood published her tenth novel , The Blind Assassin , to critical acclaim , winning both the Booker Prize","prompt_labels":"In(O) 2000(O) Atwood(B-writer) published(O) her(O) tenth(O) novel(B-literary genre) ,(O) The(B-book) Blind(I-book) Assassin(I-book) ,(O) to(O) critical(O) acclaim(O) ,(O) winning(O) both(O) the(O) Booker(B-award) Prize(I-award)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["poem","book","award","person","writer","magazine","organization","location","country","literary genre","event"],"instance":{"id":"106","words":["91","A","subsequent","journey","through","the","British","East","Africa","colonies","and","the","Belgian","Congo","formed","the","basis","of","two","books",";","the","travelogue","Remote","People","(","1931",")","and","the","comic","novel","Black","Mischief","(","1932",")",".","Sykes",",","p","."],"labels":["O","O","O","O","O","O","B-location","I-location","I-location","I-location","O","O","B-country","I-country","O","O","O","O","O","O","O","O","O","B-book","I-book","O","O","O","O","O","B-literary genre","I-literary genre","B-book","I-book","O","O","O","O","B-writer","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: poem, book, award, person, writer, magazine, organization, location, country, literary genre, event and O.\nSentence: 91 A subsequent journey through the British East Africa colonies and the Belgian Congo formed the basis of two books ; the travelogue Remote People ( 1931 ) and the comic novel Black Mischief ( 1932 ) . Sykes , p .","prompt_labels":"91(O) A(O) subsequent(O) journey(O) through(O) the(O) British(B-location) East(I-location) Africa(I-location) colonies(I-location) and(O) the(O) Belgian(B-country) Congo(I-country) formed(O) the(O) basis(O) of(O) two(O) books(O) ;(O) the(O) travelogue(O) Remote(B-book) People(I-book) ((O) 1931(O) )(O) and(O) the(O) comic(B-literary genre) novel(I-literary genre) Black(B-book) Mischief(I-book) ((O) 1932(O) )(O) .(O) Sykes(B-writer) ,(O) p(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["literary genre","location","award","magazine","country","book","writer","poem","person","event","organization"],"instance":{"id":"107","words":["The","work","was","such","a","popular","success","that","the","poet","wrote","a","sequel",",","Remedia","Amoris","(","Remedies","for","Love",")","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-poem","I-poem","O","B-poem","I-poem","I-poem","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: literary genre, location, award, magazine, country, book, writer, poem, person, event, organization and O.\nSentence: The work was such a popular success that the poet wrote a sequel , Remedia Amoris ( Remedies for Love ) .","prompt_labels":"The(O) work(O) was(O) such(O) a(O) popular(O) success(O) that(O) the(O) poet(O) wrote(O) a(O) sequel(O) ,(O) Remedia(B-poem) Amoris(I-poem) ((O) Remedies(B-poem) for(I-poem) Love(I-poem) )(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["event","country","person","organization","magazine","award","poem","literary genre","writer","book","location"],"instance":{"id":"108","words":["As","early","as","the","13th","century","when","Dante","Alighieri","depicted","him","in","Limbo","alongside","the","virtuous","non-Christian","thinkers","in","his","Divine","Comedy","such","as","Virgil",",","Averroes",",","Homer",",","Horace",",","Ovid",",","Lucan",",","Socrates",",","Plato",",","and","Saladin","."],"labels":["O","O","O","O","O","O","O","B-writer","I-writer","O","O","O","O","O","O","O","O","O","O","O","B-poem","I-poem","O","O","B-person","O","B-person","O","B-person","O","B-person","O","B-person","O","B-person","O","B-person","O","B-person","O","O","B-person","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, country, person, organization, magazine, award, poem, literary genre, writer, book, location and O.\nSentence: As early as the 13th century when Dante Alighieri depicted him in Limbo alongside the virtuous non-Christian thinkers in his Divine Comedy such as Virgil , Averroes , Homer , Horace , Ovid , Lucan , Socrates , Plato , and Saladin .","prompt_labels":"As(O) early(O) as(O) the(O) 13th(O) century(O) when(O) Dante(B-writer) Alighieri(I-writer) depicted(O) him(O) in(O) Limbo(O) alongside(O) the(O) virtuous(O) non-Christian(O) thinkers(O) in(O) his(O) Divine(B-poem) Comedy(I-poem) such(O) as(O) Virgil(B-person) ,(O) Averroes(B-person) ,(O) Homer(B-person) ,(O) Horace(B-person) ,(O) Ovid(B-person) ,(O) Lucan(B-person) ,(O) Socrates(B-person) ,(O) Plato(B-person) ,(O) and(O) Saladin(B-person) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["book","writer","location","event","literary genre","award","country","organization","poem","magazine","person"],"instance":{"id":"109","words":["His","third","book",",","and","second","novel",",","A","Fine","Balance","(","1995",")",",","won","the","second","annual","Giller","Prize","in","1995",",","and","the","Los","Angeles","Times","Book","Prize","for","Fiction","in","1996","."],"labels":["O","O","O","O","O","O","B-literary genre","O","B-book","I-book","I-book","O","O","O","O","O","O","O","O","B-award","I-award","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","I-award","I-award","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: book, writer, location, event, literary genre, award, country, organization, poem, magazine, person and O.\nSentence: His third book , and second novel , A Fine Balance ( 1995 ) , won the second annual Giller Prize in 1995 , and the Los Angeles Times Book Prize for Fiction in 1996 .","prompt_labels":"His(O) third(O) book(O) ,(O) and(O) second(O) novel(B-literary genre) ,(O) A(B-book) Fine(I-book) Balance(I-book) ((O) 1995(O) )(O) ,(O) won(O) the(O) second(O) annual(O) Giller(B-award) Prize(I-award) in(O) 1995(O) ,(O) and(O) the(O) Los(B-award) Angeles(I-award) Times(I-award) Book(I-award) Prize(I-award) for(I-award) Fiction(I-award) in(O) 1996(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["poem","event","person","location","writer","magazine","literary genre","award","organization","country","book"],"instance":{"id":"110","words":["Nominated","for","Academy","Awards","in","nine","categories",",","it","won","an","Academy","Award","for","Best","Original","Screenplay","by","Herman","J.","Mankiewicz","and","Welles","."],"labels":["O","O","B-award","I-award","O","O","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","I-award","O","B-writer","I-writer","I-writer","O","B-writer","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: poem, event, person, location, writer, magazine, literary genre, award, organization, country, book and O.\nSentence: Nominated for Academy Awards in nine categories , it won an Academy Award for Best Original Screenplay by Herman J. Mankiewicz and Welles .","prompt_labels":"Nominated(O) for(O) Academy(B-award) Awards(I-award) in(O) nine(O) categories(O) ,(O) it(O) won(O) an(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Original(I-award) Screenplay(I-award) by(O) Herman(B-writer) J.(I-writer) Mankiewicz(I-writer) and(O) Welles(B-writer) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["location","organization","award","country","magazine","person","literary genre","book","writer","event","poem"],"instance":{"id":"111","words":["The","three","films","garnered","prestigious","international","awards",",","including","the","Golden","Lion","for","Best","Film","at","the","Venice","Film","Festival","and","the","Silver","Bear","for","Best","Director","at","the","44th","Berlin","International","Film","Festival",",","in","addition","to","three","Academy","Awards","nominations","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-award","I-award","O","O","O","O","O","B-event","I-event","I-event","O","O","B-award","I-award","I-award","I-award","I-award","O","O","B-event","I-event","I-event","I-event","I-event","O","O","O","O","O","B-award","I-award","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, organization, award, country, magazine, person, literary genre, book, writer, event, poem and O.\nSentence: The three films garnered prestigious international awards , including the Golden Lion for Best Film at the Venice Film Festival and the Silver Bear for Best Director at the 44th Berlin International Film Festival , in addition to three Academy Awards nominations .","prompt_labels":"The(O) three(O) films(O) garnered(O) prestigious(O) international(O) awards(O) ,(O) including(O) the(O) Golden(B-award) Lion(I-award) for(O) Best(O) Film(O) at(O) the(O) Venice(B-event) Film(I-event) Festival(I-event) and(O) the(O) Silver(B-award) Bear(I-award) for(I-award) Best(I-award) Director(I-award) at(O) the(O) 44th(B-event) Berlin(I-event) International(I-event) Film(I-event) Festival(I-event) ,(O) in(O) addition(O) to(O) three(O) Academy(B-award) Awards(I-award) nominations(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["book","country","writer","event","award","person","literary genre","location","magazine","organization","poem"],"instance":{"id":"112","words":["Tamsin","Greig","narrated",",","and","the","cast","included","Nicky","Henson","as","Napoleon",",","Toby","Jones","as","the","propagandist","Squealer",",","and","Ralph","Ineson","as","Boxer","."],"labels":["B-person","I-person","O","O","O","O","O","O","B-person","I-person","O","B-person","O","B-person","I-person","O","O","O","O","O","O","B-person","I-person","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: book, country, writer, event, award, person, literary genre, location, magazine, organization, poem and O.\nSentence: Tamsin Greig narrated , and the cast included Nicky Henson as Napoleon , Toby Jones as the propagandist Squealer , and Ralph Ineson as Boxer .","prompt_labels":"Tamsin(B-person) Greig(I-person) narrated(O) ,(O) and(O) the(O) cast(O) included(O) Nicky(B-person) Henson(I-person) as(O) Napoleon(B-person) ,(O) Toby(B-person) Jones(I-person) as(O) the(O) propagandist(O) Squealer(O) ,(O) and(O) Ralph(B-person) Ineson(I-person) as(O) Boxer(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["organization","person","location","writer","event","award","book","country","literary genre","magazine","poem"],"instance":{"id":"113","words":["The","Door","into","Summer","is","a","science","fiction","novel","by","American","writer","Robert","A.","Heinlein",",","originally","serialized","in","The","Magazine","of","Fantasy","&","Science","Fiction","(","October",",","November",",","December","1956",",","with","covers","and","interior","illustrations","by","Kelly","Freas",")","."],"labels":["B-book","I-book","I-book","I-book","O","O","B-literary genre","I-literary genre","I-literary genre","O","O","O","B-writer","I-writer","I-writer","O","O","O","O","B-magazine","I-magazine","I-magazine","I-magazine","I-magazine","I-magazine","I-magazine","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-writer","I-writer","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, person, location, writer, event, award, book, country, literary genre, magazine, poem and O.\nSentence: The Door into Summer is a science fiction novel by American writer Robert A. Heinlein , originally serialized in The Magazine of Fantasy & Science Fiction ( October , November , December 1956 , with covers and interior illustrations by Kelly Freas ) .","prompt_labels":"The(B-book) Door(I-book) into(I-book) Summer(I-book) is(O) a(O) science(B-literary genre) fiction(I-literary genre) novel(I-literary genre) by(O) American(O) writer(O) Robert(B-writer) A.(I-writer) Heinlein(I-writer) ,(O) originally(O) serialized(O) in(O) The(B-magazine) Magazine(I-magazine) of(I-magazine) Fantasy(I-magazine) &(I-magazine) Science(I-magazine) Fiction(I-magazine) ((O) October(O) ,(O) November(O) ,(O) December(O) 1956(O) ,(O) with(O) covers(O) and(O) interior(O) illustrations(O) by(O) Kelly(B-writer) Freas(I-writer) )(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["organization","award","event","literary genre","location","magazine","country","writer","poem","person","book"],"instance":{"id":"114","words":["Writing","for","The","Spectator","in","1936",",","Graham","Greene","gave","the","film","a","good","review",",","describing","it","as","an","honest",",","interesting","and","well-made","picture","."],"labels":["O","O","B-magazine","I-magazine","O","O","O","B-writer","I-writer","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, award, event, literary genre, location, magazine, country, writer, poem, person, book and O.\nSentence: Writing for The Spectator in 1936 , Graham Greene gave the film a good review , describing it as an honest , interesting and well-made picture .","prompt_labels":"Writing(O) for(O) The(B-magazine) Spectator(I-magazine) in(O) 1936(O) ,(O) Graham(B-writer) Greene(I-writer) gave(O) the(O) film(O) a(O) good(O) review(O) ,(O) describing(O) it(O) as(O) an(O) honest(O) ,(O) interesting(O) and(O) well-made(O) picture(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["literary genre","award","event","magazine","writer","organization","book","location","person","poem","country"],"instance":{"id":"115","words":["He","particularly","revered","Johann","Wolfgang","von","Goethe",",","Petrarch",",","Pedro","Caldern","de","la","Barca","and","William","Shakespeare","."],"labels":["O","O","O","B-writer","I-writer","I-writer","I-writer","O","B-writer","O","B-writer","I-writer","I-writer","I-writer","I-writer","O","B-writer","I-writer","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: literary genre, award, event, magazine, writer, organization, book, location, person, poem, country and O.\nSentence: He particularly revered Johann Wolfgang von Goethe , Petrarch , Pedro Caldern de la Barca and William Shakespeare .","prompt_labels":"He(O) particularly(O) revered(O) Johann(B-writer) Wolfgang(I-writer) von(I-writer) Goethe(I-writer) ,(O) Petrarch(B-writer) ,(O) Pedro(B-writer) Caldern(I-writer) de(I-writer) la(I-writer) Barca(I-writer) and(O) William(B-writer) Shakespeare(I-writer) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["award","book","literary genre","organization","person","country","poem","location","event","magazine","writer"],"instance":{"id":"116","words":["In","1963","Il","Gattopardo","was","made","into","a","film",",","directed","by","Luchino","Visconti","and","starring","Burt","Lancaster",",","Alain","Delon",",","and","Claudia","Cardinale",";","it","won","the","Palme","d","'Or","at","the","Cannes","Film","Festival","."],"labels":["O","O","B-book","I-book","O","O","O","O","O","O","O","O","B-person","I-person","O","O","B-person","I-person","O","B-person","I-person","O","O","B-person","I-person","O","O","O","O","B-award","I-award","I-award","O","O","B-event","I-event","I-event","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, book, literary genre, organization, person, country, poem, location, event, magazine, writer and O.\nSentence: In 1963 Il Gattopardo was made into a film , directed by Luchino Visconti and starring Burt Lancaster , Alain Delon , and Claudia Cardinale ; it won the Palme d 'Or at the Cannes Film Festival .","prompt_labels":"In(O) 1963(O) Il(B-book) Gattopardo(I-book) was(O) made(O) into(O) a(O) film(O) ,(O) directed(O) by(O) Luchino(B-person) Visconti(I-person) and(O) starring(O) Burt(B-person) Lancaster(I-person) ,(O) Alain(B-person) Delon(I-person) ,(O) and(O) Claudia(B-person) Cardinale(I-person) ;(O) it(O) won(O) the(O) Palme(B-award) d(I-award) 'Or(I-award) at(O) the(O) Cannes(B-event) Film(I-event) Festival(I-event) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["book","magazine","country","location","writer","event","award","organization","person","literary genre","poem"],"instance":{"id":"117","words":["Rand","'s","contemporary","admirers","included","fellow","novelists",",","such","as","Ira","Levin",",","Kay","Nolte","Smith","and","L.","Neil","Smith",";","and","later","writers","such","as","Erika","Holzer","and","Terry","Goodkind","have","been","influenced","by","her","."],"labels":["B-writer","O","O","O","O","O","O","O","O","O","B-writer","I-writer","O","B-writer","I-writer","I-writer","O","B-writer","I-writer","I-writer","O","O","O","O","O","O","B-writer","I-writer","O","B-writer","I-writer","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: book, magazine, country, location, writer, event, award, organization, person, literary genre, poem and O.\nSentence: Rand 's contemporary admirers included fellow novelists , such as Ira Levin , Kay Nolte Smith and L. Neil Smith ; and later writers such as Erika Holzer and Terry Goodkind have been influenced by her .","prompt_labels":"Rand(B-writer) 's(O) contemporary(O) admirers(O) included(O) fellow(O) novelists(O) ,(O) such(O) as(O) Ira(B-writer) Levin(I-writer) ,(O) Kay(B-writer) Nolte(I-writer) Smith(I-writer) and(O) L.(B-writer) Neil(I-writer) Smith(I-writer) ;(O) and(O) later(O) writers(O) such(O) as(O) Erika(B-writer) Holzer(I-writer) and(O) Terry(B-writer) Goodkind(I-writer) have(O) been(O) influenced(O) by(O) her(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["location","country","magazine","person","award","book","event","poem","writer","organization","literary genre"],"instance":{"id":"118","words":["Liszt","included","Weiheimer","'s","symphony","on","Friedrich","Schiller","'","s","Ritter","Toggenburg","on","the","program","for","the","court","concerts","that","he","conducted","on","13","March","1860","."],"labels":["B-writer","O","B-writer","O","O","O","B-writer","I-writer","O","O","B-poem","I-poem","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, country, magazine, person, award, book, event, poem, writer, organization, literary genre and O.\nSentence: Liszt included Weiheimer 's symphony on Friedrich Schiller ' s Ritter Toggenburg on the program for the court concerts that he conducted on 13 March 1860 .","prompt_labels":"Liszt(B-writer) included(O) Weiheimer(B-writer) 's(O) symphony(O) on(O) Friedrich(B-writer) Schiller(I-writer) '(O) s(O) Ritter(B-poem) Toggenburg(I-poem) on(O) the(O) program(O) for(O) the(O) court(O) concerts(O) that(O) he(O) conducted(O) on(O) 13(O) March(O) 1860(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["literary genre","magazine","poem","award","organization","person","country","book","event","location","writer"],"instance":{"id":"119","words":["The","film","was","well","received","critically","in","the","festival","circuit",",","winning","awards","at","the","1997","Fantasia","Festival","in","Montral",",","and","Fantasporto","Film","Festival","in","Portugal","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-event","I-event","O","B-location","O","O","B-event","I-event","I-event","O","B-location","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: literary genre, magazine, poem, award, organization, person, country, book, event, location, writer and O.\nSentence: The film was well received critically in the festival circuit , winning awards at the 1997 Fantasia Festival in Montral , and Fantasporto Film Festival in Portugal .","prompt_labels":"The(O) film(O) was(O) well(O) received(O) critically(O) in(O) the(O) festival(O) circuit(O) ,(O) winning(O) awards(O) at(O) the(O) 1997(O) Fantasia(B-event) Festival(I-event) in(O) Montral(B-location) ,(O) and(O) Fantasporto(B-event) Film(I-event) Festival(I-event) in(O) Portugal(B-location) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["poem","person","location","literary genre","country","book","organization","writer","magazine","award","event"],"instance":{"id":"120","words":["The","only","completed","screenplay",",","Heaven",",","was","filmed","by","Tom","Tykwer","and","premiered","in","2002","at","the","Berlin","International","Film","Festival","."],"labels":["O","O","O","O","O","B-book","O","O","O","O","B-person","I-person","O","O","O","O","O","O","B-event","I-event","I-event","I-event","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: poem, person, location, literary genre, country, book, organization, writer, magazine, award, event and O.\nSentence: The only completed screenplay , Heaven , was filmed by Tom Tykwer and premiered in 2002 at the Berlin International Film Festival .","prompt_labels":"The(O) only(O) completed(O) screenplay(O) ,(O) Heaven(B-book) ,(O) was(O) filmed(O) by(O) Tom(B-person) Tykwer(I-person) and(O) premiered(O) in(O) 2002(O) at(O) the(O) Berlin(B-event) International(I-event) Film(I-event) Festival(I-event) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["award","person","event","book","magazine","poem","location","literary genre","country","writer","organization"],"instance":{"id":"121","words":["Another","historical","novel","by","Graves",",","Count","Belisarius","(","1938",")",",","recounts","the","career","of","the","Byzantine","Empire","general","Belisarius","."],"labels":["O","O","B-literary genre","O","B-writer","O","B-book","I-book","O","O","O","O","O","O","O","O","O","B-country","I-country","O","B-person","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, person, event, book, magazine, poem, location, literary genre, country, writer, organization and O.\nSentence: Another historical novel by Graves , Count Belisarius ( 1938 ) , recounts the career of the Byzantine Empire general Belisarius .","prompt_labels":"Another(O) historical(O) novel(B-literary genre) by(O) Graves(B-writer) ,(O) Count(B-book) Belisarius(I-book) ((O) 1938(O) )(O) ,(O) recounts(O) the(O) career(O) of(O) the(O) Byzantine(B-country) Empire(I-country) general(O) Belisarius(B-person) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["organization","poem","event","literary genre","location","book","country","person","award","writer","magazine"],"instance":{"id":"122","words":["29v",",","partway","through","Desir",")","and","3","(","fol","."],"labels":["O","O","O","O","B-poem","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, poem, event, literary genre, location, book, country, person, award, writer, magazine and O.\nSentence: 29v , partway through Desir ) and 3 ( fol .","prompt_labels":"29v(O) ,(O) partway(O) through(O) Desir(B-poem) )(O) and(O) 3(O) ((O) fol(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["country","book","poem","writer","organization","literary genre","award","event","location","person","magazine"],"instance":{"id":"123","words":["By","the","end","of","1131",",","the","kingdoms","of","Kingdom","of","France",",","Kingdom","of","England",",","Holy","Roman","Empire",",","Kingdom","of","Portugal",",","Kingdom","of","Castile",",","and","Aragon","supported","Pope","Innocent","II",";","however",",","most","of","Italy",",","southern","France",",","and","Sicily",",","with","the","Latin","patriarchs","of","Constantinople",",","Antioch",",","and","Jerusalem","supported","Antipope","Anacletus","II","."],"labels":["O","O","O","O","O","O","O","O","O","B-country","I-country","I-country","O","B-country","I-country","I-country","O","B-country","I-country","I-country","O","B-country","I-country","I-country","O","B-country","I-country","I-country","O","O","B-country","O","B-person","I-person","I-person","O","O","O","O","O","B-country","O","O","B-country","O","O","B-location","O","O","O","O","O","O","B-location","O","B-location","O","O","B-location","O","B-person","I-person","I-person","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, book, poem, writer, organization, literary genre, award, event, location, person, magazine and O.\nSentence: By the end of 1131 , the kingdoms of Kingdom of France , Kingdom of England , Holy Roman Empire , Kingdom of Portugal , Kingdom of Castile , and Aragon supported Pope Innocent II ; however , most of Italy , southern France , and Sicily , with the Latin patriarchs of Constantinople , Antioch , and Jerusalem supported Antipope Anacletus II .","prompt_labels":"By(O) the(O) end(O) of(O) 1131(O) ,(O) the(O) kingdoms(O) of(O) Kingdom(B-country) of(I-country) France(I-country) ,(O) Kingdom(B-country) of(I-country) England(I-country) ,(O) Holy(B-country) Roman(I-country) Empire(I-country) ,(O) Kingdom(B-country) of(I-country) Portugal(I-country) ,(O) Kingdom(B-country) of(I-country) Castile(I-country) ,(O) and(O) Aragon(B-country) supported(O) Pope(B-person) Innocent(I-person) II(I-person) ;(O) however(O) ,(O) most(O) of(O) Italy(B-country) ,(O) southern(O) France(B-country) ,(O) and(O) Sicily(B-location) ,(O) with(O) the(O) Latin(O) patriarchs(O) of(O) Constantinople(B-location) ,(O) Antioch(B-location) ,(O) and(O) Jerusalem(B-location) supported(O) Antipope(B-person) Anacletus(I-person) II(I-person) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["literary genre","event","award","poem","writer","person","country","book","magazine","location","organization"],"instance":{"id":"124","words":["They","believe","that","the","gathering","of","all","of","the","nations","of","the","earth","refers","to","the","uniting","of","the","world","'s","political","powers",",","as","a","gradual","process","which","began","in","1914","and","was","later","seen","in","manifestations","such","as","the","League","of","Nations","and","the","United","Nations","following","the","First","and","Second","World","War","s","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","O","O","B-organization","I-organization","O","O","O","O","B-event","I-event","I-event","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: literary genre, event, award, poem, writer, person, country, book, magazine, location, organization and O.\nSentence: They believe that the gathering of all of the nations of the earth refers to the uniting of the world 's political powers , as a gradual process which began in 1914 and was later seen in manifestations such as the League of Nations and the United Nations following the First and Second World War s .","prompt_labels":"They(O) believe(O) that(O) the(O) gathering(O) of(O) all(O) of(O) the(O) nations(O) of(O) the(O) earth(O) refers(O) to(O) the(O) uniting(O) of(O) the(O) world(O) 's(O) political(O) powers(O) ,(O) as(O) a(O) gradual(O) process(O) which(O) began(O) in(O) 1914(O) and(O) was(O) later(O) seen(O) in(O) manifestations(O) such(O) as(O) the(O) League(B-organization) of(I-organization) Nations(I-organization) and(O) the(O) United(B-organization) Nations(I-organization) following(O) the(O) First(O) and(O) Second(B-event) World(I-event) War(I-event) s(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["literary genre","book","poem","organization","country","award","location","writer","magazine","person","event"],"instance":{"id":"125","words":["In","October","2009",",","she","appeared","as","Delia","in","Peter","Hall","'","s","revival","of","Alan","Ayckbourn","'","s","Bedroom","Farce","at","the","Rose","Theatre",",","Kingston","and","in","her","first","pantomime",",","Snow","White","and","the","Seven","Dwarfs","at","Richmond","Theatre","in","December","2009",",","receiving","enthusiastic","reviews","for","both","."],"labels":["O","O","O","O","O","O","O","B-person","O","B-person","I-person","O","O","O","O","B-writer","I-writer","O","O","B-book","I-book","O","O","B-location","I-location","I-location","I-location","O","O","O","O","O","O","O","O","O","O","O","O","O","B-location","I-location","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: literary genre, book, poem, organization, country, award, location, writer, magazine, person, event and O.\nSentence: In October 2009 , she appeared as Delia in Peter Hall ' s revival of Alan Ayckbourn ' s Bedroom Farce at the Rose Theatre , Kingston and in her first pantomime , Snow White and the Seven Dwarfs at Richmond Theatre in December 2009 , receiving enthusiastic reviews for both .","prompt_labels":"In(O) October(O) 2009(O) ,(O) she(O) appeared(O) as(O) Delia(B-person) in(O) Peter(B-person) Hall(I-person) '(O) s(O) revival(O) of(O) Alan(B-writer) Ayckbourn(I-writer) '(O) s(O) Bedroom(B-book) Farce(I-book) at(O) the(O) Rose(B-location) Theatre(I-location) ,(I-location) Kingston(I-location) and(O) in(O) her(O) first(O) pantomime(O) ,(O) Snow(O) White(O) and(O) the(O) Seven(O) Dwarfs(O) at(O) Richmond(B-location) Theatre(I-location) in(O) December(O) 2009(O) ,(O) receiving(O) enthusiastic(O) reviews(O) for(O) both(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["writer","award","literary genre","book","country","poem","magazine","location","organization","event","person"],"instance":{"id":"126","words":["Asked","what","democratic","models","Myanmar","could","look","to",",","she","said",":","We","have","many",",","many","lessons","to","learn","from","various","places",",","not","just","the","Asian","countries","like","South","Korea",",","Mongolia",",","and","Indonesia","."],"labels":["O","O","O","O","B-country","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-country","I-country","O","B-country","O","O","B-country","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: writer, award, literary genre, book, country, poem, magazine, location, organization, event, person and O.\nSentence: Asked what democratic models Myanmar could look to , she said : We have many , many lessons to learn from various places , not just the Asian countries like South Korea , Mongolia , and Indonesia .","prompt_labels":"Asked(O) what(O) democratic(O) models(O) Myanmar(B-country) could(O) look(O) to(O) ,(O) she(O) said(O) :(O) We(O) have(O) many(O) ,(O) many(O) lessons(O) to(O) learn(O) from(O) various(O) places(O) ,(O) not(O) just(O) the(O) Asian(O) countries(O) like(O) South(B-country) Korea(I-country) ,(O) Mongolia(B-country) ,(O) and(O) Indonesia(B-country) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["book","event","location","literary genre","person","poem","magazine","country","award","writer","organization"],"instance":{"id":"127","words":["Federico","Fellini",",","Burke","and","Waller",",","12","His","films","have","ranked","in","polls","such","as","Cahiers","du","cinma","and","Sight","&","Sound",",","which","lists","his","1963","film","8","","as","the","10th-greatest","film","."],"labels":["B-writer","I-writer","O","B-writer","O","B-writer","O","O","O","O","O","O","O","O","O","O","B-magazine","I-magazine","I-magazine","O","B-magazine","I-magazine","I-magazine","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: book, event, location, literary genre, person, poem, magazine, country, award, writer, organization and O.\nSentence: Federico Fellini , Burke and Waller , 12 His films have ranked in polls such as Cahiers du cinma and Sight & Sound , which lists his 1963 film 8  as the 10th-greatest film .","prompt_labels":"Federico(B-writer) Fellini(I-writer) ,(O) Burke(B-writer) and(O) Waller(B-writer) ,(O) 12(O) His(O) films(O) have(O) ranked(O) in(O) polls(O) such(O) as(O) Cahiers(B-magazine) du(I-magazine) cinma(I-magazine) and(O) Sight(B-magazine) &(I-magazine) Sound(I-magazine) ,(O) which(O) lists(O) his(O) 1963(O) film(O) 8(O) (O) as(O) the(O) 10th-greatest(O) film(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["person","organization","literary genre","writer","book","poem","award","event","location","country","magazine"],"instance":{"id":"128","words":["David","Lardner","worked","for","The","New","Yorker","as","a","general","reporter","and","war","correspondent","before","he","was","killed","by","a","landmine","near","Aachen",",","Germany","on","October","19",",","1944",",","less","than","one","month","after","his","arrival","in","Europe","."],"labels":["B-writer","I-writer","O","O","B-magazine","I-magazine","I-magazine","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-location","O","B-country","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-location","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, organization, literary genre, writer, book, poem, award, event, location, country, magazine and O.\nSentence: David Lardner worked for The New Yorker as a general reporter and war correspondent before he was killed by a landmine near Aachen , Germany on October 19 , 1944 , less than one month after his arrival in Europe .","prompt_labels":"David(B-writer) Lardner(I-writer) worked(O) for(O) The(B-magazine) New(I-magazine) Yorker(I-magazine) as(O) a(O) general(O) reporter(O) and(O) war(O) correspondent(O) before(O) he(O) was(O) killed(O) by(O) a(O) landmine(O) near(O) Aachen(B-location) ,(O) Germany(B-country) on(O) October(O) 19(O) ,(O) 1944(O) ,(O) less(O) than(O) one(O) month(O) after(O) his(O) arrival(O) in(O) Europe(B-location) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["magazine","book","event","literary genre","organization","country","poem","location","award","writer","person"],"instance":{"id":"129","words":["His","most","famous","works","are","The","Book","of","Healing",",","a","philosophical","and","scientific","encyclopedia",",","and","The","Canon","of","Medicine",",","a","medical","encyclopedia"],"labels":["O","O","O","O","O","B-book","I-book","I-book","I-book","O","O","O","O","O","O","O","O","B-book","I-book","I-book","I-book","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: magazine, book, event, literary genre, organization, country, poem, location, award, writer, person and O.\nSentence: His most famous works are The Book of Healing , a philosophical and scientific encyclopedia , and The Canon of Medicine , a medical encyclopedia","prompt_labels":"His(O) most(O) famous(O) works(O) are(O) The(B-book) Book(I-book) of(I-book) Healing(I-book) ,(O) a(O) philosophical(O) and(O) scientific(O) encyclopedia(O) ,(O) and(O) The(B-book) Canon(I-book) of(I-book) Medicine(I-book) ,(O) a(O) medical(O) encyclopedia(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["magazine","organization","country","event","location","literary genre","book","award","person","writer","poem"],"instance":{"id":"130","words":["At","the","National","Book","Award","s","ceremony","in","November","2014",",","Handler","made","a","controversial","remark","after","author","Jacqueline","Woodson","was","presented","with","an","award","for","young","people","'s","literature","."],"labels":["O","O","B-award","I-award","I-award","O","O","O","O","O","O","B-writer","O","O","O","O","O","O","B-writer","I-writer","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: magazine, organization, country, event, location, literary genre, book, award, person, writer, poem and O.\nSentence: At the National Book Award s ceremony in November 2014 , Handler made a controversial remark after author Jacqueline Woodson was presented with an award for young people 's literature .","prompt_labels":"At(O) the(O) National(B-award) Book(I-award) Award(I-award) s(O) ceremony(O) in(O) November(O) 2014(O) ,(O) Handler(B-writer) made(O) a(O) controversial(O) remark(O) after(O) author(O) Jacqueline(B-writer) Woodson(I-writer) was(O) presented(O) with(O) an(O) award(O) for(O) young(O) people(O) 's(O) literature(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["poem","person","book","country","award","location","literary genre","writer","event","organization","magazine"],"instance":{"id":"131","words":["Colin","Macmillan","Turnbull","(","November","23",",","1924","-","July","28",",","1994",")","was","a","British-American","anthropologist","who","came","to","public","attention","with","the","popular","books","The","Forest","People","(","on","the","Mbuti","Pygmies","of","Zaire",")","and","The","Mountain","People","(","on","the","Ik","people","of","Uganda",")",",","and","one","of","the","first","anthropologists","to","work","in","the","field","of","ethnomusicology","."],"labels":["B-writer","I-writer","I-writer","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-book","I-book","I-book","O","O","O","B-book","I-book","I-book","I-book","O","O","B-book","I-book","I-book","O","O","O","B-book","I-book","I-book","I-book","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: poem, person, book, country, award, location, literary genre, writer, event, organization, magazine and O.\nSentence: Colin Macmillan Turnbull ( November 23 , 1924 - July 28 , 1994 ) was a British-American anthropologist who came to public attention with the popular books The Forest People ( on the Mbuti Pygmies of Zaire ) and The Mountain People ( on the Ik people of Uganda ) , and one of the first anthropologists to work in the field of ethnomusicology .","prompt_labels":"Colin(B-writer) Macmillan(I-writer) Turnbull(I-writer) ((O) November(O) 23(O) ,(O) 1924(O) -(O) July(O) 28(O) ,(O) 1994(O) )(O) was(O) a(O) British-American(O) anthropologist(O) who(O) came(O) to(O) public(O) attention(O) with(O) the(O) popular(O) books(O) The(B-book) Forest(I-book) People(I-book) ((O) on(O) the(O) Mbuti(B-book) Pygmies(I-book) of(I-book) Zaire(I-book) )(O) and(O) The(B-book) Mountain(I-book) People(I-book) ((O) on(O) the(O) Ik(B-book) people(I-book) of(I-book) Uganda(I-book) )(O) ,(O) and(O) one(O) of(O) the(O) first(O) anthropologists(O) to(O) work(O) in(O) the(O) field(O) of(O) ethnomusicology(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["country","book","poem","magazine","event","person","literary genre","organization","award","location","writer"],"instance":{"id":"132","words":["Some","of","these","friends","include",":","David","Amram",",","Bob","Kaufman",";","Diane","di","Prima",";","Jim","Cohn",";","poets","associated","with","the","Black","Mountain","College","such","as","Charles","Olson",",","Robert","Creeley",",","and","Denise","Levertov",";","poets","associated","with","the","New","York","School","such","as","Frank","O","'Hara","and","Kenneth","Koch","."],"labels":["O","O","O","O","O","O","B-writer","I-writer","O","B-writer","I-writer","O","B-writer","I-writer","I-writer","O","B-writer","I-writer","O","O","O","O","O","B-organization","I-organization","I-organization","O","O","B-writer","I-writer","O","B-writer","I-writer","O","O","B-writer","I-writer","O","O","O","O","O","B-organization","I-organization","I-organization","O","O","B-writer","I-writer","I-writer","O","B-writer","I-writer","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, book, poem, magazine, event, person, literary genre, organization, award, location, writer and O.\nSentence: Some of these friends include : David Amram , Bob Kaufman ; Diane di Prima ; Jim Cohn ; poets associated with the Black Mountain College such as Charles Olson , Robert Creeley , and Denise Levertov ; poets associated with the New York School such as Frank O 'Hara and Kenneth Koch .","prompt_labels":"Some(O) of(O) these(O) friends(O) include(O) :(O) David(B-writer) Amram(I-writer) ,(O) Bob(B-writer) Kaufman(I-writer) ;(O) Diane(B-writer) di(I-writer) Prima(I-writer) ;(O) Jim(B-writer) Cohn(I-writer) ;(O) poets(O) associated(O) with(O) the(O) Black(B-organization) Mountain(I-organization) College(I-organization) such(O) as(O) Charles(B-writer) Olson(I-writer) ,(O) Robert(B-writer) Creeley(I-writer) ,(O) and(O) Denise(B-writer) Levertov(I-writer) ;(O) poets(O) associated(O) with(O) the(O) New(B-organization) York(I-organization) School(I-organization) such(O) as(O) Frank(B-writer) O(I-writer) 'Hara(I-writer) and(O) Kenneth(B-writer) Koch(I-writer) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["literary genre","person","event","book","country","writer","organization","magazine","award","location","poem"],"instance":{"id":"133","words":["Again",",","in","the","English","Renaissance","fantasy","Armor","of","Light","by","Melissa","Scott","and","Lisa","A.","Barnett",",","the","magic","used","in","the","book",",","by","Dr.","John","Dee","and","others",",","actually","was","practiced","in","the","Renaissance",";","positing","a","secret","history","of","effective","magic","makes","this","an","alternate","history","with","a","POD",",","Sir","Philip","Sidney","'","s","surviving","the","Battle","of","Zutphen","in","1586",",","and","shortly","thereafter","saving","the","life","of","Christopher","Marlowe","."],"labels":["O","O","O","O","B-event","I-event","I-event","B-book","I-book","I-book","O","B-writer","I-writer","O","B-writer","I-writer","I-writer","O","O","O","O","O","O","O","O","O","B-person","I-person","I-person","O","O","O","O","O","O","O","O","B-event","O","O","O","O","O","O","O","O","O","O","O","B-literary genre","I-literary genre","O","O","O","O","B-person","I-person","I-person","O","O","O","O","B-event","I-event","I-event","O","O","O","O","O","O","O","O","O","O","B-person","I-person","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: literary genre, person, event, book, country, writer, organization, magazine, award, location, poem and O.\nSentence: Again , in the English Renaissance fantasy Armor of Light by Melissa Scott and Lisa A. Barnett , the magic used in the book , by Dr. John Dee and others , actually was practiced in the Renaissance ; positing a secret history of effective magic makes this an alternate history with a POD , Sir Philip Sidney ' s surviving the Battle of Zutphen in 1586 , and shortly thereafter saving the life of Christopher Marlowe .","prompt_labels":"Again(O) ,(O) in(O) the(O) English(B-event) Renaissance(I-event) fantasy(I-event) Armor(B-book) of(I-book) Light(I-book) by(O) Melissa(B-writer) Scott(I-writer) and(O) Lisa(B-writer) A.(I-writer) Barnett(I-writer) ,(O) the(O) magic(O) used(O) in(O) the(O) book(O) ,(O) by(O) Dr.(B-person) John(I-person) Dee(I-person) and(O) others(O) ,(O) actually(O) was(O) practiced(O) in(O) the(O) Renaissance(B-event) ;(O) positing(O) a(O) secret(O) history(O) of(O) effective(O) magic(O) makes(O) this(O) an(O) alternate(B-literary genre) history(I-literary genre) with(O) a(O) POD(O) ,(O) Sir(B-person) Philip(I-person) Sidney(I-person) '(O) s(O) surviving(O) the(O) Battle(B-event) of(I-event) Zutphen(I-event) in(O) 1586(O) ,(O) and(O) shortly(O) thereafter(O) saving(O) the(O) life(O) of(O) Christopher(B-person) Marlowe(I-person) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["organization","award","poem","literary genre","book","magazine","event","person","location","country","writer"],"instance":{"id":"134","words":["Disraeli","'s","early","silver","fork","novels","Vivian","Grey","(","1826",")","and","The","Young","Duke","(","1831",")","featured","romanticised","depictions","of","aristocratic","life","(","despite","his","ignorance","of","it",")","with","character","sketches","of","well-known","public","figures","lightly","disguised","."],"labels":["B-writer","O","O","B-literary genre","I-literary genre","I-literary genre","B-book","I-book","O","O","O","O","B-book","I-book","I-book","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, award, poem, literary genre, book, magazine, event, person, location, country, writer and O.\nSentence: Disraeli 's early silver fork novels Vivian Grey ( 1826 ) and The Young Duke ( 1831 ) featured romanticised depictions of aristocratic life ( despite his ignorance of it ) with character sketches of well-known public figures lightly disguised .","prompt_labels":"Disraeli(B-writer) 's(O) early(O) silver(B-literary genre) fork(I-literary genre) novels(I-literary genre) Vivian(B-book) Grey(I-book) ((O) 1826(O) )(O) and(O) The(B-book) Young(I-book) Duke(I-book) ((O) 1831(O) )(O) featured(O) romanticised(O) depictions(O) of(O) aristocratic(O) life(O) ((O) despite(O) his(O) ignorance(O) of(O) it(O) )(O) with(O) character(O) sketches(O) of(O) well-known(O) public(O) figures(O) lightly(O) disguised(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["award","poem","book","location","literary genre","magazine","writer","country","organization","person","event"],"instance":{"id":"135","words":["In","1959",",","Capp","recorded","and","released","an","album","for","Folkways","Records","(","now","owned","by","the","Smithsonian",")","on","which","he","identified","and","described","The","Mechanics","of","the","Comic","Strip","."],"labels":["O","O","O","B-writer","O","O","O","O","O","O","B-organization","I-organization","O","O","O","O","O","B-organization","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, poem, book, location, literary genre, magazine, writer, country, organization, person, event and O.\nSentence: In 1959 , Capp recorded and released an album for Folkways Records ( now owned by the Smithsonian ) on which he identified and described The Mechanics of the Comic Strip .","prompt_labels":"In(O) 1959(O) ,(O) Capp(B-writer) recorded(O) and(O) released(O) an(O) album(O) for(O) Folkways(B-organization) Records(I-organization) ((O) now(O) owned(O) by(O) the(O) Smithsonian(B-organization) )(O) on(O) which(O) he(O) identified(O) and(O) described(O) The(O) Mechanics(O) of(O) the(O) Comic(O) Strip(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["poem","magazine","book","event","organization","country","person","award","location","literary genre","writer"],"instance":{"id":"136","words":["Investigative","journalist","Michael","Specter",",","in","an","article","in","The","New","Yorker","on","25","August","2014","entitled","Seeds","of","Doubt",","],"labels":["O","O","B-writer","I-writer","O","O","O","O","O","B-magazine","I-magazine","I-magazine","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: poem, magazine, book, event, organization, country, person, award, location, literary genre, writer and O.\nSentence: Investigative journalist Michael Specter , in an article in The New Yorker on 25 August 2014 entitled Seeds of Doubt ,","prompt_labels":"Investigative(O) journalist(O) Michael(B-writer) Specter(I-writer) ,(O) in(O) an(O) article(O) in(O) The(B-magazine) New(I-magazine) Yorker(I-magazine) on(O) 25(O) August(O) 2014(O) entitled(O) Seeds(O) of(O) Doubt(O) ,(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["magazine","country","literary genre","person","location","book","poem","writer","organization","award","event"],"instance":{"id":"137","words":["In","1962",",","Percy","was","awarded","the","National","Book","Award","for","Fiction","for","his","first","novel",",","The","Moviegoer","."],"labels":["O","O","O","B-writer","O","O","O","B-award","I-award","I-award","I-award","I-award","O","O","O","B-literary genre","O","B-book","I-book","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: magazine, country, literary genre, person, location, book, poem, writer, organization, award, event and O.\nSentence: In 1962 , Percy was awarded the National Book Award for Fiction for his first novel , The Moviegoer .","prompt_labels":"In(O) 1962(O) ,(O) Percy(B-writer) was(O) awarded(O) the(O) National(B-award) Book(I-award) Award(I-award) for(I-award) Fiction(I-award) for(O) his(O) first(O) novel(B-literary genre) ,(O) The(B-book) Moviegoer(I-book) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["magazine","organization","location","book","country","person","poem","literary genre","writer","award","event"],"instance":{"id":"138","words":["The","Letterman","Foundation","for","Courtesy","and","Grooming","is","a","private","foundation","through","which","Letterman","has","donated","millions","of","dollars","to","charities","and","other","non-profits","in","Indiana","and","Montana",",","celebrity-affiliated","organizations","such","as","Paul","Newman","'","s","Hole","in","the","Wall","Gang","Camp",",","Ball","State","University",",","the","American","Cancer","Society",",","the","Salvation","Army",",","and","Mdecins","Sans","Frontires","."],"labels":["B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","O","O","O","O","O","B-writer","O","O","O","O","O","O","O","O","O","O","O","B-location","O","B-location","O","O","O","O","O","B-person","I-person","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","B-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","O","O","B-organization","I-organization","O","O","B-organization","I-organization","I-organization","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: magazine, organization, location, book, country, person, poem, literary genre, writer, award, event and O.\nSentence: The Letterman Foundation for Courtesy and Grooming is a private foundation through which Letterman has donated millions of dollars to charities and other non-profits in Indiana and Montana , celebrity-affiliated organizations such as Paul Newman ' s Hole in the Wall Gang Camp , Ball State University , the American Cancer Society , the Salvation Army , and Mdecins Sans Frontires .","prompt_labels":"The(B-organization) Letterman(I-organization) Foundation(I-organization) for(I-organization) Courtesy(I-organization) and(I-organization) Grooming(I-organization) is(O) a(O) private(O) foundation(O) through(O) which(O) Letterman(B-writer) has(O) donated(O) millions(O) of(O) dollars(O) to(O) charities(O) and(O) other(O) non-profits(O) in(O) Indiana(B-location) and(O) Montana(B-location) ,(O) celebrity-affiliated(O) organizations(O) such(O) as(O) Paul(B-person) Newman(I-person) '(O) s(O) Hole(B-organization) in(I-organization) the(I-organization) Wall(I-organization) Gang(I-organization) Camp(I-organization) ,(O) Ball(B-organization) State(I-organization) University(I-organization) ,(O) the(O) American(B-organization) Cancer(I-organization) Society(I-organization) ,(O) the(O) Salvation(B-organization) Army(I-organization) ,(O) and(O) Mdecins(B-organization) Sans(I-organization) Frontires(I-organization) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["event","literary genre","magazine","writer","award","country","person","organization","book","location","poem"],"instance":{"id":"139","words":["Poet","and","lead","singer","of","King","Missile",",","John","S.","Hall","has","also","long","been","a","vocal","opponent",",","taking","issue","with","such","factors","as","its","inherently","competitive","nature","In","his","2005","interview","in","Words","In","Your","Face",":","A","Guided","Tour","Through","Twenty","Years","of","the","New","York","City","Poetry","Slam",",","he","recalls","seeing","his","first","slam",",","at","the","Nuyorican","Poets","Caf",":","...","I","hated","it","."],"labels":["O","O","O","O","O","O","O","O","B-writer","I-writer","I-writer","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-book","I-book","I-book","I-book","I-book","I-book","I-book","I-book","I-book","I-book","I-book","I-book","I-book","I-book","I-book","I-book","I-book","I-book","O","O","O","O","O","O","O","O","O","O","B-location","I-location","I-location","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, literary genre, magazine, writer, award, country, person, organization, book, location, poem and O.\nSentence: Poet and lead singer of King Missile , John S. Hall has also long been a vocal opponent , taking issue with such factors as its inherently competitive nature In his 2005 interview in Words In Your Face : A Guided Tour Through Twenty Years of the New York City Poetry Slam , he recalls seeing his first slam , at the Nuyorican Poets Caf : ... I hated it .","prompt_labels":"Poet(O) and(O) lead(O) singer(O) of(O) King(O) Missile(O) ,(O) John(B-writer) S.(I-writer) Hall(I-writer) has(O) also(O) long(O) been(O) a(O) vocal(O) opponent(O) ,(O) taking(O) issue(O) with(O) such(O) factors(O) as(O) its(O) inherently(O) competitive(O) nature(O) In(O) his(O) 2005(O) interview(O) in(O) Words(B-book) In(I-book) Your(I-book) Face(I-book) :(I-book) A(I-book) Guided(I-book) Tour(I-book) Through(I-book) Twenty(I-book) Years(I-book) of(I-book) the(I-book) New(I-book) York(I-book) City(I-book) Poetry(I-book) Slam(I-book) ,(O) he(O) recalls(O) seeing(O) his(O) first(O) slam(O) ,(O) at(O) the(O) Nuyorican(B-location) Poets(I-location) Caf(I-location) :(O) ...(O) I(O) hated(O) it(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["person","writer","literary genre","magazine","organization","book","award","poem","event","country","location"],"instance":{"id":"140","words":["Cuarn","himself","received","two","nominations","for","his","work","on","the","film","in","Academy","Award","for","Best","Film","Editing","(","with","Alex","Rodrguez",")","and","Academy","Award","for","Best","Adapted","Screenplay","(","with","several","collaborators",")","."],"labels":["B-writer","O","O","O","O","O","O","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","I-award","O","O","B-person","I-person","O","O","B-award","I-award","I-award","I-award","I-award","I-award","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, writer, literary genre, magazine, organization, book, award, poem, event, country, location and O.\nSentence: Cuarn himself received two nominations for his work on the film in Academy Award for Best Film Editing ( with Alex Rodrguez ) and Academy Award for Best Adapted Screenplay ( with several collaborators ) .","prompt_labels":"Cuarn(B-writer) himself(O) received(O) two(O) nominations(O) for(O) his(O) work(O) on(O) the(O) film(O) in(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Film(I-award) Editing(I-award) ((O) with(O) Alex(B-person) Rodrguez(I-person) )(O) and(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Adapted(I-award) Screenplay(I-award) ((O) with(O) several(O) collaborators(O) )(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["writer","country","person","literary genre","book","event","magazine","poem","award","organization","location"],"instance":{"id":"141","words":["In","1972",",","Ian","Angus","found","the","original","typescript","titled","The","Freedom","of","the","Press",",","and","Bernard","Crick","published","it",",","together","with","his","own","introduction",",","in","The","Times","Literary","Supplement","on","15","September","1972","as","How","the","essay","came","to","be","written","."],"labels":["O","O","O","B-person","I-person","O","O","O","O","O","O","O","O","O","O","O","O","B-person","I-person","O","O","O","O","O","O","O","O","O","O","B-magazine","I-magazine","I-magazine","I-magazine","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: writer, country, person, literary genre, book, event, magazine, poem, award, organization, location and O.\nSentence: In 1972 , Ian Angus found the original typescript titled The Freedom of the Press , and Bernard Crick published it , together with his own introduction , in The Times Literary Supplement on 15 September 1972 as How the essay came to be written .","prompt_labels":"In(O) 1972(O) ,(O) Ian(B-person) Angus(I-person) found(O) the(O) original(O) typescript(O) titled(O) The(O) Freedom(O) of(O) the(O) Press(O) ,(O) and(O) Bernard(B-person) Crick(I-person) published(O) it(O) ,(O) together(O) with(O) his(O) own(O) introduction(O) ,(O) in(O) The(B-magazine) Times(I-magazine) Literary(I-magazine) Supplement(I-magazine) on(O) 15(O) September(O) 1972(O) as(O) How(O) the(O) essay(O) came(O) to(O) be(O) written(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["book","event","writer","award","poem","magazine","location","organization","person","literary genre","country"],"instance":{"id":"142","words":["Lerner","and","Loewe","'s","run","of","success","continued","with","their","next","project",",","a","film","adaptation","of","stories","from","Colette",",","the","Academy","Awards","-winning","film","musical","Gigi",",","starring","Leslie","Caron",",","Louis","Jourdan","and","Maurice","Chevalier","."],"labels":["B-writer","O","B-writer","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-writer","O","O","B-award","I-award","O","O","O","O","O","O","B-person","I-person","O","B-person","I-person","O","B-person","I-person","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: book, event, writer, award, poem, magazine, location, organization, person, literary genre, country and O.\nSentence: Lerner and Loewe 's run of success continued with their next project , a film adaptation of stories from Colette , the Academy Awards -winning film musical Gigi , starring Leslie Caron , Louis Jourdan and Maurice Chevalier .","prompt_labels":"Lerner(B-writer) and(O) Loewe(B-writer) 's(O) run(O) of(O) success(O) continued(O) with(O) their(O) next(O) project(O) ,(O) a(O) film(O) adaptation(O) of(O) stories(O) from(O) Colette(B-writer) ,(O) the(O) Academy(B-award) Awards(I-award) -winning(O) film(O) musical(O) Gigi(O) ,(O) starring(O) Leslie(B-person) Caron(I-person) ,(O) Louis(B-person) Jourdan(I-person) and(O) Maurice(B-person) Chevalier(I-person) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["poem","literary genre","magazine","award","event","person","location","writer","book","country","organization"],"instance":{"id":"143","words":["For","example",",","Susanna","Moodie","and","Catharine","Parr","Traill",",","English","sisters","who","adopted","the","country","as","their","own",",","moved","to","Upper","Canada","in","1832","."],"labels":["O","O","O","B-writer","I-writer","O","B-writer","I-writer","I-writer","O","O","O","O","O","O","O","O","O","O","O","O","O","B-country","I-country","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: poem, literary genre, magazine, award, event, person, location, writer, book, country, organization and O.\nSentence: For example , Susanna Moodie and Catharine Parr Traill , English sisters who adopted the country as their own , moved to Upper Canada in 1832 .","prompt_labels":"For(O) example(O) ,(O) Susanna(B-writer) Moodie(I-writer) and(O) Catharine(B-writer) Parr(I-writer) Traill(I-writer) ,(O) English(O) sisters(O) who(O) adopted(O) the(O) country(O) as(O) their(O) own(O) ,(O) moved(O) to(O) Upper(B-country) Canada(I-country) in(O) 1832(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["magazine","location","literary genre","book","event","award","person","organization","country","poem","writer"],"instance":{"id":"144","words":["In","a","review","in","The","Dial",",","T.","S.","Eliot","said","of","Ulysses",":","I","hold","this","book","to","be","the","most","important","expression","which","the","present","age","has","found",";","it","is","a","book","to","which","we","are","all","indebted",",","and","from","which","none","of","us","can","escape","."],"labels":["O","O","O","O","B-magazine","I-magazine","O","B-writer","I-writer","I-writer","O","O","B-book","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: magazine, location, literary genre, book, event, award, person, organization, country, poem, writer and O.\nSentence: In a review in The Dial , T. S. Eliot said of Ulysses : I hold this book to be the most important expression which the present age has found ; it is a book to which we are all indebted , and from which none of us can escape .","prompt_labels":"In(O) a(O) review(O) in(O) The(B-magazine) Dial(I-magazine) ,(O) T.(B-writer) S.(I-writer) Eliot(I-writer) said(O) of(O) Ulysses(B-book) :(O) I(O) hold(O) this(O) book(O) to(O) be(O) the(O) most(O) important(O) expression(O) which(O) the(O) present(O) age(O) has(O) found(O) ;(O) it(O) is(O) a(O) book(O) to(O) which(O) we(O) are(O) all(O) indebted(O) ,(O) and(O) from(O) which(O) none(O) of(O) us(O) can(O) escape(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["award","poem","location","event","organization","country","writer","book","person","magazine","literary genre"],"instance":{"id":"145","words":["Spengler","spent","his","final","years","in","Munich",",","listening","to","Ludwig","van","Beethoven",",","reading","Molire","and","Shakespeare",",","buying","several","thousand","books",",","and","collecting","ancient","Turkey",",","Persia","n","and","India","n","weapons","."],"labels":["B-person","O","O","O","O","O","B-location","O","O","O","B-person","I-person","I-person","O","O","B-writer","O","B-writer","O","O","O","O","O","O","O","O","O","B-country","O","B-country","O","O","B-country","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, poem, location, event, organization, country, writer, book, person, magazine, literary genre and O.\nSentence: Spengler spent his final years in Munich , listening to Ludwig van Beethoven , reading Molire and Shakespeare , buying several thousand books , and collecting ancient Turkey , Persia n and India n weapons .","prompt_labels":"Spengler(B-person) spent(O) his(O) final(O) years(O) in(O) Munich(B-location) ,(O) listening(O) to(O) Ludwig(B-person) van(I-person) Beethoven(I-person) ,(O) reading(O) Molire(B-writer) and(O) Shakespeare(B-writer) ,(O) buying(O) several(O) thousand(O) books(O) ,(O) and(O) collecting(O) ancient(O) Turkey(B-country) ,(O) Persia(B-country) n(O) and(O) India(B-country) n(O) weapons(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["location","book","writer","poem","event","organization","magazine","country","award","person","literary genre"],"instance":{"id":"146","words":["Novelist","James","Joyce","noted","that","the","TRUE","symbol","of","the","British","Empire","is","Robinson","Crusoe",",","to","whom","he","ascribed","stereotypical","and","somewhat","hostile","English","racial","characteristics",":","He","is","the","TRUE","prototype","of","the","British","colonist","."],"labels":["O","B-writer","I-writer","O","O","O","O","O","O","O","B-country","I-country","O","B-book","I-book","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, book, writer, poem, event, organization, magazine, country, award, person, literary genre and O.\nSentence: Novelist James Joyce noted that the TRUE symbol of the British Empire is Robinson Crusoe , to whom he ascribed stereotypical and somewhat hostile English racial characteristics : He is the TRUE prototype of the British colonist .","prompt_labels":"Novelist(O) James(B-writer) Joyce(I-writer) noted(O) that(O) the(O) TRUE(O) symbol(O) of(O) the(O) British(B-country) Empire(I-country) is(O) Robinson(B-book) Crusoe(I-book) ,(O) to(O) whom(O) he(O) ascribed(O) stereotypical(O) and(O) somewhat(O) hostile(O) English(O) racial(O) characteristics(O) :(O) He(O) is(O) the(O) TRUE(O) prototype(O) of(O) the(O) British(O) colonist(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["writer","country","award","event","organization","poem","magazine","person","book","literary genre","location"],"instance":{"id":"147","words":["Thompson","remains","best","known","for","Fear","and","Loathing","in","Las","Vegas","(","1971",")",",","a","book","first","serialized","in","Rolling","Stone","in","which","he","grapples","with","the","implications","of","what","he","considered","the","failure","of","the","1960s","counterculture","movement","."],"labels":["B-writer","O","O","O","O","B-book","I-book","I-book","I-book","I-book","I-book","O","O","O","O","O","O","O","O","O","B-magazine","I-magazine","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-event","I-event","I-event","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: writer, country, award, event, organization, poem, magazine, person, book, literary genre, location and O.\nSentence: Thompson remains best known for Fear and Loathing in Las Vegas ( 1971 ) , a book first serialized in Rolling Stone in which he grapples with the implications of what he considered the failure of the 1960s counterculture movement .","prompt_labels":"Thompson(B-writer) remains(O) best(O) known(O) for(O) Fear(B-book) and(I-book) Loathing(I-book) in(I-book) Las(I-book) Vegas(I-book) ((O) 1971(O) )(O) ,(O) a(O) book(O) first(O) serialized(O) in(O) Rolling(B-magazine) Stone(I-magazine) in(O) which(O) he(O) grapples(O) with(O) the(O) implications(O) of(O) what(O) he(O) considered(O) the(O) failure(O) of(O) the(O) 1960s(B-event) counterculture(I-event) movement(I-event) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["country","person","organization","location","award","book","event","writer","poem","magazine","literary genre"],"instance":{"id":"148","words":["Many","have","been","successfully","adapted","into","films",",","including","the","novels","Rebecca",",","My","Cousin","Rachel",",","and","Jamaica","Inn",",","and","the","short","stories","The","Birds","and","Don","'t","Look","Now","\/","Not","After","Midnight","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-literary genre","B-book","O","B-book","I-book","I-book","O","O","B-book","I-book","O","O","O","B-literary genre","I-literary genre","B-book","I-book","O","B-book","I-book","I-book","I-book","O","B-book","I-book","I-book","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, person, organization, location, award, book, event, writer, poem, magazine, literary genre and O.\nSentence: Many have been successfully adapted into films , including the novels Rebecca , My Cousin Rachel , and Jamaica Inn , and the short stories The Birds and Don 't Look Now \/ Not After Midnight .","prompt_labels":"Many(O) have(O) been(O) successfully(O) adapted(O) into(O) films(O) ,(O) including(O) the(O) novels(B-literary genre) Rebecca(B-book) ,(O) My(B-book) Cousin(I-book) Rachel(I-book) ,(O) and(O) Jamaica(B-book) Inn(I-book) ,(O) and(O) the(O) short(B-literary genre) stories(I-literary genre) The(B-book) Birds(I-book) and(O) Don(B-book) 't(I-book) Look(I-book) Now(I-book) \/(O) Not(B-book) After(I-book) Midnight(I-book) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["person","award","organization","book","literary genre","location","country","event","magazine","poem","writer"],"instance":{"id":"149","words":["Out","of","public","office","for","the","first","time","since","the","1960s",",","Bush","became","chairman","on","the","Executive","Committee","of","the","First","International","Bank","in","Houston.","continued","his","membership","in","the","Council","on","Foreign","Relations",",","and","joined","the","Trilateral","Commission","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","B-person","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","O","B-location","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O","O","O","O","B-organization","I-organization","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, award, organization, book, literary genre, location, country, event, magazine, poem, writer and O.\nSentence: Out of public office for the first time since the 1960s , Bush became chairman on the Executive Committee of the First International Bank in Houston. continued his membership in the Council on Foreign Relations , and joined the Trilateral Commission .","prompt_labels":"Out(O) of(O) public(O) office(O) for(O) the(O) first(O) time(O) since(O) the(O) 1960s(O) ,(O) Bush(B-person) became(O) chairman(O) on(O) the(O) Executive(O) Committee(O) of(O) the(O) First(B-organization) International(I-organization) Bank(I-organization) in(O) Houston.(B-location) continued(O) his(O) membership(O) in(O) the(O) Council(B-organization) on(I-organization) Foreign(I-organization) Relations(I-organization) ,(O) and(O) joined(O) the(O) Trilateral(B-organization) Commission(I-organization) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["organization","poem","award","book","literary genre","location","writer","person","magazine","country","event"],"instance":{"id":"150","words":["Among","books","on","the","list","considered","to","be","the","Great","American","Novel","were","Moby-Dick",",","Adventures","of","Huckleberry","Finn",",","The","Great","Gatsby",",","The","Grapes","of","Wrath",",","The","Catcher","in","the","Rye",",","Invisible","Man",",","and","To","Kill","a","Mockingbird","."],"labels":["O","O","O","O","O","O","O","O","O","B-literary genre","I-literary genre","I-literary genre","O","B-book","O","B-book","I-book","I-book","I-book","O","B-book","I-book","I-book","O","B-book","I-book","I-book","I-book","O","B-book","I-book","I-book","I-book","I-book","O","B-book","I-book","O","O","B-book","I-book","I-book","I-book","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, poem, award, book, literary genre, location, writer, person, magazine, country, event and O.\nSentence: Among books on the list considered to be the Great American Novel were Moby-Dick , Adventures of Huckleberry Finn , The Great Gatsby , The Grapes of Wrath , The Catcher in the Rye , Invisible Man , and To Kill a Mockingbird .","prompt_labels":"Among(O) books(O) on(O) the(O) list(O) considered(O) to(O) be(O) the(O) Great(B-literary genre) American(I-literary genre) Novel(I-literary genre) were(O) Moby-Dick(B-book) ,(O) Adventures(B-book) of(I-book) Huckleberry(I-book) Finn(I-book) ,(O) The(B-book) Great(I-book) Gatsby(I-book) ,(O) The(B-book) Grapes(I-book) of(I-book) Wrath(I-book) ,(O) The(B-book) Catcher(I-book) in(I-book) the(I-book) Rye(I-book) ,(O) Invisible(B-book) Man(I-book) ,(O) and(O) To(B-book) Kill(I-book) a(I-book) Mockingbird(I-book) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["person","magazine","location","award","poem","book","event","organization","literary genre","writer","country"],"instance":{"id":"151","words":["In","his","book","Trinity","of","Passion",",","author","Alan","M.","Wald","conjectures","that","Miller","was","a","member","of","a","writer","'s","unit","of","the","Communist","Party","around","1946",",","using","the","pseudonym","Matt","Wayne",",","and","editing","a","drama","column","in","the","magazine","The","New","Masses","."],"labels":["O","O","O","B-book","I-book","I-book","O","O","B-writer","I-writer","I-writer","O","O","B-writer","O","O","O","O","O","O","O","O","O","O","B-organization","I-organization","O","O","O","O","O","O","B-writer","I-writer","O","O","O","O","O","O","O","O","O","B-magazine","I-magazine","I-magazine","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, magazine, location, award, poem, book, event, organization, literary genre, writer, country and O.\nSentence: In his book Trinity of Passion , author Alan M. Wald conjectures that Miller was a member of a writer 's unit of the Communist Party around 1946 , using the pseudonym Matt Wayne , and editing a drama column in the magazine The New Masses .","prompt_labels":"In(O) his(O) book(O) Trinity(B-book) of(I-book) Passion(I-book) ,(O) author(O) Alan(B-writer) M.(I-writer) Wald(I-writer) conjectures(O) that(O) Miller(B-writer) was(O) a(O) member(O) of(O) a(O) writer(O) 's(O) unit(O) of(O) the(O) Communist(B-organization) Party(I-organization) around(O) 1946(O) ,(O) using(O) the(O) pseudonym(O) Matt(B-writer) Wayne(I-writer) ,(O) and(O) editing(O) a(O) drama(O) column(O) in(O) the(O) magazine(O) The(B-magazine) New(I-magazine) Masses(I-magazine) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["organization","award","book","writer","literary genre","country","location","person","poem","magazine","event"],"instance":{"id":"152","words":["Elkin","won","the","National","Book","Critics","Circle","Award","on","two","occasions",":","for","George","Mills","in","1982","and","for","Mrs.","Ted","Bliss",",","his","last","novel",",","in","1995","."],"labels":["B-writer","O","O","B-award","I-award","I-award","I-award","I-award","O","O","O","O","O","B-book","I-book","O","O","O","O","B-book","I-book","I-book","O","O","O","B-literary genre","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, award, book, writer, literary genre, country, location, person, poem, magazine, event and O.\nSentence: Elkin won the National Book Critics Circle Award on two occasions : for George Mills in 1982 and for Mrs. Ted Bliss , his last novel , in 1995 .","prompt_labels":"Elkin(B-writer) won(O) the(O) National(B-award) Book(I-award) Critics(I-award) Circle(I-award) Award(I-award) on(O) two(O) occasions(O) :(O) for(O) George(B-book) Mills(I-book) in(O) 1982(O) and(O) for(O) Mrs.(B-book) Ted(I-book) Bliss(I-book) ,(O) his(O) last(O) novel(B-literary genre) ,(O) in(O) 1995(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["event","writer","book","award","poem","country","literary genre","person","location","organization","magazine"],"instance":{"id":"153","words":["In","November","1924","he","was","awarded","the","Nobel","Prize","for","Literature","over","rivals","Thomas","Mann",",","George","Bernard","Shaw","and","Thomas","Hardy",",","after","he","had","been","nominated","by","Anders","sterling",",","member","of","the","Swedish","Academy","."],"labels":["O","O","O","O","O","O","O","B-award","I-award","I-award","I-award","O","O","B-writer","I-writer","O","B-writer","I-writer","I-writer","O","B-writer","I-writer","O","O","O","O","O","O","O","B-writer","I-writer","O","O","O","O","B-organization","I-organization","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, writer, book, award, poem, country, literary genre, person, location, organization, magazine and O.\nSentence: In November 1924 he was awarded the Nobel Prize for Literature over rivals Thomas Mann , George Bernard Shaw and Thomas Hardy , after he had been nominated by Anders sterling , member of the Swedish Academy .","prompt_labels":"In(O) November(O) 1924(O) he(O) was(O) awarded(O) the(O) Nobel(B-award) Prize(I-award) for(I-award) Literature(I-award) over(O) rivals(O) Thomas(B-writer) Mann(I-writer) ,(O) George(B-writer) Bernard(I-writer) Shaw(I-writer) and(O) Thomas(B-writer) Hardy(I-writer) ,(O) after(O) he(O) had(O) been(O) nominated(O) by(O) Anders(B-writer) sterling(I-writer) ,(O) member(O) of(O) the(O) Swedish(B-organization) Academy(I-organization) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["person","literary genre","award","book","writer","organization","country","magazine","event","location","poem"],"instance":{"id":"154","words":["Many","old","and","new","friends","and","family","showed","up","to","support","the","Pranksters","on","this","tour",",","which","took","them","from","Seattle","'s","Bumbershoot","all","along","the","West","Coast",",","including","a","sold-out","two-night","run","at","The","Fillmore","in","San","Francisco","to","Boulder",",","Colorado",",","where","they","coaxed","the","Beat","Generation","poet","Allen","Ginsberg","into","performing","with","them","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-location","O","B-event","O","O","O","B-location","I-location","O","O","O","O","O","O","O","B-location","I-location","O","B-location","I-location","O","B-location","O","B-location","O","O","O","O","O","O","O","O","B-writer","I-writer","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, literary genre, award, book, writer, organization, country, magazine, event, location, poem and O.\nSentence: Many old and new friends and family showed up to support the Pranksters on this tour , which took them from Seattle 's Bumbershoot all along the West Coast , including a sold-out two-night run at The Fillmore in San Francisco to Boulder , Colorado , where they coaxed the Beat Generation poet Allen Ginsberg into performing with them .","prompt_labels":"Many(O) old(O) and(O) new(O) friends(O) and(O) family(O) showed(O) up(O) to(O) support(O) the(O) Pranksters(O) on(O) this(O) tour(O) ,(O) which(O) took(O) them(O) from(O) Seattle(B-location) 's(O) Bumbershoot(B-event) all(O) along(O) the(O) West(B-location) Coast(I-location) ,(O) including(O) a(O) sold-out(O) two-night(O) run(O) at(O) The(B-location) Fillmore(I-location) in(O) San(B-location) Francisco(I-location) to(O) Boulder(B-location) ,(O) Colorado(B-location) ,(O) where(O) they(O) coaxed(O) the(O) Beat(O) Generation(O) poet(O) Allen(B-writer) Ginsberg(I-writer) into(O) performing(O) with(O) them(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["location","magazine","event","country","poem","organization","literary genre","writer","award","person","book"],"instance":{"id":"155","words":["He","entered","Yale","in","1903","but","did","not","receive","his","bachelor","'s","degree","until","1908",",","having","taken","time","off","to","work","at","Helicon","Home","Colony",",","Upton","Sinclair","'","s","cooperative","-living","colony","in","Englewood",",","New","Jersey",",","and","to","travel","to","Panama","."],"labels":["O","O","B-organization","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","O","B-writer","I-writer","O","O","O","O","O","O","B-location","O","B-location","I-location","O","O","O","O","O","B-country","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, magazine, event, country, poem, organization, literary genre, writer, award, person, book and O.\nSentence: He entered Yale in 1903 but did not receive his bachelor 's degree until 1908 , having taken time off to work at Helicon Home Colony , Upton Sinclair ' s cooperative -living colony in Englewood , New Jersey , and to travel to Panama .","prompt_labels":"He(O) entered(O) Yale(B-organization) in(O) 1903(O) but(O) did(O) not(O) receive(O) his(O) bachelor(O) 's(O) degree(O) until(O) 1908(O) ,(O) having(O) taken(O) time(O) off(O) to(O) work(O) at(O) Helicon(B-organization) Home(I-organization) Colony(I-organization) ,(O) Upton(B-writer) Sinclair(I-writer) '(O) s(O) cooperative(O) -living(O) colony(O) in(O) Englewood(B-location) ,(O) New(B-location) Jersey(I-location) ,(O) and(O) to(O) travel(O) to(O) Panama(B-country) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["award","location","literary genre","organization","poem","country","writer","magazine","event","book","person"],"instance":{"id":"156","words":["Augustus","dramatically","enlarged","the","Empire",",","annexing","Egypt",",","Dalmatia",",","Pannonia",",","Noricum",",","and","Raetia",",","expanding","possessions","in","Africa",",","and","completing","the","conquest","of","Hispania",",","but","suffered","a","major","setback","in","Germania","."],"labels":["B-person","O","O","O","O","O","O","B-country","O","B-location","O","B-location","O","B-location","O","O","B-location","O","O","O","O","B-location","O","O","O","O","B-event","I-event","I-event","O","O","O","O","O","O","O","B-location","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, location, literary genre, organization, poem, country, writer, magazine, event, book, person and O.\nSentence: Augustus dramatically enlarged the Empire , annexing Egypt , Dalmatia , Pannonia , Noricum , and Raetia , expanding possessions in Africa , and completing the conquest of Hispania , but suffered a major setback in Germania .","prompt_labels":"Augustus(B-person) dramatically(O) enlarged(O) the(O) Empire(O) ,(O) annexing(O) Egypt(B-country) ,(O) Dalmatia(B-location) ,(O) Pannonia(B-location) ,(O) Noricum(B-location) ,(O) and(O) Raetia(B-location) ,(O) expanding(O) possessions(O) in(O) Africa(B-location) ,(O) and(O) completing(O) the(O) conquest(B-event) of(I-event) Hispania(I-event) ,(O) but(O) suffered(O) a(O) major(O) setback(O) in(O) Germania(B-location) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["organization","country","location","writer","person","award","book","poem","event","literary genre","magazine"],"instance":{"id":"157","words":["In","1987","Allan","Gotthelf",",","George","Walsh","and","David","Kelley","co-founded","the","Ayn","Rand","Society",",","a","group","affiliated","with","the","American","Philosophical","Association","."],"labels":["O","O","B-person","I-person","O","B-person","I-person","O","B-person","I-person","O","O","B-organization","I-organization","I-organization","O","O","O","O","O","O","B-organization","I-organization","I-organization","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, country, location, writer, person, award, book, poem, event, literary genre, magazine and O.\nSentence: In 1987 Allan Gotthelf , George Walsh and David Kelley co-founded the Ayn Rand Society , a group affiliated with the American Philosophical Association .","prompt_labels":"In(O) 1987(O) Allan(B-person) Gotthelf(I-person) ,(O) George(B-person) Walsh(I-person) and(O) David(B-person) Kelley(I-person) co-founded(O) the(O) Ayn(B-organization) Rand(I-organization) Society(I-organization) ,(O) a(O) group(O) affiliated(O) with(O) the(O) American(B-organization) Philosophical(I-organization) Association(I-organization) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["writer","award","magazine","literary genre","event","person","poem","book","organization","location","country"],"instance":{"id":"158","words":["Avicenna","was","born","It","was","an","important","town","of","the","Samanid","Empire",",","in","what","is","today","Balkh","Province",",","Afghanistan","."],"labels":["B-writer","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-location","I-location","O","B-country","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: writer, award, magazine, literary genre, event, person, poem, book, organization, location, country and O.\nSentence: Avicenna was born It was an important town of the Samanid Empire , in what is today Balkh Province , Afghanistan .","prompt_labels":"Avicenna(B-writer) was(O) born(O) It(O) was(O) an(O) important(O) town(O) of(O) the(O) Samanid(O) Empire(O) ,(O) in(O) what(O) is(O) today(O) Balkh(B-location) Province(I-location) ,(O) Afghanistan(B-country) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["organization","literary genre","award","location","writer","person","book","event","country","poem","magazine"],"instance":{"id":"159","words":["In","2000",",","Anderson","starred","in","the","film","The","House","of","Mirth","with","Eric","Stoltz","-","Terence","Davies","'","adaptation","of","the","Edith","Wharton","novel","of","the","The","House","of","Mirth","-","for","which","she","won","critical","acclaim","and","awards","such","as","the","British","Independent","Film","Award","for","Best","Actress",",","Village","Voice","Film","Poll","Best","Lead","Performance",",","and","a","nomination","for","the","National","Society","of","Film","Critics","Award","for","Best","Actress","."],"labels":["O","O","O","B-writer","O","O","O","O","O","O","O","O","O","B-person","I-person","O","B-person","I-person","O","O","O","O","B-writer","I-writer","B-literary genre","O","O","B-book","I-book","I-book","I-book","O","O","O","O","O","O","O","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","I-award","I-award","O","B-award","I-award","I-award","I-award","I-award","I-award","I-award","O","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","I-award","I-award","I-award","I-award","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, literary genre, award, location, writer, person, book, event, country, poem, magazine and O.\nSentence: In 2000 , Anderson starred in the film The House of Mirth with Eric Stoltz - Terence Davies ' adaptation of the Edith Wharton novel of the The House of Mirth - for which she won critical acclaim and awards such as the British Independent Film Award for Best Actress , Village Voice Film Poll Best Lead Performance , and a nomination for the National Society of Film Critics Award for Best Actress .","prompt_labels":"In(O) 2000(O) ,(O) Anderson(B-writer) starred(O) in(O) the(O) film(O) The(O) House(O) of(O) Mirth(O) with(O) Eric(B-person) Stoltz(I-person) -(O) Terence(B-person) Davies(I-person) '(O) adaptation(O) of(O) the(O) Edith(B-writer) Wharton(I-writer) novel(B-literary genre) of(O) the(O) The(B-book) House(I-book) of(I-book) Mirth(I-book) -(O) for(O) which(O) she(O) won(O) critical(O) acclaim(O) and(O) awards(O) such(O) as(O) the(O) British(B-award) Independent(I-award) Film(I-award) Award(I-award) for(I-award) Best(I-award) Actress(I-award) ,(O) Village(B-award) Voice(I-award) Film(I-award) Poll(I-award) Best(I-award) Lead(I-award) Performance(I-award) ,(O) and(O) a(O) nomination(O) for(O) the(O) National(B-award) Society(I-award) of(I-award) Film(I-award) Critics(I-award) Award(I-award) for(I-award) Best(I-award) Actress(I-award) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["person","writer","country","organization","poem","magazine","book","award","location","literary genre","event"],"instance":{"id":"160","words":["In","the","sultanate",",","Burgess","sketched","the","novel","that",",","when","it","was","published","in","1961",",","was","to","be","entitled","Devil","of","a","State","and",",","although","it","dealt","with","Brunei",",","for","libel","reasons","the","action","had","to","be","transposed","to","an","imaginary","East","African","territory","similar","to","Zanzibar",",","named","Dunia","."],"labels":["O","O","O","O","B-writer","O","O","B-literary genre","O","O","O","O","O","O","O","O","O","O","O","O","O","B-book","I-book","I-book","I-book","O","O","O","O","O","O","B-country","O","O","O","O","O","O","O","O","O","O","O","O","O","B-location","I-location","O","O","O","B-country","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, writer, country, organization, poem, magazine, book, award, location, literary genre, event and O.\nSentence: In the sultanate , Burgess sketched the novel that , when it was published in 1961 , was to be entitled Devil of a State and , although it dealt with Brunei , for libel reasons the action had to be transposed to an imaginary East African territory similar to Zanzibar , named Dunia .","prompt_labels":"In(O) the(O) sultanate(O) ,(O) Burgess(B-writer) sketched(O) the(O) novel(B-literary genre) that(O) ,(O) when(O) it(O) was(O) published(O) in(O) 1961(O) ,(O) was(O) to(O) be(O) entitled(O) Devil(B-book) of(I-book) a(I-book) State(I-book) and(O) ,(O) although(O) it(O) dealt(O) with(O) Brunei(B-country) ,(O) for(O) libel(O) reasons(O) the(O) action(O) had(O) to(O) be(O) transposed(O) to(O) an(O) imaginary(O) East(B-location) African(I-location) territory(O) similar(O) to(O) Zanzibar(B-country) ,(O) named(O) Dunia(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["person","poem","organization","literary genre","location","event","book","magazine","award","country","writer"],"instance":{"id":"161","words":["Gordon","continued","her","stage","acting","career","in","the","1950s",",","and","was","nominated","for","a","1956","Tony","Award",",","for","Tony","Award","for","Best","Performance","by","a","Leading","Actress","in","a","Play",",","for","her","portrayal","of","Dolly","Levi","in","Thornton","Wilder","'","s","The","Matchmaker",",","a","role","she","also","played","in","London",",","Edinburgh","and","Berlin","."],"labels":["B-person","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-award","I-award","O","O","B-award","I-award","I-award","I-award","I-award","O","O","O","O","O","O","O","O","O","O","O","O","B-person","I-person","O","B-writer","I-writer","O","O","B-book","I-book","O","O","O","O","O","O","O","B-location","O","B-location","O","B-location","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, poem, organization, literary genre, location, event, book, magazine, award, country, writer and O.\nSentence: Gordon continued her stage acting career in the 1950s , and was nominated for a 1956 Tony Award , for Tony Award for Best Performance by a Leading Actress in a Play , for her portrayal of Dolly Levi in Thornton Wilder ' s The Matchmaker , a role she also played in London , Edinburgh and Berlin .","prompt_labels":"Gordon(B-person) continued(O) her(O) stage(O) acting(O) career(O) in(O) the(O) 1950s(O) ,(O) and(O) was(O) nominated(O) for(O) a(O) 1956(O) Tony(B-award) Award(I-award) ,(O) for(O) Tony(B-award) Award(I-award) for(I-award) Best(I-award) Performance(I-award) by(O) a(O) Leading(O) Actress(O) in(O) a(O) Play(O) ,(O) for(O) her(O) portrayal(O) of(O) Dolly(B-person) Levi(I-person) in(O) Thornton(B-writer) Wilder(I-writer) '(O) s(O) The(B-book) Matchmaker(I-book) ,(O) a(O) role(O) she(O) also(O) played(O) in(O) London(B-location) ,(O) Edinburgh(B-location) and(O) Berlin(B-location) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["event","literary genre","person","poem","award","country","book","location","magazine","organization","writer"],"instance":{"id":"162","words":["On","February","2",",","1966",",","he","made","his","Broadway","debut","as","Harry","Roat",",","Jr","in","Frederick","Knott","'","s","Wait","Until","Dark","at","the","Ethel","Barrymore","Theatre","."],"labels":["O","O","O","O","O","O","O","O","O","B-organization","O","O","B-person","I-person","I-person","I-person","O","B-writer","I-writer","O","O","B-book","I-book","I-book","O","O","B-location","I-location","I-location","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, literary genre, person, poem, award, country, book, location, magazine, organization, writer and O.\nSentence: On February 2 , 1966 , he made his Broadway debut as Harry Roat , Jr in Frederick Knott ' s Wait Until Dark at the Ethel Barrymore Theatre .","prompt_labels":"On(O) February(O) 2(O) ,(O) 1966(O) ,(O) he(O) made(O) his(O) Broadway(B-organization) debut(O) as(O) Harry(B-person) Roat(I-person) ,(I-person) Jr(I-person) in(O) Frederick(B-writer) Knott(I-writer) '(O) s(O) Wait(B-book) Until(I-book) Dark(I-book) at(O) the(O) Ethel(B-location) Barrymore(I-location) Theatre(I-location) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["organization","award","book","country","magazine","writer","location","literary genre","event","poem","person"],"instance":{"id":"163","words":["His","poem",",","Jai","Jai","Garavi","Gujarat",",","(","1873",")","is","used","as","a","de","facto","state","song","of","Gujarat","."],"labels":["O","B-literary genre","O","B-poem","I-poem","I-poem","I-poem","O","O","O","O","O","O","O","O","O","O","O","O","O","B-poem","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, award, book, country, magazine, writer, location, literary genre, event, poem, person and O.\nSentence: His poem , Jai Jai Garavi Gujarat , ( 1873 ) is used as a de facto state song of Gujarat .","prompt_labels":"His(O) poem(B-literary genre) ,(O) Jai(B-poem) Jai(I-poem) Garavi(I-poem) Gujarat(I-poem) ,(O) ((O) 1873(O) )(O) is(O) used(O) as(O) a(O) de(O) facto(O) state(O) song(O) of(O) Gujarat(B-poem) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["location","person","award","poem","writer","organization","country","book","event","literary genre","magazine"],"instance":{"id":"164","words":["In","2005",",","Arkham","House","was","awarded","the","World","Fantasy","Award","for","Small","Press","Achievements","-","the","trophy","at","that","time","was","a","bust","of","H.","P.","Lovecraft","."],"labels":["O","O","O","B-organization","I-organization","O","O","O","B-award","I-award","I-award","I-award","I-award","I-award","I-award","O","O","O","O","O","O","O","O","O","O","B-writer","I-writer","I-writer","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, person, award, poem, writer, organization, country, book, event, literary genre, magazine and O.\nSentence: In 2005 , Arkham House was awarded the World Fantasy Award for Small Press Achievements - the trophy at that time was a bust of H. P. Lovecraft .","prompt_labels":"In(O) 2005(O) ,(O) Arkham(B-organization) House(I-organization) was(O) awarded(O) the(O) World(B-award) Fantasy(I-award) Award(I-award) for(I-award) Small(I-award) Press(I-award) Achievements(I-award) -(O) the(O) trophy(O) at(O) that(O) time(O) was(O) a(O) bust(O) of(O) H.(B-writer) P.(I-writer) Lovecraft(I-writer) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["event","magazine","writer","country","literary genre","organization","book","location","person","poem","award"],"instance":{"id":"165","words":["In","addition","to","receiving","a","star","on","the","Hollywood","Walk","of","Fame",",","media","appearances","included","write-ups","in","CCM","Magazine",",","and","a","performance","on","The","View","."],"labels":["O","O","O","O","O","O","O","O","B-location","I-location","I-location","I-location","O","O","O","O","O","O","B-magazine","I-magazine","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, magazine, writer, country, literary genre, organization, book, location, person, poem, award and O.\nSentence: In addition to receiving a star on the Hollywood Walk of Fame , media appearances included write-ups in CCM Magazine , and a performance on The View .","prompt_labels":"In(O) addition(O) to(O) receiving(O) a(O) star(O) on(O) the(O) Hollywood(B-location) Walk(I-location) of(I-location) Fame(I-location) ,(O) media(O) appearances(O) included(O) write-ups(O) in(O) CCM(B-magazine) Magazine(I-magazine) ,(O) and(O) a(O) performance(O) on(O) The(O) View(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["magazine","literary genre","organization","writer","country","person","poem","award","book","event","location"],"instance":{"id":"166","words":["Her","last","novel",",","Unless","(","2002",")",",","was","nominated","for","the","2002","Giller","Prize",",","the","Governor","General","of","Canada","Literary","Award",",","the","Booker","Prize","and","the","2003","Orange","Prize","for","Fiction","."],"labels":["O","O","B-literary genre","O","B-book","O","O","O","O","O","O","O","O","O","B-award","I-award","O","O","B-award","I-award","I-award","I-award","I-award","I-award","O","O","B-award","I-award","O","O","B-award","I-award","I-award","I-award","I-award","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: magazine, literary genre, organization, writer, country, person, poem, award, book, event, location and O.\nSentence: Her last novel , Unless ( 2002 ) , was nominated for the 2002 Giller Prize , the Governor General of Canada Literary Award , the Booker Prize and the 2003 Orange Prize for Fiction .","prompt_labels":"Her(O) last(O) novel(B-literary genre) ,(O) Unless(B-book) ((O) 2002(O) )(O) ,(O) was(O) nominated(O) for(O) the(O) 2002(O) Giller(B-award) Prize(I-award) ,(O) the(O) Governor(B-award) General(I-award) of(I-award) Canada(I-award) Literary(I-award) Award(I-award) ,(O) the(O) Booker(B-award) Prize(I-award) and(O) the(O) 2003(B-award) Orange(I-award) Prize(I-award) for(I-award) Fiction(I-award) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["book","location","magazine","writer","literary genre","organization","country","award","person","poem","event"],"instance":{"id":"167","words":["In","the","same","year",",","he","produced","the","first","French","language","editions","of","Joseph","Conrad","'","s","Heart","of","Darkness","and","Lord","Jim","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","B-writer","I-writer","O","O","B-book","I-book","I-book","O","B-book","I-book","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: book, location, magazine, writer, literary genre, organization, country, award, person, poem, event and O.\nSentence: In the same year , he produced the first French language editions of Joseph Conrad ' s Heart of Darkness and Lord Jim .","prompt_labels":"In(O) the(O) same(O) year(O) ,(O) he(O) produced(O) the(O) first(O) French(O) language(O) editions(O) of(O) Joseph(B-writer) Conrad(I-writer) '(O) s(O) Heart(B-book) of(I-book) Darkness(I-book) and(O) Lord(B-book) Jim(I-book) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["person","book","event","organization","magazine","writer","award","location","poem","literary genre","country"],"instance":{"id":"168","words":["In","an","April","2015","interview","with","Billboard",",","Lavigne","announced","a","new","single","titled","Fly",",","which","was","released","on","April","26","in","association","with","the","2015","Special","Olympics","World","Summer","Games","."],"labels":["O","O","O","O","O","O","O","O","B-person","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-event","I-event","I-event","I-event","I-event","I-event","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, book, event, organization, magazine, writer, award, location, poem, literary genre, country and O.\nSentence: In an April 2015 interview with Billboard , Lavigne announced a new single titled Fly , which was released on April 26 in association with the 2015 Special Olympics World Summer Games .","prompt_labels":"In(O) an(O) April(O) 2015(O) interview(O) with(O) Billboard(O) ,(O) Lavigne(B-person) announced(O) a(O) new(O) single(O) titled(O) Fly(O) ,(O) which(O) was(O) released(O) on(O) April(O) 26(O) in(O) association(O) with(O) the(O) 2015(B-event) Special(I-event) Olympics(I-event) World(I-event) Summer(I-event) Games(I-event) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["event","book","literary genre","organization","writer","person","poem","award","magazine","location","country"],"instance":{"id":"169","words":["It","is","based","on","H.","P.","Lovecraft","'","s","Cthulhu","Mythos",",","particularly","At","the","Mountains","of","Madness",",","and","is","a","follow-up","to","Infogrames","'","earlier","Shadow","of","the","Comet","."],"labels":["O","O","O","O","B-writer","I-writer","I-writer","O","O","O","O","O","O","B-book","I-book","I-book","I-book","I-book","O","O","O","O","O","O","B-organization","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, book, literary genre, organization, writer, person, poem, award, magazine, location, country and O.\nSentence: It is based on H. P. Lovecraft ' s Cthulhu Mythos , particularly At the Mountains of Madness , and is a follow-up to Infogrames ' earlier Shadow of the Comet .","prompt_labels":"It(O) is(O) based(O) on(O) H.(B-writer) P.(I-writer) Lovecraft(I-writer) '(O) s(O) Cthulhu(O) Mythos(O) ,(O) particularly(O) At(B-book) the(I-book) Mountains(I-book) of(I-book) Madness(I-book) ,(O) and(O) is(O) a(O) follow-up(O) to(O) Infogrames(B-organization) '(O) earlier(O) Shadow(O) of(O) the(O) Comet(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["person","country","literary genre","magazine","book","event","organization","location","award","writer","poem"],"instance":{"id":"170","words":["After","leaving","formal","education",",","he","embarked","upon","a","self-directed","course","of","literature",",","including","Robinson","Crusoe",",","Gulliver","'s","Travels",",","the","fairy","tales","of","Hans","Christian","Andersen","and","Madame","d","'Aulnoy",",","the","Arabian","Nights","and","the","poems","of","Edgar","Allan","Poe","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-book","I-book","O","B-book","I-book","I-book","O","O","B-literary genre","I-literary genre","O","B-writer","I-writer","I-writer","O","B-writer","I-writer","I-writer","O","O","B-book","I-book","O","O","B-literary genre","O","B-writer","I-writer","I-writer","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, country, literary genre, magazine, book, event, organization, location, award, writer, poem and O.\nSentence: After leaving formal education , he embarked upon a self-directed course of literature , including Robinson Crusoe , Gulliver 's Travels , the fairy tales of Hans Christian Andersen and Madame d 'Aulnoy , the Arabian Nights and the poems of Edgar Allan Poe .","prompt_labels":"After(O) leaving(O) formal(O) education(O) ,(O) he(O) embarked(O) upon(O) a(O) self-directed(O) course(O) of(O) literature(O) ,(O) including(O) Robinson(B-book) Crusoe(I-book) ,(O) Gulliver(B-book) 's(I-book) Travels(I-book) ,(O) the(O) fairy(B-literary genre) tales(I-literary genre) of(O) Hans(B-writer) Christian(I-writer) Andersen(I-writer) and(O) Madame(B-writer) d(I-writer) 'Aulnoy(I-writer) ,(O) the(O) Arabian(B-book) Nights(I-book) and(O) the(O) poems(B-literary genre) of(O) Edgar(B-writer) Allan(I-writer) Poe(I-writer) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["country","book","event","writer","poem","literary genre","award","organization","location","person","magazine"],"instance":{"id":"171","words":["But","opponents","of","this","proposition","claim","that","Rabindranath","Tagore","mentioned","only","the","border","states","of","India","to","include","complete","India","."],"labels":["O","O","O","O","O","O","O","B-writer","I-writer","O","O","O","O","O","O","B-country","O","O","O","B-country","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, book, event, writer, poem, literary genre, award, organization, location, person, magazine and O.\nSentence: But opponents of this proposition claim that Rabindranath Tagore mentioned only the border states of India to include complete India .","prompt_labels":"But(O) opponents(O) of(O) this(O) proposition(O) claim(O) that(O) Rabindranath(B-writer) Tagore(I-writer) mentioned(O) only(O) the(O) border(O) states(O) of(O) India(B-country) to(O) include(O) complete(O) India(B-country) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["country","writer","literary genre","organization","person","book","location","magazine","poem","event","award"],"instance":{"id":"172","words":["In","1857",",","Dickens","hired","professional","actresses","for","the","play","The","Frozen","Deep",",","written","by","him","and","his","protg",",","Wilkie","Collins","."],"labels":["O","O","O","B-writer","O","O","O","O","O","O","B-book","I-book","I-book","O","O","O","O","O","O","O","O","B-writer","I-writer","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, writer, literary genre, organization, person, book, location, magazine, poem, event, award and O.\nSentence: In 1857 , Dickens hired professional actresses for the play The Frozen Deep , written by him and his protg , Wilkie Collins .","prompt_labels":"In(O) 1857(O) ,(O) Dickens(B-writer) hired(O) professional(O) actresses(O) for(O) the(O) play(O) The(B-book) Frozen(I-book) Deep(I-book) ,(O) written(O) by(O) him(O) and(O) his(O) protg(O) ,(O) Wilkie(B-writer) Collins(I-writer) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["book","organization","location","country","award","poem","writer","literary genre","magazine","event","person"],"instance":{"id":"173","words":["A","documentary","film","about","Rivers",",","Joan","Rivers",":","A","Piece","of","Work",",","premiered","at","the","San","Francisco","International","Film","Festival","on","May","6",",","2010","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-event","I-event","I-event","I-event","I-event","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: book, organization, location, country, award, poem, writer, literary genre, magazine, event, person and O.\nSentence: A documentary film about Rivers , Joan Rivers : A Piece of Work , premiered at the San Francisco International Film Festival on May 6 , 2010 .","prompt_labels":"A(O) documentary(O) film(O) about(O) Rivers(O) ,(O) Joan(O) Rivers(O) :(O) A(O) Piece(O) of(O) Work(O) ,(O) premiered(O) at(O) the(O) San(B-event) Francisco(I-event) International(I-event) Film(I-event) Festival(I-event) on(O) May(O) 6(O) ,(O) 2010(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["person","location","event","book","country","organization","writer","poem","literary genre","magazine","award"],"instance":{"id":"174","words":["Caravaggio","was","entered","into","the","36th","Berlin","International","Film","Festival",",","where","it","won","the","Silver","Bear","for","an","outstanding","single","achievement","."],"labels":["O","O","O","O","O","B-event","I-event","I-event","I-event","I-event","O","O","O","O","O","B-award","I-award","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, location, event, book, country, organization, writer, poem, literary genre, magazine, award and O.\nSentence: Caravaggio was entered into the 36th Berlin International Film Festival , where it won the Silver Bear for an outstanding single achievement .","prompt_labels":"Caravaggio(O) was(O) entered(O) into(O) the(O) 36th(B-event) Berlin(I-event) International(I-event) Film(I-event) Festival(I-event) ,(O) where(O) it(O) won(O) the(O) Silver(B-award) Bear(I-award) for(O) an(O) outstanding(O) single(O) achievement(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["person","writer","country","organization","literary genre","poem","event","award","magazine","location","book"],"instance":{"id":"175","words":["On","June","17",",","1915",",","shortly","after","submitting","his","patent","application","for","the","doll","'s","design",",","Johnny","Gruelle","applied","for","a","registered","trademark","for","the","Raggedy","Ann","name",",","which","he","created","by","combining","words","from","two","of","James","Whitcomb","Riley","poems",",","The","Raggedy","Man","and","Little","Orphant","Annie","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-person","I-person","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-writer","I-writer","I-writer","B-literary genre","O","B-poem","I-poem","I-poem","O","B-poem","I-poem","I-poem","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, writer, country, organization, literary genre, poem, event, award, magazine, location, book and O.\nSentence: On June 17 , 1915 , shortly after submitting his patent application for the doll 's design , Johnny Gruelle applied for a registered trademark for the Raggedy Ann name , which he created by combining words from two of James Whitcomb Riley poems , The Raggedy Man and Little Orphant Annie .","prompt_labels":"On(O) June(O) 17(O) ,(O) 1915(O) ,(O) shortly(O) after(O) submitting(O) his(O) patent(O) application(O) for(O) the(O) doll(O) 's(O) design(O) ,(O) Johnny(B-person) Gruelle(I-person) applied(O) for(O) a(O) registered(O) trademark(O) for(O) the(O) Raggedy(O) Ann(O) name(O) ,(O) which(O) he(O) created(O) by(O) combining(O) words(O) from(O) two(O) of(O) James(B-writer) Whitcomb(I-writer) Riley(I-writer) poems(B-literary genre) ,(O) The(B-poem) Raggedy(I-poem) Man(I-poem) and(O) Little(B-poem) Orphant(I-poem) Annie(I-poem) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["magazine","literary genre","organization","country","award","writer","person","location","poem","event","book"],"instance":{"id":"176","words":["Satirical","poets","outside","England","include","Poland","'","s","Ignacy","Krasicki",",","Azerbaijan","'","s","Mirza","Alakbar","Sabir","and","Portugal","'","s","Manuel","Maria","Barbosa","du","Bocage","."],"labels":["B-literary genre","O","O","B-country","O","B-country","O","O","B-writer","I-writer","O","B-country","O","O","B-writer","I-writer","I-writer","O","B-country","O","O","B-writer","I-writer","I-writer","I-writer","I-writer","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: magazine, literary genre, organization, country, award, writer, person, location, poem, event, book and O.\nSentence: Satirical poets outside England include Poland ' s Ignacy Krasicki , Azerbaijan ' s Mirza Alakbar Sabir and Portugal ' s Manuel Maria Barbosa du Bocage .","prompt_labels":"Satirical(B-literary genre) poets(O) outside(O) England(B-country) include(O) Poland(B-country) '(O) s(O) Ignacy(B-writer) Krasicki(I-writer) ,(O) Azerbaijan(B-country) '(O) s(O) Mirza(B-writer) Alakbar(I-writer) Sabir(I-writer) and(O) Portugal(B-country) '(O) s(O) Manuel(B-writer) Maria(I-writer) Barbosa(I-writer) du(I-writer) Bocage(I-writer) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["magazine","book","organization","poem","literary genre","country","award","writer","person","location","event"],"instance":{"id":"177","words":["The","main","facts","of","his","life","are","stated","in","his","long","poem","De","triumphis","ecclesiae","(","On","the","triumphs","of","the","Church",")","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-literary genre","I-literary genre","B-poem","I-poem","I-poem","O","B-poem","I-poem","I-poem","I-poem","I-poem","I-poem","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: magazine, book, organization, poem, literary genre, country, award, writer, person, location, event and O.\nSentence: The main facts of his life are stated in his long poem De triumphis ecclesiae ( On the triumphs of the Church ) .","prompt_labels":"The(O) main(O) facts(O) of(O) his(O) life(O) are(O) stated(O) in(O) his(O) long(B-literary genre) poem(I-literary genre) De(B-poem) triumphis(I-poem) ecclesiae(I-poem) ((O) On(B-poem) the(I-poem) triumphs(I-poem) of(I-poem) the(I-poem) Church(I-poem) )(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["organization","location","book","magazine","person","writer","poem","event","award","literary genre","country"],"instance":{"id":"178","words":["Guillaume","Apollinaire",",","Andr","Salmon","and","Max","Jacob","sought","him","out","in","his","truncated","apartment","."],"labels":["B-writer","I-writer","O","B-writer","I-writer","O","B-writer","I-writer","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, location, book, magazine, person, writer, poem, event, award, literary genre, country and O.\nSentence: Guillaume Apollinaire , Andr Salmon and Max Jacob sought him out in his truncated apartment .","prompt_labels":"Guillaume(B-writer) Apollinaire(I-writer) ,(O) Andr(B-writer) Salmon(I-writer) and(O) Max(B-writer) Jacob(I-writer) sought(O) him(O) out(O) in(O) his(O) truncated(O) apartment(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["writer","magazine","person","location","event","poem","award","literary genre","book","organization","country"],"instance":{"id":"179","words":["It","has","been","credited","by","American","poets","like","W.","S.","Merwin",",","and","American","scholars","like","Clare","Cavanagh",",","with","having","a","profound","impact","."],"labels":["O","O","O","O","O","O","O","O","B-writer","I-writer","I-writer","O","O","O","O","O","B-writer","I-writer","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: writer, magazine, person, location, event, poem, award, literary genre, book, organization, country and O.\nSentence: It has been credited by American poets like W. S. Merwin , and American scholars like Clare Cavanagh , with having a profound impact .","prompt_labels":"It(O) has(O) been(O) credited(O) by(O) American(O) poets(O) like(O) W.(B-writer) S.(I-writer) Merwin(I-writer) ,(O) and(O) American(O) scholars(O) like(O) Clare(B-writer) Cavanagh(I-writer) ,(O) with(O) having(O) a(O) profound(O) impact(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["magazine","person","location","organization","poem","writer","country","award","book","literary genre","event"],"instance":{"id":"180","words":["Fredric","Brown","employed","this","subgenre","to","satirize","the","science","fiction","pulps","and","their","adolescent","readers","-","and","fears","of","foreign","invasion","-","in","the","classic","What","Mad","Universe","(","1949",")","."],"labels":["B-writer","I-writer","O","O","O","O","O","O","B-literary genre","I-literary genre","I-literary genre","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-book","I-book","I-book","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: magazine, person, location, organization, poem, writer, country, award, book, literary genre, event and O.\nSentence: Fredric Brown employed this subgenre to satirize the science fiction pulps and their adolescent readers - and fears of foreign invasion - in the classic What Mad Universe ( 1949 ) .","prompt_labels":"Fredric(B-writer) Brown(I-writer) employed(O) this(O) subgenre(O) to(O) satirize(O) the(O) science(B-literary genre) fiction(I-literary genre) pulps(I-literary genre) and(O) their(O) adolescent(O) readers(O) -(O) and(O) fears(O) of(O) foreign(O) invasion(O) -(O) in(O) the(O) classic(O) What(B-book) Mad(I-book) Universe(I-book) ((O) 1949(O) )(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["writer","award","organization","literary genre","event","magazine","book","poem","location","country","person"],"instance":{"id":"181","words":["Like","his","contemporaries","Algernon","Blackwood","and","Arthur","Machen",",","Rohmer","claimed","membership","to","one","of","the","factions","of","the","qabbalistic","Hermetic","Order","of","the","Golden","Dawn","."],"labels":["O","O","O","B-writer","I-writer","O","B-writer","I-writer","O","B-writer","O","O","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: writer, award, organization, literary genre, event, magazine, book, poem, location, country, person and O.\nSentence: Like his contemporaries Algernon Blackwood and Arthur Machen , Rohmer claimed membership to one of the factions of the qabbalistic Hermetic Order of the Golden Dawn .","prompt_labels":"Like(O) his(O) contemporaries(O) Algernon(B-writer) Blackwood(I-writer) and(O) Arthur(B-writer) Machen(I-writer) ,(O) Rohmer(B-writer) claimed(O) membership(O) to(O) one(O) of(O) the(O) factions(O) of(O) the(O) qabbalistic(O) Hermetic(B-organization) Order(I-organization) of(I-organization) the(I-organization) Golden(I-organization) Dawn(I-organization) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["event","poem","magazine","book","location","organization","person","country","writer","award","literary genre"],"instance":{"id":"182","words":["Asimov","notes","in","his","introduction","to","the","short","story","collection","The","Complete","Robot","(","1982",")","that","he","was","largely","inspired","by","the","almost","relentless","tendency","of","robots","up","to","that","time","to","fall","consistently","into","a","Frankenstein","plot","in","which","they","destroyed","their","creators","."],"labels":["B-writer","O","O","O","O","O","O","B-literary genre","I-literary genre","O","B-book","I-book","I-book","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-book","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, poem, magazine, book, location, organization, person, country, writer, award, literary genre and O.\nSentence: Asimov notes in his introduction to the short story collection The Complete Robot ( 1982 ) that he was largely inspired by the almost relentless tendency of robots up to that time to fall consistently into a Frankenstein plot in which they destroyed their creators .","prompt_labels":"Asimov(B-writer) notes(O) in(O) his(O) introduction(O) to(O) the(O) short(B-literary genre) story(I-literary genre) collection(O) The(B-book) Complete(I-book) Robot(I-book) ((O) 1982(O) )(O) that(O) he(O) was(O) largely(O) inspired(O) by(O) the(O) almost(O) relentless(O) tendency(O) of(O) robots(O) up(O) to(O) that(O) time(O) to(O) fall(O) consistently(O) into(O) a(O) Frankenstein(B-book) plot(O) in(O) which(O) they(O) destroyed(O) their(O) creators(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["event","magazine","literary genre","award","person","writer","poem","location","book","country","organization"],"instance":{"id":"183","words":["The","Pulitzer","Prize","-winning","The","Grapes","of","Wrath","(","1939",")"],"labels":["O","B-award","I-award","O","B-book","I-book","I-book","I-book","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, magazine, literary genre, award, person, writer, poem, location, book, country, organization and O.\nSentence: The Pulitzer Prize -winning The Grapes of Wrath ( 1939 )","prompt_labels":"The(O) Pulitzer(B-award) Prize(I-award) -winning(O) The(B-book) Grapes(I-book) of(I-book) Wrath(I-book) ((O) 1939(O) )(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["book","event","award","person","writer","organization","location","magazine","poem","country","literary genre"],"instance":{"id":"184","words":["Carter","has","been","nominated","nine","times","for","the","Grammy","Award","for","Best","Spoken","Word","Album","for","audio","recordings","of","his","books",",","and","has","won","three","times","-","for","Our","Endangered","Values","(","2007",")",",","A","Full","Life",":","Reflections","at","90","(","2016",")","and","Faith",":","A","Journey","For","All","(","2019",")","."],"labels":["B-person","O","O","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","I-award","I-award","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-book","I-book","I-book","O","O","O","O","B-book","I-book","I-book","I-book","I-book","I-book","I-book","O","O","O","O","B-book","I-book","I-book","I-book","I-book","I-book","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: book, event, award, person, writer, organization, location, magazine, poem, country, literary genre and O.\nSentence: Carter has been nominated nine times for the Grammy Award for Best Spoken Word Album for audio recordings of his books , and has won three times - for Our Endangered Values ( 2007 ) , A Full Life : Reflections at 90 ( 2016 ) and Faith : A Journey For All ( 2019 ) .","prompt_labels":"Carter(B-person) has(O) been(O) nominated(O) nine(O) times(O) for(O) the(O) Grammy(B-award) Award(I-award) for(I-award) Best(I-award) Spoken(I-award) Word(I-award) Album(I-award) for(O) audio(O) recordings(O) of(O) his(O) books(O) ,(O) and(O) has(O) won(O) three(O) times(O) -(O) for(O) Our(B-book) Endangered(I-book) Values(I-book) ((O) 2007(O) )(O) ,(O) A(B-book) Full(I-book) Life(I-book) :(I-book) Reflections(I-book) at(I-book) 90(I-book) ((O) 2016(O) )(O) and(O) Faith(B-book) :(I-book) A(I-book) Journey(I-book) For(I-book) All(I-book) ((O) 2019(O) )(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["magazine","location","book","award","writer","country","person","organization","poem","event","literary genre"],"instance":{"id":"185","words":["Kamel","Daoud","has","written","a","novel","The","Meursault","Investigation","(","2013","\/","2014",")",",","first","published","in","Algeria","in","2013",",","and","then","republished","in","France","to","critical","acclaim","."],"labels":["B-writer","I-writer","O","O","O","B-literary genre","B-book","I-book","I-book","O","O","O","O","O","O","O","O","O","B-country","O","O","O","O","O","O","O","B-country","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: magazine, location, book, award, writer, country, person, organization, poem, event, literary genre and O.\nSentence: Kamel Daoud has written a novel The Meursault Investigation ( 2013 \/ 2014 ) , first published in Algeria in 2013 , and then republished in France to critical acclaim .","prompt_labels":"Kamel(B-writer) Daoud(I-writer) has(O) written(O) a(O) novel(B-literary genre) The(B-book) Meursault(I-book) Investigation(I-book) ((O) 2013(O) \/(O) 2014(O) )(O) ,(O) first(O) published(O) in(O) Algeria(B-country) in(O) 2013(O) ,(O) and(O) then(O) republished(O) in(O) France(B-country) to(O) critical(O) acclaim(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["book","magazine","event","poem","literary genre","location","award","writer","country","person","organization"],"instance":{"id":"186","words":["Thereafter",",","the","first","piece","to","provide","substantial","information","about","Pynchon","'s","personal","life","was","a","biographical","account","written","by","a","former","Cornell","University","friend",",","Jules","Siegel",",","and","published","in","Playboy","magazine","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-writer","O","O","O","O","O","O","O","O","O","O","O","B-organization","I-organization","O","O","B-writer","I-writer","O","O","O","O","B-magazine","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: book, magazine, event, poem, literary genre, location, award, writer, country, person, organization and O.\nSentence: Thereafter , the first piece to provide substantial information about Pynchon 's personal life was a biographical account written by a former Cornell University friend , Jules Siegel , and published in Playboy magazine .","prompt_labels":"Thereafter(O) ,(O) the(O) first(O) piece(O) to(O) provide(O) substantial(O) information(O) about(O) Pynchon(B-writer) 's(O) personal(O) life(O) was(O) a(O) biographical(O) account(O) written(O) by(O) a(O) former(O) Cornell(B-organization) University(I-organization) friend(O) ,(O) Jules(B-writer) Siegel(I-writer) ,(O) and(O) published(O) in(O) Playboy(B-magazine) magazine(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["magazine","person","award","book","poem","event","literary genre","writer","country","location","organization"],"instance":{"id":"187","words":["H.","P.","Lovecraft","stated","that","in","sheer","daemonic","strangeness","and","fertility","of","conception",",","Clark","Ashton","Smith","is","perhaps","unexcelled",",","and","Ray","Bradbury","said","that","Smith","filled","my","mind","with","incredible","worlds",",","impossibly","beautiful","cities",",","and","still","more","fantastic","creatures","."],"labels":["B-writer","I-writer","I-writer","O","O","O","O","O","O","O","O","O","O","O","B-writer","I-writer","I-writer","O","O","O","O","O","B-writer","I-writer","O","O","B-writer","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: magazine, person, award, book, poem, event, literary genre, writer, country, location, organization and O.\nSentence: H. P. Lovecraft stated that in sheer daemonic strangeness and fertility of conception , Clark Ashton Smith is perhaps unexcelled , and Ray Bradbury said that Smith filled my mind with incredible worlds , impossibly beautiful cities , and still more fantastic creatures .","prompt_labels":"H.(B-writer) P.(I-writer) Lovecraft(I-writer) stated(O) that(O) in(O) sheer(O) daemonic(O) strangeness(O) and(O) fertility(O) of(O) conception(O) ,(O) Clark(B-writer) Ashton(I-writer) Smith(I-writer) is(O) perhaps(O) unexcelled(O) ,(O) and(O) Ray(B-writer) Bradbury(I-writer) said(O) that(O) Smith(B-writer) filled(O) my(O) mind(O) with(O) incredible(O) worlds(O) ,(O) impossibly(O) beautiful(O) cities(O) ,(O) and(O) still(O) more(O) fantastic(O) creatures(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["award","magazine","poem","writer","organization","person","book","event","literary genre","country","location"],"instance":{"id":"188","words":["In","September","2006","Kenneth","Branagh","announced","at","the","Venice","Film","Festival","his","new","film","of","the","play",",","with","the","screenplay","by","Nobel","laureate","Harold","Pinter","."],"labels":["O","O","O","B-person","I-person","O","O","O","B-event","I-event","I-event","O","O","O","O","O","O","O","O","O","O","O","B-award","O","B-writer","I-writer","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, magazine, poem, writer, organization, person, book, event, literary genre, country, location and O.\nSentence: In September 2006 Kenneth Branagh announced at the Venice Film Festival his new film of the play , with the screenplay by Nobel laureate Harold Pinter .","prompt_labels":"In(O) September(O) 2006(O) Kenneth(B-person) Branagh(I-person) announced(O) at(O) the(O) Venice(B-event) Film(I-event) Festival(I-event) his(O) new(O) film(O) of(O) the(O) play(O) ,(O) with(O) the(O) screenplay(O) by(O) Nobel(B-award) laureate(O) Harold(B-writer) Pinter(I-writer) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["magazine","literary genre","country","organization","poem","award","book","location","person","writer","event"],"instance":{"id":"189","words":["These","avant-garde","poets","drew","inspiration","from","earlier","Greek","authors",",","especially","Sappho","and","Callimachus",";","Catullus","himself","used","Sapphic","meter","in","two","poems",",","Catullus","11","and","51",",","the","second","of","which","is","almost","a","translation","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","B-writer","O","B-writer","O","B-writer","O","O","B-literary genre","I-literary genre","O","O","B-literary genre","O","B-poem","I-poem","O","B-poem","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: magazine, literary genre, country, organization, poem, award, book, location, person, writer, event and O.\nSentence: These avant-garde poets drew inspiration from earlier Greek authors , especially Sappho and Callimachus ; Catullus himself used Sapphic meter in two poems , Catullus 11 and 51 , the second of which is almost a translation .","prompt_labels":"These(O) avant-garde(O) poets(O) drew(O) inspiration(O) from(O) earlier(O) Greek(O) authors(O) ,(O) especially(O) Sappho(B-writer) and(O) Callimachus(B-writer) ;(O) Catullus(B-writer) himself(O) used(O) Sapphic(B-literary genre) meter(I-literary genre) in(O) two(O) poems(B-literary genre) ,(O) Catullus(B-poem) 11(I-poem) and(O) 51(B-poem) ,(O) the(O) second(O) of(O) which(O) is(O) almost(O) a(O) translation(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["award","magazine","country","literary genre","book","person","writer","poem","organization","location","event"],"instance":{"id":"190","words":["Another","poem","that","is","ambiguous","in","this","respect","is","The","Virgin","Carrying","a","Lantern","."],"labels":["O","O","O","O","O","O","O","O","O","B-poem","I-poem","I-poem","I-poem","I-poem","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, magazine, country, literary genre, book, person, writer, poem, organization, location, event and O.\nSentence: Another poem that is ambiguous in this respect is The Virgin Carrying a Lantern .","prompt_labels":"Another(O) poem(O) that(O) is(O) ambiguous(O) in(O) this(O) respect(O) is(O) The(B-poem) Virgin(I-poem) Carrying(I-poem) a(I-poem) Lantern(I-poem) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["literary genre","location","event","magazine","organization","country","poem","award","person","writer","book"],"instance":{"id":"191","words":["Of","Things","to","Come",",","The","New","York","Times","Book","Review",",","October","26",",","1975","Theodore","Sturgeon","praised","The","Dispossessed","as","a","beautifully","written",",","beautifully","composed","book",",","saying","it","performs","one","of","science","fiction","'s","prime","functions",",","which","is","to","create","another","kind","of","social","system","to","see","how","it","would","work","."],"labels":["O","O","O","O","O","B-magazine","I-magazine","I-magazine","I-magazine","I-magazine","I-magazine","O","O","O","O","O","B-writer","I-writer","O","B-book","I-book","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-literary genre","I-literary genre","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: literary genre, location, event, magazine, organization, country, poem, award, person, writer, book and O.\nSentence: Of Things to Come , The New York Times Book Review , October 26 , 1975 Theodore Sturgeon praised The Dispossessed as a beautifully written , beautifully composed book , saying it performs one of science fiction 's prime functions , which is to create another kind of social system to see how it would work .","prompt_labels":"Of(O) Things(O) to(O) Come(O) ,(O) The(B-magazine) New(I-magazine) York(I-magazine) Times(I-magazine) Book(I-magazine) Review(I-magazine) ,(O) October(O) 26(O) ,(O) 1975(O) Theodore(B-writer) Sturgeon(I-writer) praised(O) The(B-book) Dispossessed(I-book) as(O) a(O) beautifully(O) written(O) ,(O) beautifully(O) composed(O) book(O) ,(O) saying(O) it(O) performs(O) one(O) of(O) science(B-literary genre) fiction(I-literary genre) 's(O) prime(O) functions(O) ,(O) which(O) is(O) to(O) create(O) another(O) kind(O) of(O) social(O) system(O) to(O) see(O) how(O) it(O) would(O) work(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["magazine","writer","country","literary genre","award","person","book","location","organization","poem","event"],"instance":{"id":"192","words":["On","the","day","of","the","preview",",","however",",","he","was","expelled","from","the","Surrealist","Group","by","Andr","Breton",",","who","ordered","the","poet","Paul","luard","to","take","down","his","pictures","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-organization","I-organization","O","B-writer","I-writer","O","O","O","O","O","B-writer","I-writer","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: magazine, writer, country, literary genre, award, person, book, location, organization, poem, event and O.\nSentence: On the day of the preview , however , he was expelled from the Surrealist Group by Andr Breton , who ordered the poet Paul luard to take down his pictures .","prompt_labels":"On(O) the(O) day(O) of(O) the(O) preview(O) ,(O) however(O) ,(O) he(O) was(O) expelled(O) from(O) the(O) Surrealist(B-organization) Group(I-organization) by(O) Andr(B-writer) Breton(I-writer) ,(O) who(O) ordered(O) the(O) poet(O) Paul(B-writer) luard(I-writer) to(O) take(O) down(O) his(O) pictures(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["literary genre","magazine","writer","poem","event","person","country","location","award","book","organization"],"instance":{"id":"193","words":["In","view","of","the","success","of","her","novels",",","particularly","Jane","Eyre",",","Bront","was","persuaded","by","her","publisher","to","make","occasional","visits","to","London",",","where","she","revealed","her","TRUE","identity","and","began","to","move","in","more","exalted","social","circles",",","becoming","friends","with","Harriet","Martineau","and","Elizabeth","Gaskell",",","and","acquainted","with","William","Makepeace","Thackeray","and","G.H.","Lewes","."],"labels":["O","O","O","O","O","O","O","B-literary genre","O","O","B-book","I-book","O","B-writer","O","O","O","O","O","O","O","O","O","O","B-location","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-writer","I-writer","O","B-writer","I-writer","O","O","O","O","B-writer","I-writer","I-writer","O","B-writer","I-writer","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: literary genre, magazine, writer, poem, event, person, country, location, award, book, organization and O.\nSentence: In view of the success of her novels , particularly Jane Eyre , Bront was persuaded by her publisher to make occasional visits to London , where she revealed her TRUE identity and began to move in more exalted social circles , becoming friends with Harriet Martineau and Elizabeth Gaskell , and acquainted with William Makepeace Thackeray and G.H. Lewes .","prompt_labels":"In(O) view(O) of(O) the(O) success(O) of(O) her(O) novels(B-literary genre) ,(O) particularly(O) Jane(B-book) Eyre(I-book) ,(O) Bront(B-writer) was(O) persuaded(O) by(O) her(O) publisher(O) to(O) make(O) occasional(O) visits(O) to(O) London(B-location) ,(O) where(O) she(O) revealed(O) her(O) TRUE(O) identity(O) and(O) began(O) to(O) move(O) in(O) more(O) exalted(O) social(O) circles(O) ,(O) becoming(O) friends(O) with(O) Harriet(B-writer) Martineau(I-writer) and(O) Elizabeth(B-writer) Gaskell(I-writer) ,(O) and(O) acquainted(O) with(O) William(B-writer) Makepeace(I-writer) Thackeray(I-writer) and(O) G.H.(B-writer) Lewes(I-writer) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["event","literary genre","location","writer","award","magazine","country","book","organization","person","poem"],"instance":{"id":"194","words":["His","non-fiction","works",",","including","The","Road","to","Wigan","Pier","(","1937",")",",","documenting","his","experience","of","working-class","life","in","the","north","of","England",",","and","Homage","to","Catalonia","(","1938",")",",","an","account","of","his","experiences","soldiering","for","the","Republican","faction","of","the","Spanish","Civil","War","(","1936-1939",")",",","are","as","critically","respected","as","his","essays","on","politics","and","literature",",","language","and","culture","."],"labels":["O","O","O","O","O","B-book","I-book","I-book","I-book","I-book","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-country","O","O","B-book","I-book","I-book","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-event","I-event","I-event","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, literary genre, location, writer, award, magazine, country, book, organization, person, poem and O.\nSentence: His non-fiction works , including The Road to Wigan Pier ( 1937 ) , documenting his experience of working-class life in the north of England , and Homage to Catalonia ( 1938 ) , an account of his experiences soldiering for the Republican faction of the Spanish Civil War ( 1936-1939 ) , are as critically respected as his essays on politics and literature , language and culture .","prompt_labels":"His(O) non-fiction(O) works(O) ,(O) including(O) The(B-book) Road(I-book) to(I-book) Wigan(I-book) Pier(I-book) ((O) 1937(O) )(O) ,(O) documenting(O) his(O) experience(O) of(O) working-class(O) life(O) in(O) the(O) north(O) of(O) England(B-country) ,(O) and(O) Homage(B-book) to(I-book) Catalonia(I-book) ((O) 1938(O) )(O) ,(O) an(O) account(O) of(O) his(O) experiences(O) soldiering(O) for(O) the(O) Republican(O) faction(O) of(O) the(O) Spanish(B-event) Civil(I-event) War(I-event) ((O) 1936-1939(O) )(O) ,(O) are(O) as(O) critically(O) respected(O) as(O) his(O) essays(O) on(O) politics(O) and(O) literature(O) ,(O) language(O) and(O) culture(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["magazine","book","writer","country","literary genre","location","organization","event","person","award","poem"],"instance":{"id":"195","words":["Big","Brother","is","a","fictional","character","and","symbol","in","George","Orwell","'","s","dystopian","novel","Nineteen","Eighty-Four",",","published","in","1949","."],"labels":["B-person","I-person","O","O","O","O","O","O","O","B-writer","I-writer","O","O","B-literary genre","I-literary genre","B-book","I-book","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: magazine, book, writer, country, literary genre, location, organization, event, person, award, poem and O.\nSentence: Big Brother is a fictional character and symbol in George Orwell ' s dystopian novel Nineteen Eighty-Four , published in 1949 .","prompt_labels":"Big(B-person) Brother(I-person) is(O) a(O) fictional(O) character(O) and(O) symbol(O) in(O) George(B-writer) Orwell(I-writer) '(O) s(O) dystopian(B-literary genre) novel(I-literary genre) Nineteen(B-book) Eighty-Four(I-book) ,(O) published(O) in(O) 1949(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["organization","person","magazine","writer","country","event","literary genre","book","award","location","poem"],"instance":{"id":"196","words":["In","May","1999",",","after","the","Council","of","Fashion","Designers","of","America","recognized","Cher","with","an","award","for","her","influence","on","fashion",",","Robin","Givhan","of","the","Los","Angeles","Times","called","her","a","fashion","visionary","for","striking","just","the","right","note","of","contemporary","wretched","excess","."],"labels":["O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","B-writer","O","O","O","O","O","O","O","O","O","B-writer","I-writer","O","O","B-organization","I-organization","I-organization","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, person, magazine, writer, country, event, literary genre, book, award, location, poem and O.\nSentence: In May 1999 , after the Council of Fashion Designers of America recognized Cher with an award for her influence on fashion , Robin Givhan of the Los Angeles Times called her a fashion visionary for striking just the right note of contemporary wretched excess .","prompt_labels":"In(O) May(O) 1999(O) ,(O) after(O) the(O) Council(B-organization) of(I-organization) Fashion(I-organization) Designers(I-organization) of(I-organization) America(I-organization) recognized(O) Cher(B-writer) with(O) an(O) award(O) for(O) her(O) influence(O) on(O) fashion(O) ,(O) Robin(B-writer) Givhan(I-writer) of(O) the(O) Los(B-organization) Angeles(I-organization) Times(I-organization) called(O) her(O) a(O) fashion(O) visionary(O) for(O) striking(O) just(O) the(O) right(O) note(O) of(O) contemporary(O) wretched(O) excess(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["person","poem","award","literary genre","location","writer","magazine","organization","event","country","book"],"instance":{"id":"197","words":["Adams","'s","posthumously","published","work",",","The","Salmon","of","Doubt",",","features","several","articles","by","him","on","the","subject","of","technology",",","including","reprints","of","articles","that","originally","ran","in","MacUser","magazine",",","and","in","The","Independent","on","Sunday","newspaper","."],"labels":["B-writer","O","O","O","O","O","B-book","I-book","I-book","I-book","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-magazine","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, poem, award, literary genre, location, writer, magazine, organization, event, country, book and O.\nSentence: Adams 's posthumously published work , The Salmon of Doubt , features several articles by him on the subject of technology , including reprints of articles that originally ran in MacUser magazine , and in The Independent on Sunday newspaper .","prompt_labels":"Adams(B-writer) 's(O) posthumously(O) published(O) work(O) ,(O) The(B-book) Salmon(I-book) of(I-book) Doubt(I-book) ,(O) features(O) several(O) articles(O) by(O) him(O) on(O) the(O) subject(O) of(O) technology(O) ,(O) including(O) reprints(O) of(O) articles(O) that(O) originally(O) ran(O) in(O) MacUser(B-magazine) magazine(O) ,(O) and(O) in(O) The(B-organization) Independent(I-organization) on(I-organization) Sunday(I-organization) newspaper(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["magazine","event","literary genre","person","location","country","poem","award","writer","book","organization"],"instance":{"id":"198","words":["When","Martin","Gardner","retired","from","writing","his","Mathematical","Games","column","for","Scientific","American","magazine",",","Hofstadter","succeeded","him","in","1981-1983","with","a","column","titled","Metamagical","Themas","(","an","anagram","of","Mathematical","Games",")","."],"labels":["O","B-writer","I-writer","O","O","O","O","B-book","I-book","O","O","B-magazine","I-magazine","O","O","B-writer","O","O","O","O","O","O","O","O","B-book","I-book","O","O","O","O","B-book","I-book","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: magazine, event, literary genre, person, location, country, poem, award, writer, book, organization and O.\nSentence: When Martin Gardner retired from writing his Mathematical Games column for Scientific American magazine , Hofstadter succeeded him in 1981-1983 with a column titled Metamagical Themas ( an anagram of Mathematical Games ) .","prompt_labels":"When(O) Martin(B-writer) Gardner(I-writer) retired(O) from(O) writing(O) his(O) Mathematical(B-book) Games(I-book) column(O) for(O) Scientific(B-magazine) American(I-magazine) magazine(O) ,(O) Hofstadter(B-writer) succeeded(O) him(O) in(O) 1981-1983(O) with(O) a(O) column(O) titled(O) Metamagical(B-book) Themas(I-book) ((O) an(O) anagram(O) of(O) Mathematical(B-book) Games(I-book) )(O) .(O)"}}
{"dataset":"crossner_literature","split":"dev","label_list":["book","country","poem","literary genre","award","location","event","writer","organization","magazine","person"],"instance":{"id":"199","words":["Norman","Spinrad","wrote","The","Iron","Dream","in","1972",",","which","is","intended","to","be","a","science","fiction","novel","written","by","Adolf","Hitler","after","fleeing","from","Europe","to","North","America","in","the","1920s","."],"labels":["B-writer","I-writer","O","B-book","I-book","I-book","O","O","O","O","O","O","O","O","O","B-literary genre","I-literary genre","I-literary genre","O","O","B-person","I-person","O","O","O","B-location","O","B-location","I-location","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: book, country, poem, literary genre, award, location, event, writer, organization, magazine, person and O.\nSentence: Norman Spinrad wrote The Iron Dream in 1972 , which is intended to be a science fiction novel written by Adolf Hitler after fleeing from Europe to North America in the 1920s .","prompt_labels":"Norman(B-writer) Spinrad(I-writer) wrote(O) The(B-book) Iron(I-book) Dream(I-book) in(O) 1972(O) ,(O) which(O) is(O) intended(O) to(O) be(O) a(O) science(B-literary genre) fiction(I-literary genre) novel(I-literary genre) written(O) by(O) Adolf(B-person) Hitler(I-person) after(O) fleeing(O) from(O) Europe(B-location) to(O) North(B-location) America(I-location) in(O) the(O) 1920s(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["song","band","musical artist","award","location","organization","person","album","music genre","musical instrument","country","event"],"instance":{"id":"0","words":["As","part","of","the","2010","leg","of","the","My","Christmas","Tour",",","Bocelli","gave","two","concerts","in","The","O2","Arena",",","in","London",",","and","the","Manchester","Arena",",","in","Manchester",",","and","a","concert","at","3Arena",",","in","Dublin",",","in","late","November","2010","."],"labels":["O","O","O","O","O","O","O","O","B-event","I-event","I-event","O","B-musical artist","O","O","O","O","B-location","I-location","I-location","O","O","B-location","O","O","O","B-location","I-location","O","O","B-location","O","O","O","O","O","B-location","O","O","B-location","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, band, musical artist, award, location, organization, person, album, music genre, musical instrument, country, event and O.\nSentence: As part of the 2010 leg of the My Christmas Tour , Bocelli gave two concerts in The O2 Arena , in London , and the Manchester Arena , in Manchester , and a concert at 3Arena , in Dublin , in late November 2010 .","prompt_labels":"As(O) part(O) of(O) the(O) 2010(O) leg(O) of(O) the(O) My(B-event) Christmas(I-event) Tour(I-event) ,(O) Bocelli(B-musical artist) gave(O) two(O) concerts(O) in(O) The(B-location) O2(I-location) Arena(I-location) ,(O) in(O) London(B-location) ,(O) and(O) the(O) Manchester(B-location) Arena(I-location) ,(O) in(O) Manchester(B-location) ,(O) and(O) a(O) concert(O) at(O) 3Arena(B-location) ,(O) in(O) Dublin(B-location) ,(O) in(O) late(O) November(O) 2010(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["person","event","musical artist","music genre","musical instrument","album","award","country","organization","location","band","song"],"instance":{"id":"1","words":["Squarepusher","continues","to","push","new","boundaries","to","this","day",",","where","he","still","calls","Warp","Records","his","home",",","having","released","numerous","albums","to","critical","acclaim","in","the","years","to","follow",",","such","as","Go","Plastic",",","Do","You","Know","Squarepusher",",","Ultravisitor",",","Hello","Everything",",","Just","a","Souvenir",",","Solo","Electric","Bass","1",",","Ufabulum","and","Damogen","Furies","."],"labels":["B-musical artist","O","O","O","O","O","O","O","O","O","O","O","O","O","B-organization","I-organization","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-album","I-album","O","B-album","I-album","I-album","I-album","O","B-album","O","B-album","I-album","O","B-album","I-album","I-album","O","B-album","I-album","I-album","I-album","O","B-album","O","B-album","I-album","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, event, musical artist, music genre, musical instrument, album, award, country, organization, location, band, song and O.\nSentence: Squarepusher continues to push new boundaries to this day , where he still calls Warp Records his home , having released numerous albums to critical acclaim in the years to follow , such as Go Plastic , Do You Know Squarepusher , Ultravisitor , Hello Everything , Just a Souvenir , Solo Electric Bass 1 , Ufabulum and Damogen Furies .","prompt_labels":"Squarepusher(B-musical artist) continues(O) to(O) push(O) new(O) boundaries(O) to(O) this(O) day(O) ,(O) where(O) he(O) still(O) calls(O) Warp(B-organization) Records(I-organization) his(O) home(O) ,(O) having(O) released(O) numerous(O) albums(O) to(O) critical(O) acclaim(O) in(O) the(O) years(O) to(O) follow(O) ,(O) such(O) as(O) Go(B-album) Plastic(I-album) ,(O) Do(B-album) You(I-album) Know(I-album) Squarepusher(I-album) ,(O) Ultravisitor(B-album) ,(O) Hello(B-album) Everything(I-album) ,(O) Just(B-album) a(I-album) Souvenir(I-album) ,(O) Solo(B-album) Electric(I-album) Bass(I-album) 1(I-album) ,(O) Ufabulum(B-album) and(O) Damogen(B-album) Furies(I-album) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["music genre","person","album","song","musical instrument","event","country","band","award","musical artist","location","organization"],"instance":{"id":"2","words":["During","the","1990s",",","many","releases","included","recordings","of","classical","compositions",":","Pictures","at","an","Exhibition","(","on","Turn","of","the","Tides",")",",","Largo","(","from","Xerxes",")","(","on","Tyranny","of","Beauty",")",",","Symphony","in","A","Minor","(","by","J.","S.","Bach",")",",","and","Concerto","in","A","Major","\/","Adagio","(","by","Wolfgang","Amadeus","Mozart",")","(","both","on","Ambient","Monkeys",")","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","B-song","I-song","I-song","I-song","O","O","B-album","I-album","I-album","I-album","O","O","B-song","O","O","O","O","O","O","B-album","I-album","I-album","O","O","B-song","I-song","I-song","I-song","O","O","B-musical artist","I-musical artist","I-musical artist","O","O","O","B-song","I-song","I-song","I-song","I-song","I-song","O","O","B-musical artist","I-musical artist","I-musical artist","O","O","O","O","B-album","I-album","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: music genre, person, album, song, musical instrument, event, country, band, award, musical artist, location, organization and O.\nSentence: During the 1990s , many releases included recordings of classical compositions : Pictures at an Exhibition ( on Turn of the Tides ) , Largo ( from Xerxes ) ( on Tyranny of Beauty ) , Symphony in A Minor ( by J. S. Bach ) , and Concerto in A Major \/ Adagio ( by Wolfgang Amadeus Mozart ) ( both on Ambient Monkeys ) .","prompt_labels":"During(O) the(O) 1990s(O) ,(O) many(O) releases(O) included(O) recordings(O) of(O) classical(O) compositions(O) :(O) Pictures(B-song) at(I-song) an(I-song) Exhibition(I-song) ((O) on(O) Turn(B-album) of(I-album) the(I-album) Tides(I-album) )(O) ,(O) Largo(B-song) ((O) from(O) Xerxes(O) )(O) ((O) on(O) Tyranny(B-album) of(I-album) Beauty(I-album) )(O) ,(O) Symphony(B-song) in(I-song) A(I-song) Minor(I-song) ((O) by(O) J.(B-musical artist) S.(I-musical artist) Bach(I-musical artist) )(O) ,(O) and(O) Concerto(B-song) in(I-song) A(I-song) Major(I-song) \/(I-song) Adagio(I-song) ((O) by(O) Wolfgang(B-musical artist) Amadeus(I-musical artist) Mozart(I-musical artist) )(O) ((O) both(O) on(O) Ambient(B-album) Monkeys(I-album) )(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["musical instrument","album","musical artist","person","organization","award","music genre","location","song","country","event","band"],"instance":{"id":"3","words":["He","has","also","won","three","Grammy","Awards",",","14","Academy","of","Country","Music","awards",",","11","Country","Music","Association","(","CMA",")","awards",",","10","American","Music","Awards",",","and","three","People","'s","Choice","Awards","."],"labels":["O","O","O","O","O","B-award","I-award","O","O","B-award","I-award","I-award","I-award","I-award","O","O","B-award","I-award","I-award","I-award","I-award","I-award","I-award","O","O","B-award","I-award","I-award","O","O","O","B-award","I-award","I-award","I-award","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: musical instrument, album, musical artist, person, organization, award, music genre, location, song, country, event, band and O.\nSentence: He has also won three Grammy Awards , 14 Academy of Country Music awards , 11 Country Music Association ( CMA ) awards , 10 American Music Awards , and three People 's Choice Awards .","prompt_labels":"He(O) has(O) also(O) won(O) three(O) Grammy(B-award) Awards(I-award) ,(O) 14(O) Academy(B-award) of(I-award) Country(I-award) Music(I-award) awards(I-award) ,(O) 11(O) Country(B-award) Music(I-award) Association(I-award) ((I-award) CMA(I-award) )(I-award) awards(I-award) ,(O) 10(O) American(B-award) Music(I-award) Awards(I-award) ,(O) and(O) three(O) People(B-award) 's(I-award) Choice(I-award) Awards(I-award) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["country","event","organization","musical artist","music genre","musical instrument","song","award","album","person","location","band"],"instance":{"id":"4","words":["ABBA","were","soon","recognised","and","embraced","by","other","acts",":","Evan","Dando","of","the","Lemonheads","recorded","a","cover","version","of","Knowing","Me",",","Knowing","You",";","Sinad","O","'Connor","and","Boyzone","'s","Stephen","Gately","have","recorded","Chiquitita",";","Tanita","Tikaram",",","Blancmange","and","Steven","Wilson","paid","tribute","to","The","Day","Before","You","Came","."],"labels":["B-band","O","O","O","O","O","O","O","O","O","B-musical artist","I-musical artist","O","B-band","I-band","O","O","O","O","O","B-song","I-song","I-song","I-song","I-song","O","B-musical artist","I-musical artist","I-musical artist","O","B-band","O","B-musical artist","I-musical artist","O","O","B-song","O","B-musical artist","I-musical artist","O","B-band","O","B-musical artist","I-musical artist","O","O","O","B-song","I-song","I-song","I-song","I-song","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, event, organization, musical artist, music genre, musical instrument, song, award, album, person, location, band and O.\nSentence: ABBA were soon recognised and embraced by other acts : Evan Dando of the Lemonheads recorded a cover version of Knowing Me , Knowing You ; Sinad O 'Connor and Boyzone 's Stephen Gately have recorded Chiquitita ; Tanita Tikaram , Blancmange and Steven Wilson paid tribute to The Day Before You Came .","prompt_labels":"ABBA(B-band) were(O) soon(O) recognised(O) and(O) embraced(O) by(O) other(O) acts(O) :(O) Evan(B-musical artist) Dando(I-musical artist) of(O) the(B-band) Lemonheads(I-band) recorded(O) a(O) cover(O) version(O) of(O) Knowing(B-song) Me(I-song) ,(I-song) Knowing(I-song) You(I-song) ;(O) Sinad(B-musical artist) O(I-musical artist) 'Connor(I-musical artist) and(O) Boyzone(B-band) 's(O) Stephen(B-musical artist) Gately(I-musical artist) have(O) recorded(O) Chiquitita(B-song) ;(O) Tanita(B-musical artist) Tikaram(I-musical artist) ,(O) Blancmange(B-band) and(O) Steven(B-musical artist) Wilson(I-musical artist) paid(O) tribute(O) to(O) The(B-song) Day(I-song) Before(I-song) You(I-song) Came(I-song) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["person","organization","location","award","band","musical artist","musical instrument","music genre","country","album","event","song"],"instance":{"id":"5","words":["His","style","incorporates","elements","of","Rock","music",",","blues",",","Soul","music",",","R","&","B",",","funk",",","jazz",",","reggae",",","hard","rock",",","Psychedelic","rock",",","Pop","music",",","Folk","music",",","and","ballads","."],"labels":["O","O","O","O","O","B-music genre","I-music genre","O","B-music genre","O","B-music genre","I-music genre","O","B-music genre","I-music genre","I-music genre","O","B-music genre","O","B-music genre","O","B-music genre","O","B-music genre","I-music genre","O","B-music genre","I-music genre","O","B-music genre","I-music genre","O","B-music genre","I-music genre","O","O","B-music genre","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, organization, location, award, band, musical artist, musical instrument, music genre, country, album, event, song and O.\nSentence: His style incorporates elements of Rock music , blues , Soul music , R & B , funk , jazz , reggae , hard rock , Psychedelic rock , Pop music , Folk music , and ballads .","prompt_labels":"His(O) style(O) incorporates(O) elements(O) of(O) Rock(B-music genre) music(I-music genre) ,(O) blues(B-music genre) ,(O) Soul(B-music genre) music(I-music genre) ,(O) R(B-music genre) &(I-music genre) B(I-music genre) ,(O) funk(B-music genre) ,(O) jazz(B-music genre) ,(O) reggae(B-music genre) ,(O) hard(B-music genre) rock(I-music genre) ,(O) Psychedelic(B-music genre) rock(I-music genre) ,(O) Pop(B-music genre) music(I-music genre) ,(O) Folk(B-music genre) music(I-music genre) ,(O) and(O) ballads(B-music genre) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["musical artist","song","event","location","musical instrument","album","organization","music genre","award","person","country","band"],"instance":{"id":"6","words":["Hildy","tempts","him","into","taking","a","tour","of","the","city",",","but","all","the","places","he","wants","to","go","(","New","York","Hippodrome",",","the","Forrest","Theatre","to","see","Tobacco","Road",",","the","New","York","City","Aquarium",",","and","the","Woolworth","Building",")","are","either","no","longer","in","existence","or","no","longer","notable","."],"labels":["B-person","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-location","I-location","I-location","O","O","B-location","I-location","O","O","B-location","I-location","O","O","B-location","I-location","I-location","I-location","O","O","O","B-location","I-location","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: musical artist, song, event, location, musical instrument, album, organization, music genre, award, person, country, band and O.\nSentence: Hildy tempts him into taking a tour of the city , but all the places he wants to go ( New York Hippodrome , the Forrest Theatre to see Tobacco Road , the New York City Aquarium , and the Woolworth Building ) are either no longer in existence or no longer notable .","prompt_labels":"Hildy(B-person) tempts(O) him(O) into(O) taking(O) a(O) tour(O) of(O) the(O) city(O) ,(O) but(O) all(O) the(O) places(O) he(O) wants(O) to(O) go(O) ((O) New(B-location) York(I-location) Hippodrome(I-location) ,(O) the(O) Forrest(B-location) Theatre(I-location) to(O) see(O) Tobacco(B-location) Road(I-location) ,(O) the(O) New(B-location) York(I-location) City(I-location) Aquarium(I-location) ,(O) and(O) the(O) Woolworth(B-location) Building(I-location) )(O) are(O) either(O) no(O) longer(O) in(O) existence(O) or(O) no(O) longer(O) notable(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["organization","event","album","band","music genre","person","musical instrument","musical artist","award","country","song","location"],"instance":{"id":"7","words":["It","was","Recording","Industry","Association","of","America","triple","platinum","in","America",",","Two","more","singles","from","the","album","-","Policy","of","Truth","and","World","in","My","Eyes","-","were","hits","in","the","UK",",","with","the","former","also","charting","in","the","US","."],"labels":["O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","O","O","B-country","O","O","O","O","O","O","O","O","B-song","I-song","I-song","O","B-song","I-song","I-song","I-song","O","O","O","O","O","B-country","O","O","O","O","O","O","O","O","B-country","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, event, album, band, music genre, person, musical instrument, musical artist, award, country, song, location and O.\nSentence: It was Recording Industry Association of America triple platinum in America , Two more singles from the album - Policy of Truth and World in My Eyes - were hits in the UK , with the former also charting in the US .","prompt_labels":"It(O) was(O) Recording(B-organization) Industry(I-organization) Association(I-organization) of(I-organization) America(I-organization) triple(O) platinum(O) in(O) America(B-country) ,(O) Two(O) more(O) singles(O) from(O) the(O) album(O) -(O) Policy(B-song) of(I-song) Truth(I-song) and(O) World(B-song) in(I-song) My(I-song) Eyes(I-song) -(O) were(O) hits(O) in(O) the(O) UK(B-country) ,(O) with(O) the(O) former(O) also(O) charting(O) in(O) the(O) US(B-country) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["award","musical artist","country","person","band","event","album","song","location","musical instrument","organization","music genre"],"instance":{"id":"8","words":["The","album","was","certified","seven-times","platinum","in","Australia","by","the","Australian","Recording","Industry","Association","(","ARIA",")",",","five-times","platinum","in","the","UK","by","the","British","Phonographic","Industry","(","BPI",")",",","and","platinum","in","the","US","by","the","Recording","Industry","Association","of","America","(","RIAA",")","."],"labels":["O","O","O","O","O","O","O","B-country","O","O","B-organization","I-organization","I-organization","I-organization","O","B-organization","O","O","O","O","O","O","B-country","O","O","B-organization","I-organization","I-organization","O","B-organization","O","O","O","O","O","O","B-country","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","B-organization","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, musical artist, country, person, band, event, album, song, location, musical instrument, organization, music genre and O.\nSentence: The album was certified seven-times platinum in Australia by the Australian Recording Industry Association ( ARIA ) , five-times platinum in the UK by the British Phonographic Industry ( BPI ) , and platinum in the US by the Recording Industry Association of America ( RIAA ) .","prompt_labels":"The(O) album(O) was(O) certified(O) seven-times(O) platinum(O) in(O) Australia(B-country) by(O) the(O) Australian(B-organization) Recording(I-organization) Industry(I-organization) Association(I-organization) ((O) ARIA(B-organization) )(O) ,(O) five-times(O) platinum(O) in(O) the(O) UK(B-country) by(O) the(O) British(B-organization) Phonographic(I-organization) Industry(I-organization) ((O) BPI(B-organization) )(O) ,(O) and(O) platinum(O) in(O) the(O) US(B-country) by(O) the(O) Recording(B-organization) Industry(I-organization) Association(I-organization) of(I-organization) America(I-organization) ((O) RIAA(B-organization) )(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["event","location","musical artist","musical instrument","song","album","music genre","organization","band","award","country","person"],"instance":{"id":"9","words":["Ernest","Jennings","Ford","(","February","13",",","1919","-","October","17",",","1991",")",",","known","professionally","as","Tennessee","Ernie","Ford",",","was","an","American","singer","and","television","host","who","enjoyed","success","in","the","Country","music",",","Pop","music",",","and","Gospel","music","musical","genres","."],"labels":["B-musical artist","I-musical artist","I-musical artist","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-musical artist","I-musical artist","I-musical artist","O","O","O","O","O","O","O","O","O","O","O","O","O","B-music genre","I-music genre","O","B-music genre","I-music genre","O","O","B-music genre","I-music genre","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, location, musical artist, musical instrument, song, album, music genre, organization, band, award, country, person and O.\nSentence: Ernest Jennings Ford ( February 13 , 1919 - October 17 , 1991 ) , known professionally as Tennessee Ernie Ford , was an American singer and television host who enjoyed success in the Country music , Pop music , and Gospel music musical genres .","prompt_labels":"Ernest(B-musical artist) Jennings(I-musical artist) Ford(I-musical artist) ((O) February(O) 13(O) ,(O) 1919(O) -(O) October(O) 17(O) ,(O) 1991(O) )(O) ,(O) known(O) professionally(O) as(O) Tennessee(B-musical artist) Ernie(I-musical artist) Ford(I-musical artist) ,(O) was(O) an(O) American(O) singer(O) and(O) television(O) host(O) who(O) enjoyed(O) success(O) in(O) the(O) Country(B-music genre) music(I-music genre) ,(O) Pop(B-music genre) music(I-music genre) ,(O) and(O) Gospel(B-music genre) music(I-music genre) musical(O) genres(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["award","music genre","musical artist","musical instrument","country","album","song","organization","location","band","event","person"],"instance":{"id":"10","words":["South","Africa","'s","Cape","Town","Opera","has","frequently","performed","Porgy","and","Bess","abroad",",","most","notably","with","the","Welsh","National","Opera",",","NorrlandsOperan",",","Deutsche","Oper","Berlin","and","at","the","Wales","Millennium","Centre",",","Royal","Festival","Hall","and","Edinburgh","Festival","Theatre","."],"labels":["B-country","I-country","O","B-organization","I-organization","I-organization","O","O","O","O","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","O","B-organization","O","B-organization","I-organization","I-organization","O","O","O","B-location","I-location","I-location","O","B-location","I-location","I-location","O","B-location","I-location","I-location","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, music genre, musical artist, musical instrument, country, album, song, organization, location, band, event, person and O.\nSentence: South Africa 's Cape Town Opera has frequently performed Porgy and Bess abroad , most notably with the Welsh National Opera , NorrlandsOperan , Deutsche Oper Berlin and at the Wales Millennium Centre , Royal Festival Hall and Edinburgh Festival Theatre .","prompt_labels":"South(B-country) Africa(I-country) 's(O) Cape(B-organization) Town(I-organization) Opera(I-organization) has(O) frequently(O) performed(O) Porgy(O) and(O) Bess(O) abroad(O) ,(O) most(O) notably(O) with(O) the(O) Welsh(B-organization) National(I-organization) Opera(I-organization) ,(O) NorrlandsOperan(B-organization) ,(O) Deutsche(B-organization) Oper(I-organization) Berlin(I-organization) and(O) at(O) the(O) Wales(B-location) Millennium(I-location) Centre(I-location) ,(O) Royal(B-location) Festival(I-location) Hall(I-location) and(O) Edinburgh(B-location) Festival(I-location) Theatre(I-location) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["award","location","album","musical instrument","country","music genre","event","song","band","musical artist","person","organization"],"instance":{"id":"11","words":["Some","of","his","most","celebrated","designs","adorned","the","sleeves","of","albums","such","as","Midnight","Blue",",","Out","to","Lunch","!",",","Unity",",","Somethin","'","Else",",","Let","Freedom","Ring",",","Hub-Tones",",","No","Room","for","Squares",",","Cool","Struttin","'",",","and","The","Sidewinder","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","B-album","I-album","O","B-album","I-album","I-album","I-album","O","B-album","O","B-album","I-album","I-album","O","B-album","I-album","I-album","O","B-album","O","B-album","I-album","I-album","I-album","O","B-album","I-album","I-album","O","O","B-album","I-album","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, location, album, musical instrument, country, music genre, event, song, band, musical artist, person, organization and O.\nSentence: Some of his most celebrated designs adorned the sleeves of albums such as Midnight Blue , Out to Lunch ! , Unity , Somethin ' Else , Let Freedom Ring , Hub-Tones , No Room for Squares , Cool Struttin ' , and The Sidewinder .","prompt_labels":"Some(O) of(O) his(O) most(O) celebrated(O) designs(O) adorned(O) the(O) sleeves(O) of(O) albums(O) such(O) as(O) Midnight(B-album) Blue(I-album) ,(O) Out(B-album) to(I-album) Lunch(I-album) !(I-album) ,(O) Unity(B-album) ,(O) Somethin(B-album) '(I-album) Else(I-album) ,(O) Let(B-album) Freedom(I-album) Ring(I-album) ,(O) Hub-Tones(B-album) ,(O) No(B-album) Room(I-album) for(I-album) Squares(I-album) ,(O) Cool(B-album) Struttin(I-album) '(I-album) ,(O) and(O) The(B-album) Sidewinder(I-album) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["person","band","album","musical artist","event","award","country","music genre","song","organization","musical instrument","location"],"instance":{"id":"12","words":["Pop","'s","music","has","encompassed","a","number","of","styles","over","the","course","of","his","career",",","including","garage","rock",",","punk","rock",",","hard","rock",",","Heavy","metal","music",",","art","rock",",","New","wave","music",",","jazz",",","blues",",","and","Electronic","music","."],"labels":["B-music genre","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-music genre","I-music genre","O","B-music genre","I-music genre","O","B-music genre","I-music genre","O","B-music genre","I-music genre","I-music genre","O","B-music genre","I-music genre","O","B-music genre","I-music genre","I-music genre","O","B-music genre","O","B-music genre","O","O","B-music genre","I-music genre","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, band, album, musical artist, event, award, country, music genre, song, organization, musical instrument, location and O.\nSentence: Pop 's music has encompassed a number of styles over the course of his career , including garage rock , punk rock , hard rock , Heavy metal music , art rock , New wave music , jazz , blues , and Electronic music .","prompt_labels":"Pop(B-music genre) 's(O) music(O) has(O) encompassed(O) a(O) number(O) of(O) styles(O) over(O) the(O) course(O) of(O) his(O) career(O) ,(O) including(O) garage(B-music genre) rock(I-music genre) ,(O) punk(B-music genre) rock(I-music genre) ,(O) hard(B-music genre) rock(I-music genre) ,(O) Heavy(B-music genre) metal(I-music genre) music(I-music genre) ,(O) art(B-music genre) rock(I-music genre) ,(O) New(B-music genre) wave(I-music genre) music(I-music genre) ,(O) jazz(B-music genre) ,(O) blues(B-music genre) ,(O) and(O) Electronic(B-music genre) music(I-music genre) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["country","music genre","song","event","musical instrument","organization","location","musical artist","award","band","person","album"],"instance":{"id":"13","words":["Although","his","bandmate","Martin","Gore","continues","to","be","the","main","songwriter","for","Depeche","Mode",",","Gahan","has","contributed","a","number","of","songs","to","the","albums","Playing","the","Angel","(","2005",")",",","Sounds","of","the","Universe","(","2009",")",",","Delta","Machine","(","2013",")","and","Spirit","(","2017",")","."],"labels":["O","O","O","B-musical artist","I-musical artist","O","O","O","O","O","O","O","B-band","I-band","O","B-musical artist","O","O","O","O","O","O","O","O","O","B-album","I-album","I-album","O","O","O","O","B-album","I-album","I-album","I-album","O","O","O","O","B-album","I-album","O","O","O","O","B-album","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, music genre, song, event, musical instrument, organization, location, musical artist, award, band, person, album and O.\nSentence: Although his bandmate Martin Gore continues to be the main songwriter for Depeche Mode , Gahan has contributed a number of songs to the albums Playing the Angel ( 2005 ) , Sounds of the Universe ( 2009 ) , Delta Machine ( 2013 ) and Spirit ( 2017 ) .","prompt_labels":"Although(O) his(O) bandmate(O) Martin(B-musical artist) Gore(I-musical artist) continues(O) to(O) be(O) the(O) main(O) songwriter(O) for(O) Depeche(B-band) Mode(I-band) ,(O) Gahan(B-musical artist) has(O) contributed(O) a(O) number(O) of(O) songs(O) to(O) the(O) albums(O) Playing(B-album) the(I-album) Angel(I-album) ((O) 2005(O) )(O) ,(O) Sounds(B-album) of(I-album) the(I-album) Universe(I-album) ((O) 2009(O) )(O) ,(O) Delta(B-album) Machine(I-album) ((O) 2013(O) )(O) and(O) Spirit(B-album) ((O) 2017(O) )(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["musical instrument","organization","album","person","song","award","location","event","band","musical artist","music genre","country"],"instance":{"id":"14","words":["Phoenix","has","long","been","a","social","activist",",","lending","his","support","to","a","number","of","charities","and","humanitarian","organizations",",","such","as","Amnesty","International",",","The","Art","of","Elysium",",","HEART",",","and","the","Peace","Alliance","(","which","campaigns","for","a","United","States","Department","of","Peace",")","."],"labels":["B-band","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-organization","I-organization","O","B-organization","I-organization","I-organization","I-organization","O","B-organization","O","O","O","B-organization","I-organization","O","O","O","O","O","B-country","I-country","B-organization","I-organization","I-organization","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: musical instrument, organization, album, person, song, award, location, event, band, musical artist, music genre, country and O.\nSentence: Phoenix has long been a social activist , lending his support to a number of charities and humanitarian organizations , such as Amnesty International , The Art of Elysium , HEART , and the Peace Alliance ( which campaigns for a United States Department of Peace ) .","prompt_labels":"Phoenix(B-band) has(O) long(O) been(O) a(O) social(O) activist(O) ,(O) lending(O) his(O) support(O) to(O) a(O) number(O) of(O) charities(O) and(O) humanitarian(O) organizations(O) ,(O) such(O) as(O) Amnesty(B-organization) International(I-organization) ,(O) The(B-organization) Art(I-organization) of(I-organization) Elysium(I-organization) ,(O) HEART(B-organization) ,(O) and(O) the(O) Peace(B-organization) Alliance(I-organization) ((O) which(O) campaigns(O) for(O) a(O) United(B-country) States(I-country) Department(B-organization) of(I-organization) Peace(I-organization) )(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["band","song","country","organization","musical artist","music genre","location","person","award","musical instrument","album","event"],"instance":{"id":"15","words":["The","best-selling","album","in","the","band","'s","catalog",",","I","Against","I","is","an","album","that","mixes","American","hardcore","punk","with","funk",",","Soul","music",",","reggae","and","Heavy","metal","music","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-album","O","O","O","O","O","O","O","B-music genre","I-music genre","O","B-music genre","O","B-music genre","I-music genre","O","B-music genre","O","B-music genre","I-music genre","I-music genre","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: band, song, country, organization, musical artist, music genre, location, person, award, musical instrument, album, event and O.\nSentence: The best-selling album in the band 's catalog , I Against I is an album that mixes American hardcore punk with funk , Soul music , reggae and Heavy metal music .","prompt_labels":"The(O) best-selling(O) album(O) in(O) the(O) band(O) 's(O) catalog(O) ,(O) I(O) Against(B-album) I(O) is(O) an(O) album(O) that(O) mixes(O) American(O) hardcore(B-music genre) punk(I-music genre) with(O) funk(B-music genre) ,(O) Soul(B-music genre) music(I-music genre) ,(O) reggae(B-music genre) and(O) Heavy(B-music genre) metal(I-music genre) music(I-music genre) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["event","musical artist","organization","person","band","location","album","country","musical instrument","award","music genre","song"],"instance":{"id":"16","words":["Since","the","introduction","of","the","50","\/","50","voting","system","in","2009",",","the","juries","and","the","voters","have","disagreed","on","the","winner","on","five","occasions",",","in","Eurovision","Song","Contest","2011",",","Eurovision","Song","Contest","2015",",","Eurovision","Song","Contest","2016",",","Eurovision","Song","Contest","2018","and","Eurovision","Song","Contest","2019","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-event","I-event","I-event","I-event","O","B-event","I-event","I-event","I-event","O","B-event","I-event","I-event","I-event","O","B-event","I-event","I-event","I-event","O","B-event","I-event","I-event","I-event","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, musical artist, organization, person, band, location, album, country, musical instrument, award, music genre, song and O.\nSentence: Since the introduction of the 50 \/ 50 voting system in 2009 , the juries and the voters have disagreed on the winner on five occasions , in Eurovision Song Contest 2011 , Eurovision Song Contest 2015 , Eurovision Song Contest 2016 , Eurovision Song Contest 2018 and Eurovision Song Contest 2019 .","prompt_labels":"Since(O) the(O) introduction(O) of(O) the(O) 50(O) \/(O) 50(O) voting(O) system(O) in(O) 2009(O) ,(O) the(O) juries(O) and(O) the(O) voters(O) have(O) disagreed(O) on(O) the(O) winner(O) on(O) five(O) occasions(O) ,(O) in(O) Eurovision(B-event) Song(I-event) Contest(I-event) 2011(I-event) ,(O) Eurovision(B-event) Song(I-event) Contest(I-event) 2015(I-event) ,(O) Eurovision(B-event) Song(I-event) Contest(I-event) 2016(I-event) ,(O) Eurovision(B-event) Song(I-event) Contest(I-event) 2018(I-event) and(O) Eurovision(B-event) Song(I-event) Contest(I-event) 2019(I-event) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["music genre","band","musical artist","musical instrument","location","person","song","organization","event","album","award","country"],"instance":{"id":"17","words":["Artists","from","outside","California","who","were","associated","with","early","alternative","country","included","singer-songwriters","such","as","Lucinda","Williams",",","Lyle","Lovett","and","Steve","Earle",",","the","Nashville","country","rock","band","Jason","and","the","Scorchers","and","the","British","post-punk","band","The","Mekons","."],"labels":["O","O","O","B-location","O","O","O","O","O","B-music genre","I-music genre","O","O","O","O","B-musical artist","I-musical artist","O","B-musical artist","I-musical artist","O","B-musical artist","I-musical artist","O","O","O","O","O","O","B-band","I-band","I-band","I-band","O","O","O","B-music genre","O","B-band","I-band","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: music genre, band, musical artist, musical instrument, location, person, song, organization, event, album, award, country and O.\nSentence: Artists from outside California who were associated with early alternative country included singer-songwriters such as Lucinda Williams , Lyle Lovett and Steve Earle , the Nashville country rock band Jason and the Scorchers and the British post-punk band The Mekons .","prompt_labels":"Artists(O) from(O) outside(O) California(B-location) who(O) were(O) associated(O) with(O) early(O) alternative(B-music genre) country(I-music genre) included(O) singer-songwriters(O) such(O) as(O) Lucinda(B-musical artist) Williams(I-musical artist) ,(O) Lyle(B-musical artist) Lovett(I-musical artist) and(O) Steve(B-musical artist) Earle(I-musical artist) ,(O) the(O) Nashville(O) country(O) rock(O) band(O) Jason(B-band) and(I-band) the(I-band) Scorchers(I-band) and(O) the(O) British(O) post-punk(B-music genre) band(O) The(B-band) Mekons(I-band) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["album","music genre","organization","location","musical artist","musical instrument","band","song","award","person","country","event"],"instance":{"id":"18","words":["Andrews","has","won","an","Academy","Award",",","a","BAFTA",",","five","Golden","Globes",",","three","Grammy","Award",",","two","Emmy","Award",",","the","AFI","Life","Achievement","Award",",","the","Screen","Actors","Guild","Life","Achievement","Award",",","the","Kennedy","Center","Honors","Award",",","and","the","Disney","Legends","Award","."],"labels":["B-person","O","O","O","B-award","I-award","O","O","B-award","O","O","B-award","I-award","O","O","B-award","I-award","O","O","B-award","I-award","O","O","B-award","I-award","I-award","I-award","O","O","B-award","I-award","I-award","I-award","I-award","I-award","O","O","B-award","I-award","I-award","I-award","O","O","O","B-award","I-award","I-award","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: album, music genre, organization, location, musical artist, musical instrument, band, song, award, person, country, event and O.\nSentence: Andrews has won an Academy Award , a BAFTA , five Golden Globes , three Grammy Award , two Emmy Award , the AFI Life Achievement Award , the Screen Actors Guild Life Achievement Award , the Kennedy Center Honors Award , and the Disney Legends Award .","prompt_labels":"Andrews(B-person) has(O) won(O) an(O) Academy(B-award) Award(I-award) ,(O) a(O) BAFTA(B-award) ,(O) five(O) Golden(B-award) Globes(I-award) ,(O) three(O) Grammy(B-award) Award(I-award) ,(O) two(O) Emmy(B-award) Award(I-award) ,(O) the(O) AFI(B-award) Life(I-award) Achievement(I-award) Award(I-award) ,(O) the(O) Screen(B-award) Actors(I-award) Guild(I-award) Life(I-award) Achievement(I-award) Award(I-award) ,(O) the(O) Kennedy(B-award) Center(I-award) Honors(I-award) Award(I-award) ,(O) and(O) the(O) Disney(B-award) Legends(I-award) Award(I-award) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["organization","person","musical artist","country","award","event","location","band","music genre","musical instrument","album","song"],"instance":{"id":"19","words":["The","film","was","nominated","for","the","Academy","Awards","for","Academy","Award","for","Best","Picture",",","as","well","as","Academy","Award","for","Best","Production","Design","(","Carroll","Clark","and","Van","Nest","Polglase",")",",","Academy","Award","for","Best","Original","Song","(","Irving","Berlin","for","Cheek","to","Cheek",")",",","and","Dance","Direction","(","Hermes","Pan","for","Piccolino","and","Top","Hat",")","."],"labels":["O","O","O","O","O","O","B-award","I-award","O","B-award","I-award","I-award","I-award","I-award","O","O","O","O","B-award","I-award","I-award","I-award","I-award","I-award","O","B-person","I-person","O","B-person","I-person","I-person","O","O","B-award","I-award","I-award","I-award","I-award","I-award","O","B-musical artist","I-musical artist","O","B-song","I-song","I-song","O","O","O","B-award","I-award","O","B-person","I-person","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, person, musical artist, country, award, event, location, band, music genre, musical instrument, album, song and O.\nSentence: The film was nominated for the Academy Awards for Academy Award for Best Picture , as well as Academy Award for Best Production Design ( Carroll Clark and Van Nest Polglase ) , Academy Award for Best Original Song ( Irving Berlin for Cheek to Cheek ) , and Dance Direction ( Hermes Pan for Piccolino and Top Hat ) .","prompt_labels":"The(O) film(O) was(O) nominated(O) for(O) the(O) Academy(B-award) Awards(I-award) for(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Picture(I-award) ,(O) as(O) well(O) as(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Production(I-award) Design(I-award) ((O) Carroll(B-person) Clark(I-person) and(O) Van(B-person) Nest(I-person) Polglase(I-person) )(O) ,(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Original(I-award) Song(I-award) ((O) Irving(B-musical artist) Berlin(I-musical artist) for(O) Cheek(B-song) to(I-song) Cheek(I-song) )(O) ,(O) and(O) Dance(B-award) Direction(I-award) ((O) Hermes(B-person) Pan(I-person) for(O) Piccolino(O) and(O) Top(O) Hat(O) )(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["person","award","band","location","song","music genre","event","album","musical artist","organization","musical instrument","country"],"instance":{"id":"20","words":["It","received","14","nominations","at","the","89th","Academy","Awards",",","tying","the","record","for","most","nominations","with","All","About","Eve","(","1950",")","and","Titanic","(","1997",")",",","and","won","the","awards","for","Academy","Award","for","Best","Director",",","Academy","Award","for","Best","Actress",",","Academy","Award","for","Best","Cinematography",",","Academy","Award","for","Best","Original","Score",",","Academy","Award","for","Best","Original","Song",",","and","Academy","Award","for","Best","Production","Design","."],"labels":["O","O","O","O","O","O","B-award","I-award","I-award","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","O","B-award","I-award","I-award","I-award","I-award","O","B-award","I-award","I-award","I-award","I-award","O","B-award","I-award","I-award","I-award","I-award","I-award","O","B-award","I-award","I-award","I-award","I-award","I-award","O","O","B-award","I-award","I-award","I-award","I-award","I-award","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, award, band, location, song, music genre, event, album, musical artist, organization, musical instrument, country and O.\nSentence: It received 14 nominations at the 89th Academy Awards , tying the record for most nominations with All About Eve ( 1950 ) and Titanic ( 1997 ) , and won the awards for Academy Award for Best Director , Academy Award for Best Actress , Academy Award for Best Cinematography , Academy Award for Best Original Score , Academy Award for Best Original Song , and Academy Award for Best Production Design .","prompt_labels":"It(O) received(O) 14(O) nominations(O) at(O) the(O) 89th(B-award) Academy(I-award) Awards(I-award) ,(O) tying(O) the(O) record(O) for(O) most(O) nominations(O) with(O) All(O) About(O) Eve(O) ((O) 1950(O) )(O) and(O) Titanic(O) ((O) 1997(O) )(O) ,(O) and(O) won(O) the(O) awards(O) for(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Director(I-award) ,(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Actress(I-award) ,(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Cinematography(I-award) ,(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Original(I-award) Score(I-award) ,(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Original(I-award) Song(I-award) ,(O) and(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Production(I-award) Design(I-award) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["band","music genre","musical artist","award","person","event","country","organization","song","album","location","musical instrument"],"instance":{"id":"21","words":["Western","music","artists","such","as","Michael","Martin","Murphey",",","and","artists","within","the","aforementioned","styles","and","genres",",","have","seen","continued","success","throughout","their","respective","fields",",","including","the","likes","of","The","Great","Divide",",","Lorenzo","Antonio",",","Sparx",",","Pat","Green",",","and","Jack","Ingram","."],"labels":["B-music genre","I-music genre","O","O","O","B-musical artist","I-musical artist","I-musical artist","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-band","I-band","I-band","O","B-musical artist","I-musical artist","O","B-band","O","B-musical artist","I-musical artist","O","O","B-musical artist","I-musical artist","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: band, music genre, musical artist, award, person, event, country, organization, song, album, location, musical instrument and O.\nSentence: Western music artists such as Michael Martin Murphey , and artists within the aforementioned styles and genres , have seen continued success throughout their respective fields , including the likes of The Great Divide , Lorenzo Antonio , Sparx , Pat Green , and Jack Ingram .","prompt_labels":"Western(B-music genre) music(I-music genre) artists(O) such(O) as(O) Michael(B-musical artist) Martin(I-musical artist) Murphey(I-musical artist) ,(O) and(O) artists(O) within(O) the(O) aforementioned(O) styles(O) and(O) genres(O) ,(O) have(O) seen(O) continued(O) success(O) throughout(O) their(O) respective(O) fields(O) ,(O) including(O) the(O) likes(O) of(O) The(B-band) Great(I-band) Divide(I-band) ,(O) Lorenzo(B-musical artist) Antonio(I-musical artist) ,(O) Sparx(B-band) ,(O) Pat(B-musical artist) Green(I-musical artist) ,(O) and(O) Jack(B-musical artist) Ingram(I-musical artist) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["location","person","song","country","musical instrument","award","band","musical artist","organization","album","event","music genre"],"instance":{"id":"22","words":["The","band","have","received","seven","Grammy","Award","s",",","four","Brit","Awards",",","an","Academy","Award","(","for","Best","Original","Song","Score","for","the","1970","film","Let","It","Be",")","and","fifteen","Ivor","Novello","Awards","."],"labels":["O","O","O","O","O","B-award","I-award","O","O","O","B-award","I-award","O","O","B-award","I-award","O","O","B-award","I-award","I-award","I-award","O","O","O","O","O","O","O","O","O","O","B-award","I-award","I-award","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, person, song, country, musical instrument, award, band, musical artist, organization, album, event, music genre and O.\nSentence: The band have received seven Grammy Award s , four Brit Awards , an Academy Award ( for Best Original Song Score for the 1970 film Let It Be ) and fifteen Ivor Novello Awards .","prompt_labels":"The(O) band(O) have(O) received(O) seven(O) Grammy(B-award) Award(I-award) s(O) ,(O) four(O) Brit(B-award) Awards(I-award) ,(O) an(O) Academy(B-award) Award(I-award) ((O) for(O) Best(B-award) Original(I-award) Song(I-award) Score(I-award) for(O) the(O) 1970(O) film(O) Let(O) It(O) Be(O) )(O) and(O) fifteen(O) Ivor(B-award) Novello(I-award) Awards(I-award) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["organization","band","music genre","country","location","musical instrument","award","person","song","musical artist","album","event"],"instance":{"id":"23","words":["She","rose","to","stardom","in","the","romantic","comedy","Roman","Holiday","(","1953",")",",","alongside","Gregory","Peck",",","for","which","she","was","the","first","actress","to","win","an","Academy","Awards",",","a","Golden","Globe","Awards",",","and","a","British","Academy","Film","Awards","for","a","single","performance","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-person","I-person","O","O","O","O","O","O","O","O","O","O","O","B-award","I-award","O","O","B-award","I-award","I-award","O","O","O","B-award","I-award","I-award","I-award","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, band, music genre, country, location, musical instrument, award, person, song, musical artist, album, event and O.\nSentence: She rose to stardom in the romantic comedy Roman Holiday ( 1953 ) , alongside Gregory Peck , for which she was the first actress to win an Academy Awards , a Golden Globe Awards , and a British Academy Film Awards for a single performance .","prompt_labels":"She(O) rose(O) to(O) stardom(O) in(O) the(O) romantic(O) comedy(O) Roman(O) Holiday(O) ((O) 1953(O) )(O) ,(O) alongside(O) Gregory(B-person) Peck(I-person) ,(O) for(O) which(O) she(O) was(O) the(O) first(O) actress(O) to(O) win(O) an(O) Academy(B-award) Awards(I-award) ,(O) a(O) Golden(B-award) Globe(I-award) Awards(I-award) ,(O) and(O) a(O) British(B-award) Academy(I-award) Film(I-award) Awards(I-award) for(O) a(O) single(O) performance(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["event","musical instrument","organization","award","location","album","music genre","person","country","musical artist","band","song"],"instance":{"id":"24","words":["Within","the","mainline","United","States","drum","and","bugle","corps","can","trace","their","origins","to","the","many","Veterans","of","Foreign","Wars","(","VFW",")","and","American","Legion","(","AL",")","meeting","halls",",","where","First","World","War","and","Spanish-American","War","veterans","met","and","formed","musical","ensemble","s","to","entertain","their","communities","."],"labels":["O","O","O","B-country","I-country","B-event","I-event","I-event","I-event","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O","B-organization","O","O","B-organization","I-organization","O","B-organization","O","O","O","O","O","B-event","I-event","I-event","O","B-event","I-event","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, musical instrument, organization, award, location, album, music genre, person, country, musical artist, band, song and O.\nSentence: Within the mainline United States drum and bugle corps can trace their origins to the many Veterans of Foreign Wars ( VFW ) and American Legion ( AL ) meeting halls , where First World War and Spanish-American War veterans met and formed musical ensemble s to entertain their communities .","prompt_labels":"Within(O) the(O) mainline(O) United(B-country) States(I-country) drum(B-event) and(I-event) bugle(I-event) corps(I-event) can(O) trace(O) their(O) origins(O) to(O) the(O) many(O) Veterans(B-organization) of(I-organization) Foreign(I-organization) Wars(I-organization) ((O) VFW(B-organization) )(O) and(O) American(B-organization) Legion(I-organization) ((O) AL(B-organization) )(O) meeting(O) halls(O) ,(O) where(O) First(B-event) World(I-event) War(I-event) and(O) Spanish-American(B-event) War(I-event) veterans(O) met(O) and(O) formed(O) musical(O) ensemble(O) s(O) to(O) entertain(O) their(O) communities(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["award","music genre","person","song","event","location","band","musical instrument","album","country","organization","musical artist"],"instance":{"id":"25","words":["Western","music","'s","influence","would","continue","to","grow","within","the","country","music","sphere",",","Western","musicians","like","Michael","Martin","Murphey",",","New","Mexico","music","artists","Al","Hurricane","and","Antonia","Apodaca",",","Tejano","music","performer","Little","Joe",",","and","even","folk","revivalist","John","Denver",",","all","first","rose","to","prominence","during","this","time","."],"labels":["B-music genre","I-music genre","O","O","O","O","O","O","O","O","B-music genre","I-music genre","O","O","B-music genre","O","O","B-musical artist","I-musical artist","I-musical artist","O","B-music genre","I-music genre","I-music genre","O","B-musical artist","I-musical artist","O","B-person","I-person","O","B-music genre","I-music genre","O","B-musical artist","I-musical artist","O","O","O","O","O","B-musical artist","I-musical artist","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, music genre, person, song, event, location, band, musical instrument, album, country, organization, musical artist and O.\nSentence: Western music 's influence would continue to grow within the country music sphere , Western musicians like Michael Martin Murphey , New Mexico music artists Al Hurricane and Antonia Apodaca , Tejano music performer Little Joe , and even folk revivalist John Denver , all first rose to prominence during this time .","prompt_labels":"Western(B-music genre) music(I-music genre) 's(O) influence(O) would(O) continue(O) to(O) grow(O) within(O) the(O) country(B-music genre) music(I-music genre) sphere(O) ,(O) Western(B-music genre) musicians(O) like(O) Michael(B-musical artist) Martin(I-musical artist) Murphey(I-musical artist) ,(O) New(B-music genre) Mexico(I-music genre) music(I-music genre) artists(O) Al(B-musical artist) Hurricane(I-musical artist) and(O) Antonia(B-person) Apodaca(I-person) ,(O) Tejano(B-music genre) music(I-music genre) performer(O) Little(B-musical artist) Joe(I-musical artist) ,(O) and(O) even(O) folk(O) revivalist(O) John(B-musical artist) Denver(I-musical artist) ,(O) all(O) first(O) rose(O) to(O) prominence(O) during(O) this(O) time(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["event","band","musical artist","music genre","organization","musical instrument","song","award","location","album","person","country"],"instance":{"id":"26","words":["Special","guests","were","Pete","Seeger",",","Bonnie","Raitt",",","David","Bromberg","and","Jerry","Jeff","Walker","."],"labels":["O","O","O","B-musical artist","I-musical artist","O","B-musical artist","I-musical artist","O","B-musical artist","I-musical artist","O","B-musical artist","I-musical artist","I-musical artist","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, band, musical artist, music genre, organization, musical instrument, song, award, location, album, person, country and O.\nSentence: Special guests were Pete Seeger , Bonnie Raitt , David Bromberg and Jerry Jeff Walker .","prompt_labels":"Special(O) guests(O) were(O) Pete(B-musical artist) Seeger(I-musical artist) ,(O) Bonnie(B-musical artist) Raitt(I-musical artist) ,(O) David(B-musical artist) Bromberg(I-musical artist) and(O) Jerry(B-musical artist) Jeff(I-musical artist) Walker(I-musical artist) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["band","event","musical instrument","music genre","song","award","person","organization","country","musical artist","album","location"],"instance":{"id":"27","words":["Under","the","current","voting","system",",","in","place","since","2016",",","the","highest-scoring","winner","is","Salvador","Sobral","of","Portugal","who","won","the","Eurovision","Song","Contest","2017","in","Kiev",",","Ukraine",",","with","758","points",";","under","the","previous","system",",","the","highest-scoring","winner","was","Alexander","Rybak","of","Norway","with","387","points","in","Eurovision","Song","Contest","2009","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-musical artist","I-musical artist","O","B-country","O","O","O","B-event","I-event","I-event","I-event","O","B-location","O","B-country","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-musical artist","I-musical artist","O","B-country","O","O","O","O","B-event","I-event","I-event","I-event","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: band, event, musical instrument, music genre, song, award, person, organization, country, musical artist, album, location and O.\nSentence: Under the current voting system , in place since 2016 , the highest-scoring winner is Salvador Sobral of Portugal who won the Eurovision Song Contest 2017 in Kiev , Ukraine , with 758 points ; under the previous system , the highest-scoring winner was Alexander Rybak of Norway with 387 points in Eurovision Song Contest 2009 .","prompt_labels":"Under(O) the(O) current(O) voting(O) system(O) ,(O) in(O) place(O) since(O) 2016(O) ,(O) the(O) highest-scoring(O) winner(O) is(O) Salvador(B-musical artist) Sobral(I-musical artist) of(O) Portugal(B-country) who(O) won(O) the(O) Eurovision(B-event) Song(I-event) Contest(I-event) 2017(I-event) in(O) Kiev(B-location) ,(O) Ukraine(B-country) ,(O) with(O) 758(O) points(O) ;(O) under(O) the(O) previous(O) system(O) ,(O) the(O) highest-scoring(O) winner(O) was(O) Alexander(B-musical artist) Rybak(I-musical artist) of(O) Norway(B-country) with(O) 387(O) points(O) in(O) Eurovision(B-event) Song(I-event) Contest(I-event) 2009(I-event) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["musical artist","person","band","award","country","event","album","musical instrument","music genre","organization","location","song"],"instance":{"id":"28","words":["The","band","'s","biggest","hit","singles","are","Sentimental","ballad","such","as","Easy",",","Three","Times","a","Lady",",","and","Nightshift",";","and","funk","y","dance","hits","which","include","Brick","House",",","Fancy","Dancer",",","Lady","(","You","Bring","Me","Up",")",",","and","Too","Hot","ta","Trot","."],"labels":["O","O","O","O","O","O","O","B-music genre","I-music genre","O","O","B-song","O","B-song","I-song","I-song","I-song","O","O","B-song","O","O","O","O","O","O","O","O","B-song","I-song","O","B-song","I-song","O","B-song","I-song","I-song","I-song","I-song","I-song","I-song","O","O","B-song","I-song","I-song","I-song","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: musical artist, person, band, award, country, event, album, musical instrument, music genre, organization, location, song and O.\nSentence: The band 's biggest hit singles are Sentimental ballad such as Easy , Three Times a Lady , and Nightshift ; and funk y dance hits which include Brick House , Fancy Dancer , Lady ( You Bring Me Up ) , and Too Hot ta Trot .","prompt_labels":"The(O) band(O) 's(O) biggest(O) hit(O) singles(O) are(O) Sentimental(B-music genre) ballad(I-music genre) such(O) as(O) Easy(B-song) ,(O) Three(B-song) Times(I-song) a(I-song) Lady(I-song) ,(O) and(O) Nightshift(B-song) ;(O) and(O) funk(O) y(O) dance(O) hits(O) which(O) include(O) Brick(B-song) House(I-song) ,(O) Fancy(B-song) Dancer(I-song) ,(O) Lady(B-song) ((I-song) You(I-song) Bring(I-song) Me(I-song) Up(I-song) )(I-song) ,(O) and(O) Too(B-song) Hot(I-song) ta(I-song) Trot(I-song) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["music genre","organization","event","musical artist","song","person","award","musical instrument","location","country","album","band"],"instance":{"id":"29","words":["In","central","Europe",",","Italo","disco","(","a.k.a.","1980s","Euro","disco",")","and","Euro","house","were","the","predominant","attempts","by","young","musicians","to","have","a","hit","record","in","and","beyond","the","borders","of","their","own","country","."],"labels":["O","B-location","I-location","O","B-music genre","I-music genre","O","O","O","B-music genre","I-music genre","O","O","B-music genre","I-music genre","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: music genre, organization, event, musical artist, song, person, award, musical instrument, location, country, album, band and O.\nSentence: In central Europe , Italo disco ( a.k.a. 1980s Euro disco ) and Euro house were the predominant attempts by young musicians to have a hit record in and beyond the borders of their own country .","prompt_labels":"In(O) central(B-location) Europe(I-location) ,(O) Italo(B-music genre) disco(I-music genre) ((O) a.k.a.(O) 1980s(O) Euro(B-music genre) disco(I-music genre) )(O) and(O) Euro(B-music genre) house(I-music genre) were(O) the(O) predominant(O) attempts(O) by(O) young(O) musicians(O) to(O) have(O) a(O) hit(O) record(O) in(O) and(O) beyond(O) the(O) borders(O) of(O) their(O) own(O) country(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["music genre","song","album","musical instrument","country","organization","band","award","musical artist","person","location","event"],"instance":{"id":"30","words":["Some","modern","artists","that","primarily","or","entirely","produce","country","pop","music","include","Kacey","Musgraves",",","Maren","Morris",",","Kelsea","Ballerini",",","Sam","Hunt",",","Kane","Brown",",","Chris","Lane",",","and","Dan","+","Shay","."],"labels":["O","O","O","O","O","O","O","O","B-music genre","I-music genre","I-music genre","O","B-musical artist","I-musical artist","O","B-musical artist","I-musical artist","O","B-musical artist","I-musical artist","O","B-musical artist","I-musical artist","O","B-musical artist","I-musical artist","O","B-musical artist","I-musical artist","O","O","B-band","I-band","I-band","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: music genre, song, album, musical instrument, country, organization, band, award, musical artist, person, location, event and O.\nSentence: Some modern artists that primarily or entirely produce country pop music include Kacey Musgraves , Maren Morris , Kelsea Ballerini , Sam Hunt , Kane Brown , Chris Lane , and Dan + Shay .","prompt_labels":"Some(O) modern(O) artists(O) that(O) primarily(O) or(O) entirely(O) produce(O) country(B-music genre) pop(I-music genre) music(I-music genre) include(O) Kacey(B-musical artist) Musgraves(I-musical artist) ,(O) Maren(B-musical artist) Morris(I-musical artist) ,(O) Kelsea(B-musical artist) Ballerini(I-musical artist) ,(O) Sam(B-musical artist) Hunt(I-musical artist) ,(O) Kane(B-musical artist) Brown(I-musical artist) ,(O) Chris(B-musical artist) Lane(I-musical artist) ,(O) and(O) Dan(B-band) +(I-band) Shay(I-band) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["location","band","music genre","country","award","organization","song","album","musical instrument","person","event","musical artist"],"instance":{"id":"31","words":["In","the","summer","of","2004",",","Diab",",","having","left","Alam","El","Phan",",","released","his","first","album","with","Rotana","Records",",","Leily","Nahary",",","which","he","followed","up","with","the","hugely","successful","Kammel","Kalamak","(","2005",")",",","and","El","Lilady","(","2007",")","."],"labels":["O","O","O","O","O","O","B-musical artist","O","O","O","B-organization","I-organization","I-organization","O","O","O","O","O","O","B-organization","I-organization","O","B-album","I-album","O","O","O","O","O","O","O","O","O","B-album","I-album","O","O","O","O","O","B-album","I-album","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, band, music genre, country, award, organization, song, album, musical instrument, person, event, musical artist and O.\nSentence: In the summer of 2004 , Diab , having left Alam El Phan , released his first album with Rotana Records , Leily Nahary , which he followed up with the hugely successful Kammel Kalamak ( 2005 ) , and El Lilady ( 2007 ) .","prompt_labels":"In(O) the(O) summer(O) of(O) 2004(O) ,(O) Diab(B-musical artist) ,(O) having(O) left(O) Alam(B-organization) El(I-organization) Phan(I-organization) ,(O) released(O) his(O) first(O) album(O) with(O) Rotana(B-organization) Records(I-organization) ,(O) Leily(B-album) Nahary(I-album) ,(O) which(O) he(O) followed(O) up(O) with(O) the(O) hugely(O) successful(O) Kammel(B-album) Kalamak(I-album) ((O) 2005(O) )(O) ,(O) and(O) El(B-album) Lilady(I-album) ((O) 2007(O) )(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["organization","song","musical instrument","album","person","musical artist","location","country","event","award","band","music genre"],"instance":{"id":"32","words":["Four","singles","-","Until","It","Sleeps",",","Hero","of","the","Day",",","Mama","Said",",","and","King","Nothing","-","were","released","as","part","of","the","marketing","campaign","for","the","album","."],"labels":["O","O","O","B-song","I-song","I-song","O","B-song","I-song","I-song","I-song","O","B-song","I-song","O","O","B-song","I-song","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, song, musical instrument, album, person, musical artist, location, country, event, award, band, music genre and O.\nSentence: Four singles - Until It Sleeps , Hero of the Day , Mama Said , and King Nothing - were released as part of the marketing campaign for the album .","prompt_labels":"Four(O) singles(O) -(O) Until(B-song) It(I-song) Sleeps(I-song) ,(O) Hero(B-song) of(I-song) the(I-song) Day(I-song) ,(O) Mama(B-song) Said(I-song) ,(O) and(O) King(B-song) Nothing(I-song) -(O) were(O) released(O) as(O) part(O) of(O) the(O) marketing(O) campaign(O) for(O) the(O) album(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["location","album","musical instrument","country","award","event","band","song","organization","musical artist","music genre","person"],"instance":{"id":"33","words":["In","2007",",","Standing","on","the","Outside",":","The","Songs","of","Cold","Chisel","was","released",",","featuring","a","collection","of","the","band","'s","songs","as","performed","by","artists","including","The","Living","End",",","Evermore",",","Something","for","Kate",",","Pete","Murray",",","Katie","Noonan",",","You","Am","I",",","Paul","Kelly",",","Alex","Lloyd",",","Thirsty","Merc","and","Ben","Lee",","],"labels":["O","O","O","B-album","I-album","I-album","I-album","I-album","I-album","I-album","I-album","I-album","I-album","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-band","I-band","I-band","O","B-band","O","B-band","I-band","I-band","O","B-band","I-band","O","B-musical artist","I-musical artist","O","B-band","I-band","I-band","O","B-musical artist","I-musical artist","O","B-band","I-band","O","B-band","I-band","O","B-musical artist","I-musical artist","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, album, musical instrument, country, award, event, band, song, organization, musical artist, music genre, person and O.\nSentence: In 2007 , Standing on the Outside : The Songs of Cold Chisel was released , featuring a collection of the band 's songs as performed by artists including The Living End , Evermore , Something for Kate , Pete Murray , Katie Noonan , You Am I , Paul Kelly , Alex Lloyd , Thirsty Merc and Ben Lee ,","prompt_labels":"In(O) 2007(O) ,(O) Standing(B-album) on(I-album) the(I-album) Outside(I-album) :(I-album) The(I-album) Songs(I-album) of(I-album) Cold(I-album) Chisel(I-album) was(O) released(O) ,(O) featuring(O) a(O) collection(O) of(O) the(O) band(O) 's(O) songs(O) as(O) performed(O) by(O) artists(O) including(O) The(B-band) Living(I-band) End(I-band) ,(O) Evermore(B-band) ,(O) Something(B-band) for(I-band) Kate(I-band) ,(O) Pete(B-band) Murray(I-band) ,(O) Katie(B-musical artist) Noonan(I-musical artist) ,(O) You(B-band) Am(I-band) I(I-band) ,(O) Paul(B-musical artist) Kelly(I-musical artist) ,(O) Alex(B-band) Lloyd(I-band) ,(O) Thirsty(B-band) Merc(I-band) and(O) Ben(B-musical artist) Lee(I-musical artist) ,(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["event","location","person","musical instrument","award","song","music genre","country","band","musical artist","album","organization"],"instance":{"id":"34","words":["Heard","released","five","albums","for","the","label",";","1981","'s","Stop","the","Dominoes",",","1982","'s","Victims","of","the","Age",";","1983","'s","Eye","of","the","Storm",";","1984","'s","Ashes","and","Light",";","and","1985","'s","Mosaics","."],"labels":["B-musical artist","O","O","O","O","O","O","O","O","O","B-album","I-album","I-album","O","O","O","B-album","I-album","I-album","I-album","O","O","O","B-album","I-album","I-album","I-album","O","O","O","B-album","I-album","I-album","O","O","O","O","B-album","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, location, person, musical instrument, award, song, music genre, country, band, musical artist, album, organization and O.\nSentence: Heard released five albums for the label ; 1981 's Stop the Dominoes , 1982 's Victims of the Age ; 1983 's Eye of the Storm ; 1984 's Ashes and Light ; and 1985 's Mosaics .","prompt_labels":"Heard(B-musical artist) released(O) five(O) albums(O) for(O) the(O) label(O) ;(O) 1981(O) 's(O) Stop(B-album) the(I-album) Dominoes(I-album) ,(O) 1982(O) 's(O) Victims(B-album) of(I-album) the(I-album) Age(I-album) ;(O) 1983(O) 's(O) Eye(B-album) of(I-album) the(I-album) Storm(I-album) ;(O) 1984(O) 's(O) Ashes(B-album) and(I-album) Light(I-album) ;(O) and(O) 1985(O) 's(O) Mosaics(B-album) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["musical artist","musical instrument","country","event","person","album","band","song","music genre","location","organization","award"],"instance":{"id":"35","words":["Construction","commenced","in","1975","and","the","venue","opened","ahead","of","the","1978","Commonwealth","Games","(","hence","its","name",")",",","replacing","the","adjacent","Clarke","Stadium","as","the","Eskimos","home","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","B-event","I-event","I-event","O","O","O","O","O","O","O","O","O","B-location","I-location","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: musical artist, musical instrument, country, event, person, album, band, song, music genre, location, organization, award and O.\nSentence: Construction commenced in 1975 and the venue opened ahead of the 1978 Commonwealth Games ( hence its name ) , replacing the adjacent Clarke Stadium as the Eskimos home .","prompt_labels":"Construction(O) commenced(O) in(O) 1975(O) and(O) the(O) venue(O) opened(O) ahead(O) of(O) the(O) 1978(B-event) Commonwealth(I-event) Games(I-event) ((O) hence(O) its(O) name(O) )(O) ,(O) replacing(O) the(O) adjacent(O) Clarke(B-location) Stadium(I-location) as(O) the(O) Eskimos(O) home(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["event","band","award","musical instrument","musical artist","song","country","music genre","person","album","organization","location"],"instance":{"id":"36","words":["Rocks","and","Honey","was","released","in","2013","and","features","the","single","Believe","in","Me","which","she","performed","representing","the","United","Kingdom","at","the","Eurovision","Song","Contest","2013","in","Malm",",","Sweden","."],"labels":["B-album","I-album","I-album","O","O","O","O","O","O","O","O","B-song","I-song","I-song","O","O","O","O","O","B-country","I-country","O","O","B-album","I-album","I-album","I-album","O","B-location","O","B-country","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, band, award, musical instrument, musical artist, song, country, music genre, person, album, organization, location and O.\nSentence: Rocks and Honey was released in 2013 and features the single Believe in Me which she performed representing the United Kingdom at the Eurovision Song Contest 2013 in Malm , Sweden .","prompt_labels":"Rocks(B-album) and(I-album) Honey(I-album) was(O) released(O) in(O) 2013(O) and(O) features(O) the(O) single(O) Believe(B-song) in(I-song) Me(I-song) which(O) she(O) performed(O) representing(O) the(O) United(B-country) Kingdom(I-country) at(O) the(O) Eurovision(B-album) Song(I-album) Contest(I-album) 2013(I-album) in(O) Malm(B-location) ,(O) Sweden(B-country) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["event","musical instrument","location","musical artist","band","music genre","person","organization","award","song","country","album"],"instance":{"id":"37","words":["Several","albums","that","continued","this","style",",","which","had","come","to","be","known","as","technical","thrash","metal",",","were","released","in","1991",",","such","as","Overkill","'s","Horrorscope",",","Heathen","'","s","Victims","of","Deception",",","Dark","Angel","'","s","Time","Does","Not","Heal",",","Sepultura","'s","Arise",",","and","Coroner","'s","Mental","Vortex","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-music genre","I-music genre","I-music genre","O","O","O","O","O","O","O","O","B-band","O","B-album","O","B-band","O","O","B-album","I-album","I-album","O","B-band","I-band","O","O","B-album","I-album","I-album","I-album","O","B-band","O","B-album","O","O","B-band","O","B-album","I-album","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, musical instrument, location, musical artist, band, music genre, person, organization, award, song, country, album and O.\nSentence: Several albums that continued this style , which had come to be known as technical thrash metal , were released in 1991 , such as Overkill 's Horrorscope , Heathen ' s Victims of Deception , Dark Angel ' s Time Does Not Heal , Sepultura 's Arise , and Coroner 's Mental Vortex .","prompt_labels":"Several(O) albums(O) that(O) continued(O) this(O) style(O) ,(O) which(O) had(O) come(O) to(O) be(O) known(O) as(O) technical(B-music genre) thrash(I-music genre) metal(I-music genre) ,(O) were(O) released(O) in(O) 1991(O) ,(O) such(O) as(O) Overkill(B-band) 's(O) Horrorscope(B-album) ,(O) Heathen(B-band) '(O) s(O) Victims(B-album) of(I-album) Deception(I-album) ,(O) Dark(B-band) Angel(I-band) '(O) s(O) Time(B-album) Does(I-album) Not(I-album) Heal(I-album) ,(O) Sepultura(B-band) 's(O) Arise(B-album) ,(O) and(O) Coroner(B-band) 's(O) Mental(B-album) Vortex(I-album) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["band","music genre","person","musical artist","organization","country","event","album","award","musical instrument","song","location"],"instance":{"id":"38","words":["Burton","'s","work","on","Sweeney","Todd","won","the","National","Board","of","Review","Award","for","Best","Director",",","and","won","an","Academy","Awards","for","Academy","Award","for","Best","Production","Design","."],"labels":["B-person","O","O","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","I-award","I-award","I-award","O","O","O","O","B-award","I-award","O","B-award","I-award","I-award","I-award","I-award","I-award","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: band, music genre, person, musical artist, organization, country, event, album, award, musical instrument, song, location and O.\nSentence: Burton 's work on Sweeney Todd won the National Board of Review Award for Best Director , and won an Academy Awards for Academy Award for Best Production Design .","prompt_labels":"Burton(B-person) 's(O) work(O) on(O) Sweeney(O) Todd(O) won(O) the(O) National(B-award) Board(I-award) of(I-award) Review(I-award) Award(I-award) for(I-award) Best(I-award) Director(I-award) ,(O) and(O) won(O) an(O) Academy(B-award) Awards(I-award) for(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Production(I-award) Design(I-award) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["music genre","musical artist","organization","location","song","award","event","country","band","person","album","musical instrument"],"instance":{"id":"39","words":["It","received","a","total","of","13","Academy","Awards","nominations",",","including","Academy","Award","for","Best","Picture","-","a","record","for","any","film","released","by","Walt","Disney","Studios","-","and","won","five",":","Academy","Award","for","Best","Actress","for","Andrews",",","Academy","Award","for","Best","Film","Editing",",","Academy","Award","for","Best","Original","Score",",","Academy","Award","for","Best","Visual","Effects",",","and","Academy","Award","for","Best","Original","Song","for","Chim","Chim","Cher-ee","."],"labels":["O","O","O","O","O","O","B-award","I-award","O","O","O","B-award","I-award","I-award","I-award","I-award","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","O","B-person","O","B-award","I-award","I-award","I-award","I-award","I-award","O","B-award","I-award","I-award","I-award","I-award","I-award","O","B-award","I-award","I-award","I-award","I-award","I-award","O","O","B-award","I-award","I-award","I-award","I-award","I-award","O","B-song","I-song","I-song","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: music genre, musical artist, organization, location, song, award, event, country, band, person, album, musical instrument and O.\nSentence: It received a total of 13 Academy Awards nominations , including Academy Award for Best Picture - a record for any film released by Walt Disney Studios - and won five : Academy Award for Best Actress for Andrews , Academy Award for Best Film Editing , Academy Award for Best Original Score , Academy Award for Best Visual Effects , and Academy Award for Best Original Song for Chim Chim Cher-ee .","prompt_labels":"It(O) received(O) a(O) total(O) of(O) 13(O) Academy(B-award) Awards(I-award) nominations(O) ,(O) including(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Picture(I-award) -(O) a(O) record(O) for(O) any(O) film(O) released(O) by(O) Walt(B-organization) Disney(I-organization) Studios(I-organization) -(O) and(O) won(O) five(O) :(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Actress(I-award) for(O) Andrews(B-person) ,(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Film(I-award) Editing(I-award) ,(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Original(I-award) Score(I-award) ,(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Visual(I-award) Effects(I-award) ,(O) and(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Original(I-award) Song(I-award) for(O) Chim(B-song) Chim(I-song) Cher-ee(I-song) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["event","country","location","musical artist","album","award","band","song","musical instrument","organization","music genre","person"],"instance":{"id":"40","words":["Notable","rockabilly","revivalists","and","psychobilly","performers","from","the","1990s","and","first","decade","of","the","21st","century","include","Scott","Owen","(","from","the","Australian","band","The","Living","End",")",",","Jimbo","Wallace","(","from","the","US","band","Reverend","Horton","Heat",")",",","Kim","Nekroman","(","Nekromantix",")",",","Patricia","Day","(","HorrorPops",")",",","Geoff","Kresge","(","Tiger","Army",",","ex-","AFI",")","."],"labels":["O","B-music genre","O","O","B-music genre","O","O","O","O","O","O","O","O","O","O","O","O","B-musical artist","I-musical artist","O","O","O","O","O","B-band","I-band","I-band","O","O","B-musical artist","I-musical artist","O","O","O","B-country","O","B-band","I-band","I-band","O","O","B-musical artist","I-musical artist","O","B-band","O","O","B-musical artist","I-musical artist","O","B-band","O","O","B-musical artist","I-musical artist","O","B-band","I-band","O","O","B-band","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, country, location, musical artist, album, award, band, song, musical instrument, organization, music genre, person and O.\nSentence: Notable rockabilly revivalists and psychobilly performers from the 1990s and first decade of the 21st century include Scott Owen ( from the Australian band The Living End ) , Jimbo Wallace ( from the US band Reverend Horton Heat ) , Kim Nekroman ( Nekromantix ) , Patricia Day ( HorrorPops ) , Geoff Kresge ( Tiger Army , ex- AFI ) .","prompt_labels":"Notable(O) rockabilly(B-music genre) revivalists(O) and(O) psychobilly(B-music genre) performers(O) from(O) the(O) 1990s(O) and(O) first(O) decade(O) of(O) the(O) 21st(O) century(O) include(O) Scott(B-musical artist) Owen(I-musical artist) ((O) from(O) the(O) Australian(O) band(O) The(B-band) Living(I-band) End(I-band) )(O) ,(O) Jimbo(B-musical artist) Wallace(I-musical artist) ((O) from(O) the(O) US(B-country) band(O) Reverend(B-band) Horton(I-band) Heat(I-band) )(O) ,(O) Kim(B-musical artist) Nekroman(I-musical artist) ((O) Nekromantix(B-band) )(O) ,(O) Patricia(B-musical artist) Day(I-musical artist) ((O) HorrorPops(B-band) )(O) ,(O) Geoff(B-musical artist) Kresge(I-musical artist) ((O) Tiger(B-band) Army(I-band) ,(O) ex-(O) AFI(B-band) )(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["song","event","organization","person","band","musical artist","country","location","award","album","music genre","musical instrument"],"instance":{"id":"41","words":["In","2009",",","Paltrow","received","a","Grammy","Award","nomination","for","Grammy","Award","for","Best","Spoken","Word","Album","for","Children","for","the","children","'s","audiobook","Brown","Bear","and","Friends","and","won","the","Primetime","Emmy","Award","for","Outstanding","Guest","Actress","in","a","Comedy","Series","for","her","guest","role","as","Holly","Holliday","on","the","Fox","musical","comedy-drama","television","series","Glee","in","2011","."],"labels":["O","O","O","B-musical artist","O","O","B-award","I-award","O","O","B-award","I-award","I-award","I-award","I-award","I-award","I-award","I-award","I-award","O","O","O","O","O","O","O","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","I-award","I-award","I-award","I-award","I-award","I-award","O","O","O","O","O","B-person","I-person","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, event, organization, person, band, musical artist, country, location, award, album, music genre, musical instrument and O.\nSentence: In 2009 , Paltrow received a Grammy Award nomination for Grammy Award for Best Spoken Word Album for Children for the children 's audiobook Brown Bear and Friends and won the Primetime Emmy Award for Outstanding Guest Actress in a Comedy Series for her guest role as Holly Holliday on the Fox musical comedy-drama television series Glee in 2011 .","prompt_labels":"In(O) 2009(O) ,(O) Paltrow(B-musical artist) received(O) a(O) Grammy(B-award) Award(I-award) nomination(O) for(O) Grammy(B-award) Award(I-award) for(I-award) Best(I-award) Spoken(I-award) Word(I-award) Album(I-award) for(I-award) Children(I-award) for(O) the(O) children(O) 's(O) audiobook(O) Brown(O) Bear(O) and(O) Friends(O) and(O) won(O) the(O) Primetime(B-award) Emmy(I-award) Award(I-award) for(I-award) Outstanding(I-award) Guest(I-award) Actress(I-award) in(I-award) a(I-award) Comedy(I-award) Series(I-award) for(O) her(O) guest(O) role(O) as(O) Holly(B-person) Holliday(I-person) on(O) the(O) Fox(O) musical(O) comedy-drama(O) television(O) series(O) Glee(O) in(O) 2011(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["album","location","song","award","person","event","music genre","musical artist","musical instrument","country","band","organization"],"instance":{"id":"42","words":["In","1956",",","the","arrival","of","rockabilly","was","underlined","by","the","success","of","songs","like","Folsom","Prison","Blues","by","Johnny","Cash",",","Blue","Suede","Shoes","by","Perkins","and","the","No.","1","hit","Heartbreak","Hotel","by","Presley","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-song","I-song","I-song","O","B-musical artist","I-musical artist","O","B-song","I-song","I-song","O","B-musical artist","O","O","O","O","O","B-song","I-song","O","B-musical artist","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: album, location, song, award, person, event, music genre, musical artist, musical instrument, country, band, organization and O.\nSentence: In 1956 , the arrival of rockabilly was underlined by the success of songs like Folsom Prison Blues by Johnny Cash , Blue Suede Shoes by Perkins and the No. 1 hit Heartbreak Hotel by Presley .","prompt_labels":"In(O) 1956(O) ,(O) the(O) arrival(O) of(O) rockabilly(O) was(O) underlined(O) by(O) the(O) success(O) of(O) songs(O) like(O) Folsom(B-song) Prison(I-song) Blues(I-song) by(O) Johnny(B-musical artist) Cash(I-musical artist) ,(O) Blue(B-song) Suede(I-song) Shoes(I-song) by(O) Perkins(B-musical artist) and(O) the(O) No.(O) 1(O) hit(O) Heartbreak(B-song) Hotel(I-song) by(O) Presley(B-musical artist) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["event","band","award","album","music genre","song","person","organization","musical instrument","location","musical artist","country"],"instance":{"id":"43","words":["Olympia","71",",","Olympia","74",",","and","Olympia","77","are","live","albums","."],"labels":["B-album","I-album","O","B-album","I-album","O","O","B-album","I-album","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, band, award, album, music genre, song, person, organization, musical instrument, location, musical artist, country and O.\nSentence: Olympia 71 , Olympia 74 , and Olympia 77 are live albums .","prompt_labels":"Olympia(B-album) 71(I-album) ,(O) Olympia(B-album) 74(I-album) ,(O) and(O) Olympia(B-album) 77(I-album) are(O) live(O) albums(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["music genre","musical artist","country","award","album","organization","location","band","musical instrument","event","person","song"],"instance":{"id":"44","words":["There","are","many","kinds","of","bubens",",","including","def",",","daf",",","or","qaval","(","Azerbaijan",")",",","daf","or","khaval","(","Armenia",")",",","daira","(","Georgia",")",",","doira","(","Uzbekistan","and","Tajikistan",")",",","daire","or","def","(","Iran",")",",","bendeir","(","Arab","countries",")",",","pandero","(","Spain",")","."],"labels":["O","O","O","O","O","B-musical instrument","O","O","B-musical instrument","O","B-musical instrument","O","O","B-musical instrument","O","B-country","O","O","B-musical instrument","O","B-musical instrument","O","B-country","O","O","B-musical instrument","O","B-country","O","O","B-musical instrument","O","B-country","O","B-country","O","O","B-musical instrument","O","B-musical instrument","O","B-country","O","O","B-musical instrument","O","O","O","O","O","B-musical instrument","O","B-country","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: music genre, musical artist, country, award, album, organization, location, band, musical instrument, event, person, song and O.\nSentence: There are many kinds of bubens , including def , daf , or qaval ( Azerbaijan ) , daf or khaval ( Armenia ) , daira ( Georgia ) , doira ( Uzbekistan and Tajikistan ) , daire or def ( Iran ) , bendeir ( Arab countries ) , pandero ( Spain ) .","prompt_labels":"There(O) are(O) many(O) kinds(O) of(O) bubens(B-musical instrument) ,(O) including(O) def(B-musical instrument) ,(O) daf(B-musical instrument) ,(O) or(O) qaval(B-musical instrument) ((O) Azerbaijan(B-country) )(O) ,(O) daf(B-musical instrument) or(O) khaval(B-musical instrument) ((O) Armenia(B-country) )(O) ,(O) daira(B-musical instrument) ((O) Georgia(B-country) )(O) ,(O) doira(B-musical instrument) ((O) Uzbekistan(B-country) and(O) Tajikistan(B-country) )(O) ,(O) daire(B-musical instrument) or(O) def(B-musical instrument) ((O) Iran(B-country) )(O) ,(O) bendeir(B-musical instrument) ((O) Arab(O) countries(O) )(O) ,(O) pandero(B-musical instrument) ((O) Spain(B-country) )(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["location","music genre","person","award","event","band","song","musical instrument","organization","musical artist","album","country"],"instance":{"id":"45","words":["The","venue","hosted","Badminton","at","the","2012","Summer","Olympics","and","Gymnastics","at","the","2012","Summer","Olympics","at","the","2012","Summer","Olympics","."],"labels":["O","O","O","B-event","I-event","I-event","I-event","I-event","I-event","O","B-event","I-event","I-event","I-event","I-event","I-event","O","O","B-event","I-event","I-event","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, music genre, person, award, event, band, song, musical instrument, organization, musical artist, album, country and O.\nSentence: The venue hosted Badminton at the 2012 Summer Olympics and Gymnastics at the 2012 Summer Olympics at the 2012 Summer Olympics .","prompt_labels":"The(O) venue(O) hosted(O) Badminton(B-event) at(I-event) the(I-event) 2012(I-event) Summer(I-event) Olympics(I-event) and(O) Gymnastics(B-event) at(I-event) the(I-event) 2012(I-event) Summer(I-event) Olympics(I-event) at(O) the(O) 2012(B-event) Summer(I-event) Olympics(I-event) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["album","musical instrument","award","song","location","person","musical artist","music genre","organization","country","event","band"],"instance":{"id":"46","words":["The","group","gave","two","particularly","noteworthy","concerts","in","New","York","City",":","once","in","2000","at","the","Zee","Gold","Bollywood","Awards","in","the","Nassau","Coliseum",",","and","again","in","2002","at","the","Bollywood","Music","Awards","in","the","Hammerstein","Ballroom","."],"labels":["O","O","O","O","O","O","O","O","B-location","I-location","I-location","O","O","O","O","O","O","B-award","I-award","I-award","I-award","O","O","B-location","I-location","O","O","O","O","O","O","O","B-award","I-award","I-award","O","O","B-location","I-location","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: album, musical instrument, award, song, location, person, musical artist, music genre, organization, country, event, band and O.\nSentence: The group gave two particularly noteworthy concerts in New York City : once in 2000 at the Zee Gold Bollywood Awards in the Nassau Coliseum , and again in 2002 at the Bollywood Music Awards in the Hammerstein Ballroom .","prompt_labels":"The(O) group(O) gave(O) two(O) particularly(O) noteworthy(O) concerts(O) in(O) New(B-location) York(I-location) City(I-location) :(O) once(O) in(O) 2000(O) at(O) the(O) Zee(B-award) Gold(I-award) Bollywood(I-award) Awards(I-award) in(O) the(O) Nassau(B-location) Coliseum(I-location) ,(O) and(O) again(O) in(O) 2002(O) at(O) the(O) Bollywood(B-award) Music(I-award) Awards(I-award) in(O) the(O) Hammerstein(B-location) Ballroom(I-location) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["music genre","musical artist","location","album","musical instrument","award","song","band","country","organization","person","event"],"instance":{"id":"47","words":["One","of","the","main","differences","between","American","and","European","pop","is","that","Europop","is","generally","more","Dance","music","and","Trance","music","oriented","."],"labels":["O","O","O","O","O","O","O","O","O","B-music genre","O","O","B-music genre","O","O","O","B-music genre","I-music genre","O","B-music genre","I-music genre","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: music genre, musical artist, location, album, musical instrument, award, song, band, country, organization, person, event and O.\nSentence: One of the main differences between American and European pop is that Europop is generally more Dance music and Trance music oriented .","prompt_labels":"One(O) of(O) the(O) main(O) differences(O) between(O) American(O) and(O) European(O) pop(B-music genre) is(O) that(O) Europop(B-music genre) is(O) generally(O) more(O) Dance(B-music genre) music(I-music genre) and(O) Trance(B-music genre) music(I-music genre) oriented(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["award","band","person","musical artist","location","musical instrument","organization","country","music genre","song","album","event"],"instance":{"id":"48","words":["All","ten","of","Cannibal","Corpse","'s","albums",",","the","live","album","Live","Cannibalism",",","the","boxed","set","15","Year","Killing","Spree",",","the","EP","Worm","Infested",",","and","the","single","Hammer","Smashed","Face","were","re-released","in","Australia","between","2006","and","2007",",","finally","classified","by","ARIA","and","allowed","for","sale","in","Australia","."],"labels":["O","O","O","B-band","I-band","O","O","O","O","O","O","B-album","I-album","O","O","O","O","B-album","I-album","I-album","I-album","O","O","O","B-album","I-album","O","O","O","O","B-song","I-song","I-song","O","O","O","B-country","O","O","O","O","O","O","O","O","B-organization","O","O","O","O","O","B-country","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, band, person, musical artist, location, musical instrument, organization, country, music genre, song, album, event and O.\nSentence: All ten of Cannibal Corpse 's albums , the live album Live Cannibalism , the boxed set 15 Year Killing Spree , the EP Worm Infested , and the single Hammer Smashed Face were re-released in Australia between 2006 and 2007 , finally classified by ARIA and allowed for sale in Australia .","prompt_labels":"All(O) ten(O) of(O) Cannibal(B-band) Corpse(I-band) 's(O) albums(O) ,(O) the(O) live(O) album(O) Live(B-album) Cannibalism(I-album) ,(O) the(O) boxed(O) set(O) 15(B-album) Year(I-album) Killing(I-album) Spree(I-album) ,(O) the(O) EP(O) Worm(B-album) Infested(I-album) ,(O) and(O) the(O) single(O) Hammer(B-song) Smashed(I-song) Face(I-song) were(O) re-released(O) in(O) Australia(B-country) between(O) 2006(O) and(O) 2007(O) ,(O) finally(O) classified(O) by(O) ARIA(B-organization) and(O) allowed(O) for(O) sale(O) in(O) Australia(B-country) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["album","music genre","organization","song","award","location","musical instrument","country","event","band","musical artist","person"],"instance":{"id":"49","words":["Material","from","the","1966-1968","sessions","was","released","on","Miles","Smiles","(","1966",")",",","Sorcerer","(","1967",")",",","Nefertiti","(","1967",")",",","Miles","in","the","Sky","(","1968",")",",","and","Filles","de","Kilimanjaro","(","1968",")","."],"labels":["O","O","O","O","O","O","O","O","B-album","I-album","O","O","O","O","B-album","O","O","O","O","B-album","O","O","O","O","B-album","I-album","I-album","I-album","O","O","O","O","O","B-album","I-album","I-album","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: album, music genre, organization, song, award, location, musical instrument, country, event, band, musical artist, person and O.\nSentence: Material from the 1966-1968 sessions was released on Miles Smiles ( 1966 ) , Sorcerer ( 1967 ) , Nefertiti ( 1967 ) , Miles in the Sky ( 1968 ) , and Filles de Kilimanjaro ( 1968 ) .","prompt_labels":"Material(O) from(O) the(O) 1966-1968(O) sessions(O) was(O) released(O) on(O) Miles(B-album) Smiles(I-album) ((O) 1966(O) )(O) ,(O) Sorcerer(B-album) ((O) 1967(O) )(O) ,(O) Nefertiti(B-album) ((O) 1967(O) )(O) ,(O) Miles(B-album) in(I-album) the(I-album) Sky(I-album) ((O) 1968(O) )(O) ,(O) and(O) Filles(B-album) de(I-album) Kilimanjaro(I-album) ((O) 1968(O) )(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["person","country","event","musical artist","location","award","music genre","band","musical instrument","organization","song","album"],"instance":{"id":"50","words":["Castellano","switched","to","rhythm","guitar","and","keyboards","(","Castellano","also","filled","in","on","lead","guitar","and","vocals","for","an","ailing","Buck","Dharma","in","two","shows","in","2005",")",",","and","the","position","of","bassist","was","taken","up","by","Rudy","Sarzo","(","previously","a","member","of","Quiet","Riot",",","Whitesnake",",","Ozzy","Osbourne","and","Dio",")",",","with","the","band","employing","Danny","Miranda","and","Jon","Rogers","as","guest","bassists","to","fill","in","when","Sarzo","was","unavailable","."],"labels":["B-musical artist","O","O","B-musical instrument","I-musical instrument","O","B-musical instrument","O","B-musical artist","O","O","O","O","O","B-musical instrument","O","O","O","O","O","B-musical artist","I-musical artist","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-musical artist","I-musical artist","O","O","O","O","O","B-band","I-band","O","B-band","O","B-musical artist","I-musical artist","O","B-musical artist","O","O","O","O","O","O","B-musical artist","I-musical artist","O","B-musical artist","I-musical artist","O","O","O","O","O","O","O","B-musical artist","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, country, event, musical artist, location, award, music genre, band, musical instrument, organization, song, album and O.\nSentence: Castellano switched to rhythm guitar and keyboards ( Castellano also filled in on lead guitar and vocals for an ailing Buck Dharma in two shows in 2005 ) , and the position of bassist was taken up by Rudy Sarzo ( previously a member of Quiet Riot , Whitesnake , Ozzy Osbourne and Dio ) , with the band employing Danny Miranda and Jon Rogers as guest bassists to fill in when Sarzo was unavailable .","prompt_labels":"Castellano(B-musical artist) switched(O) to(O) rhythm(B-musical instrument) guitar(I-musical instrument) and(O) keyboards(B-musical instrument) ((O) Castellano(B-musical artist) also(O) filled(O) in(O) on(O) lead(O) guitar(B-musical instrument) and(O) vocals(O) for(O) an(O) ailing(O) Buck(B-musical artist) Dharma(I-musical artist) in(O) two(O) shows(O) in(O) 2005(O) )(O) ,(O) and(O) the(O) position(O) of(O) bassist(O) was(O) taken(O) up(O) by(O) Rudy(B-musical artist) Sarzo(I-musical artist) ((O) previously(O) a(O) member(O) of(O) Quiet(B-band) Riot(I-band) ,(O) Whitesnake(B-band) ,(O) Ozzy(B-musical artist) Osbourne(I-musical artist) and(O) Dio(B-musical artist) )(O) ,(O) with(O) the(O) band(O) employing(O) Danny(B-musical artist) Miranda(I-musical artist) and(O) Jon(B-musical artist) Rogers(I-musical artist) as(O) guest(O) bassists(O) to(O) fill(O) in(O) when(O) Sarzo(B-musical artist) was(O) unavailable(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["musical instrument","country","organization","song","event","album","music genre","band","location","award","musical artist","person"],"instance":{"id":"51","words":["This","album","featured","vocal","contributions","by","Vicotnik","of","Ved","Buens","Ende","and","Ddheimsgard","and","Aldrahn","of","Ddheimsgard","and","Zyklon-B","."],"labels":["O","O","O","O","O","O","B-musical artist","O","B-band","I-band","I-band","O","B-band","O","B-musical artist","O","B-band","O","B-band","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: musical instrument, country, organization, song, event, album, music genre, band, location, award, musical artist, person and O.\nSentence: This album featured vocal contributions by Vicotnik of Ved Buens Ende and Ddheimsgard and Aldrahn of Ddheimsgard and Zyklon-B .","prompt_labels":"This(O) album(O) featured(O) vocal(O) contributions(O) by(O) Vicotnik(B-musical artist) of(O) Ved(B-band) Buens(I-band) Ende(I-band) and(O) Ddheimsgard(B-band) and(O) Aldrahn(B-musical artist) of(O) Ddheimsgard(B-band) and(O) Zyklon-B(B-band) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["person","event","music genre","country","song","musical instrument","band","album","location","musical artist","award","organization"],"instance":{"id":"52","words":["Originally","based","in","West","Germany",",","the","four","original","members","of","the","group","'s","official","line-up","were","Liz","Mitchell","and","Marcia","Barrett","from","Jamaica",",","Maizie","Williams","from","Montserrat","and","Bobby","Farrell",",","a","performing","artist","from","Aruba","."],"labels":["O","O","O","B-country","I-country","O","O","O","O","O","O","O","O","O","O","O","O","B-musical artist","I-musical artist","O","B-musical artist","I-musical artist","O","B-country","O","B-musical artist","I-musical artist","O","B-location","O","B-musical artist","I-musical artist","O","O","O","O","O","B-country","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, event, music genre, country, song, musical instrument, band, album, location, musical artist, award, organization and O.\nSentence: Originally based in West Germany , the four original members of the group 's official line-up were Liz Mitchell and Marcia Barrett from Jamaica , Maizie Williams from Montserrat and Bobby Farrell , a performing artist from Aruba .","prompt_labels":"Originally(O) based(O) in(O) West(B-country) Germany(I-country) ,(O) the(O) four(O) original(O) members(O) of(O) the(O) group(O) 's(O) official(O) line-up(O) were(O) Liz(B-musical artist) Mitchell(I-musical artist) and(O) Marcia(B-musical artist) Barrett(I-musical artist) from(O) Jamaica(B-country) ,(O) Maizie(B-musical artist) Williams(I-musical artist) from(O) Montserrat(B-location) and(O) Bobby(B-musical artist) Farrell(I-musical artist) ,(O) a(O) performing(O) artist(O) from(O) Aruba(B-country) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["music genre","event","song","musical artist","country","award","location","organization","person","musical instrument","band","album"],"instance":{"id":"53","words":["Morricone","'s","best-known","compositions","include","The","Ecstasy","of","Gold",",","Se","Telefonando",",","Man","with","a","Harmonica",",","Here","'s","to","You",",","the","UK","No.","2","single","Chi","Mai",",","Gabriel","'s","Oboe","and","E","Pi","Ti","Penso","."],"labels":["B-musical artist","O","O","O","O","B-song","I-song","I-song","I-song","O","B-song","I-song","O","B-song","I-song","I-song","I-song","O","B-song","I-song","I-song","I-song","O","O","B-country","O","O","O","B-song","I-song","O","B-song","I-song","I-song","O","B-song","I-song","I-song","I-song","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: music genre, event, song, musical artist, country, award, location, organization, person, musical instrument, band, album and O.\nSentence: Morricone 's best-known compositions include The Ecstasy of Gold , Se Telefonando , Man with a Harmonica , Here 's to You , the UK No. 2 single Chi Mai , Gabriel 's Oboe and E Pi Ti Penso .","prompt_labels":"Morricone(B-musical artist) 's(O) best-known(O) compositions(O) include(O) The(B-song) Ecstasy(I-song) of(I-song) Gold(I-song) ,(O) Se(B-song) Telefonando(I-song) ,(O) Man(B-song) with(I-song) a(I-song) Harmonica(I-song) ,(O) Here(B-song) 's(I-song) to(I-song) You(I-song) ,(O) the(O) UK(B-country) No.(O) 2(O) single(O) Chi(B-song) Mai(I-song) ,(O) Gabriel(B-song) 's(I-song) Oboe(I-song) and(O) E(B-song) Pi(I-song) Ti(I-song) Penso(I-song) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["music genre","person","song","location","album","musical instrument","band","event","organization","country","musical artist","award"],"instance":{"id":"54","words":["After","the","festival",",","the","Experience","was","booked","for","five","concerts","at","Bill","Graham","'s","The","Fillmore",",","with","Big","Brother","and","the","Holding","Company","and","Jefferson","Airplane","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","B-person","I-person","O","B-location","I-location","O","O","B-band","I-band","I-band","I-band","I-band","I-band","O","B-band","I-band","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: music genre, person, song, location, album, musical instrument, band, event, organization, country, musical artist, award and O.\nSentence: After the festival , the Experience was booked for five concerts at Bill Graham 's The Fillmore , with Big Brother and the Holding Company and Jefferson Airplane .","prompt_labels":"After(O) the(O) festival(O) ,(O) the(O) Experience(O) was(O) booked(O) for(O) five(O) concerts(O) at(O) Bill(B-person) Graham(I-person) 's(O) The(B-location) Fillmore(I-location) ,(O) with(O) Big(B-band) Brother(I-band) and(I-band) the(I-band) Holding(I-band) Company(I-band) and(O) Jefferson(B-band) Airplane(I-band) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["song","album","music genre","location","person","musical artist","band","event","musical instrument","award","country","organization"],"instance":{"id":"55","words":["The","film","won","Academy","Awards","for","Academy","Award","for","Best","Actor","(","James","Cagney",")",",","Academy","Award","for","Best","Original","Score","and","Academy","Award","for","Best","Sound","Mixing","(","Nathan","Levinson",")","."],"labels":["O","O","O","B-award","I-award","O","B-award","I-award","I-award","I-award","I-award","O","B-person","I-person","O","O","B-award","I-award","I-award","I-award","I-award","I-award","O","B-award","I-award","I-award","I-award","I-award","I-award","O","B-musical artist","I-musical artist","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, album, music genre, location, person, musical artist, band, event, musical instrument, award, country, organization and O.\nSentence: The film won Academy Awards for Academy Award for Best Actor ( James Cagney ) , Academy Award for Best Original Score and Academy Award for Best Sound Mixing ( Nathan Levinson ) .","prompt_labels":"The(O) film(O) won(O) Academy(B-award) Awards(I-award) for(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Actor(I-award) ((O) James(B-person) Cagney(I-person) )(O) ,(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Original(I-award) Score(I-award) and(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Sound(I-award) Mixing(I-award) ((O) Nathan(B-musical artist) Levinson(I-musical artist) )(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["location","country","song","person","event","organization","award","band","music genre","musical artist","musical instrument","album"],"instance":{"id":"56","words":["Subsequent","releases",",","such","as","The","Force","Behind","the","Power","(","1991",")",",","Take","Me","Higher","(","1995",")",",","and","Every","Day","Is","a","New","Day","(","1999",")","produced","similar","results","."],"labels":["O","O","O","O","O","B-album","I-album","I-album","I-album","I-album","O","O","O","O","B-album","I-album","I-album","O","O","O","O","O","B-album","I-album","I-album","I-album","I-album","I-album","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, country, song, person, event, organization, award, band, music genre, musical artist, musical instrument, album and O.\nSentence: Subsequent releases , such as The Force Behind the Power ( 1991 ) , Take Me Higher ( 1995 ) , and Every Day Is a New Day ( 1999 ) produced similar results .","prompt_labels":"Subsequent(O) releases(O) ,(O) such(O) as(O) The(B-album) Force(I-album) Behind(I-album) the(I-album) Power(I-album) ((O) 1991(O) )(O) ,(O) Take(B-album) Me(I-album) Higher(I-album) ((O) 1995(O) )(O) ,(O) and(O) Every(B-album) Day(I-album) Is(I-album) a(I-album) New(I-album) Day(I-album) ((O) 1999(O) )(O) produced(O) similar(O) results(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["album","song","country","person","band","musical artist","musical instrument","music genre","event","award","location","organization"],"instance":{"id":"57","words":["The","arena","also","hosted","the","Ice","hockey","at","the","2010","Winter","Olympics","events","at","the","2010","Winter","Olympics","."],"labels":["O","B-organization","O","O","O","B-event","I-event","I-event","I-event","I-event","I-event","I-event","O","O","O","B-event","I-event","I-event","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: album, song, country, person, band, musical artist, musical instrument, music genre, event, award, location, organization and O.\nSentence: The arena also hosted the Ice hockey at the 2010 Winter Olympics events at the 2010 Winter Olympics .","prompt_labels":"The(O) arena(B-organization) also(O) hosted(O) the(O) Ice(B-event) hockey(I-event) at(I-event) the(I-event) 2010(I-event) Winter(I-event) Olympics(I-event) events(O) at(O) the(O) 2010(B-event) Winter(I-event) Olympics(I-event) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["song","location","album","musical artist","event","musical instrument","person","music genre","country","organization","band","award"],"instance":{"id":"58","words":["Since","the","early","1980s",",","the","Zulu","Nation","has","since","established","(","autonomous",")","branches","in","Japanese","hip","hop",",","France",",","the","British","hip","hop",",","Australian","hip","hop",",","Canada",",","Korean","hip","hop","and","the","Cape","Flats","in","Cape","Town","South","Africa","."],"labels":["O","O","O","O","O","O","B-band","I-band","O","O","O","O","O","O","O","O","B-music genre","I-music genre","I-music genre","O","B-country","O","O","B-music genre","I-music genre","I-music genre","O","B-music genre","I-music genre","I-music genre","O","B-country","O","B-music genre","I-music genre","I-music genre","O","O","B-location","I-location","O","B-location","I-location","B-country","I-country","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, location, album, musical artist, event, musical instrument, person, music genre, country, organization, band, award and O.\nSentence: Since the early 1980s , the Zulu Nation has since established ( autonomous ) branches in Japanese hip hop , France , the British hip hop , Australian hip hop , Canada , Korean hip hop and the Cape Flats in Cape Town South Africa .","prompt_labels":"Since(O) the(O) early(O) 1980s(O) ,(O) the(O) Zulu(B-band) Nation(I-band) has(O) since(O) established(O) ((O) autonomous(O) )(O) branches(O) in(O) Japanese(B-music genre) hip(I-music genre) hop(I-music genre) ,(O) France(B-country) ,(O) the(O) British(B-music genre) hip(I-music genre) hop(I-music genre) ,(O) Australian(B-music genre) hip(I-music genre) hop(I-music genre) ,(O) Canada(B-country) ,(O) Korean(B-music genre) hip(I-music genre) hop(I-music genre) and(O) the(O) Cape(B-location) Flats(I-location) in(O) Cape(B-location) Town(I-location) South(B-country) Africa(I-country) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["country","event","award","location","musical artist","band","person","song","album","musical instrument","organization","music genre"],"instance":{"id":"59","words":["Since","TG","has","permanently","disbanded","following","the","death","of","Christopherson",",","the","label","'s","plan","is","to","re-release","the","original","TG","albums","(","The","Second","Annual","Report",",","D.o.A",":","The","Third","and","Final","Report",",","20","Jazz","Funk","Greats",",","Heathen","Earth","and","Greatest","Hits",")","on","the","label","."],"labels":["O","B-band","O","O","O","O","O","O","O","B-musical artist","O","O","O","O","O","O","O","O","O","O","B-band","O","O","B-album","I-album","I-album","I-album","O","B-album","I-album","I-album","I-album","I-album","I-album","I-album","O","B-album","I-album","I-album","I-album","O","B-album","I-album","O","B-album","I-album","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, event, award, location, musical artist, band, person, song, album, musical instrument, organization, music genre and O.\nSentence: Since TG has permanently disbanded following the death of Christopherson , the label 's plan is to re-release the original TG albums ( The Second Annual Report , D.o.A : The Third and Final Report , 20 Jazz Funk Greats , Heathen Earth and Greatest Hits ) on the label .","prompt_labels":"Since(O) TG(B-band) has(O) permanently(O) disbanded(O) following(O) the(O) death(O) of(O) Christopherson(B-musical artist) ,(O) the(O) label(O) 's(O) plan(O) is(O) to(O) re-release(O) the(O) original(O) TG(B-band) albums(O) ((O) The(B-album) Second(I-album) Annual(I-album) Report(I-album) ,(O) D.o.A(B-album) :(I-album) The(I-album) Third(I-album) and(I-album) Final(I-album) Report(I-album) ,(O) 20(B-album) Jazz(I-album) Funk(I-album) Greats(I-album) ,(O) Heathen(B-album) Earth(I-album) and(O) Greatest(B-album) Hits(I-album) )(O) on(O) the(O) label(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["location","person","album","song","award","musical artist","country","music genre","event","organization","musical instrument","band"],"instance":{"id":"60","words":["Boogie","Down","and","KRS","retorted","angrily","with","songs","such","as","The","Bridge","is","Over","and","South","Bronx",",","which","started","one","of","the","first","notable","hip","hop","wars","as","MC","Shan",",","Marley","Marl",",","Roxanne","Shant","and","Blaq","Poet","all","released","songs","featuring","verses","personally","attacking","KRS","and","Scott","La","Rock","."],"labels":["B-band","I-band","O","B-musical artist","O","O","O","O","O","O","B-song","I-song","I-song","I-song","O","B-song","I-song","O","O","O","O","O","O","O","O","B-music genre","I-music genre","O","O","B-musical artist","I-musical artist","O","B-musical artist","I-musical artist","O","B-musical artist","I-musical artist","O","B-musical artist","I-musical artist","O","O","O","O","O","O","O","B-musical artist","O","B-musical artist","I-musical artist","I-musical artist","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, person, album, song, award, musical artist, country, music genre, event, organization, musical instrument, band and O.\nSentence: Boogie Down and KRS retorted angrily with songs such as The Bridge is Over and South Bronx , which started one of the first notable hip hop wars as MC Shan , Marley Marl , Roxanne Shant and Blaq Poet all released songs featuring verses personally attacking KRS and Scott La Rock .","prompt_labels":"Boogie(B-band) Down(I-band) and(O) KRS(B-musical artist) retorted(O) angrily(O) with(O) songs(O) such(O) as(O) The(B-song) Bridge(I-song) is(I-song) Over(I-song) and(O) South(B-song) Bronx(I-song) ,(O) which(O) started(O) one(O) of(O) the(O) first(O) notable(O) hip(B-music genre) hop(I-music genre) wars(O) as(O) MC(B-musical artist) Shan(I-musical artist) ,(O) Marley(B-musical artist) Marl(I-musical artist) ,(O) Roxanne(B-musical artist) Shant(I-musical artist) and(O) Blaq(B-musical artist) Poet(I-musical artist) all(O) released(O) songs(O) featuring(O) verses(O) personally(O) attacking(O) KRS(B-musical artist) and(O) Scott(B-musical artist) La(I-musical artist) Rock(I-musical artist) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["song","music genre","country","organization","event","location","person","album","award","musical instrument","band","musical artist"],"instance":{"id":"61","words":["Other","top-10","entries","from","2015","like","Mark","Ronson","'","s","disco","groove-infused","Uptown","Funk",",","Maroon","5","'","s","Sugar",",","the","Weeknd","'","s","Can","'t","Feel","My","Face","and","Jason","Derulo","'","s","Want","to","Want","Me","also","ascended","the","charts","and","have","a","strong","disco","influence","."],"labels":["O","O","O","O","O","O","B-musical artist","I-musical artist","O","O","B-song","I-song","B-song","I-song","O","B-band","I-band","O","O","B-song","O","B-band","I-band","O","O","B-song","I-song","I-song","I-song","I-song","O","B-musical artist","I-musical artist","O","O","B-song","I-song","I-song","I-song","O","O","O","O","O","O","O","O","B-music genre","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, music genre, country, organization, event, location, person, album, award, musical instrument, band, musical artist and O.\nSentence: Other top-10 entries from 2015 like Mark Ronson ' s disco groove-infused Uptown Funk , Maroon 5 ' s Sugar , the Weeknd ' s Can 't Feel My Face and Jason Derulo ' s Want to Want Me also ascended the charts and have a strong disco influence .","prompt_labels":"Other(O) top-10(O) entries(O) from(O) 2015(O) like(O) Mark(B-musical artist) Ronson(I-musical artist) '(O) s(O) disco(B-song) groove-infused(I-song) Uptown(B-song) Funk(I-song) ,(O) Maroon(B-band) 5(I-band) '(O) s(O) Sugar(B-song) ,(O) the(B-band) Weeknd(I-band) '(O) s(O) Can(B-song) 't(I-song) Feel(I-song) My(I-song) Face(I-song) and(O) Jason(B-musical artist) Derulo(I-musical artist) '(O) s(O) Want(B-song) to(I-song) Want(I-song) Me(I-song) also(O) ascended(O) the(O) charts(O) and(O) have(O) a(O) strong(O) disco(B-music genre) influence(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["band","album","person","country","event","musical artist","musical instrument","location","song","music genre","award","organization"],"instance":{"id":"62","words":["142","He","returned","to","the","stage","on","8","September","2005",",","appearing","with","Arcade","Fire","for","the","US","nationally","televised","event","Fashion","Rocks",",","and","performed","with","the","Canadian","band","for","the","second","time","a","week","later","during","the","CMJ","Music","Marathon",".","Thompson","(","2006",")",":","pp.","291-92","He","contributed","backing","vocals","on","TV","on","the","Radio","'","s","song","Province","for","their","album","Return","to","Cookie","Mountain",","],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","B-band","I-band","O","O","B-country","O","O","O","B-event","I-event","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-event","I-event","I-event","O","B-musical artist","O","O","O","O","O","O","O","O","O","O","O","B-band","I-band","I-band","I-band","O","O","O","B-song","O","O","O","B-album","I-album","I-album","I-album","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: band, album, person, country, event, musical artist, musical instrument, location, song, music genre, award, organization and O.\nSentence: 142 He returned to the stage on 8 September 2005 , appearing with Arcade Fire for the US nationally televised event Fashion Rocks , and performed with the Canadian band for the second time a week later during the CMJ Music Marathon . Thompson ( 2006 ) : pp. 291-92 He contributed backing vocals on TV on the Radio ' s song Province for their album Return to Cookie Mountain ,","prompt_labels":"142(O) He(O) returned(O) to(O) the(O) stage(O) on(O) 8(O) September(O) 2005(O) ,(O) appearing(O) with(O) Arcade(B-band) Fire(I-band) for(O) the(O) US(B-country) nationally(O) televised(O) event(O) Fashion(B-event) Rocks(I-event) ,(O) and(O) performed(O) with(O) the(O) Canadian(O) band(O) for(O) the(O) second(O) time(O) a(O) week(O) later(O) during(O) the(O) CMJ(B-event) Music(I-event) Marathon(I-event) .(O) Thompson(B-musical artist) ((O) 2006(O) )(O) :(O) pp.(O) 291-92(O) He(O) contributed(O) backing(O) vocals(O) on(O) TV(B-band) on(I-band) the(I-band) Radio(I-band) '(O) s(O) song(O) Province(B-song) for(O) their(O) album(O) Return(B-album) to(I-album) Cookie(I-album) Mountain(I-album) ,(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["country","music genre","musical instrument","award","person","location","musical artist","event","organization","album","band","song"],"instance":{"id":"63","words":["In","December","2011","the","band","announced","they","would","be","performing","Tellin","'","Stories","in","its","entirety","at","London","'s","HMV","Hammersmith","Apollo",",","O2","Apollo","Manchester","and","Glasgow","'s","Barrowland","Ballroom","in","June","2012","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-album","I-album","I-album","O","O","O","O","B-location","O","B-location","I-location","I-location","O","B-location","I-location","I-location","O","B-location","O","B-location","I-location","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, music genre, musical instrument, award, person, location, musical artist, event, organization, album, band, song and O.\nSentence: In December 2011 the band announced they would be performing Tellin ' Stories in its entirety at London 's HMV Hammersmith Apollo , O2 Apollo Manchester and Glasgow 's Barrowland Ballroom in June 2012 .","prompt_labels":"In(O) December(O) 2011(O) the(O) band(O) announced(O) they(O) would(O) be(O) performing(O) Tellin(B-album) '(I-album) Stories(I-album) in(O) its(O) entirety(O) at(O) London(B-location) 's(O) HMV(B-location) Hammersmith(I-location) Apollo(I-location) ,(O) O2(B-location) Apollo(I-location) Manchester(I-location) and(O) Glasgow(B-location) 's(O) Barrowland(B-location) Ballroom(I-location) in(O) June(O) 2012(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["band","award","music genre","event","organization","musical instrument","song","musical artist","location","country","person","album"],"instance":{"id":"64","words":["One","of","the","best-selling","music","groups","of","the","1960s",",","their","biggest","hits","-","including","The","Sound","of","Silence","(","1965",")",",","Mrs.","Robinson","(","1968",")",",","The","Boxer","(","1969",")",",","and","Bridge","over","Troubled","Water","(","1970",")","-","reached","number","one","on","singles","charts","worldwide","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-song","I-song","I-song","I-song","O","O","O","O","B-song","I-song","O","O","O","O","B-song","I-song","O","O","O","O","O","B-album","I-album","I-album","I-album","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: band, award, music genre, event, organization, musical instrument, song, musical artist, location, country, person, album and O.\nSentence: One of the best-selling music groups of the 1960s , their biggest hits - including The Sound of Silence ( 1965 ) , Mrs. Robinson ( 1968 ) , The Boxer ( 1969 ) , and Bridge over Troubled Water ( 1970 ) - reached number one on singles charts worldwide .","prompt_labels":"One(O) of(O) the(O) best-selling(O) music(O) groups(O) of(O) the(O) 1960s(O) ,(O) their(O) biggest(O) hits(O) -(O) including(O) The(B-song) Sound(I-song) of(I-song) Silence(I-song) ((O) 1965(O) )(O) ,(O) Mrs.(B-song) Robinson(I-song) ((O) 1968(O) )(O) ,(O) The(B-song) Boxer(I-song) ((O) 1969(O) )(O) ,(O) and(O) Bridge(B-album) over(I-album) Troubled(I-album) Water(I-album) ((O) 1970(O) )(O) -(O) reached(O) number(O) one(O) on(O) singles(O) charts(O) worldwide(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["album","award","musical instrument","song","music genre","organization","person","musical artist","location","event","band","country"],"instance":{"id":"65","words":["The","Eurasian","Economic","Union",",","the","Gulf","Cooperation","Council",",","CARICOM","and","the","European","Union","are","current","examples","of","single","markets",",","although","the","Gulf","Cooperation","Council","'","s","single","market","has","been","described","as","malfunctioning","in","2014","."],"labels":["O","B-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","O","B-organization","O","O","B-organization","I-organization","O","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: album, award, musical instrument, song, music genre, organization, person, musical artist, location, event, band, country and O.\nSentence: The Eurasian Economic Union , the Gulf Cooperation Council , CARICOM and the European Union are current examples of single markets , although the Gulf Cooperation Council ' s single market has been described as malfunctioning in 2014 .","prompt_labels":"The(O) Eurasian(B-organization) Economic(I-organization) Union(I-organization) ,(O) the(O) Gulf(B-organization) Cooperation(I-organization) Council(I-organization) ,(O) CARICOM(B-organization) and(O) the(O) European(B-organization) Union(I-organization) are(O) current(O) examples(O) of(O) single(O) markets(O) ,(O) although(O) the(O) Gulf(B-organization) Cooperation(I-organization) Council(I-organization) '(O) s(O) single(O) market(O) has(O) been(O) described(O) as(O) malfunctioning(O) in(O) 2014(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["album","music genre","person","event","country","location","song","musical artist","band","musical instrument","award","organization"],"instance":{"id":"66","words":["In","1984",",","Loverboy","recorded","the","United","States","at","the","1984","Summer","Olympics","theme","for","the","1984","Summer","Olympics",",","Nothing","'s","Gonna","Stop","You","Now","."],"labels":["O","O","O","B-band","O","O","B-country","I-country","O","O","B-event","I-event","I-event","O","O","O","B-event","I-event","I-event","O","B-song","I-song","I-song","I-song","I-song","I-song","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: album, music genre, person, event, country, location, song, musical artist, band, musical instrument, award, organization and O.\nSentence: In 1984 , Loverboy recorded the United States at the 1984 Summer Olympics theme for the 1984 Summer Olympics , Nothing 's Gonna Stop You Now .","prompt_labels":"In(O) 1984(O) ,(O) Loverboy(B-band) recorded(O) the(O) United(B-country) States(I-country) at(O) the(O) 1984(B-event) Summer(I-event) Olympics(I-event) theme(O) for(O) the(O) 1984(B-event) Summer(I-event) Olympics(I-event) ,(O) Nothing(B-song) 's(I-song) Gonna(I-song) Stop(I-song) You(I-song) Now(I-song) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["person","music genre","award","location","musical instrument","band","album","event","song","country","musical artist","organization"],"instance":{"id":"67","words":["In","1990",",","he","appeared","on","Kool","Thing",",","a","song","by","the","alternative","rock","band","Sonic","Youth",",","and","along","with","Flavor","Flav",",","he","sang","on","George","Clinton","'","s","song","Tweakin","'",",","which","appears","on","his","1989","album","The","Cinderella","Theory","."],"labels":["O","O","O","O","O","O","B-song","I-song","O","O","O","O","O","B-music genre","I-music genre","O","B-band","I-band","O","O","O","O","B-musical artist","I-musical artist","O","O","O","O","B-musical artist","I-musical artist","O","O","O","B-song","O","O","O","O","O","O","O","O","B-album","I-album","I-album","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, music genre, award, location, musical instrument, band, album, event, song, country, musical artist, organization and O.\nSentence: In 1990 , he appeared on Kool Thing , a song by the alternative rock band Sonic Youth , and along with Flavor Flav , he sang on George Clinton ' s song Tweakin ' , which appears on his 1989 album The Cinderella Theory .","prompt_labels":"In(O) 1990(O) ,(O) he(O) appeared(O) on(O) Kool(B-song) Thing(I-song) ,(O) a(O) song(O) by(O) the(O) alternative(B-music genre) rock(I-music genre) band(O) Sonic(B-band) Youth(I-band) ,(O) and(O) along(O) with(O) Flavor(B-musical artist) Flav(I-musical artist) ,(O) he(O) sang(O) on(O) George(B-musical artist) Clinton(I-musical artist) '(O) s(O) song(O) Tweakin(B-song) '(O) ,(O) which(O) appears(O) on(O) his(O) 1989(O) album(O) The(B-album) Cinderella(I-album) Theory(I-album) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["organization","song","musical artist","event","person","music genre","location","musical instrument","country","album","award","band"],"instance":{"id":"68","words":["They","also","visited","South","America","for","the","second","time","(","the","first","time","being","in","1999",")",",","arriving","at","Chile",",","Argentina",",","and","Brazil","."],"labels":["O","O","O","B-location","I-location","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-country","O","B-country","O","O","B-country","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, song, musical artist, event, person, music genre, location, musical instrument, country, album, award, band and O.\nSentence: They also visited South America for the second time ( the first time being in 1999 ) , arriving at Chile , Argentina , and Brazil .","prompt_labels":"They(O) also(O) visited(O) South(B-location) America(I-location) for(O) the(O) second(O) time(O) ((O) the(O) first(O) time(O) being(O) in(O) 1999(O) )(O) ,(O) arriving(O) at(O) Chile(B-country) ,(O) Argentina(B-country) ,(O) and(O) Brazil(B-country) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["event","music genre","song","country","award","album","location","organization","band","musical instrument","person","musical artist"],"instance":{"id":"69","words":["With","the","eventual","commercial","dominance","of","West","Coast","hip","hop","gangsta","rap",",","particularly","the","emergence","of","the","relaxed","sounds","of","G-funk","by","the","early","nineties",",","the","East","Coast","hip","hop","new","school","\/","golden","age","can","be","said","to","have","ended",",","with","hardcore","rappers","such","as","the","Wu-Tang","Clan","and","gangsta","rappers","such","as","Nas","and","The","Notorious","B.I.G.","coming","to","dominate","the","East","Coast","scene","."],"labels":["O","O","O","O","O","O","B-music genre","I-music genre","I-music genre","I-music genre","I-music genre","I-music genre","O","O","O","O","O","O","O","O","O","B-music genre","O","O","O","O","O","O","B-event","I-event","I-event","I-event","I-event","I-event","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-band","I-band","O","O","O","O","O","B-musical artist","O","B-musical artist","I-musical artist","I-musical artist","O","O","O","O","B-music genre","I-music genre","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, music genre, song, country, award, album, location, organization, band, musical instrument, person, musical artist and O.\nSentence: With the eventual commercial dominance of West Coast hip hop gangsta rap , particularly the emergence of the relaxed sounds of G-funk by the early nineties , the East Coast hip hop new school \/ golden age can be said to have ended , with hardcore rappers such as the Wu-Tang Clan and gangsta rappers such as Nas and The Notorious B.I.G. coming to dominate the East Coast scene .","prompt_labels":"With(O) the(O) eventual(O) commercial(O) dominance(O) of(O) West(B-music genre) Coast(I-music genre) hip(I-music genre) hop(I-music genre) gangsta(I-music genre) rap(I-music genre) ,(O) particularly(O) the(O) emergence(O) of(O) the(O) relaxed(O) sounds(O) of(O) G-funk(B-music genre) by(O) the(O) early(O) nineties(O) ,(O) the(O) East(B-event) Coast(I-event) hip(I-event) hop(I-event) new(I-event) school(I-event) \/(O) golden(O) age(O) can(O) be(O) said(O) to(O) have(O) ended(O) ,(O) with(O) hardcore(O) rappers(O) such(O) as(O) the(O) Wu-Tang(B-band) Clan(I-band) and(O) gangsta(O) rappers(O) such(O) as(O) Nas(B-musical artist) and(O) The(B-musical artist) Notorious(I-musical artist) B.I.G.(I-musical artist) coming(O) to(O) dominate(O) the(O) East(B-music genre) Coast(I-music genre) scene(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["person","song","album","music genre","organization","musical artist","musical instrument","band","country","award","location","event"],"instance":{"id":"70","words":["Alexander","has","had","an","active","career","on","stage",",","appearing","in","several","Broadway","musicals","including","Jerome","Robbins","'","Broadway","in","1989",",","for","which","he","won","the","Tony","Award","as","Best","Leading","Actor","in","a","Musical","and","a","Grammy","Award","for","Grammy","Award","for","Best","Musical","Theater","Album","."],"labels":["B-musical artist","O","O","O","O","O","O","O","O","O","O","O","B-organization","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-award","I-award","O","B-award","I-award","I-award","I-award","I-award","I-award","O","O","B-award","I-award","O","B-award","I-award","I-award","I-award","I-award","I-award","I-award","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, song, album, music genre, organization, musical artist, musical instrument, band, country, award, location, event and O.\nSentence: Alexander has had an active career on stage , appearing in several Broadway musicals including Jerome Robbins ' Broadway in 1989 , for which he won the Tony Award as Best Leading Actor in a Musical and a Grammy Award for Grammy Award for Best Musical Theater Album .","prompt_labels":"Alexander(B-musical artist) has(O) had(O) an(O) active(O) career(O) on(O) stage(O) ,(O) appearing(O) in(O) several(O) Broadway(B-organization) musicals(O) including(O) Jerome(O) Robbins(O) '(O) Broadway(O) in(O) 1989(O) ,(O) for(O) which(O) he(O) won(O) the(O) Tony(B-award) Award(I-award) as(O) Best(B-award) Leading(I-award) Actor(I-award) in(I-award) a(I-award) Musical(I-award) and(O) a(O) Grammy(B-award) Award(I-award) for(O) Grammy(B-award) Award(I-award) for(I-award) Best(I-award) Musical(I-award) Theater(I-award) Album(I-award) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["musical artist","musical instrument","country","award","album","person","organization","band","event","location","music genre","song"],"instance":{"id":"71","words":["The","Bee","Gees","used","Barry","Gibb","'","s","falsetto","to","garner","hits","such","as","You","Should","Be","Dancing",",","Stayin","'","Alive",",","Night","Fever",",","More","Than","A","Woman","and","Love","You","Inside","Out","."],"labels":["O","B-band","I-band","O","B-musical artist","I-musical artist","O","O","B-song","O","O","O","O","O","B-song","I-song","I-song","I-song","O","B-song","I-song","I-song","O","B-song","I-song","O","B-song","I-song","I-song","I-song","O","B-song","I-song","I-song","I-song","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: musical artist, musical instrument, country, award, album, person, organization, band, event, location, music genre, song and O.\nSentence: The Bee Gees used Barry Gibb ' s falsetto to garner hits such as You Should Be Dancing , Stayin ' Alive , Night Fever , More Than A Woman and Love You Inside Out .","prompt_labels":"The(O) Bee(B-band) Gees(I-band) used(O) Barry(B-musical artist) Gibb(I-musical artist) '(O) s(O) falsetto(B-song) to(O) garner(O) hits(O) such(O) as(O) You(B-song) Should(I-song) Be(I-song) Dancing(I-song) ,(O) Stayin(B-song) '(I-song) Alive(I-song) ,(O) Night(B-song) Fever(I-song) ,(O) More(B-song) Than(I-song) A(I-song) Woman(I-song) and(O) Love(B-song) You(I-song) Inside(I-song) Out(I-song) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["album","location","event","musical artist","musical instrument","music genre","award","person","song","band","organization","country"],"instance":{"id":"72","words":["They","were","accompanied","by","a","varying","number","of","session","musicians","and","some","relatively","consistent","band","members","such","as","guitarist","Ian","Bairnson",",","arranger","Andrew","Powell",",","bassist","and","vocalist","David","Paton",",","drummer","Stuart","Elliott",",","and","vocalists","Lenny","Zakatek","and","Chris","Rainbow","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-musical artist","I-musical artist","O","O","B-musical artist","I-musical artist","O","O","O","O","B-musical artist","I-musical artist","O","O","B-musical artist","I-musical artist","O","O","O","B-musical artist","I-musical artist","O","B-musical artist","I-musical artist","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: album, location, event, musical artist, musical instrument, music genre, award, person, song, band, organization, country and O.\nSentence: They were accompanied by a varying number of session musicians and some relatively consistent band members such as guitarist Ian Bairnson , arranger Andrew Powell , bassist and vocalist David Paton , drummer Stuart Elliott , and vocalists Lenny Zakatek and Chris Rainbow .","prompt_labels":"They(O) were(O) accompanied(O) by(O) a(O) varying(O) number(O) of(O) session(O) musicians(O) and(O) some(O) relatively(O) consistent(O) band(O) members(O) such(O) as(O) guitarist(O) Ian(B-musical artist) Bairnson(I-musical artist) ,(O) arranger(O) Andrew(B-musical artist) Powell(I-musical artist) ,(O) bassist(O) and(O) vocalist(O) David(B-musical artist) Paton(I-musical artist) ,(O) drummer(O) Stuart(B-musical artist) Elliott(I-musical artist) ,(O) and(O) vocalists(O) Lenny(B-musical artist) Zakatek(I-musical artist) and(O) Chris(B-musical artist) Rainbow(I-musical artist) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["musical instrument","musical artist","album","award","event","band","music genre","organization","location","country","song","person"],"instance":{"id":"73","words":["His","13","Grammy","Award","nominations","have","resulted","in","2","awards","won",",","along","with","Billboard","Music","Award","s",",","Country","Music","Association","Awards",",","and","many","others","."],"labels":["O","O","B-award","I-award","O","O","O","O","O","O","O","O","O","O","B-award","I-award","I-award","O","O","B-award","I-award","I-award","I-award","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: musical instrument, musical artist, album, award, event, band, music genre, organization, location, country, song, person and O.\nSentence: His 13 Grammy Award nominations have resulted in 2 awards won , along with Billboard Music Award s , Country Music Association Awards , and many others .","prompt_labels":"His(O) 13(O) Grammy(B-award) Award(I-award) nominations(O) have(O) resulted(O) in(O) 2(O) awards(O) won(O) ,(O) along(O) with(O) Billboard(B-award) Music(I-award) Award(I-award) s(O) ,(O) Country(B-award) Music(I-award) Association(I-award) Awards(I-award) ,(O) and(O) many(O) others(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["band","musical instrument","event","location","song","musical artist","award","country","album","music genre","person","organization"],"instance":{"id":"74","words":["In","2019",",","Fonsi","performed","Right","Where","I","'m","Supposed","to","Be","as","the","Official","Song","of","the","2019","Special","Olympics","World","Summer","Games","in","Abu","Dhabi",",","United","Arab","Emirates","in","collaboration","with","Ryan","Tedder",",","Avril","Lavigne","Hussain","Al","Jassmi",",","Assala","Nasri","and","Tamer","Hosny","."],"labels":["O","O","O","B-musical artist","O","B-song","I-song","I-song","I-song","I-song","I-song","I-song","O","O","O","O","O","O","B-event","I-event","I-event","I-event","I-event","I-event","O","B-location","I-location","O","B-country","I-country","I-country","O","O","O","B-musical artist","I-musical artist","O","B-musical artist","I-musical artist","B-musical artist","I-musical artist","I-musical artist","O","B-musical artist","I-musical artist","O","B-musical artist","I-musical artist","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: band, musical instrument, event, location, song, musical artist, award, country, album, music genre, person, organization and O.\nSentence: In 2019 , Fonsi performed Right Where I 'm Supposed to Be as the Official Song of the 2019 Special Olympics World Summer Games in Abu Dhabi , United Arab Emirates in collaboration with Ryan Tedder , Avril Lavigne Hussain Al Jassmi , Assala Nasri and Tamer Hosny .","prompt_labels":"In(O) 2019(O) ,(O) Fonsi(B-musical artist) performed(O) Right(B-song) Where(I-song) I(I-song) 'm(I-song) Supposed(I-song) to(I-song) Be(I-song) as(O) the(O) Official(O) Song(O) of(O) the(O) 2019(B-event) Special(I-event) Olympics(I-event) World(I-event) Summer(I-event) Games(I-event) in(O) Abu(B-location) Dhabi(I-location) ,(O) United(B-country) Arab(I-country) Emirates(I-country) in(O) collaboration(O) with(O) Ryan(B-musical artist) Tedder(I-musical artist) ,(O) Avril(B-musical artist) Lavigne(I-musical artist) Hussain(B-musical artist) Al(I-musical artist) Jassmi(I-musical artist) ,(O) Assala(B-musical artist) Nasri(I-musical artist) and(O) Tamer(B-musical artist) Hosny(I-musical artist) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["band","organization","location","country","award","song","musical instrument","person","musical artist","event","album","music genre"],"instance":{"id":"75","words":["Among","the","songs","Johnson","recorded","in","San","Antonio","were","Come","On","in","My","Kitchen",",","Kind","Hearted","Woman","Blues",",","Dust","My","Broom","and","Cross","Road","Blues","."],"labels":["O","O","O","B-musical artist","O","O","B-location","I-location","O","B-song","I-song","I-song","I-song","I-song","O","B-song","I-song","I-song","I-song","O","B-song","I-song","I-song","O","B-song","I-song","I-song","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: band, organization, location, country, award, song, musical instrument, person, musical artist, event, album, music genre and O.\nSentence: Among the songs Johnson recorded in San Antonio were Come On in My Kitchen , Kind Hearted Woman Blues , Dust My Broom and Cross Road Blues .","prompt_labels":"Among(O) the(O) songs(O) Johnson(B-musical artist) recorded(O) in(O) San(B-location) Antonio(I-location) were(O) Come(B-song) On(I-song) in(I-song) My(I-song) Kitchen(I-song) ,(O) Kind(B-song) Hearted(I-song) Woman(I-song) Blues(I-song) ,(O) Dust(B-song) My(I-song) Broom(I-song) and(O) Cross(B-song) Road(I-song) Blues(I-song) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["song","country","band","award","album","event","organization","location","music genre","musical instrument","person","musical artist"],"instance":{"id":"76","words":["It","comprises","the","music","of","Bosnia","and","Herzegovina",",","Bulgaria",",","Croatia",",","Music","of","Greece",",","Montenegro",",","Serbia",",","Romania",",","Republic","of","Macedonia",",","Albania",",","some","of","the","historical","states","of","Yugoslavia","or","the","State","Union","of","Serbia","and","Montenegro","and","geographical","regions","such","as","Thrace","."],"labels":["O","O","O","B-music genre","I-music genre","I-music genre","I-music genre","I-music genre","O","B-country","O","B-country","O","B-music genre","I-music genre","I-music genre","O","B-country","O","B-country","O","B-country","O","B-country","I-country","I-country","O","B-country","O","O","O","O","O","O","O","B-country","O","O","B-country","I-country","I-country","I-country","I-country","I-country","O","O","O","O","O","B-location","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, country, band, award, album, event, organization, location, music genre, musical instrument, person, musical artist and O.\nSentence: It comprises the music of Bosnia and Herzegovina , Bulgaria , Croatia , Music of Greece , Montenegro , Serbia , Romania , Republic of Macedonia , Albania , some of the historical states of Yugoslavia or the State Union of Serbia and Montenegro and geographical regions such as Thrace .","prompt_labels":"It(O) comprises(O) the(O) music(B-music genre) of(I-music genre) Bosnia(I-music genre) and(I-music genre) Herzegovina(I-music genre) ,(O) Bulgaria(B-country) ,(O) Croatia(B-country) ,(O) Music(B-music genre) of(I-music genre) Greece(I-music genre) ,(O) Montenegro(B-country) ,(O) Serbia(B-country) ,(O) Romania(B-country) ,(O) Republic(B-country) of(I-country) Macedonia(I-country) ,(O) Albania(B-country) ,(O) some(O) of(O) the(O) historical(O) states(O) of(O) Yugoslavia(B-country) or(O) the(O) State(B-country) Union(I-country) of(I-country) Serbia(I-country) and(I-country) Montenegro(I-country) and(O) geographical(O) regions(O) such(O) as(O) Thrace(B-location) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["music genre","musical artist","person","song","award","organization","event","musical instrument","band","location","country","album"],"instance":{"id":"77","words":["Schmidt","was","born","in","Pozsony","(","known","in","German","as","Pressburg",")",",","in","the","Hungary","part","of","the","Austria-Hungary","(","the","city","is","now","Bratislava",",","capital","of","Slovakia",")","."],"labels":["B-person","O","O","O","B-location","O","O","O","O","O","B-location","O","O","O","O","B-country","O","O","O","B-location","O","O","O","O","O","B-location","O","O","O","B-country","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: music genre, musical artist, person, song, award, organization, event, musical instrument, band, location, country, album and O.\nSentence: Schmidt was born in Pozsony ( known in German as Pressburg ) , in the Hungary part of the Austria-Hungary ( the city is now Bratislava , capital of Slovakia ) .","prompt_labels":"Schmidt(B-person) was(O) born(O) in(O) Pozsony(B-location) ((O) known(O) in(O) German(O) as(O) Pressburg(B-location) )(O) ,(O) in(O) the(O) Hungary(B-country) part(O) of(O) the(O) Austria-Hungary(B-location) ((O) the(O) city(O) is(O) now(O) Bratislava(B-location) ,(O) capital(O) of(O) Slovakia(B-country) )(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["album","person","musical instrument","organization","musical artist","award","country","song","event","band","music genre","location"],"instance":{"id":"78","words":["In","2005","Jamieson","won","Best","Male","Performer","in","the","second","annual","Jack","Awards",",","Jamieson","showcased","the","sounds","of","Grinspoon","to","millions","of","viewers","in","March","2006",",","playing","live","at","Melbourne","Cricket","Ground","as","part","of","the","closing","ceremony","of","the","2006","Commonwealth","Games","."],"labels":["O","O","B-musical artist","O","O","O","O","O","O","B-award","I-award","I-award","I-award","O","B-musical artist","O","O","O","O","B-band","O","O","O","O","O","O","O","O","O","O","O","B-location","I-location","I-location","O","O","O","O","O","O","O","O","B-event","I-event","I-event","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: album, person, musical instrument, organization, musical artist, award, country, song, event, band, music genre, location and O.\nSentence: In 2005 Jamieson won Best Male Performer in the second annual Jack Awards , Jamieson showcased the sounds of Grinspoon to millions of viewers in March 2006 , playing live at Melbourne Cricket Ground as part of the closing ceremony of the 2006 Commonwealth Games .","prompt_labels":"In(O) 2005(O) Jamieson(B-musical artist) won(O) Best(O) Male(O) Performer(O) in(O) the(O) second(B-award) annual(I-award) Jack(I-award) Awards(I-award) ,(O) Jamieson(B-musical artist) showcased(O) the(O) sounds(O) of(O) Grinspoon(B-band) to(O) millions(O) of(O) viewers(O) in(O) March(O) 2006(O) ,(O) playing(O) live(O) at(O) Melbourne(B-location) Cricket(I-location) Ground(I-location) as(O) part(O) of(O) the(O) closing(O) ceremony(O) of(O) the(O) 2006(B-event) Commonwealth(I-event) Games(I-event) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["song","band","event","musical instrument","country","album","person","musical artist","music genre","location","organization","award"],"instance":{"id":"79","words":["Funds","raised","by","the","project","will","go","to","Amazon","Watch","and","Extinction","Rebellion","."],"labels":["O","O","O","O","O","O","O","O","B-organization","I-organization","O","B-organization","I-organization","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, band, event, musical instrument, country, album, person, musical artist, music genre, location, organization, award and O.\nSentence: Funds raised by the project will go to Amazon Watch and Extinction Rebellion .","prompt_labels":"Funds(O) raised(O) by(O) the(O) project(O) will(O) go(O) to(O) Amazon(B-organization) Watch(I-organization) and(O) Extinction(B-organization) Rebellion(I-organization) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["person","musical artist","event","album","location","musical instrument","music genre","band","award","country","organization","song"],"instance":{"id":"80","words":["This","is","the","method","used","by","Bands","of","America",",","the","Indiana","State","School","Music","Association",",","Kentucky","Music","Educators","Association","and","the","University","Interscholastic","League","."],"labels":["O","O","O","O","O","O","B-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","B-organization","I-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, musical artist, event, album, location, musical instrument, music genre, band, award, country, organization, song and O.\nSentence: This is the method used by Bands of America , the Indiana State School Music Association , Kentucky Music Educators Association and the University Interscholastic League .","prompt_labels":"This(O) is(O) the(O) method(O) used(O) by(O) Bands(B-organization) of(I-organization) America(I-organization) ,(O) the(O) Indiana(B-organization) State(I-organization) School(I-organization) Music(I-organization) Association(I-organization) ,(O) Kentucky(B-organization) Music(I-organization) Educators(I-organization) Association(I-organization) and(O) the(O) University(B-organization) Interscholastic(I-organization) League(I-organization) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["song","award","music genre","album","musical artist","organization","location","event","band","country","person","musical instrument"],"instance":{"id":"81","words":["Featuring","LaLonde","and","Alexander",",","Primus","recorded","the","live","album","Suck","on","This","in","1989",",","followed","by","four","studio","albums",":","Frizzle","Fry",",","Sailing","the","Seas","of","Cheese",",","Pork","Soda",",","and","Tales","from","the","Punchbowl","."],"labels":["O","B-musical artist","O","B-musical artist","O","B-band","O","O","O","O","B-album","I-album","I-album","O","O","O","O","O","O","O","O","O","B-album","I-album","O","B-album","I-album","I-album","I-album","I-album","O","B-album","I-album","O","O","B-album","I-album","I-album","I-album","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, award, music genre, album, musical artist, organization, location, event, band, country, person, musical instrument and O.\nSentence: Featuring LaLonde and Alexander , Primus recorded the live album Suck on This in 1989 , followed by four studio albums : Frizzle Fry , Sailing the Seas of Cheese , Pork Soda , and Tales from the Punchbowl .","prompt_labels":"Featuring(O) LaLonde(B-musical artist) and(O) Alexander(B-musical artist) ,(O) Primus(B-band) recorded(O) the(O) live(O) album(O) Suck(B-album) on(I-album) This(I-album) in(O) 1989(O) ,(O) followed(O) by(O) four(O) studio(O) albums(O) :(O) Frizzle(B-album) Fry(I-album) ,(O) Sailing(B-album) the(I-album) Seas(I-album) of(I-album) Cheese(I-album) ,(O) Pork(B-album) Soda(I-album) ,(O) and(O) Tales(B-album) from(I-album) the(I-album) Punchbowl(I-album) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["location","album","award","musical instrument","person","country","music genre","organization","musical artist","song","event","band"],"instance":{"id":"82","words":["In","1977","Summer",",","Moroder","and","Bellotte","further","released","I","Feel","Love",",","as","the","B-side","of","Can","'t","We","Just","Sit","Down","(","And","Talk","It","Over",")",",","which","revolutionized","dance","music","with","its","mostly","Electronic","music","production","and","was","a","massive","worldwide","success",",","spawning","the","Hi-NRG","subgenre","."],"labels":["O","O","O","O","B-musical artist","O","B-musical artist","O","O","B-song","I-song","I-song","O","O","O","O","O","B-song","I-song","I-song","I-song","I-song","I-song","O","B-song","I-song","I-song","I-song","O","O","O","O","O","O","O","O","O","B-music genre","I-music genre","O","O","O","O","O","O","O","O","O","O","B-music genre","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, album, award, musical instrument, person, country, music genre, organization, musical artist, song, event, band and O.\nSentence: In 1977 Summer , Moroder and Bellotte further released I Feel Love , as the B-side of Can 't We Just Sit Down ( And Talk It Over ) , which revolutionized dance music with its mostly Electronic music production and was a massive worldwide success , spawning the Hi-NRG subgenre .","prompt_labels":"In(O) 1977(O) Summer(O) ,(O) Moroder(B-musical artist) and(O) Bellotte(B-musical artist) further(O) released(O) I(B-song) Feel(I-song) Love(I-song) ,(O) as(O) the(O) B-side(O) of(O) Can(B-song) 't(I-song) We(I-song) Just(I-song) Sit(I-song) Down(I-song) ((O) And(B-song) Talk(I-song) It(I-song) Over(I-song) )(O) ,(O) which(O) revolutionized(O) dance(O) music(O) with(O) its(O) mostly(O) Electronic(B-music genre) music(I-music genre) production(O) and(O) was(O) a(O) massive(O) worldwide(O) success(O) ,(O) spawning(O) the(O) Hi-NRG(B-music genre) subgenre(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["person","musical instrument","band","country","award","location","event","song","organization","album","music genre","musical artist"],"instance":{"id":"83","words":["The","film","drew","many","of","the","biggest","living","influencers","of","the","rhythm","and","blues","genre","together",",","such","as","Ray","Charles",",","James","Brown",",","Cab","Calloway",",","Aretha","Franklin",",","and","John","Lee","Hooker","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","B-music genre","I-music genre","I-music genre","O","O","O","O","O","B-musical artist","I-musical artist","O","B-musical artist","I-musical artist","O","B-musical artist","I-musical artist","O","B-musical artist","I-musical artist","O","O","B-musical artist","I-musical artist","I-musical artist","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, musical instrument, band, country, award, location, event, song, organization, album, music genre, musical artist and O.\nSentence: The film drew many of the biggest living influencers of the rhythm and blues genre together , such as Ray Charles , James Brown , Cab Calloway , Aretha Franklin , and John Lee Hooker .","prompt_labels":"The(O) film(O) drew(O) many(O) of(O) the(O) biggest(O) living(O) influencers(O) of(O) the(O) rhythm(B-music genre) and(I-music genre) blues(I-music genre) genre(O) together(O) ,(O) such(O) as(O) Ray(B-musical artist) Charles(I-musical artist) ,(O) James(B-musical artist) Brown(I-musical artist) ,(O) Cab(B-musical artist) Calloway(I-musical artist) ,(O) Aretha(B-musical artist) Franklin(I-musical artist) ,(O) and(O) John(B-musical artist) Lee(I-musical artist) Hooker(I-musical artist) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["location","award","album","band","person","musical instrument","song","event","country","musical artist","music genre","organization"],"instance":{"id":"84","words":["Other","acts","who","became","prominent","in","the","alt-country","genre","during","the","1990s","and","2000s","included","The","Bottle","Rockets",",","The","Handsome","Family",",","Blue","Mountain",",","Robbie","Fulks",",","Blood","Oranges",",","Bright","Eyes",",","Drive-By","Truckers",",","Old","97","'s",",","Old","Crow","Medicine","Show",",","Nickel","Creek",",","Neko","Case",",","and","Whiskeytown",",","whose","lead","singer","Ryan","Adams","later","had","a","successful","solo-career","."],"labels":["O","O","O","O","O","O","O","B-music genre","I-music genre","O","O","O","O","O","O","B-band","I-band","I-band","O","B-band","I-band","I-band","O","B-band","I-band","O","B-band","I-band","O","B-band","I-band","O","B-band","I-band","O","B-band","I-band","O","B-band","I-band","I-band","O","B-band","I-band","I-band","I-band","O","B-band","I-band","O","B-musical artist","I-musical artist","O","O","B-band","O","O","O","O","B-musical artist","I-musical artist","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, award, album, band, person, musical instrument, song, event, country, musical artist, music genre, organization and O.\nSentence: Other acts who became prominent in the alt-country genre during the 1990s and 2000s included The Bottle Rockets , The Handsome Family , Blue Mountain , Robbie Fulks , Blood Oranges , Bright Eyes , Drive-By Truckers , Old 97 's , Old Crow Medicine Show , Nickel Creek , Neko Case , and Whiskeytown , whose lead singer Ryan Adams later had a successful solo-career .","prompt_labels":"Other(O) acts(O) who(O) became(O) prominent(O) in(O) the(O) alt-country(B-music genre) genre(I-music genre) during(O) the(O) 1990s(O) and(O) 2000s(O) included(O) The(B-band) Bottle(I-band) Rockets(I-band) ,(O) The(B-band) Handsome(I-band) Family(I-band) ,(O) Blue(B-band) Mountain(I-band) ,(O) Robbie(B-band) Fulks(I-band) ,(O) Blood(B-band) Oranges(I-band) ,(O) Bright(B-band) Eyes(I-band) ,(O) Drive-By(B-band) Truckers(I-band) ,(O) Old(B-band) 97(I-band) 's(I-band) ,(O) Old(B-band) Crow(I-band) Medicine(I-band) Show(I-band) ,(O) Nickel(B-band) Creek(I-band) ,(O) Neko(B-musical artist) Case(I-musical artist) ,(O) and(O) Whiskeytown(B-band) ,(O) whose(O) lead(O) singer(O) Ryan(B-musical artist) Adams(I-musical artist) later(O) had(O) a(O) successful(O) solo-career(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["music genre","band","musical artist","person","musical instrument","award","event","location","album","song","country","organization"],"instance":{"id":"85","words":["The","West","Side","sound","had","strong","rhythmic","support","from","a","rhythm","guitar",",","bass","guitar","and","drums","and","as","perfected","by","Guy",",","Freddie","King",",","Magic","Slim","and","Luther","Allison","was","dominated","by","amplified","electric","lead","guitar","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-musical instrument","I-musical instrument","O","B-musical instrument","I-musical instrument","O","B-musical instrument","O","O","O","O","B-band","O","B-musical artist","I-musical artist","O","B-musical artist","I-musical artist","O","B-musical artist","I-musical artist","O","O","O","O","B-musical instrument","I-musical instrument","I-musical instrument","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: music genre, band, musical artist, person, musical instrument, award, event, location, album, song, country, organization and O.\nSentence: The West Side sound had strong rhythmic support from a rhythm guitar , bass guitar and drums and as perfected by Guy , Freddie King , Magic Slim and Luther Allison was dominated by amplified electric lead guitar .","prompt_labels":"The(O) West(O) Side(O) sound(O) had(O) strong(O) rhythmic(O) support(O) from(O) a(O) rhythm(B-musical instrument) guitar(I-musical instrument) ,(O) bass(B-musical instrument) guitar(I-musical instrument) and(O) drums(B-musical instrument) and(O) as(O) perfected(O) by(O) Guy(B-band) ,(O) Freddie(B-musical artist) King(I-musical artist) ,(O) Magic(B-musical artist) Slim(I-musical artist) and(O) Luther(B-musical artist) Allison(I-musical artist) was(O) dominated(O) by(O) amplified(O) electric(B-musical instrument) lead(I-musical instrument) guitar(I-musical instrument) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["musical artist","location","song","person","musical instrument","band","album","country","organization","music genre","event","award"],"instance":{"id":"86","words":["Other","early","examples","include","the","Mercury","Music","Prize","winning","albums","New","Forms","(","1997",")","from","Reprazent","and","OK","(","1998",")","from","Talvin","Singh",",","4hero","'","s","Mercury-nominated","Two","Pages","from","1998",",","and","Pendulum","'","s","Hold","Your","Colour","in","2005","(","the","best","selling","drum","and","bass","album","of","all","time",")","."],"labels":["O","O","O","O","O","B-award","I-award","I-award","O","O","B-album","I-album","O","O","O","O","B-band","O","B-band","O","O","O","O","B-musical artist","I-musical artist","O","B-band","O","O","O","B-album","I-album","O","O","O","O","B-band","O","O","B-album","I-album","I-album","O","O","O","O","O","O","B-musical instrument","O","B-musical instrument","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: musical artist, location, song, person, musical instrument, band, album, country, organization, music genre, event, award and O.\nSentence: Other early examples include the Mercury Music Prize winning albums New Forms ( 1997 ) from Reprazent and OK ( 1998 ) from Talvin Singh , 4hero ' s Mercury-nominated Two Pages from 1998 , and Pendulum ' s Hold Your Colour in 2005 ( the best selling drum and bass album of all time ) .","prompt_labels":"Other(O) early(O) examples(O) include(O) the(O) Mercury(B-award) Music(I-award) Prize(I-award) winning(O) albums(O) New(B-album) Forms(I-album) ((O) 1997(O) )(O) from(O) Reprazent(B-band) and(O) OK(B-band) ((O) 1998(O) )(O) from(O) Talvin(B-musical artist) Singh(I-musical artist) ,(O) 4hero(B-band) '(O) s(O) Mercury-nominated(O) Two(B-album) Pages(I-album) from(O) 1998(O) ,(O) and(O) Pendulum(B-band) '(O) s(O) Hold(B-album) Your(I-album) Colour(I-album) in(O) 2005(O) ((O) the(O) best(O) selling(O) drum(B-musical instrument) and(O) bass(B-musical instrument) album(O) of(O) all(O) time(O) )(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["song","event","musical instrument","country","music genre","award","location","album","band","person","musical artist","organization"],"instance":{"id":"87","words":["Florida","breaks","was","heavily","influenced","by","Miami","bass","in","addition","to","elements","of","House","music",",","and","deep","bass","that","eventually","created","The","Orlando","Sound","."],"labels":["B-music genre","I-music genre","O","O","O","O","B-music genre","I-music genre","O","O","O","O","O","B-music genre","I-music genre","O","O","O","O","O","O","O","B-music genre","I-music genre","I-music genre","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, event, musical instrument, country, music genre, award, location, album, band, person, musical artist, organization and O.\nSentence: Florida breaks was heavily influenced by Miami bass in addition to elements of House music , and deep bass that eventually created The Orlando Sound .","prompt_labels":"Florida(B-music genre) breaks(I-music genre) was(O) heavily(O) influenced(O) by(O) Miami(B-music genre) bass(I-music genre) in(O) addition(O) to(O) elements(O) of(O) House(B-music genre) music(I-music genre) ,(O) and(O) deep(O) bass(O) that(O) eventually(O) created(O) The(B-music genre) Orlando(I-music genre) Sound(I-music genre) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["event","musical instrument","organization","album","song","band","music genre","musical artist","country","person","location","award"],"instance":{"id":"88","words":["Miles","Davis","on","the","roster",",","and","his","late","1960s","recordings",",","In","a","Silent","Way","and","Bitches","Brew",",","pioneered","a","Jazz","fusion","."],"labels":["B-musical artist","I-musical artist","O","O","O","O","O","O","O","O","O","O","B-album","I-album","I-album","I-album","O","B-album","I-album","O","O","O","B-music genre","I-music genre","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, musical instrument, organization, album, song, band, music genre, musical artist, country, person, location, award and O.\nSentence: Miles Davis on the roster , and his late 1960s recordings , In a Silent Way and Bitches Brew , pioneered a Jazz fusion .","prompt_labels":"Miles(B-musical artist) Davis(I-musical artist) on(O) the(O) roster(O) ,(O) and(O) his(O) late(O) 1960s(O) recordings(O) ,(O) In(B-album) a(I-album) Silent(I-album) Way(I-album) and(O) Bitches(B-album) Brew(I-album) ,(O) pioneered(O) a(O) Jazz(B-music genre) fusion(I-music genre) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["person","organization","album","award","location","band","music genre","event","musical artist","musical instrument","country","song"],"instance":{"id":"89","words":["Ullman","and","the","show","went","on","to","receive","a","slew","of","awards","including","six","Emmy","Awards",",","two","CableAce","Awards",",","three","American","Comedy","Awards",",","two","GLAAD","Media","Award","s",",","as","well","as","a","Screen","Actors","Guild","Awards","in","1999","for","Screen","Actors","Guild","Award","for","Outstanding","Performance","by","a","Female","Actor","in","a","Comedy","Series","."],"labels":["B-musical artist","O","O","O","O","O","O","O","O","O","O","O","O","O","B-award","I-award","O","O","B-award","I-award","O","O","B-award","I-award","I-award","O","O","B-award","I-award","I-award","O","O","O","O","O","O","B-award","I-award","I-award","I-award","O","O","O","B-award","I-award","I-award","I-award","I-award","I-award","I-award","I-award","I-award","I-award","I-award","I-award","I-award","I-award","I-award","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, organization, album, award, location, band, music genre, event, musical artist, musical instrument, country, song and O.\nSentence: Ullman and the show went on to receive a slew of awards including six Emmy Awards , two CableAce Awards , three American Comedy Awards , two GLAAD Media Award s , as well as a Screen Actors Guild Awards in 1999 for Screen Actors Guild Award for Outstanding Performance by a Female Actor in a Comedy Series .","prompt_labels":"Ullman(B-musical artist) and(O) the(O) show(O) went(O) on(O) to(O) receive(O) a(O) slew(O) of(O) awards(O) including(O) six(O) Emmy(B-award) Awards(I-award) ,(O) two(O) CableAce(B-award) Awards(I-award) ,(O) three(O) American(B-award) Comedy(I-award) Awards(I-award) ,(O) two(O) GLAAD(B-award) Media(I-award) Award(I-award) s(O) ,(O) as(O) well(O) as(O) a(O) Screen(B-award) Actors(I-award) Guild(I-award) Awards(I-award) in(O) 1999(O) for(O) Screen(B-award) Actors(I-award) Guild(I-award) Award(I-award) for(I-award) Outstanding(I-award) Performance(I-award) by(I-award) a(I-award) Female(I-award) Actor(I-award) in(I-award) a(I-award) Comedy(I-award) Series(I-award) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["country","organization","person","band","event","music genre","location","award","musical artist","musical instrument","album","song"],"instance":{"id":"90","words":["Electropop","pioneers","Haruomi","Hosono","and","Ryuichi","Sakamoto","of","the","Yellow","Magic","Orchestra","produced","a","1978","Electronic","music","album",",","Cochin","Moon",",","based","on","an","experimental","fusion","of","electronic","music","and","Bollywood-inspired","Indian","music","."],"labels":["B-music genre","O","B-musical artist","I-musical artist","O","B-musical artist","I-musical artist","O","O","B-band","I-band","I-band","O","O","O","B-music genre","I-music genre","O","O","B-album","I-album","O","O","O","O","O","O","O","B-music genre","I-music genre","O","B-music genre","I-music genre","I-music genre","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, organization, person, band, event, music genre, location, award, musical artist, musical instrument, album, song and O.\nSentence: Electropop pioneers Haruomi Hosono and Ryuichi Sakamoto of the Yellow Magic Orchestra produced a 1978 Electronic music album , Cochin Moon , based on an experimental fusion of electronic music and Bollywood-inspired Indian music .","prompt_labels":"Electropop(B-music genre) pioneers(O) Haruomi(B-musical artist) Hosono(I-musical artist) and(O) Ryuichi(B-musical artist) Sakamoto(I-musical artist) of(O) the(O) Yellow(B-band) Magic(I-band) Orchestra(I-band) produced(O) a(O) 1978(O) Electronic(B-music genre) music(I-music genre) album(O) ,(O) Cochin(B-album) Moon(I-album) ,(O) based(O) on(O) an(O) experimental(O) fusion(O) of(O) electronic(B-music genre) music(I-music genre) and(O) Bollywood-inspired(B-music genre) Indian(I-music genre) music(I-music genre) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["musical instrument","organization","country","location","event","musical artist","band","album","award","song","person","music genre"],"instance":{"id":"91","words":["Black","Holes","and","Revelations","(","2006",")","incorporated","Electronic","music","and","Pop","music","elements",",","displayed","in","singles","such","as","Supermassive","Black","Hole",",","Their","seventh","album",",","Drones","(","2015",")",",","was","a","concept","album","about","drone","warfare","and","returned","to","a","harder","rock","sound","."],"labels":["B-album","I-album","I-album","I-album","O","O","O","O","B-music genre","I-music genre","O","B-music genre","I-music genre","O","O","O","O","O","O","O","B-song","I-song","I-song","O","O","O","O","O","B-album","O","O","O","O","O","O","O","O","O","B-album","I-album","O","O","O","O","O","B-music genre","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: musical instrument, organization, country, location, event, musical artist, band, album, award, song, person, music genre and O.\nSentence: Black Holes and Revelations ( 2006 ) incorporated Electronic music and Pop music elements , displayed in singles such as Supermassive Black Hole , Their seventh album , Drones ( 2015 ) , was a concept album about drone warfare and returned to a harder rock sound .","prompt_labels":"Black(B-album) Holes(I-album) and(I-album) Revelations(I-album) ((O) 2006(O) )(O) incorporated(O) Electronic(B-music genre) music(I-music genre) and(O) Pop(B-music genre) music(I-music genre) elements(O) ,(O) displayed(O) in(O) singles(O) such(O) as(O) Supermassive(B-song) Black(I-song) Hole(I-song) ,(O) Their(O) seventh(O) album(O) ,(O) Drones(B-album) ((O) 2015(O) )(O) ,(O) was(O) a(O) concept(O) album(O) about(O) drone(B-album) warfare(I-album) and(O) returned(O) to(O) a(O) harder(O) rock(B-music genre) sound(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["organization","musical instrument","song","country","band","musical artist","person","event","album","music genre","award","location"],"instance":{"id":"92","words":["The","5th","Dimension","is","an","United","States","popular","music","vocal","group",",","whose","repertoire","includes","Pop","music",",","Rhythm","and","blues",",","Soul","music",",","jazz",",","light","opera",",","and","Broadway","-","the","melange","was","coined","as","Champagne","Soul","."],"labels":["B-band","I-band","I-band","O","O","B-country","I-country","B-music genre","I-music genre","O","O","O","O","O","O","B-music genre","I-music genre","O","B-music genre","I-music genre","I-music genre","O","B-music genre","I-music genre","O","B-music genre","O","B-music genre","I-music genre","O","O","B-music genre","O","O","O","O","O","O","B-music genre","I-music genre","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, musical instrument, song, country, band, musical artist, person, event, album, music genre, award, location and O.\nSentence: The 5th Dimension is an United States popular music vocal group , whose repertoire includes Pop music , Rhythm and blues , Soul music , jazz , light opera , and Broadway - the melange was coined as Champagne Soul .","prompt_labels":"The(B-band) 5th(I-band) Dimension(I-band) is(O) an(O) United(B-country) States(I-country) popular(B-music genre) music(I-music genre) vocal(O) group(O) ,(O) whose(O) repertoire(O) includes(O) Pop(B-music genre) music(I-music genre) ,(O) Rhythm(B-music genre) and(I-music genre) blues(I-music genre) ,(O) Soul(B-music genre) music(I-music genre) ,(O) jazz(B-music genre) ,(O) light(B-music genre) opera(I-music genre) ,(O) and(O) Broadway(B-music genre) -(O) the(O) melange(O) was(O) coined(O) as(O) Champagne(B-music genre) Soul(I-music genre) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["music genre","band","country","organization","person","musical artist","event","award","musical instrument","song","album","location"],"instance":{"id":"93","words":["Barney","Bubbles","directed","several","videos",",","including","the","Specials","'","Ghost","Town",",","Squeeze","'","s","Is","That","Love","and","Tempted",",","Elvis","Costello","'","s","Clubland","and","New","Lace","Sleeves",",","and","Fun","Boy","Three","'","s","The","Lunatics","Have","Taken","Over","the","Asylum","."],"labels":["B-person","I-person","O","O","O","O","O","B-band","I-band","O","B-song","I-song","O","B-band","O","O","B-song","I-song","I-song","O","B-song","O","B-musical artist","I-musical artist","O","O","B-song","O","B-song","I-song","I-song","O","O","B-band","I-band","I-band","O","O","B-song","I-song","I-song","I-song","I-song","I-song","I-song","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: music genre, band, country, organization, person, musical artist, event, award, musical instrument, song, album, location and O.\nSentence: Barney Bubbles directed several videos , including the Specials ' Ghost Town , Squeeze ' s Is That Love and Tempted , Elvis Costello ' s Clubland and New Lace Sleeves , and Fun Boy Three ' s The Lunatics Have Taken Over the Asylum .","prompt_labels":"Barney(B-person) Bubbles(I-person) directed(O) several(O) videos(O) ,(O) including(O) the(B-band) Specials(I-band) '(O) Ghost(B-song) Town(I-song) ,(O) Squeeze(B-band) '(O) s(O) Is(B-song) That(I-song) Love(I-song) and(O) Tempted(B-song) ,(O) Elvis(B-musical artist) Costello(I-musical artist) '(O) s(O) Clubland(B-song) and(O) New(B-song) Lace(I-song) Sleeves(I-song) ,(O) and(O) Fun(B-band) Boy(I-band) Three(I-band) '(O) s(O) The(B-song) Lunatics(I-song) Have(I-song) Taken(I-song) Over(I-song) the(I-song) Asylum(I-song) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["location","song","award","album","event","band","organization","musical artist","person","musical instrument","music genre","country"],"instance":{"id":"94","words":["Their","first","album",",","Let","Them","Eat","Bingo",",","included","the","number","one","single","Dub","Be","Good","to","Me",",","which","caused","a","legal","dispute","revolving","around","allegations","of","infringement","of","copyright","through","the","liberal","use","of","unauthorised","samples",":","the","bassline","was","a","note-for-note","lift","from","The","Guns","of","Brixton","by","The","Clash","and","the","lyrics","borrowed","heavily","from","Just","Be","Good","to","Me","by","The","S.O.S.","Band","."],"labels":["O","O","O","O","B-album","I-album","I-album","I-album","O","O","O","O","O","O","B-song","I-song","I-song","I-song","I-song","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-music genre","O","O","O","O","O","B-song","I-song","I-song","I-song","O","B-band","I-band","O","O","O","O","O","O","B-song","I-song","I-song","I-song","I-song","O","B-band","I-band","I-band","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, song, award, album, event, band, organization, musical artist, person, musical instrument, music genre, country and O.\nSentence: Their first album , Let Them Eat Bingo , included the number one single Dub Be Good to Me , which caused a legal dispute revolving around allegations of infringement of copyright through the liberal use of unauthorised samples : the bassline was a note-for-note lift from The Guns of Brixton by The Clash and the lyrics borrowed heavily from Just Be Good to Me by The S.O.S. Band .","prompt_labels":"Their(O) first(O) album(O) ,(O) Let(B-album) Them(I-album) Eat(I-album) Bingo(I-album) ,(O) included(O) the(O) number(O) one(O) single(O) Dub(B-song) Be(I-song) Good(I-song) to(I-song) Me(I-song) ,(O) which(O) caused(O) a(O) legal(O) dispute(O) revolving(O) around(O) allegations(O) of(O) infringement(O) of(O) copyright(O) through(O) the(O) liberal(O) use(O) of(O) unauthorised(O) samples(O) :(O) the(O) bassline(B-music genre) was(O) a(O) note-for-note(O) lift(O) from(O) The(B-song) Guns(I-song) of(I-song) Brixton(I-song) by(O) The(B-band) Clash(I-band) and(O) the(O) lyrics(O) borrowed(O) heavily(O) from(O) Just(B-song) Be(I-song) Good(I-song) to(I-song) Me(I-song) by(O) The(B-band) S.O.S.(I-band) Band(I-band) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["album","person","musical artist","location","song","musical instrument","music genre","country","event","organization","award","band"],"instance":{"id":"95","words":["In","June","1932","he","joined","the","British","Astronomical","Association",",","in","November","of","the","same","year","he","became","a","Fellow","of","the","Royal","Astronomical","Society","."],"labels":["O","O","O","O","O","O","B-organization","I-organization","I-organization","O","O","O","O","O","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","I-award","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: album, person, musical artist, location, song, musical instrument, music genre, country, event, organization, award, band and O.\nSentence: In June 1932 he joined the British Astronomical Association , in November of the same year he became a Fellow of the Royal Astronomical Society .","prompt_labels":"In(O) June(O) 1932(O) he(O) joined(O) the(O) British(B-organization) Astronomical(I-organization) Association(I-organization) ,(O) in(O) November(O) of(O) the(O) same(O) year(O) he(O) became(O) a(O) Fellow(B-award) of(I-award) the(I-award) Royal(I-award) Astronomical(I-award) Society(I-award) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["musical artist","music genre","song","person","musical instrument","award","event","location","album","country","organization","band"],"instance":{"id":"96","words":["These","were","finished","by","early","1984",",","with","all","night","games","in","Adelaide","moving","from","the","suburban","grounds","(","Norwood","Oval","and","Thebarton","Oval",")","to","league","headquarters","for","the","next","16","years","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","B-location","O","O","O","O","O","O","B-location","I-location","O","B-location","I-location","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: musical artist, music genre, song, person, musical instrument, award, event, location, album, country, organization, band and O.\nSentence: These were finished by early 1984 , with all night games in Adelaide moving from the suburban grounds ( Norwood Oval and Thebarton Oval ) to league headquarters for the next 16 years .","prompt_labels":"These(O) were(O) finished(O) by(O) early(O) 1984(O) ,(O) with(O) all(O) night(O) games(O) in(O) Adelaide(B-location) moving(O) from(O) the(O) suburban(O) grounds(O) ((O) Norwood(B-location) Oval(I-location) and(O) Thebarton(B-location) Oval(I-location) )(O) to(O) league(O) headquarters(O) for(O) the(O) next(O) 16(O) years(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["event","person","award","musical instrument","country","song","musical artist","band","organization","location","album","music genre"],"instance":{"id":"97","words":["A","more","extensive","tribute","was","given","later","that","year","in","December","at","the","Southbank","Centre","in","the","Queen","Elizabeth","Hall","called","The","Lady",":","A","Tribute","to","Sandy","Denny","with","a","band","composed","of","members","of","Bellowhead",",","the","evening","featured","a","mix","of","young","folk","acts","like","Jim","Moray","and","Lisa","Knapp","alongside","those","that","had","known","and","worked","with","Denny","such","as","Dave","Swarbrick","and","Jerry","Donahue","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","B-location","I-location","O","O","B-location","I-location","I-location","O","B-event","I-event","I-event","I-event","I-event","I-event","I-event","I-event","O","O","O","O","O","O","O","B-band","O","O","O","O","O","O","O","O","O","O","O","B-musical artist","I-musical artist","O","B-musical artist","I-musical artist","O","O","O","O","O","O","O","O","B-musical artist","O","O","B-musical artist","I-musical artist","O","B-musical artist","I-musical artist","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, person, award, musical instrument, country, song, musical artist, band, organization, location, album, music genre and O.\nSentence: A more extensive tribute was given later that year in December at the Southbank Centre in the Queen Elizabeth Hall called The Lady : A Tribute to Sandy Denny with a band composed of members of Bellowhead , the evening featured a mix of young folk acts like Jim Moray and Lisa Knapp alongside those that had known and worked with Denny such as Dave Swarbrick and Jerry Donahue .","prompt_labels":"A(O) more(O) extensive(O) tribute(O) was(O) given(O) later(O) that(O) year(O) in(O) December(O) at(O) the(O) Southbank(B-location) Centre(I-location) in(O) the(O) Queen(B-location) Elizabeth(I-location) Hall(I-location) called(O) The(B-event) Lady(I-event) :(I-event) A(I-event) Tribute(I-event) to(I-event) Sandy(I-event) Denny(I-event) with(O) a(O) band(O) composed(O) of(O) members(O) of(O) Bellowhead(B-band) ,(O) the(O) evening(O) featured(O) a(O) mix(O) of(O) young(O) folk(O) acts(O) like(O) Jim(B-musical artist) Moray(I-musical artist) and(O) Lisa(B-musical artist) Knapp(I-musical artist) alongside(O) those(O) that(O) had(O) known(O) and(O) worked(O) with(O) Denny(B-musical artist) such(O) as(O) Dave(B-musical artist) Swarbrick(I-musical artist) and(O) Jerry(B-musical artist) Donahue(I-musical artist) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["award","song","band","music genre","album","musical artist","location","country","musical instrument","event","person","organization"],"instance":{"id":"98","words":["Lynn","has","received","numerous","awards","and","other","accolades","for","her","groundbreaking","role","in","country","music",",","including","awards","from","both","the","Country","Music","Association","and","Academy","of","Country","Music","as","a","duet","partner","and","an","individual","artist","."],"labels":["B-musical artist","O","O","O","O","O","O","O","O","O","O","O","O","B-music genre","I-music genre","O","O","O","O","O","O","B-organization","I-organization","I-organization","O","B-organization","I-organization","I-organization","I-organization","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, song, band, music genre, album, musical artist, location, country, musical instrument, event, person, organization and O.\nSentence: Lynn has received numerous awards and other accolades for her groundbreaking role in country music , including awards from both the Country Music Association and Academy of Country Music as a duet partner and an individual artist .","prompt_labels":"Lynn(B-musical artist) has(O) received(O) numerous(O) awards(O) and(O) other(O) accolades(O) for(O) her(O) groundbreaking(O) role(O) in(O) country(B-music genre) music(I-music genre) ,(O) including(O) awards(O) from(O) both(O) the(O) Country(B-organization) Music(I-organization) Association(I-organization) and(O) Academy(B-organization) of(I-organization) Country(I-organization) Music(I-organization) as(O) a(O) duet(O) partner(O) and(O) an(O) individual(O) artist(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["musical artist","song","person","award","musical instrument","country","band","organization","album","location","event","music genre"],"instance":{"id":"99","words":["Phish",",","Soul","Rebels","Brass","Band",",","Galactic",",","and","Soulive","are","all","examples","of","funk","bands","that","play","funk","jam","."],"labels":["B-band","O","B-band","I-band","I-band","I-band","O","B-band","O","O","B-band","O","O","O","O","B-music genre","O","O","O","B-music genre","I-music genre","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: musical artist, song, person, award, musical instrument, country, band, organization, album, location, event, music genre and O.\nSentence: Phish , Soul Rebels Brass Band , Galactic , and Soulive are all examples of funk bands that play funk jam .","prompt_labels":"Phish(B-band) ,(O) Soul(B-band) Rebels(I-band) Brass(I-band) Band(I-band) ,(O) Galactic(B-band) ,(O) and(O) Soulive(B-band) are(O) all(O) examples(O) of(O) funk(B-music genre) bands(O) that(O) play(O) funk(B-music genre) jam(I-music genre) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["person","album","musical artist","country","organization","event","music genre","song","location","band","musical instrument","award"],"instance":{"id":"100","words":["Taylor","Momsen",",","Marcus","Durant",",","Brandi","Carlile","and","Taylor","Hawkins","contributed","vocals","to","Soundgarden",",","who","performed","Rusty","Cage",",","Flower",",","Outshined",",","Drawing","Flies",",","Loud","Love",",","I","Awake",",","The","Day","I","Tried","to","Live","and","Black","Hole","Sun",",","making","this","their","only","performance","since","Cornell","'s","death","."],"labels":["B-musical artist","I-musical artist","O","B-band","I-band","O","B-musical artist","I-musical artist","O","B-musical artist","I-musical artist","O","O","O","B-band","O","O","O","B-song","I-song","O","B-song","O","B-song","O","B-song","I-song","O","B-song","I-song","O","B-song","I-song","O","B-song","I-song","I-song","I-song","I-song","I-song","O","B-song","I-song","I-song","O","O","O","O","O","O","O","B-musical artist","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, album, musical artist, country, organization, event, music genre, song, location, band, musical instrument, award and O.\nSentence: Taylor Momsen , Marcus Durant , Brandi Carlile and Taylor Hawkins contributed vocals to Soundgarden , who performed Rusty Cage , Flower , Outshined , Drawing Flies , Loud Love , I Awake , The Day I Tried to Live and Black Hole Sun , making this their only performance since Cornell 's death .","prompt_labels":"Taylor(B-musical artist) Momsen(I-musical artist) ,(O) Marcus(B-band) Durant(I-band) ,(O) Brandi(B-musical artist) Carlile(I-musical artist) and(O) Taylor(B-musical artist) Hawkins(I-musical artist) contributed(O) vocals(O) to(O) Soundgarden(B-band) ,(O) who(O) performed(O) Rusty(B-song) Cage(I-song) ,(O) Flower(B-song) ,(O) Outshined(B-song) ,(O) Drawing(B-song) Flies(I-song) ,(O) Loud(B-song) Love(I-song) ,(O) I(B-song) Awake(I-song) ,(O) The(B-song) Day(I-song) I(I-song) Tried(I-song) to(I-song) Live(I-song) and(O) Black(B-song) Hole(I-song) Sun(I-song) ,(O) making(O) this(O) their(O) only(O) performance(O) since(O) Cornell(B-musical artist) 's(O) death(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["music genre","band","person","event","album","organization","song","country","location","award","musical instrument","musical artist"],"instance":{"id":"101","words":["The","film","received","several","Golden","Globe","Awards","and","Academy","Awards","nominations",",","and","earned","Kidman","a","fourth","Screen","Actors","Guild","Award","nomination",",","as","part","of","the","Screen","Actors","Guild","Award","for","Outstanding","Performance","by","a","Cast","in","a","Motion","Picture","."],"labels":["O","O","O","O","B-award","I-award","I-award","O","B-award","I-award","O","O","O","O","O","O","O","B-award","I-award","I-award","I-award","O","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","I-award","I-award","I-award","I-award","I-award","I-award","I-award","I-award","I-award","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: music genre, band, person, event, album, organization, song, country, location, award, musical instrument, musical artist and O.\nSentence: The film received several Golden Globe Awards and Academy Awards nominations , and earned Kidman a fourth Screen Actors Guild Award nomination , as part of the Screen Actors Guild Award for Outstanding Performance by a Cast in a Motion Picture .","prompt_labels":"The(O) film(O) received(O) several(O) Golden(B-award) Globe(I-award) Awards(I-award) and(O) Academy(B-award) Awards(I-award) nominations(O) ,(O) and(O) earned(O) Kidman(O) a(O) fourth(O) Screen(B-award) Actors(I-award) Guild(I-award) Award(I-award) nomination(O) ,(O) as(O) part(O) of(O) the(O) Screen(B-award) Actors(I-award) Guild(I-award) Award(I-award) for(I-award) Outstanding(I-award) Performance(I-award) by(I-award) a(I-award) Cast(I-award) in(I-award) a(I-award) Motion(I-award) Picture(I-award) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["event","musical instrument","album","award","music genre","musical artist","location","organization","country","band","song","person"],"instance":{"id":"102","words":["Steve","Young",",","David","Allan","Coe",",","John","Prine",",","Billy","Joe","Shaver",",","Gary","Stewart",",","Townes","Van","Zandt",",","Kris","Kristofferson",",","Michael","Martin","Murphey",",","Tompall","Glaser",",","Steve","Earle",",","and","the","later","career","renaissance","of","Johnny","Cash",",","along","with","a","few","female","vocalists","such","as","Jessi","Colter",",","Sammi","Smith",",","Tanya","Tucker",",","and","Rosanne","Cash","."],"labels":["B-musical artist","I-musical artist","O","B-musical artist","I-musical artist","I-musical artist","O","B-musical artist","I-musical artist","O","B-musical artist","I-musical artist","I-musical artist","O","B-musical artist","I-musical artist","O","B-musical artist","I-musical artist","I-musical artist","O","B-musical artist","I-musical artist","O","B-musical artist","I-musical artist","I-musical artist","O","B-musical artist","I-musical artist","O","B-musical artist","I-musical artist","O","O","O","O","O","O","O","B-musical artist","I-musical artist","O","O","O","O","O","O","O","O","O","B-musical artist","I-musical artist","O","B-musical artist","I-musical artist","O","B-musical artist","I-musical artist","O","O","B-musical artist","I-musical artist","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, musical instrument, album, award, music genre, musical artist, location, organization, country, band, song, person and O.\nSentence: Steve Young , David Allan Coe , John Prine , Billy Joe Shaver , Gary Stewart , Townes Van Zandt , Kris Kristofferson , Michael Martin Murphey , Tompall Glaser , Steve Earle , and the later career renaissance of Johnny Cash , along with a few female vocalists such as Jessi Colter , Sammi Smith , Tanya Tucker , and Rosanne Cash .","prompt_labels":"Steve(B-musical artist) Young(I-musical artist) ,(O) David(B-musical artist) Allan(I-musical artist) Coe(I-musical artist) ,(O) John(B-musical artist) Prine(I-musical artist) ,(O) Billy(B-musical artist) Joe(I-musical artist) Shaver(I-musical artist) ,(O) Gary(B-musical artist) Stewart(I-musical artist) ,(O) Townes(B-musical artist) Van(I-musical artist) Zandt(I-musical artist) ,(O) Kris(B-musical artist) Kristofferson(I-musical artist) ,(O) Michael(B-musical artist) Martin(I-musical artist) Murphey(I-musical artist) ,(O) Tompall(B-musical artist) Glaser(I-musical artist) ,(O) Steve(B-musical artist) Earle(I-musical artist) ,(O) and(O) the(O) later(O) career(O) renaissance(O) of(O) Johnny(B-musical artist) Cash(I-musical artist) ,(O) along(O) with(O) a(O) few(O) female(O) vocalists(O) such(O) as(O) Jessi(B-musical artist) Colter(I-musical artist) ,(O) Sammi(B-musical artist) Smith(I-musical artist) ,(O) Tanya(B-musical artist) Tucker(I-musical artist) ,(O) and(O) Rosanne(B-musical artist) Cash(I-musical artist) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["person","music genre","musical artist","award","organization","album","location","country","band","musical instrument","song","event"],"instance":{"id":"103","words":["New","York","'s","rock","scene","includes","clubs","such","as","Irving","Plaza",",","while","the","city","'s","avant-garde","downtown","scene","includes","The","Kitchen",",","Roulette",",","and","Knitting","Factory","."],"labels":["B-location","I-location","O","B-music genre","O","O","O","O","O","B-location","I-location","O","O","O","O","O","O","O","O","O","B-location","I-location","O","B-location","O","O","B-location","I-location","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, music genre, musical artist, award, organization, album, location, country, band, musical instrument, song, event and O.\nSentence: New York 's rock scene includes clubs such as Irving Plaza , while the city 's avant-garde downtown scene includes The Kitchen , Roulette , and Knitting Factory .","prompt_labels":"New(B-location) York(I-location) 's(O) rock(B-music genre) scene(O) includes(O) clubs(O) such(O) as(O) Irving(B-location) Plaza(I-location) ,(O) while(O) the(O) city(O) 's(O) avant-garde(O) downtown(O) scene(O) includes(O) The(B-location) Kitchen(I-location) ,(O) Roulette(B-location) ,(O) and(O) Knitting(B-location) Factory(I-location) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["country","award","music genre","person","organization","event","band","musical artist","song","musical instrument","location","album"],"instance":{"id":"104","words":["He","has","chaired","the","Southern","Growth","Policies","Board",",","the","Southern","Regional","Education","Board",",","the","Southern","Technology","Council",",","the","Interstate","Oil","and","Gas","Compact","Commission",",","and","the","Education","Commission","of","the","States","."],"labels":["O","O","O","O","B-organization","I-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, award, music genre, person, organization, event, band, musical artist, song, musical instrument, location, album and O.\nSentence: He has chaired the Southern Growth Policies Board , the Southern Regional Education Board , the Southern Technology Council , the Interstate Oil and Gas Compact Commission , and the Education Commission of the States .","prompt_labels":"He(O) has(O) chaired(O) the(O) Southern(B-organization) Growth(I-organization) Policies(I-organization) Board(I-organization) ,(O) the(O) Southern(B-organization) Regional(I-organization) Education(I-organization) Board(I-organization) ,(O) the(O) Southern(B-organization) Technology(I-organization) Council(I-organization) ,(O) the(O) Interstate(B-organization) Oil(I-organization) and(I-organization) Gas(I-organization) Compact(I-organization) Commission(I-organization) ,(O) and(O) the(O) Education(B-organization) Commission(I-organization) of(I-organization) the(I-organization) States(I-organization) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["organization","country","location","song","event","album","award","musical artist","band","musical instrument","music genre","person"],"instance":{"id":"105","words":["The","group","'s","evolution","can","be","traced","through","the","albums","The","John","Coltrane","Quartet","Plays",",","Living","Space",",","Transition",",","New","Thing","at","Newport",",","Sun","Ship",",","and","First","Meditations","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-album","I-album","I-album","I-album","I-album","O","B-album","I-album","O","B-album","O","B-album","I-album","I-album","I-album","O","B-album","I-album","O","O","B-album","I-album","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, country, location, song, event, album, award, musical artist, band, musical instrument, music genre, person and O.\nSentence: The group 's evolution can be traced through the albums The John Coltrane Quartet Plays , Living Space , Transition , New Thing at Newport , Sun Ship , and First Meditations .","prompt_labels":"The(O) group(O) 's(O) evolution(O) can(O) be(O) traced(O) through(O) the(O) albums(O) The(B-album) John(I-album) Coltrane(I-album) Quartet(I-album) Plays(I-album) ,(O) Living(B-album) Space(I-album) ,(O) Transition(B-album) ,(O) New(B-album) Thing(I-album) at(I-album) Newport(I-album) ,(O) Sun(B-album) Ship(I-album) ,(O) and(O) First(B-album) Meditations(I-album) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["country","organization","person","musical instrument","location","album","song","band","event","music genre","award","musical artist"],"instance":{"id":"106","words":["It","is","based","on","the","classic","song","The","Guns","of","Brixton","on","The","Clash","'","s","London","Calling","and","has","proven","to","be","a","success","on","the","modern","rock","charts","."],"labels":["O","O","O","O","O","O","O","B-song","I-song","I-song","I-song","O","B-band","I-band","O","O","B-album","I-album","O","O","O","O","O","O","O","O","O","B-music genre","I-music genre","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, organization, person, musical instrument, location, album, song, band, event, music genre, award, musical artist and O.\nSentence: It is based on the classic song The Guns of Brixton on The Clash ' s London Calling and has proven to be a success on the modern rock charts .","prompt_labels":"It(O) is(O) based(O) on(O) the(O) classic(O) song(O) The(B-song) Guns(I-song) of(I-song) Brixton(I-song) on(O) The(B-band) Clash(I-band) '(O) s(O) London(B-album) Calling(I-album) and(O) has(O) proven(O) to(O) be(O) a(O) success(O) on(O) the(O) modern(B-music genre) rock(I-music genre) charts(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["song","award","location","person","organization","musical instrument","music genre","country","event","album","musical artist","band"],"instance":{"id":"107","words":["1995","saw","the","release","of","Tri","Repetae",",","their","third","album",",","as","well","as","the","EPs","Anvil","Vapre","and","Garbage",",","featuring","a","monochrome","cover","designed","by","The","Designers","Republic",",","with","whom","Autechre","have","long","held","a","close","association","."],"labels":["O","O","O","O","O","B-album","I-album","O","O","O","O","O","O","O","O","O","O","B-album","I-album","O","B-album","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","O","O","O","B-band","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, award, location, person, organization, musical instrument, music genre, country, event, album, musical artist, band and O.\nSentence: 1995 saw the release of Tri Repetae , their third album , as well as the EPs Anvil Vapre and Garbage , featuring a monochrome cover designed by The Designers Republic , with whom Autechre have long held a close association .","prompt_labels":"1995(O) saw(O) the(O) release(O) of(O) Tri(B-album) Repetae(I-album) ,(O) their(O) third(O) album(O) ,(O) as(O) well(O) as(O) the(O) EPs(O) Anvil(B-album) Vapre(I-album) and(O) Garbage(B-album) ,(O) featuring(O) a(O) monochrome(O) cover(O) designed(O) by(O) The(B-organization) Designers(I-organization) Republic(I-organization) ,(O) with(O) whom(O) Autechre(B-band) have(O) long(O) held(O) a(O) close(O) association(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["song","event","organization","musical instrument","musical artist","music genre","person","location","album","award","band","country"],"instance":{"id":"108","words":["The","accordion","has","been","used","by","tropipop","musicians","such","as","Carlos","Vives",",","Andrs","Cabas",",","Fonseca","(","singer",")","and","Bacilos",",","as","well","as","rock","musicians","such","as","Juanes","and","pop","musicians","as","Shakira","."],"labels":["O","B-musical instrument","O","O","O","O","B-music genre","O","O","O","B-musical artist","I-musical artist","O","B-musical artist","I-musical artist","O","B-musical artist","O","O","O","O","B-band","O","O","O","O","B-music genre","O","O","O","B-musical artist","O","B-music genre","O","O","B-musical artist","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, event, organization, musical instrument, musical artist, music genre, person, location, album, award, band, country and O.\nSentence: The accordion has been used by tropipop musicians such as Carlos Vives , Andrs Cabas , Fonseca ( singer ) and Bacilos , as well as rock musicians such as Juanes and pop musicians as Shakira .","prompt_labels":"The(O) accordion(B-musical instrument) has(O) been(O) used(O) by(O) tropipop(B-music genre) musicians(O) such(O) as(O) Carlos(B-musical artist) Vives(I-musical artist) ,(O) Andrs(B-musical artist) Cabas(I-musical artist) ,(O) Fonseca(B-musical artist) ((O) singer(O) )(O) and(O) Bacilos(B-band) ,(O) as(O) well(O) as(O) rock(B-music genre) musicians(O) such(O) as(O) Juanes(B-musical artist) and(O) pop(B-music genre) musicians(O) as(O) Shakira(B-musical artist) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["musical instrument","country","event","award","musical artist","band","song","location","organization","person","music genre","album"],"instance":{"id":"109","words":["First",",","they","played","a","series","of","concerts","at","the","Glr","Theatre","in","Ennis",",","County","Clare","(","on","23","&","amp",";","24","January","2004",")","and","at","Vicar","Street","in","Dublin","(","on","30","&","amp",";","31","January","and","on","4","&","amp",";","5",",","11","&","amp",";","12","February","2004",")",",","which","were","recorded","and","from","which","selected","material","was","released","on","the","CD","Live","2004","and","its","associated","DVD","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-location","I-location","O","B-location","O","B-location","B-location","O","O","O","O","O","O","O","O","O","O","O","O","B-location","I-location","O","B-location","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-album","I-album","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: musical instrument, country, event, award, musical artist, band, song, location, organization, person, music genre, album and O.\nSentence: First , they played a series of concerts at the Glr Theatre in Ennis , County Clare ( on 23 & amp ; 24 January 2004 ) and at Vicar Street in Dublin ( on 30 & amp ; 31 January and on 4 & amp ; 5 , 11 & amp ; 12 February 2004 ) , which were recorded and from which selected material was released on the CD Live 2004 and its associated DVD .","prompt_labels":"First(O) ,(O) they(O) played(O) a(O) series(O) of(O) concerts(O) at(O) the(O) Glr(B-location) Theatre(I-location) in(O) Ennis(B-location) ,(O) County(B-location) Clare(B-location) ((O) on(O) 23(O) &(O) amp(O) ;(O) 24(O) January(O) 2004(O) )(O) and(O) at(O) Vicar(B-location) Street(I-location) in(O) Dublin(B-location) ((O) on(O) 30(O) &(O) amp(O) ;(O) 31(O) January(O) and(O) on(O) 4(O) &(O) amp(O) ;(O) 5(O) ,(O) 11(O) &(O) amp(O) ;(O) 12(O) February(O) 2004(O) )(O) ,(O) which(O) were(O) recorded(O) and(O) from(O) which(O) selected(O) material(O) was(O) released(O) on(O) the(O) CD(O) Live(B-album) 2004(I-album) and(O) its(O) associated(O) DVD(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["location","album","organization","country","musical instrument","musical artist","award","song","person","music genre","band","event"],"instance":{"id":"110","words":["Further","nominations","at","the","46th","Academy","Awards","included","Academy","Award","for","Best","Director","(","George","Lucas",")",",","Best","Original","Screenplay","(","Lucas",",","Willard","Huyck","and","Gloria","Katz",")",",","Academy","Award","for","Best","Supporting","Actress","(","Candy","Clark",")","and","Academy","Award","for","Best","Film","Editing","(","Verna","Fields","and","Marcia","Lucas",")","."],"labels":["O","O","O","O","B-award","I-award","I-award","O","B-award","I-award","I-award","I-award","I-award","O","B-person","I-person","O","O","B-award","I-award","I-award","O","B-person","O","B-person","I-person","O","B-person","I-person","O","O","B-award","I-award","I-award","I-award","I-award","I-award","O","B-person","I-person","O","O","B-award","I-award","I-award","I-award","I-award","I-award","O","B-person","I-person","O","B-person","I-person","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, album, organization, country, musical instrument, musical artist, award, song, person, music genre, band, event and O.\nSentence: Further nominations at the 46th Academy Awards included Academy Award for Best Director ( George Lucas ) , Best Original Screenplay ( Lucas , Willard Huyck and Gloria Katz ) , Academy Award for Best Supporting Actress ( Candy Clark ) and Academy Award for Best Film Editing ( Verna Fields and Marcia Lucas ) .","prompt_labels":"Further(O) nominations(O) at(O) the(O) 46th(B-award) Academy(I-award) Awards(I-award) included(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Director(I-award) ((O) George(B-person) Lucas(I-person) )(O) ,(O) Best(B-award) Original(I-award) Screenplay(I-award) ((O) Lucas(B-person) ,(O) Willard(B-person) Huyck(I-person) and(O) Gloria(B-person) Katz(I-person) )(O) ,(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Supporting(I-award) Actress(I-award) ((O) Candy(B-person) Clark(I-person) )(O) and(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Film(I-award) Editing(I-award) ((O) Verna(B-person) Fields(I-person) and(O) Marcia(B-person) Lucas(I-person) )(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["song","person","organization","location","band","musical instrument","album","music genre","event","award","country","musical artist"],"instance":{"id":"111","words":["British","genres","such","as","Lovers","rock",",","Ragga","jungle","and","grime","are","also","influenced","by","Jamaican","music","."],"labels":["O","O","O","O","B-music genre","I-music genre","O","B-music genre","I-music genre","O","B-music genre","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, person, organization, location, band, musical instrument, album, music genre, event, award, country, musical artist and O.\nSentence: British genres such as Lovers rock , Ragga jungle and grime are also influenced by Jamaican music .","prompt_labels":"British(O) genres(O) such(O) as(O) Lovers(B-music genre) rock(I-music genre) ,(O) Ragga(B-music genre) jungle(I-music genre) and(O) grime(B-music genre) are(O) also(O) influenced(O) by(O) Jamaican(O) music(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["country","music genre","band","location","album","award","musical artist","person","event","organization","song","musical instrument"],"instance":{"id":"112","words":["some","of","his","performances","will","finish","without","some","blues","and","Tejano","music","tunes","playing","as","well","as","Surf","music","instrumentals","."],"labels":["O","O","O","O","O","O","O","O","B-music genre","O","B-music genre","I-music genre","O","O","O","O","O","B-music genre","I-music genre","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, music genre, band, location, album, award, musical artist, person, event, organization, song, musical instrument and O.\nSentence: some of his performances will finish without some blues and Tejano music tunes playing as well as Surf music instrumentals .","prompt_labels":"some(O) of(O) his(O) performances(O) will(O) finish(O) without(O) some(O) blues(B-music genre) and(O) Tejano(B-music genre) music(I-music genre) tunes(O) playing(O) as(O) well(O) as(O) Surf(B-music genre) music(I-music genre) instrumentals(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["country","song","person","organization","music genre","musical instrument","band","location","award","event","musical artist","album"],"instance":{"id":"113","words":["They","have","won","two","Grammy","Award","s",",","six","American","Music","Awards",",","two","Billboard","Music","Award",",","four","MTV","Video","Music","Award","s",",","10","MTV","Europe","Music","Award","and","three","World","Music","Awards","."],"labels":["O","O","O","O","B-award","I-award","O","O","O","B-award","I-award","I-award","O","O","B-award","I-award","I-award","O","O","B-award","I-award","I-award","I-award","O","O","O","B-award","I-award","I-award","I-award","O","O","B-award","I-award","I-award","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, song, person, organization, music genre, musical instrument, band, location, award, event, musical artist, album and O.\nSentence: They have won two Grammy Award s , six American Music Awards , two Billboard Music Award , four MTV Video Music Award s , 10 MTV Europe Music Award and three World Music Awards .","prompt_labels":"They(O) have(O) won(O) two(O) Grammy(B-award) Award(I-award) s(O) ,(O) six(O) American(B-award) Music(I-award) Awards(I-award) ,(O) two(O) Billboard(B-award) Music(I-award) Award(I-award) ,(O) four(O) MTV(B-award) Video(I-award) Music(I-award) Award(I-award) s(O) ,(O) 10(O) MTV(B-award) Europe(I-award) Music(I-award) Award(I-award) and(O) three(O) World(B-award) Music(I-award) Awards(I-award) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["event","music genre","musical instrument","album","band","country","musical artist","organization","song","award","location","person"],"instance":{"id":"114","words":["With","the","continued","success","of","Backstreet","Boys","and","NSYNC",",","American","and","British","groups","like","98","Degrees",",","Westlife",",","O-Town",",","A1",",","Blue",",","and","Busted","gained","quick","popularity","both","domestically","and","internationally","."],"labels":["O","O","O","O","O","B-band","I-band","O","B-band","O","O","O","O","O","O","B-band","I-band","O","B-band","O","B-band","O","B-band","O","B-band","O","O","B-band","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, music genre, musical instrument, album, band, country, musical artist, organization, song, award, location, person and O.\nSentence: With the continued success of Backstreet Boys and NSYNC , American and British groups like 98 Degrees , Westlife , O-Town , A1 , Blue , and Busted gained quick popularity both domestically and internationally .","prompt_labels":"With(O) the(O) continued(O) success(O) of(O) Backstreet(B-band) Boys(I-band) and(O) NSYNC(B-band) ,(O) American(O) and(O) British(O) groups(O) like(O) 98(B-band) Degrees(I-band) ,(O) Westlife(B-band) ,(O) O-Town(B-band) ,(O) A1(B-band) ,(O) Blue(B-band) ,(O) and(O) Busted(B-band) gained(O) quick(O) popularity(O) both(O) domestically(O) and(O) internationally(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["location","person","musical artist","band","musical instrument","song","event","award","album","organization","country","music genre"],"instance":{"id":"115","words":["The","Coliseum","played","host","to","Figure","skating","at","the","2010","Winter","Olympics","and","Short","track","speed","skating","at","the","2010","Winter","Olympics","events","for","the","XXI","Olympic","Winter","Games","in","Vancouver",",","from","February","12","to","28",",","2010","."],"labels":["O","B-location","O","O","O","B-event","I-event","I-event","I-event","I-event","I-event","I-event","O","B-event","I-event","I-event","I-event","I-event","I-event","I-event","I-event","I-event","O","O","O","B-event","I-event","I-event","I-event","O","B-location","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, person, musical artist, band, musical instrument, song, event, award, album, organization, country, music genre and O.\nSentence: The Coliseum played host to Figure skating at the 2010 Winter Olympics and Short track speed skating at the 2010 Winter Olympics events for the XXI Olympic Winter Games in Vancouver , from February 12 to 28 , 2010 .","prompt_labels":"The(O) Coliseum(B-location) played(O) host(O) to(O) Figure(B-event) skating(I-event) at(I-event) the(I-event) 2010(I-event) Winter(I-event) Olympics(I-event) and(O) Short(B-event) track(I-event) speed(I-event) skating(I-event) at(I-event) the(I-event) 2010(I-event) Winter(I-event) Olympics(I-event) events(O) for(O) the(O) XXI(B-event) Olympic(I-event) Winter(I-event) Games(I-event) in(O) Vancouver(B-location) ,(O) from(O) February(O) 12(O) to(O) 28(O) ,(O) 2010(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["country","organization","album","song","person","musical instrument","event","award","band","music genre","location","musical artist"],"instance":{"id":"116","words":["I","Don","'t","Stand","a","Ghost","of","a","Chance","With","You","was","his","most","successful","composition",",","recorded","by","Duke","Ellington",",","Frank","Sinatra",",","Thelonious","Monk",",","Billie","Holiday",",","and","Mildred","Bailey",",","among","others","."],"labels":["B-song","I-song","I-song","I-song","I-song","I-song","I-song","I-song","I-song","I-song","I-song","O","O","O","O","O","O","O","O","B-musical artist","I-musical artist","O","B-musical artist","I-musical artist","O","B-musical artist","I-musical artist","O","B-musical artist","I-musical artist","O","O","B-musical artist","I-musical artist","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, organization, album, song, person, musical instrument, event, award, band, music genre, location, musical artist and O.\nSentence: I Don 't Stand a Ghost of a Chance With You was his most successful composition , recorded by Duke Ellington , Frank Sinatra , Thelonious Monk , Billie Holiday , and Mildred Bailey , among others .","prompt_labels":"I(B-song) Don(I-song) 't(I-song) Stand(I-song) a(I-song) Ghost(I-song) of(I-song) a(I-song) Chance(I-song) With(I-song) You(I-song) was(O) his(O) most(O) successful(O) composition(O) ,(O) recorded(O) by(O) Duke(B-musical artist) Ellington(I-musical artist) ,(O) Frank(B-musical artist) Sinatra(I-musical artist) ,(O) Thelonious(B-musical artist) Monk(I-musical artist) ,(O) Billie(B-musical artist) Holiday(I-musical artist) ,(O) and(O) Mildred(B-musical artist) Bailey(I-musical artist) ,(O) among(O) others(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["song","musical artist","location","album","music genre","band","musical instrument","person","event","organization","country","award"],"instance":{"id":"117","words":["Jones","supports","a","number","of","other","charities",",","including","the","NAACP",",","GLAAD",",","Peace","Games",",","AmfAR",",","and","the","Maybach","Foundation","."],"labels":["B-musical artist","O","O","O","O","O","O","O","O","O","B-organization","O","B-organization","O","B-organization","I-organization","O","B-organization","O","O","O","B-organization","I-organization","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, musical artist, location, album, music genre, band, musical instrument, person, event, organization, country, award and O.\nSentence: Jones supports a number of other charities , including the NAACP , GLAAD , Peace Games , AmfAR , and the Maybach Foundation .","prompt_labels":"Jones(B-musical artist) supports(O) a(O) number(O) of(O) other(O) charities(O) ,(O) including(O) the(O) NAACP(B-organization) ,(O) GLAAD(B-organization) ,(O) Peace(B-organization) Games(I-organization) ,(O) AmfAR(B-organization) ,(O) and(O) the(O) Maybach(B-organization) Foundation(I-organization) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["event","musical instrument","country","person","award","musical artist","band","album","location","music genre","song","organization"],"instance":{"id":"118","words":["Urban","male","performers","included","popular","black","musicians","of","the","era",",","such","as","Tampa","Red",",","Big","Bill","Broonzy","and","Leroy","Carr","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","B-musical artist","I-musical artist","O","B-musical artist","I-musical artist","I-musical artist","O","B-musical artist","I-musical artist","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, musical instrument, country, person, award, musical artist, band, album, location, music genre, song, organization and O.\nSentence: Urban male performers included popular black musicians of the era , such as Tampa Red , Big Bill Broonzy and Leroy Carr .","prompt_labels":"Urban(O) male(O) performers(O) included(O) popular(O) black(O) musicians(O) of(O) the(O) era(O) ,(O) such(O) as(O) Tampa(B-musical artist) Red(I-musical artist) ,(O) Big(B-musical artist) Bill(I-musical artist) Broonzy(I-musical artist) and(O) Leroy(B-musical artist) Carr(I-musical artist) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["music genre","award","musical instrument","album","organization","band","song","musical artist","location","person","country","event"],"instance":{"id":"119","words":["The","group","had","since","released","seven","more","albums",":","Paul","'s","Boutique","(","1989",")",",","Check","Your","Head","(","1992",")",",","Ill","Communication","(","1994",")",",","Hello","Nasty","(","1998",")",",","To","the","5","Boroughs","(","2004",")",",","The","Mix-Up","(","2007",")",",","and","Hot","Sauce","Committee","Part","Two","(","2011",")","."],"labels":["O","O","O","O","O","O","O","O","O","B-album","I-album","I-album","O","O","O","O","B-album","I-album","I-album","O","O","O","O","B-album","I-album","O","O","O","O","B-album","I-album","O","O","O","O","B-album","I-album","I-album","I-album","O","O","O","O","B-album","I-album","O","O","O","O","O","B-album","I-album","I-album","I-album","I-album","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: music genre, award, musical instrument, album, organization, band, song, musical artist, location, person, country, event and O.\nSentence: The group had since released seven more albums : Paul 's Boutique ( 1989 ) , Check Your Head ( 1992 ) , Ill Communication ( 1994 ) , Hello Nasty ( 1998 ) , To the 5 Boroughs ( 2004 ) , The Mix-Up ( 2007 ) , and Hot Sauce Committee Part Two ( 2011 ) .","prompt_labels":"The(O) group(O) had(O) since(O) released(O) seven(O) more(O) albums(O) :(O) Paul(B-album) 's(I-album) Boutique(I-album) ((O) 1989(O) )(O) ,(O) Check(B-album) Your(I-album) Head(I-album) ((O) 1992(O) )(O) ,(O) Ill(B-album) Communication(I-album) ((O) 1994(O) )(O) ,(O) Hello(B-album) Nasty(I-album) ((O) 1998(O) )(O) ,(O) To(B-album) the(I-album) 5(I-album) Boroughs(I-album) ((O) 2004(O) )(O) ,(O) The(B-album) Mix-Up(I-album) ((O) 2007(O) )(O) ,(O) and(O) Hot(B-album) Sauce(I-album) Committee(I-album) Part(I-album) Two(I-album) ((O) 2011(O) )(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["event","country","person","award","music genre","band","location","musical instrument","musical artist","organization","song","album"],"instance":{"id":"120","words":["Spears","has","earned","numerous","awards","and","accolades",",","including","a","Grammy","Award",";","seven","Guinness","World","Records",";","six","MTV","Video","Music","Awards",",","including","the","Michael","Jackson","Video","Vanguard","Award",";","seven","Billboard","Music","Awards",",","including","the","Millennium","Award",";","the","inaugural","Radio","Disney","Icon","Award",";","the","GLAAD","Media","Award","'","s","Vanguard","Award","and","a","star","on","the","Hollywood","Walk","of","Fame","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-award","I-award","O","O","B-award","I-award","I-award","O","O","B-award","I-award","I-award","I-award","O","O","O","B-award","I-award","I-award","I-award","I-award","O","O","B-award","I-award","I-award","O","O","O","B-award","I-award","O","O","B-award","I-award","I-award","I-award","I-award","O","O","B-award","I-award","I-award","O","O","B-award","I-award","O","O","O","O","O","B-location","I-location","I-location","I-location","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, country, person, award, music genre, band, location, musical instrument, musical artist, organization, song, album and O.\nSentence: Spears has earned numerous awards and accolades , including a Grammy Award ; seven Guinness World Records ; six MTV Video Music Awards , including the Michael Jackson Video Vanguard Award ; seven Billboard Music Awards , including the Millennium Award ; the inaugural Radio Disney Icon Award ; the GLAAD Media Award ' s Vanguard Award and a star on the Hollywood Walk of Fame .","prompt_labels":"Spears(O) has(O) earned(O) numerous(O) awards(O) and(O) accolades(O) ,(O) including(O) a(O) Grammy(B-award) Award(I-award) ;(O) seven(O) Guinness(B-award) World(I-award) Records(I-award) ;(O) six(O) MTV(B-award) Video(I-award) Music(I-award) Awards(I-award) ,(O) including(O) the(O) Michael(B-award) Jackson(I-award) Video(I-award) Vanguard(I-award) Award(I-award) ;(O) seven(O) Billboard(B-award) Music(I-award) Awards(I-award) ,(O) including(O) the(O) Millennium(B-award) Award(I-award) ;(O) the(O) inaugural(B-award) Radio(I-award) Disney(I-award) Icon(I-award) Award(I-award) ;(O) the(O) GLAAD(B-award) Media(I-award) Award(I-award) '(O) s(O) Vanguard(B-award) Award(I-award) and(O) a(O) star(O) on(O) the(O) Hollywood(B-location) Walk(I-location) of(I-location) Fame(I-location) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["musical artist","location","event","organization","award","music genre","song","album","band","country","person","musical instrument"],"instance":{"id":"121","words":["The","venue","was","the","site","of","several","Commonwealth","Games","sports","in","1978","Commonwealth","Games",",","and","part","of","Universiade","(","the","World","University","Games",")","in","1983","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","B-event","I-event","I-event","O","O","O","O","B-event","O","O","B-event","I-event","I-event","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: musical artist, location, event, organization, award, music genre, song, album, band, country, person, musical instrument and O.\nSentence: The venue was the site of several Commonwealth Games sports in 1978 Commonwealth Games , and part of Universiade ( the World University Games ) in 1983 .","prompt_labels":"The(O) venue(O) was(O) the(O) site(O) of(O) several(O) Commonwealth(O) Games(O) sports(O) in(O) 1978(B-event) Commonwealth(I-event) Games(I-event) ,(O) and(O) part(O) of(O) Universiade(B-event) ((O) the(O) World(B-event) University(I-event) Games(I-event) )(O) in(O) 1983(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["musical instrument","event","music genre","band","organization","person","country","location","album","musical artist","song","award"],"instance":{"id":"122","words":["Kraftwerk","'s","musical","style","and","image","can","be","heard","and","seen","in","1980s","synthpop","groups","such","as","Gary","Numan",",","Ultravox",",","John","Foxx",",","Orchestral","Manoeuvres","in","the","Dark",",","Human","League",",","Depeche","Mode",",","Visage",",","and","Soft","Cell","."],"labels":["B-musical artist","O","O","O","O","O","O","O","O","O","O","O","O","B-music genre","O","O","O","B-musical artist","I-musical artist","O","B-band","O","B-musical artist","I-musical artist","O","B-band","I-band","I-band","I-band","I-band","O","B-band","I-band","O","B-band","I-band","O","B-band","O","O","B-band","I-band","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: musical instrument, event, music genre, band, organization, person, country, location, album, musical artist, song, award and O.\nSentence: Kraftwerk 's musical style and image can be heard and seen in 1980s synthpop groups such as Gary Numan , Ultravox , John Foxx , Orchestral Manoeuvres in the Dark , Human League , Depeche Mode , Visage , and Soft Cell .","prompt_labels":"Kraftwerk(B-musical artist) 's(O) musical(O) style(O) and(O) image(O) can(O) be(O) heard(O) and(O) seen(O) in(O) 1980s(O) synthpop(B-music genre) groups(O) such(O) as(O) Gary(B-musical artist) Numan(I-musical artist) ,(O) Ultravox(B-band) ,(O) John(B-musical artist) Foxx(I-musical artist) ,(O) Orchestral(B-band) Manoeuvres(I-band) in(I-band) the(I-band) Dark(I-band) ,(O) Human(B-band) League(I-band) ,(O) Depeche(B-band) Mode(I-band) ,(O) Visage(B-band) ,(O) and(O) Soft(B-band) Cell(I-band) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["location","organization","country","music genre","song","musical artist","album","event","person","musical instrument","award","band"],"instance":{"id":"123","words":["Styles","like","Rock","music",",","Heavy","metal","music",",","Pop","rock",",","Folk","rock",",","Neo-Romantic",",","Pop","and","some","experimental","styles","(","e.g.","Cantorock",")","were","introduced","."],"labels":["O","O","B-music genre","I-music genre","O","B-music genre","I-music genre","I-music genre","O","B-music genre","I-music genre","O","B-music genre","I-music genre","O","B-music genre","O","B-music genre","O","O","O","O","O","O","B-music genre","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, organization, country, music genre, song, musical artist, album, event, person, musical instrument, award, band and O.\nSentence: Styles like Rock music , Heavy metal music , Pop rock , Folk rock , Neo-Romantic , Pop and some experimental styles ( e.g. Cantorock ) were introduced .","prompt_labels":"Styles(O) like(O) Rock(B-music genre) music(I-music genre) ,(O) Heavy(B-music genre) metal(I-music genre) music(I-music genre) ,(O) Pop(B-music genre) rock(I-music genre) ,(O) Folk(B-music genre) rock(I-music genre) ,(O) Neo-Romantic(B-music genre) ,(O) Pop(B-music genre) and(O) some(O) experimental(O) styles(O) ((O) e.g.(O) Cantorock(B-music genre) )(O) were(O) introduced(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["musical artist","event","location","award","album","song","music genre","organization","musical instrument","band","country","person"],"instance":{"id":"124","words":["High-pitched","screaming","is","occasionally","utilized","in","death","metal",",","being","heard","in","songs","by","Death",",","Aborted",",","Exhumed",",","Dying","Fetus",",","Cannibal","Corpse",",","and","Deicide","."],"labels":["O","O","O","O","O","O","B-music genre","I-music genre","O","O","O","O","O","O","B-band","O","B-band","O","B-band","O","B-band","I-band","O","B-band","I-band","O","O","B-band","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: musical artist, event, location, award, album, song, music genre, organization, musical instrument, band, country, person and O.\nSentence: High-pitched screaming is occasionally utilized in death metal , being heard in songs by Death , Aborted , Exhumed , Dying Fetus , Cannibal Corpse , and Deicide .","prompt_labels":"High-pitched(O) screaming(O) is(O) occasionally(O) utilized(O) in(O) death(B-music genre) metal(I-music genre) ,(O) being(O) heard(O) in(O) songs(O) by(O) Death(B-band) ,(O) Aborted(B-band) ,(O) Exhumed(B-band) ,(O) Dying(B-band) Fetus(I-band) ,(O) Cannibal(B-band) Corpse(I-band) ,(O) and(O) Deicide(B-band) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["album","song","award","musical instrument","organization","musical artist","location","band","music genre","country","event","person"],"instance":{"id":"125","words":["Rodgers","was","the","first","person","to","win","what","is","considered","the","top","American","entertainment","awards","in","television",",","recording",",","movies",",","and","Broadway","-","an","Emmy","Award",",","a","Grammy","Award",",","an","Academy","Awards",",","and","a","Tony","Award","-","now","known","collectively","as","an","EGOT","."],"labels":["B-musical artist","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-organization","O","O","B-award","I-award","O","O","B-award","I-award","O","O","B-award","I-award","O","O","O","B-award","I-award","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: album, song, award, musical instrument, organization, musical artist, location, band, music genre, country, event, person and O.\nSentence: Rodgers was the first person to win what is considered the top American entertainment awards in television , recording , movies , and Broadway - an Emmy Award , a Grammy Award , an Academy Awards , and a Tony Award - now known collectively as an EGOT .","prompt_labels":"Rodgers(B-musical artist) was(O) the(O) first(O) person(O) to(O) win(O) what(O) is(O) considered(O) the(O) top(O) American(O) entertainment(O) awards(O) in(O) television(O) ,(O) recording(O) ,(O) movies(O) ,(O) and(O) Broadway(B-organization) -(O) an(O) Emmy(B-award) Award(I-award) ,(O) a(O) Grammy(B-award) Award(I-award) ,(O) an(O) Academy(B-award) Awards(I-award) ,(O) and(O) a(O) Tony(B-award) Award(I-award) -(O) now(O) known(O) collectively(O) as(O) an(O) EGOT(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["event","award","location","country","album","music genre","organization","musical instrument","band","song","person","musical artist"],"instance":{"id":"126","words":["During","his","musical","career",",","Tankian","has","released","five","albums","with","System","of","a","Down",",","one","with","Arto","Tunboyacyan","(","Serart",")",",","as","well","as","the","five","solo","albums","Elect","the","Dead",",","Imperfect","Harmonies",",","Harakiri",",","Orca","Symphony","No.","1",",","and","Jazz-Iz-Christ","."],"labels":["O","O","O","O","O","B-musical artist","O","O","O","O","O","B-band","I-band","I-band","I-band","O","O","O","B-musical artist","I-musical artist","O","B-album","O","O","O","O","O","O","O","O","O","B-album","I-album","I-album","O","B-album","I-album","O","B-album","O","B-album","I-album","I-album","I-album","O","O","B-album","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, award, location, country, album, music genre, organization, musical instrument, band, song, person, musical artist and O.\nSentence: During his musical career , Tankian has released five albums with System of a Down , one with Arto Tunboyacyan ( Serart ) , as well as the five solo albums Elect the Dead , Imperfect Harmonies , Harakiri , Orca Symphony No. 1 , and Jazz-Iz-Christ .","prompt_labels":"During(O) his(O) musical(O) career(O) ,(O) Tankian(B-musical artist) has(O) released(O) five(O) albums(O) with(O) System(B-band) of(I-band) a(I-band) Down(I-band) ,(O) one(O) with(O) Arto(B-musical artist) Tunboyacyan(I-musical artist) ((O) Serart(B-album) )(O) ,(O) as(O) well(O) as(O) the(O) five(O) solo(O) albums(O) Elect(B-album) the(I-album) Dead(I-album) ,(O) Imperfect(B-album) Harmonies(I-album) ,(O) Harakiri(B-album) ,(O) Orca(B-album) Symphony(I-album) No.(I-album) 1(I-album) ,(O) and(O) Jazz-Iz-Christ(B-album) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["music genre","country","organization","album","person","award","musical instrument","band","musical artist","location","song","event"],"instance":{"id":"127","words":["This","period","on","the","RCA","label","(","1971-75",")","produced","Muswell","Hillbillies",",","Everybody","'s","in","Show-Biz",",","Preservation","Act","1","and","Preservation","Act","2",",","Soap","Opera","and","Schoolboys","in","Disgrace","."],"labels":["O","O","O","O","B-organization","I-organization","O","O","O","O","B-album","I-album","O","B-album","I-album","I-album","I-album","O","B-album","I-album","I-album","O","B-album","I-album","I-album","O","B-album","I-album","O","B-album","I-album","I-album","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: music genre, country, organization, album, person, award, musical instrument, band, musical artist, location, song, event and O.\nSentence: This period on the RCA label ( 1971-75 ) produced Muswell Hillbillies , Everybody 's in Show-Biz , Preservation Act 1 and Preservation Act 2 , Soap Opera and Schoolboys in Disgrace .","prompt_labels":"This(O) period(O) on(O) the(O) RCA(B-organization) label(I-organization) ((O) 1971-75(O) )(O) produced(O) Muswell(B-album) Hillbillies(I-album) ,(O) Everybody(B-album) 's(I-album) in(I-album) Show-Biz(I-album) ,(O) Preservation(B-album) Act(I-album) 1(I-album) and(O) Preservation(B-album) Act(I-album) 2(I-album) ,(O) Soap(B-album) Opera(I-album) and(O) Schoolboys(B-album) in(I-album) Disgrace(I-album) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["song","band","organization","location","musical instrument","person","event","music genre","musical artist","album","award","country"],"instance":{"id":"128","words":["They","restarted","to","perform","live","regularly",",","touring","the","world","with","rapturous","feedbacks",":","they","brought","their","distinguishable","sound","in","great","venues","such","as","the","Kings","Place","in","London",",","the","Soma","Festival","in","Belfast",",","the","Bolshoi","Theatre","in","Moscow","and","the","Star","Pine","'s","cafe","in","Tokyo","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-location","I-location","O","B-location","O","O","B-event","I-event","O","B-location","O","O","B-location","I-location","O","B-location","O","O","B-location","I-location","I-location","I-location","O","B-location","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, band, organization, location, musical instrument, person, event, music genre, musical artist, album, award, country and O.\nSentence: They restarted to perform live regularly , touring the world with rapturous feedbacks : they brought their distinguishable sound in great venues such as the Kings Place in London , the Soma Festival in Belfast , the Bolshoi Theatre in Moscow and the Star Pine 's cafe in Tokyo .","prompt_labels":"They(O) restarted(O) to(O) perform(O) live(O) regularly(O) ,(O) touring(O) the(O) world(O) with(O) rapturous(O) feedbacks(O) :(O) they(O) brought(O) their(O) distinguishable(O) sound(O) in(O) great(O) venues(O) such(O) as(O) the(O) Kings(B-location) Place(I-location) in(O) London(B-location) ,(O) the(O) Soma(B-event) Festival(I-event) in(O) Belfast(B-location) ,(O) the(O) Bolshoi(B-location) Theatre(I-location) in(O) Moscow(B-location) and(O) the(O) Star(B-location) Pine(I-location) 's(I-location) cafe(I-location) in(O) Tokyo(B-location) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["musical instrument","album","award","musical artist","event","person","music genre","song","organization","location","country","band"],"instance":{"id":"129","words":["The","Hall","is","flanked","by","The","Royal","Lyceum","Theatre","on","the","right","and","The","Traverse","Theatre","on","the","left","."],"labels":["O","O","O","O","O","O","B-location","I-location","I-location","O","O","O","O","O","B-location","I-location","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: musical instrument, album, award, musical artist, event, person, music genre, song, organization, location, country, band and O.\nSentence: The Hall is flanked by The Royal Lyceum Theatre on the right and The Traverse Theatre on the left .","prompt_labels":"The(O) Hall(O) is(O) flanked(O) by(O) The(O) Royal(B-location) Lyceum(I-location) Theatre(I-location) on(O) the(O) right(O) and(O) The(O) Traverse(B-location) Theatre(I-location) on(O) the(O) left(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["award","location","country","musical artist","band","album","event","musical instrument","song","person","music genre","organization"],"instance":{"id":"130","words":["Following","the","number-one","success","of","MARRS","'","Pump","Up","The","Volume","in","October",",","in","1987","to","1989",",","UK","acts","such","as","The","Beatmasters",",","Krush",",","Coldcut",",","Yazz",",","Bomb","The","Bass",",","S-Express",",","and","Italy","'s","Black","Box","opened","the","doors","to","house","music","success","on","the","UK","charts","."],"labels":["O","O","O","O","O","B-band","O","B-song","I-song","I-song","I-song","O","O","O","O","O","O","O","O","B-country","O","O","O","B-band","I-band","O","B-band","O","B-band","O","B-band","O","B-band","I-band","I-band","O","B-band","O","O","B-country","O","B-band","I-band","O","O","O","O","B-music genre","I-music genre","O","O","O","B-country","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, location, country, musical artist, band, album, event, musical instrument, song, person, music genre, organization and O.\nSentence: Following the number-one success of MARRS ' Pump Up The Volume in October , in 1987 to 1989 , UK acts such as The Beatmasters , Krush , Coldcut , Yazz , Bomb The Bass , S-Express , and Italy 's Black Box opened the doors to house music success on the UK charts .","prompt_labels":"Following(O) the(O) number-one(O) success(O) of(O) MARRS(B-band) '(O) Pump(B-song) Up(I-song) The(I-song) Volume(I-song) in(O) October(O) ,(O) in(O) 1987(O) to(O) 1989(O) ,(O) UK(B-country) acts(O) such(O) as(O) The(B-band) Beatmasters(I-band) ,(O) Krush(B-band) ,(O) Coldcut(B-band) ,(O) Yazz(B-band) ,(O) Bomb(B-band) The(I-band) Bass(I-band) ,(O) S-Express(B-band) ,(O) and(O) Italy(B-country) 's(O) Black(B-band) Box(I-band) opened(O) the(O) doors(O) to(O) house(B-music genre) music(I-music genre) success(O) on(O) the(O) UK(B-country) charts(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["album","person","musical artist","country","band","award","location","song","organization","musical instrument","event","music genre"],"instance":{"id":"131","words":["Organised","by","the","European","Broadcasting","Union","(","EBU",")","and","host","broadcaster","Eesti","Televisioon","(","ETV",")",",","the","contest","was","held","at","the","Saku","Suurhall",",","with","the","final","on","25","May","2002","."],"labels":["O","O","O","B-organization","I-organization","I-organization","O","B-organization","O","O","O","O","B-organization","I-organization","O","B-organization","O","O","O","O","O","O","O","O","B-location","I-location","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: album, person, musical artist, country, band, award, location, song, organization, musical instrument, event, music genre and O.\nSentence: Organised by the European Broadcasting Union ( EBU ) and host broadcaster Eesti Televisioon ( ETV ) , the contest was held at the Saku Suurhall , with the final on 25 May 2002 .","prompt_labels":"Organised(O) by(O) the(O) European(B-organization) Broadcasting(I-organization) Union(I-organization) ((O) EBU(B-organization) )(O) and(O) host(O) broadcaster(O) Eesti(B-organization) Televisioon(I-organization) ((O) ETV(B-organization) )(O) ,(O) the(O) contest(O) was(O) held(O) at(O) the(O) Saku(B-location) Suurhall(I-location) ,(O) with(O) the(O) final(O) on(O) 25(O) May(O) 2002(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["location","musical instrument","person","country","award","song","event","band","organization","music genre","musical artist","album"],"instance":{"id":"132","words":["Since","Between","the","Buttons","(","1967",")",",","he","has","sung","lead","or","co-lead","on","at","least","one","track","(","see","list","below",")","of","every","Rolling","Stones","studio","album","except","Their","Satanic","Majesties","Request",",","Sticky","Fingers",",","It","'s","Only","Rock","'","n","Roll",",","and","Blue","&","Lonesome","."],"labels":["O","B-album","I-album","I-album","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-band","I-band","O","O","O","B-album","I-album","I-album","I-album","O","B-album","I-album","O","B-album","I-album","I-album","I-album","I-album","I-album","I-album","O","O","B-album","I-album","I-album","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, musical instrument, person, country, award, song, event, band, organization, music genre, musical artist, album and O.\nSentence: Since Between the Buttons ( 1967 ) , he has sung lead or co-lead on at least one track ( see list below ) of every Rolling Stones studio album except Their Satanic Majesties Request , Sticky Fingers , It 's Only Rock ' n Roll , and Blue & Lonesome .","prompt_labels":"Since(O) Between(B-album) the(I-album) Buttons(I-album) ((O) 1967(O) )(O) ,(O) he(O) has(O) sung(O) lead(O) or(O) co-lead(O) on(O) at(O) least(O) one(O) track(O) ((O) see(O) list(O) below(O) )(O) of(O) every(O) Rolling(B-band) Stones(I-band) studio(O) album(O) except(O) Their(B-album) Satanic(I-album) Majesties(I-album) Request(I-album) ,(O) Sticky(B-album) Fingers(I-album) ,(O) It(B-album) 's(I-album) Only(I-album) Rock(I-album) '(I-album) n(I-album) Roll(I-album) ,(O) and(O) Blue(B-album) &(I-album) Lonesome(I-album) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["organization","song","band","event","country","musical artist","music genre","location","person","album","musical instrument","award"],"instance":{"id":"133","words":["In","2006",",","the","Doha","Asian","Games","Organising","Committee","has","named","Gary","Valenciano","the","official","performer","of","the","2006","Asian","Games","'","theme","song",",","Side","By","Side","."],"labels":["O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","O","B-musical artist","I-musical artist","O","O","O","O","O","B-event","I-event","I-event","O","O","O","O","B-song","I-song","I-song","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, song, band, event, country, musical artist, music genre, location, person, album, musical instrument, award and O.\nSentence: In 2006 , the Doha Asian Games Organising Committee has named Gary Valenciano the official performer of the 2006 Asian Games ' theme song , Side By Side .","prompt_labels":"In(O) 2006(O) ,(O) the(O) Doha(B-organization) Asian(I-organization) Games(I-organization) Organising(I-organization) Committee(I-organization) has(O) named(O) Gary(B-musical artist) Valenciano(I-musical artist) the(O) official(O) performer(O) of(O) the(O) 2006(B-event) Asian(I-event) Games(I-event) '(O) theme(O) song(O) ,(O) Side(B-song) By(I-song) Side(I-song) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["location","music genre","event","person","organization","album","song","award","musical instrument","band","country","musical artist"],"instance":{"id":"134","words":["DC","Talk","(","stylized","as","dc","Talk",")","is","a","Christian","hip","hop","and","Christian","rock","trio","."],"labels":["B-band","I-band","O","O","O","B-band","I-band","O","O","O","B-music genre","I-music genre","I-music genre","O","B-music genre","I-music genre","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, music genre, event, person, organization, album, song, award, musical instrument, band, country, musical artist and O.\nSentence: DC Talk ( stylized as dc Talk ) is a Christian hip hop and Christian rock trio .","prompt_labels":"DC(B-band) Talk(I-band) ((O) stylized(O) as(O) dc(B-band) Talk(I-band) )(O) is(O) a(O) Christian(B-music genre) hip(I-music genre) hop(I-music genre) and(O) Christian(B-music genre) rock(I-music genre) trio(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["country","musical artist","location","song","event","person","music genre","musical instrument","organization","award","band","album"],"instance":{"id":"135","words":["Well-known","disco","artists","include","Donna","Summer",",","Gloria","Gaynor",",","the","Bee","Gees",",","Chic",",","KC","and","the","Sunshine","Band",",","Thelma","Houston",",","Sister","Sledge",",","The","Trammps",",","the","Village","People","and","Michael","Jackson","."],"labels":["O","B-music genre","O","O","B-musical artist","I-musical artist","O","B-musical artist","I-musical artist","O","O","B-band","I-band","O","B-band","O","B-band","I-band","I-band","I-band","I-band","O","B-musical artist","I-musical artist","O","B-band","I-band","O","B-band","I-band","O","O","B-band","I-band","O","B-person","I-person","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, musical artist, location, song, event, person, music genre, musical instrument, organization, award, band, album and O.\nSentence: Well-known disco artists include Donna Summer , Gloria Gaynor , the Bee Gees , Chic , KC and the Sunshine Band , Thelma Houston , Sister Sledge , The Trammps , the Village People and Michael Jackson .","prompt_labels":"Well-known(O) disco(B-music genre) artists(O) include(O) Donna(B-musical artist) Summer(I-musical artist) ,(O) Gloria(B-musical artist) Gaynor(I-musical artist) ,(O) the(O) Bee(B-band) Gees(I-band) ,(O) Chic(B-band) ,(O) KC(B-band) and(I-band) the(I-band) Sunshine(I-band) Band(I-band) ,(O) Thelma(B-musical artist) Houston(I-musical artist) ,(O) Sister(B-band) Sledge(I-band) ,(O) The(B-band) Trammps(I-band) ,(O) the(O) Village(B-band) People(I-band) and(O) Michael(B-person) Jackson(I-person) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["person","musical instrument","album","organization","location","country","music genre","event","song","band","musical artist","award"],"instance":{"id":"136","words":["Dalida","employed","various","musical","styles","ranging","from","Pop","music","and","easy","listening","to","disco","and","adult","contemporary",",","employing","even","Folk","music","and","Rock","music","."],"labels":["B-musical artist","O","O","O","O","O","O","B-music genre","I-music genre","O","B-music genre","I-music genre","O","B-music genre","O","B-music genre","I-music genre","O","O","O","B-music genre","I-music genre","O","B-music genre","I-music genre","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, musical instrument, album, organization, location, country, music genre, event, song, band, musical artist, award and O.\nSentence: Dalida employed various musical styles ranging from Pop music and easy listening to disco and adult contemporary , employing even Folk music and Rock music .","prompt_labels":"Dalida(B-musical artist) employed(O) various(O) musical(O) styles(O) ranging(O) from(O) Pop(B-music genre) music(I-music genre) and(O) easy(B-music genre) listening(I-music genre) to(O) disco(B-music genre) and(O) adult(B-music genre) contemporary(I-music genre) ,(O) employing(O) even(O) Folk(B-music genre) music(I-music genre) and(O) Rock(B-music genre) music(I-music genre) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["album","award","musical instrument","band","music genre","organization","musical artist","location","country","song","person","event"],"instance":{"id":"137","words":["Weir","is","on","the","board","of","directors","of","the","Rex","Foundation",",","the","Furthur","Foundation",",","and","HeadCount","..","He","is","also","on","the","honorary","board","of","directors","of","Little","Kids","Rock",",","a","non-profit","organization","that","provides","free","musical","instruments","and","instruction","to","children","in","under-served","public","schools","throughout","the","U.S","."],"labels":["B-musical artist","O","O","O","O","O","O","O","O","B-organization","I-organization","O","O","B-organization","I-organization","O","O","B-organization","O","O","O","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-country","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: album, award, musical instrument, band, music genre, organization, musical artist, location, country, song, person, event and O.\nSentence: Weir is on the board of directors of the Rex Foundation , the Furthur Foundation , and HeadCount .. He is also on the honorary board of directors of Little Kids Rock , a non-profit organization that provides free musical instruments and instruction to children in under-served public schools throughout the U.S .","prompt_labels":"Weir(B-musical artist) is(O) on(O) the(O) board(O) of(O) directors(O) of(O) the(O) Rex(B-organization) Foundation(I-organization) ,(O) the(O) Furthur(B-organization) Foundation(I-organization) ,(O) and(O) HeadCount(B-organization) ..(O) He(O) is(O) also(O) on(O) the(O) honorary(O) board(O) of(O) directors(O) of(O) Little(B-organization) Kids(I-organization) Rock(I-organization) ,(O) a(O) non-profit(O) organization(O) that(O) provides(O) free(O) musical(O) instruments(O) and(O) instruction(O) to(O) children(O) in(O) under-served(O) public(O) schools(O) throughout(O) the(O) U.S(B-country) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["country","person","location","musical instrument","song","musical artist","music genre","album","award","band","event","organization"],"instance":{"id":"138","words":["He","has","appeared","as","a","featured","artist","on","many","other","songs","and","albums",",","having","collaborated","with","artists","such","as","Janet","Jackson",",","Kool","Moe","Dee",",","The","Dope","Poet","Society",",","Run-D.M.C.",",","Ice","Cube",",","Boom","Boom","Satellites",",","Rage","Against","the","Machine",",","Anthrax",",","John","Mellencamp","and","many","others","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-musical artist","I-musical artist","O","B-musical artist","I-musical artist","I-musical artist","O","B-band","I-band","I-band","I-band","O","B-band","O","B-person","I-person","O","B-band","I-band","I-band","O","B-band","I-band","I-band","I-band","O","B-band","O","B-musical artist","I-musical artist","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, person, location, musical instrument, song, musical artist, music genre, album, award, band, event, organization and O.\nSentence: He has appeared as a featured artist on many other songs and albums , having collaborated with artists such as Janet Jackson , Kool Moe Dee , The Dope Poet Society , Run-D.M.C. , Ice Cube , Boom Boom Satellites , Rage Against the Machine , Anthrax , John Mellencamp and many others .","prompt_labels":"He(O) has(O) appeared(O) as(O) a(O) featured(O) artist(O) on(O) many(O) other(O) songs(O) and(O) albums(O) ,(O) having(O) collaborated(O) with(O) artists(O) such(O) as(O) Janet(B-musical artist) Jackson(I-musical artist) ,(O) Kool(B-musical artist) Moe(I-musical artist) Dee(I-musical artist) ,(O) The(B-band) Dope(I-band) Poet(I-band) Society(I-band) ,(O) Run-D.M.C.(B-band) ,(O) Ice(B-person) Cube(I-person) ,(O) Boom(B-band) Boom(I-band) Satellites(I-band) ,(O) Rage(B-band) Against(I-band) the(I-band) Machine(I-band) ,(O) Anthrax(B-band) ,(O) John(B-musical artist) Mellencamp(I-musical artist) and(O) many(O) others(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["location","organization","musical instrument","award","album","band","song","event","musical artist","country","music genre","person"],"instance":{"id":"139","words":["For","the","majority","of","its","existence",",","the","group","was","composed","of","Mike","D","(","vocals",",","drums",")",",","Adam","Yauch","(","vocals",",","bass",")","and","Ad-Rock","(","vocals",",","guitar",",","programming",")","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","B-musical artist","I-musical artist","O","O","O","B-musical instrument","O","O","B-musical artist","I-musical artist","O","O","O","B-musical instrument","O","O","B-musical artist","O","O","O","B-musical instrument","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, organization, musical instrument, award, album, band, song, event, musical artist, country, music genre, person and O.\nSentence: For the majority of its existence , the group was composed of Mike D ( vocals , drums ) , Adam Yauch ( vocals , bass ) and Ad-Rock ( vocals , guitar , programming ) .","prompt_labels":"For(O) the(O) majority(O) of(O) its(O) existence(O) ,(O) the(O) group(O) was(O) composed(O) of(O) Mike(B-musical artist) D(I-musical artist) ((O) vocals(O) ,(O) drums(B-musical instrument) )(O) ,(O) Adam(B-musical artist) Yauch(I-musical artist) ((O) vocals(O) ,(O) bass(B-musical instrument) )(O) and(O) Ad-Rock(B-musical artist) ((O) vocals(O) ,(O) guitar(B-musical instrument) ,(O) programming(O) )(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["award","song","album","organization","band","person","music genre","country","musical instrument","location","musical artist","event"],"instance":{"id":"140","words":["Black","metal","album","covers","are","typically","dark","and","tend","to","be","atmospheric","or","provocative",";","some","feature","natural","or","fantasy","landscapes","(","for","example","Burzum","'","s","Filosofem","and","Emperor","'s","In","the","Nightside","Eclipse",")","while","others","are","violent",",","sexually","transgressive",",","sacrilegious",",","or","iconoclastic","(","for","example","Marduk","'","s","Fuck","Me","Jesus","and","Dimmu","Borgir","'","s","In","Sorte","Diaboli",")","."],"labels":["B-music genre","I-music genre","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-band","O","O","B-album","O","B-band","O","B-album","I-album","I-album","I-album","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-band","O","O","B-album","I-album","I-album","O","B-band","I-band","O","O","B-album","I-album","I-album","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, song, album, organization, band, person, music genre, country, musical instrument, location, musical artist, event and O.\nSentence: Black metal album covers are typically dark and tend to be atmospheric or provocative ; some feature natural or fantasy landscapes ( for example Burzum ' s Filosofem and Emperor 's In the Nightside Eclipse ) while others are violent , sexually transgressive , sacrilegious , or iconoclastic ( for example Marduk ' s Fuck Me Jesus and Dimmu Borgir ' s In Sorte Diaboli ) .","prompt_labels":"Black(B-music genre) metal(I-music genre) album(O) covers(O) are(O) typically(O) dark(O) and(O) tend(O) to(O) be(O) atmospheric(O) or(O) provocative(O) ;(O) some(O) feature(O) natural(O) or(O) fantasy(O) landscapes(O) ((O) for(O) example(O) Burzum(B-band) '(O) s(O) Filosofem(B-album) and(O) Emperor(B-band) 's(O) In(B-album) the(I-album) Nightside(I-album) Eclipse(I-album) )(O) while(O) others(O) are(O) violent(O) ,(O) sexually(O) transgressive(O) ,(O) sacrilegious(O) ,(O) or(O) iconoclastic(O) ((O) for(O) example(O) Marduk(B-band) '(O) s(O) Fuck(B-album) Me(I-album) Jesus(I-album) and(O) Dimmu(B-band) Borgir(I-band) '(O) s(O) In(B-album) Sorte(I-album) Diaboli(I-album) )(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["location","musical instrument","organization","award","musical artist","event","song","album","person","music genre","country","band"],"instance":{"id":"141","words":["Parliament-Funkadelic","'s","musical","influence","can","also","be","heard","in","rhythm","and","blues",",","Soul","music",",","electronica",",","Gospel","music",",","jazz",",","and","New","wave","music","."],"labels":["B-band","O","O","O","O","O","O","O","O","B-music genre","I-music genre","I-music genre","O","B-music genre","I-music genre","O","B-music genre","O","B-music genre","I-music genre","O","B-music genre","O","O","B-music genre","I-music genre","I-music genre","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, musical instrument, organization, award, musical artist, event, song, album, person, music genre, country, band and O.\nSentence: Parliament-Funkadelic 's musical influence can also be heard in rhythm and blues , Soul music , electronica , Gospel music , jazz , and New wave music .","prompt_labels":"Parliament-Funkadelic(B-band) 's(O) musical(O) influence(O) can(O) also(O) be(O) heard(O) in(O) rhythm(B-music genre) and(I-music genre) blues(I-music genre) ,(O) Soul(B-music genre) music(I-music genre) ,(O) electronica(B-music genre) ,(O) Gospel(B-music genre) music(I-music genre) ,(O) jazz(B-music genre) ,(O) and(O) New(B-music genre) wave(I-music genre) music(I-music genre) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["musical artist","location","country","award","song","organization","band","event","musical instrument","album","music genre","person"],"instance":{"id":"142","words":["The","set","includes","the","first","round","of","the","remastered","series","plus","the","long-awaited","remastered","versions","of","On","Your","Feet","or","on","Your","Knees","(","1975",")",",","Mirrors",",","Cultsaurus","Erectus",",","Fire","Of","Unknown","Origin",",","Extraterrestrial","Live",",","The","Revlution","by","Night",",","Club","Ninja","and","Imaginos","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-album","I-album","I-album","I-album","I-album","I-album","I-album","O","O","O","O","B-album","O","B-album","I-album","O","B-album","I-album","I-album","I-album","O","B-album","I-album","O","B-album","I-album","I-album","I-album","O","B-album","I-album","O","B-album","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: musical artist, location, country, award, song, organization, band, event, musical instrument, album, music genre, person and O.\nSentence: The set includes the first round of the remastered series plus the long-awaited remastered versions of On Your Feet or on Your Knees ( 1975 ) , Mirrors , Cultsaurus Erectus , Fire Of Unknown Origin , Extraterrestrial Live , The Revlution by Night , Club Ninja and Imaginos .","prompt_labels":"The(O) set(O) includes(O) the(O) first(O) round(O) of(O) the(O) remastered(O) series(O) plus(O) the(O) long-awaited(O) remastered(O) versions(O) of(O) On(B-album) Your(I-album) Feet(I-album) or(I-album) on(I-album) Your(I-album) Knees(I-album) ((O) 1975(O) )(O) ,(O) Mirrors(B-album) ,(O) Cultsaurus(B-album) Erectus(I-album) ,(O) Fire(B-album) Of(I-album) Unknown(I-album) Origin(I-album) ,(O) Extraterrestrial(B-album) Live(I-album) ,(O) The(B-album) Revlution(I-album) by(I-album) Night(I-album) ,(O) Club(B-album) Ninja(I-album) and(O) Imaginos(B-album) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["band","musical instrument","event","album","organization","song","musical artist","location","country","award","person","music genre"],"instance":{"id":"143","words":["In","1994",",","Yauch","and","activist","Erin","Potts","The","events","became","annual",",","and","shortly","after","went","international","with","acts","such","as","Live",",","Mike","Mills","and","Michael","Stipe","of","R.E.M.",",","Rage","Against","the","Machine",",","The","Smashing","Pumpkins",",","and","U2","."],"labels":["O","O","O","B-musical artist","O","O","B-musical artist","I-musical artist","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-band","O","B-musical artist","I-musical artist","O","B-musical artist","I-musical artist","O","B-band","O","B-band","I-band","I-band","I-band","O","B-band","I-band","I-band","O","O","B-band","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: band, musical instrument, event, album, organization, song, musical artist, location, country, award, person, music genre and O.\nSentence: In 1994 , Yauch and activist Erin Potts The events became annual , and shortly after went international with acts such as Live , Mike Mills and Michael Stipe of R.E.M. , Rage Against the Machine , The Smashing Pumpkins , and U2 .","prompt_labels":"In(O) 1994(O) ,(O) Yauch(B-musical artist) and(O) activist(O) Erin(B-musical artist) Potts(I-musical artist) The(O) events(O) became(O) annual(O) ,(O) and(O) shortly(O) after(O) went(O) international(O) with(O) acts(O) such(O) as(O) Live(B-band) ,(O) Mike(B-musical artist) Mills(I-musical artist) and(O) Michael(B-musical artist) Stipe(I-musical artist) of(O) R.E.M.(B-band) ,(O) Rage(B-band) Against(I-band) the(I-band) Machine(I-band) ,(O) The(B-band) Smashing(I-band) Pumpkins(I-band) ,(O) and(O) U2(B-band) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["band","music genre","musical artist","person","location","organization","album","award","country","event","song","musical instrument"],"instance":{"id":"144","words":["Dimmu","Borgir","'s","older","releases","(","since","1994","to","1999",")","are",",","according","to","Allmusic","journalist","Bradley","Torreano",",","strongly","influenced","by","Darkthrone",",","Mayhem",",","Bathory",",","Emperor",",","Celtic","Frost",",","Immortal",",","Venom",",","and","Iron","Maiden","."],"labels":["B-band","I-band","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-musical artist","I-musical artist","O","O","O","O","B-band","O","B-band","O","B-band","O","B-band","O","B-band","I-band","O","B-band","O","B-band","O","O","B-band","I-band","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: band, music genre, musical artist, person, location, organization, album, award, country, event, song, musical instrument and O.\nSentence: Dimmu Borgir 's older releases ( since 1994 to 1999 ) are , according to Allmusic journalist Bradley Torreano , strongly influenced by Darkthrone , Mayhem , Bathory , Emperor , Celtic Frost , Immortal , Venom , and Iron Maiden .","prompt_labels":"Dimmu(B-band) Borgir(I-band) 's(O) older(O) releases(O) ((O) since(O) 1994(O) to(O) 1999(O) )(O) are(O) ,(O) according(O) to(O) Allmusic(O) journalist(O) Bradley(B-musical artist) Torreano(I-musical artist) ,(O) strongly(O) influenced(O) by(O) Darkthrone(B-band) ,(O) Mayhem(B-band) ,(O) Bathory(B-band) ,(O) Emperor(B-band) ,(O) Celtic(B-band) Frost(I-band) ,(O) Immortal(B-band) ,(O) Venom(B-band) ,(O) and(O) Iron(B-band) Maiden(I-band) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["song","event","band","music genre","country","organization","musical artist","album","location","award","person","musical instrument"],"instance":{"id":"145","words":["UK","Christmas","hit","singles",";","Merry","Xmas","Everybody","by","Slade",",","I","Wish","It","Could","Be","Christmas","Everyday","by","Wizzard","and","Lonely","This","Christmas","by","Mud",",","all","of","which","have","remained","hugely","popular","..","14","December","2012","PRS","press","release","."],"labels":["B-country","B-event","O","O","O","B-song","I-song","I-song","O","B-band","O","B-song","I-song","I-song","I-song","I-song","I-song","I-song","O","B-band","O","B-song","I-song","I-song","O","B-band","O","O","O","O","O","O","O","O","O","O","O","O","B-organization","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, event, band, music genre, country, organization, musical artist, album, location, award, person, musical instrument and O.\nSentence: UK Christmas hit singles ; Merry Xmas Everybody by Slade , I Wish It Could Be Christmas Everyday by Wizzard and Lonely This Christmas by Mud , all of which have remained hugely popular .. 14 December 2012 PRS press release .","prompt_labels":"UK(B-country) Christmas(B-event) hit(O) singles(O) ;(O) Merry(B-song) Xmas(I-song) Everybody(I-song) by(O) Slade(B-band) ,(O) I(B-song) Wish(I-song) It(I-song) Could(I-song) Be(I-song) Christmas(I-song) Everyday(I-song) by(O) Wizzard(B-band) and(O) Lonely(B-song) This(I-song) Christmas(I-song) by(O) Mud(B-band) ,(O) all(O) of(O) which(O) have(O) remained(O) hugely(O) popular(O) ..(O) 14(O) December(O) 2012(O) PRS(B-organization) press(O) release(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["musical instrument","award","person","song","music genre","band","location","event","musical artist","organization","album","country"],"instance":{"id":"146","words":["Major","artists","who","have","been","influenced","by","Costello","include","Green","Day",",","Prince",",","Billy","Bragg",",","Goldfinger",",","the","Pogues",",","Radiohead",",","Dexys","Midnight","Runners",",","Pulp",",","Crowded","House",",","James",",","Suzanne","Vega",",","Less","than","Jake",",","and","Foo","Fighters","."],"labels":["O","O","O","O","O","O","O","B-musical artist","O","B-band","I-band","O","B-band","O","B-musical artist","I-musical artist","O","B-band","O","B-band","I-band","O","B-band","O","B-band","I-band","I-band","O","B-band","O","B-band","I-band","O","B-band","O","B-musical artist","I-musical artist","O","B-band","I-band","I-band","O","O","B-band","I-band","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: musical instrument, award, person, song, music genre, band, location, event, musical artist, organization, album, country and O.\nSentence: Major artists who have been influenced by Costello include Green Day , Prince , Billy Bragg , Goldfinger , the Pogues , Radiohead , Dexys Midnight Runners , Pulp , Crowded House , James , Suzanne Vega , Less than Jake , and Foo Fighters .","prompt_labels":"Major(O) artists(O) who(O) have(O) been(O) influenced(O) by(O) Costello(B-musical artist) include(O) Green(B-band) Day(I-band) ,(O) Prince(B-band) ,(O) Billy(B-musical artist) Bragg(I-musical artist) ,(O) Goldfinger(B-band) ,(O) the(B-band) Pogues(I-band) ,(O) Radiohead(B-band) ,(O) Dexys(B-band) Midnight(I-band) Runners(I-band) ,(O) Pulp(B-band) ,(O) Crowded(B-band) House(I-band) ,(O) James(B-band) ,(O) Suzanne(B-musical artist) Vega(I-musical artist) ,(O) Less(B-band) than(I-band) Jake(I-band) ,(O) and(O) Foo(B-band) Fighters(I-band) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["band","music genre","organization","song","musical instrument","musical artist","location","person","event","album","country","award"],"instance":{"id":"147","words":["Western","music",",","influenced","by","the","cowboy","ballads",",","New","Mexico","music",",","Texas","country","music","and","Tejano","music","rhythms","of","the","Southwestern","United","States","and","Northern","Mexico",",","reached","its","peak","in","popularity","in","the","late","1950s",",","most","notably","with","the","song","El","Paso",",","first","recorded","by","Marty","Robbins","in","September","1959","."],"labels":["B-music genre","I-music genre","O","O","O","O","O","O","O","B-music genre","I-music genre","I-music genre","O","B-music genre","I-music genre","I-music genre","O","B-music genre","I-music genre","O","O","O","B-location","I-location","I-location","O","B-location","I-location","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-song","I-song","O","O","O","O","B-musical artist","I-musical artist","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: band, music genre, organization, song, musical instrument, musical artist, location, person, event, album, country, award and O.\nSentence: Western music , influenced by the cowboy ballads , New Mexico music , Texas country music and Tejano music rhythms of the Southwestern United States and Northern Mexico , reached its peak in popularity in the late 1950s , most notably with the song El Paso , first recorded by Marty Robbins in September 1959 .","prompt_labels":"Western(B-music genre) music(I-music genre) ,(O) influenced(O) by(O) the(O) cowboy(O) ballads(O) ,(O) New(B-music genre) Mexico(I-music genre) music(I-music genre) ,(O) Texas(B-music genre) country(I-music genre) music(I-music genre) and(O) Tejano(B-music genre) music(I-music genre) rhythms(O) of(O) the(O) Southwestern(B-location) United(I-location) States(I-location) and(O) Northern(B-location) Mexico(I-location) ,(O) reached(O) its(O) peak(O) in(O) popularity(O) in(O) the(O) late(O) 1950s(O) ,(O) most(O) notably(O) with(O) the(O) song(O) El(B-song) Paso(I-song) ,(O) first(O) recorded(O) by(O) Marty(B-musical artist) Robbins(I-musical artist) in(O) September(O) 1959(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["song","location","band","musical instrument","country","musical artist","award","person","music genre","organization","album","event"],"instance":{"id":"148","words":["In","the","1990s",",","country","music","became","a","worldwide","phenomenon","thanks","to","Garth","Brooks",",","Other","artists","that","experienced","success","during","this","time","included","Clint","Black",",","Sammy","Kershaw",",","Aaron","Tippin",",","Travis","Tritt",",","Alan","Jackson","and","the","newly","formed","duo","of","Brooks","&","amp",";","Dunn",";","George","Strait",",","whose","career","began","in","the","1980s",",","also","continued","to","have","widespread","success","in","this","decade","and","beyond","."],"labels":["O","O","O","O","B-music genre","I-music genre","O","O","O","O","O","O","B-musical artist","I-musical artist","O","O","O","O","O","O","O","O","O","O","B-musical artist","I-musical artist","O","B-musical artist","I-musical artist","O","B-musical artist","I-musical artist","O","B-musical artist","I-musical artist","O","B-musical artist","I-musical artist","O","O","O","O","O","O","B-band","I-band","I-band","I-band","I-band","O","B-musical artist","I-musical artist","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, location, band, musical instrument, country, musical artist, award, person, music genre, organization, album, event and O.\nSentence: In the 1990s , country music became a worldwide phenomenon thanks to Garth Brooks , Other artists that experienced success during this time included Clint Black , Sammy Kershaw , Aaron Tippin , Travis Tritt , Alan Jackson and the newly formed duo of Brooks & amp ; Dunn ; George Strait , whose career began in the 1980s , also continued to have widespread success in this decade and beyond .","prompt_labels":"In(O) the(O) 1990s(O) ,(O) country(B-music genre) music(I-music genre) became(O) a(O) worldwide(O) phenomenon(O) thanks(O) to(O) Garth(B-musical artist) Brooks(I-musical artist) ,(O) Other(O) artists(O) that(O) experienced(O) success(O) during(O) this(O) time(O) included(O) Clint(B-musical artist) Black(I-musical artist) ,(O) Sammy(B-musical artist) Kershaw(I-musical artist) ,(O) Aaron(B-musical artist) Tippin(I-musical artist) ,(O) Travis(B-musical artist) Tritt(I-musical artist) ,(O) Alan(B-musical artist) Jackson(I-musical artist) and(O) the(O) newly(O) formed(O) duo(O) of(O) Brooks(B-band) &(I-band) amp(I-band) ;(I-band) Dunn(I-band) ;(O) George(B-musical artist) Strait(I-musical artist) ,(O) whose(O) career(O) began(O) in(O) the(O) 1980s(O) ,(O) also(O) continued(O) to(O) have(O) widespread(O) success(O) in(O) this(O) decade(O) and(O) beyond(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["organization","country","location","event","musical instrument","album","musical artist","song","music genre","award","band","person"],"instance":{"id":"149","words":["Sidney","Simien","(","April","9",",","1938","-","February","25",",","1998",")",",","known","as","Rockin","'","Sidney","and","Count","Rockin","'","Sidney",",","was","an","American","Rhythm","and","blues",",","zydeco",",","and","Soul","music","musician","who","began","recording","in","the","late","1950s","and","continued","performing","until","his","death","."],"labels":["B-musical artist","I-musical artist","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-musical artist","I-musical artist","I-musical artist","O","B-musical artist","I-musical artist","I-musical artist","I-musical artist","O","O","O","O","B-music genre","I-music genre","I-music genre","O","B-music genre","O","O","B-music genre","I-music genre","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, country, location, event, musical instrument, album, musical artist, song, music genre, award, band, person and O.\nSentence: Sidney Simien ( April 9 , 1938 - February 25 , 1998 ) , known as Rockin ' Sidney and Count Rockin ' Sidney , was an American Rhythm and blues , zydeco , and Soul music musician who began recording in the late 1950s and continued performing until his death .","prompt_labels":"Sidney(B-musical artist) Simien(I-musical artist) ((O) April(O) 9(O) ,(O) 1938(O) -(O) February(O) 25(O) ,(O) 1998(O) )(O) ,(O) known(O) as(O) Rockin(B-musical artist) '(I-musical artist) Sidney(I-musical artist) and(O) Count(B-musical artist) Rockin(I-musical artist) '(I-musical artist) Sidney(I-musical artist) ,(O) was(O) an(O) American(O) Rhythm(B-music genre) and(I-music genre) blues(I-music genre) ,(O) zydeco(B-music genre) ,(O) and(O) Soul(B-music genre) music(I-music genre) musician(O) who(O) began(O) recording(O) in(O) the(O) late(O) 1950s(O) and(O) continued(O) performing(O) until(O) his(O) death(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["musical instrument","person","musical artist","country","organization","music genre","award","event","song","location","album","band"],"instance":{"id":"150","words":["These","included","depictions","of","local","Civil","Defence","during","World","War","II","including","St.","John","Ambulance",",","the","British","Red","Cross","and","the","fire","services","along","with","air","raid","wardens",",","police","officers",",","the","Home","Guard","and","the","Royal","Voluntary","Service","."],"labels":["O","O","O","O","O","O","O","O","B-event","I-event","I-event","O","B-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-organization","I-organization","O","O","B-organization","I-organization","I-organization","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: musical instrument, person, musical artist, country, organization, music genre, award, event, song, location, album, band and O.\nSentence: These included depictions of local Civil Defence during World War II including St. John Ambulance , the British Red Cross and the fire services along with air raid wardens , police officers , the Home Guard and the Royal Voluntary Service .","prompt_labels":"These(O) included(O) depictions(O) of(O) local(O) Civil(O) Defence(O) during(O) World(B-event) War(I-event) II(I-event) including(O) St.(B-organization) John(I-organization) Ambulance(I-organization) ,(O) the(O) British(B-organization) Red(I-organization) Cross(I-organization) and(O) the(O) fire(O) services(O) along(O) with(O) air(O) raid(O) wardens(O) ,(O) police(O) officers(O) ,(O) the(O) Home(B-organization) Guard(I-organization) and(O) the(O) Royal(B-organization) Voluntary(I-organization) Service(I-organization) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["award","person","album","event","music genre","musical artist","location","musical instrument","band","country","song","organization"],"instance":{"id":"151","words":["Drawing","influences","from","hip","hop",",","dub",",","pop",",","Gorillaz","released","their","self-titled","debut","album","in","2001","to","worldwide","success",",","spawning","successful","follow-ups","Demon","Days","(","2005",")",",","Plastic","Beach",",","The","Fall","(","both","released","in","2010",")",",","Humanz","(","2017",")",",","and","The","Now","Now","(","2018",")","."],"labels":["O","O","O","B-music genre","I-music genre","O","B-music genre","O","B-music genre","O","B-band","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-album","I-album","O","O","O","O","B-album","I-album","O","B-album","I-album","O","O","O","O","O","O","O","B-album","O","O","O","O","O","B-album","I-album","I-album","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, person, album, event, music genre, musical artist, location, musical instrument, band, country, song, organization and O.\nSentence: Drawing influences from hip hop , dub , pop , Gorillaz released their self-titled debut album in 2001 to worldwide success , spawning successful follow-ups Demon Days ( 2005 ) , Plastic Beach , The Fall ( both released in 2010 ) , Humanz ( 2017 ) , and The Now Now ( 2018 ) .","prompt_labels":"Drawing(O) influences(O) from(O) hip(B-music genre) hop(I-music genre) ,(O) dub(B-music genre) ,(O) pop(B-music genre) ,(O) Gorillaz(B-band) released(O) their(O) self-titled(O) debut(O) album(O) in(O) 2001(O) to(O) worldwide(O) success(O) ,(O) spawning(O) successful(O) follow-ups(O) Demon(B-album) Days(I-album) ((O) 2005(O) )(O) ,(O) Plastic(B-album) Beach(I-album) ,(O) The(B-album) Fall(I-album) ((O) both(O) released(O) in(O) 2010(O) )(O) ,(O) Humanz(B-album) ((O) 2017(O) )(O) ,(O) and(O) The(B-album) Now(I-album) Now(I-album) ((O) 2018(O) )(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["person","event","music genre","musical artist","album","song","award","organization","country","band","location","musical instrument"],"instance":{"id":"152","words":["The","Academy","sought","to","promote","country","\/","western","music","in","the","western","states",";","this","was","in","contrast","to","the","Country","Music","Association",",","based","in","Nashville",",","Tennessee","(","then","the","center","of","the","pop-oriented","Nashville","sound",")","."],"labels":["O","O","O","O","O","B-music genre","I-music genre","I-music genre","I-music genre","O","O","O","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","O","O","O","B-location","O","B-location","O","O","O","O","O","O","O","B-music genre","I-music genre","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, event, music genre, musical artist, album, song, award, organization, country, band, location, musical instrument and O.\nSentence: The Academy sought to promote country \/ western music in the western states ; this was in contrast to the Country Music Association , based in Nashville , Tennessee ( then the center of the pop-oriented Nashville sound ) .","prompt_labels":"The(O) Academy(O) sought(O) to(O) promote(O) country(B-music genre) \/(I-music genre) western(I-music genre) music(I-music genre) in(O) the(O) western(O) states(O) ;(O) this(O) was(O) in(O) contrast(O) to(O) the(O) Country(B-organization) Music(I-organization) Association(I-organization) ,(O) based(O) in(O) Nashville(B-location) ,(O) Tennessee(B-location) ((O) then(O) the(O) center(O) of(O) the(O) pop-oriented(O) Nashville(B-music genre) sound(I-music genre) )(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["band","event","musical instrument","music genre","location","song","award","musical artist","album","organization","person","country"],"instance":{"id":"153","words":["Muggs","released","Soul","Assassins",":","Chapter","1","featuring","contributions","from","Dr.","Dre",",","KRS-One",",","Wyclef","Jean","and","Mobb","Deep","."],"labels":["B-musical artist","O","O","O","O","O","O","O","O","O","B-musical artist","I-musical artist","O","B-musical artist","O","B-musical artist","I-musical artist","O","B-band","I-band","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: band, event, musical instrument, music genre, location, song, award, musical artist, album, organization, person, country and O.\nSentence: Muggs released Soul Assassins : Chapter 1 featuring contributions from Dr. Dre , KRS-One , Wyclef Jean and Mobb Deep .","prompt_labels":"Muggs(B-musical artist) released(O) Soul(O) Assassins(O) :(O) Chapter(O) 1(O) featuring(O) contributions(O) from(O) Dr.(B-musical artist) Dre(I-musical artist) ,(O) KRS-One(B-musical artist) ,(O) Wyclef(B-musical artist) Jean(I-musical artist) and(O) Mobb(B-band) Deep(I-band) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["musical artist","person","country","award","song","musical instrument","band","event","music genre","album","organization","location"],"instance":{"id":"154","words":["In","recognition","of","her","film","career",",","she","received","BAFTA","'s","Lifetime","Achievement","Award",",","the","Golden","Globe","Cecil","B.","DeMille","Award",",","the","Screen","Actors","Guild","Life","Achievement","Award",",","and","the","Special","Tony","Award","."],"labels":["O","O","O","O","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","O","O","B-award","I-award","I-award","I-award","I-award","I-award","O","O","B-award","I-award","I-award","I-award","I-award","I-award","O","O","O","B-award","I-award","I-award","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: musical artist, person, country, award, song, musical instrument, band, event, music genre, album, organization, location and O.\nSentence: In recognition of her film career , she received BAFTA 's Lifetime Achievement Award , the Golden Globe Cecil B. DeMille Award , the Screen Actors Guild Life Achievement Award , and the Special Tony Award .","prompt_labels":"In(O) recognition(O) of(O) her(O) film(O) career(O) ,(O) she(O) received(O) BAFTA(B-award) 's(I-award) Lifetime(I-award) Achievement(I-award) Award(I-award) ,(O) the(O) Golden(B-award) Globe(I-award) Cecil(I-award) B.(I-award) DeMille(I-award) Award(I-award) ,(O) the(O) Screen(B-award) Actors(I-award) Guild(I-award) Life(I-award) Achievement(I-award) Award(I-award) ,(O) and(O) the(O) Special(B-award) Tony(I-award) Award(I-award) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["band","organization","country","location","person","music genre","album","musical artist","song","musical instrument","award","event"],"instance":{"id":"155","words":["It","also","produced","the","Top","5","single","Rage","Hard","(","#","1","in","Germany",")",",","Top","20","single","Warriors","of","the","Wasteland","and","Top","30","single","Watching","the","Wildlife","."],"labels":["O","O","O","O","O","O","O","B-song","I-song","O","O","O","O","B-country","O","O","O","O","O","B-song","I-song","I-song","I-song","O","O","O","O","B-song","I-song","I-song","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: band, organization, country, location, person, music genre, album, musical artist, song, musical instrument, award, event and O.\nSentence: It also produced the Top 5 single Rage Hard ( # 1 in Germany ) , Top 20 single Warriors of the Wasteland and Top 30 single Watching the Wildlife .","prompt_labels":"It(O) also(O) produced(O) the(O) Top(O) 5(O) single(O) Rage(B-song) Hard(I-song) ((O) #(O) 1(O) in(O) Germany(B-country) )(O) ,(O) Top(O) 20(O) single(O) Warriors(B-song) of(I-song) the(I-song) Wasteland(I-song) and(O) Top(O) 30(O) single(O) Watching(B-song) the(I-song) Wildlife(I-song) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["award","location","musical artist","band","organization","country","musical instrument","song","music genre","person","event","album"],"instance":{"id":"156","words":["His","best-known","songs","include","I","Ain","'t","Marching","Anymore",",","Changes",",","Crucifixion",",","Draft","Dodger","Rag",",","Love","Me",",","I","'m","a","Liberal",",","Outside","of","a","Small","Circle","of","Friends",",","Power","and","the","Glory",",","There","but","for","Fortune",",","and","The","War","Is","Over","."],"labels":["O","O","O","O","B-song","I-song","I-song","I-song","I-song","O","B-song","O","B-song","O","B-song","I-song","I-song","O","B-song","I-song","I-song","I-song","I-song","I-song","I-song","O","B-song","I-song","I-song","I-song","I-song","I-song","I-song","O","B-song","I-song","I-song","I-song","O","B-song","I-song","I-song","I-song","O","O","B-song","I-song","I-song","I-song","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, location, musical artist, band, organization, country, musical instrument, song, music genre, person, event, album and O.\nSentence: His best-known songs include I Ain 't Marching Anymore , Changes , Crucifixion , Draft Dodger Rag , Love Me , I 'm a Liberal , Outside of a Small Circle of Friends , Power and the Glory , There but for Fortune , and The War Is Over .","prompt_labels":"His(O) best-known(O) songs(O) include(O) I(B-song) Ain(I-song) 't(I-song) Marching(I-song) Anymore(I-song) ,(O) Changes(B-song) ,(O) Crucifixion(B-song) ,(O) Draft(B-song) Dodger(I-song) Rag(I-song) ,(O) Love(B-song) Me(I-song) ,(I-song) I(I-song) 'm(I-song) a(I-song) Liberal(I-song) ,(O) Outside(B-song) of(I-song) a(I-song) Small(I-song) Circle(I-song) of(I-song) Friends(I-song) ,(O) Power(B-song) and(I-song) the(I-song) Glory(I-song) ,(O) There(B-song) but(I-song) for(I-song) Fortune(I-song) ,(O) and(O) The(B-song) War(I-song) Is(I-song) Over(I-song) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["musical artist","person","musical instrument","music genre","organization","event","award","album","country","band","location","song"],"instance":{"id":"157","words":["In","the","2010s",",","the","alt-country","genre","saw","an","increase","in","its","critical","and","commercial","popularity",",","owing","to","the","success","of","artists","such","as","The","Civil","Wars",",","Chris","Stapleton",",","Sturgill","Simpson",",","Jason","Isbell",",","Lydia","Loveless","and","Margo","Price","."],"labels":["O","O","O","O","O","B-music genre","I-music genre","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-band","I-band","I-band","O","B-musical artist","I-musical artist","O","B-musical artist","I-musical artist","O","B-musical artist","I-musical artist","O","B-band","I-band","O","B-musical artist","I-musical artist","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: musical artist, person, musical instrument, music genre, organization, event, award, album, country, band, location, song and O.\nSentence: In the 2010s , the alt-country genre saw an increase in its critical and commercial popularity , owing to the success of artists such as The Civil Wars , Chris Stapleton , Sturgill Simpson , Jason Isbell , Lydia Loveless and Margo Price .","prompt_labels":"In(O) the(O) 2010s(O) ,(O) the(O) alt-country(B-music genre) genre(I-music genre) saw(O) an(O) increase(O) in(O) its(O) critical(O) and(O) commercial(O) popularity(O) ,(O) owing(O) to(O) the(O) success(O) of(O) artists(O) such(O) as(O) The(B-band) Civil(I-band) Wars(I-band) ,(O) Chris(B-musical artist) Stapleton(I-musical artist) ,(O) Sturgill(B-musical artist) Simpson(I-musical artist) ,(O) Jason(B-musical artist) Isbell(I-musical artist) ,(O) Lydia(B-band) Loveless(I-band) and(O) Margo(B-musical artist) Price(I-musical artist) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["organization","musical artist","music genre","event","person","album","award","band","musical instrument","location","song","country"],"instance":{"id":"158","words":["At","the","51st","Academy","Awards",",","it","was","nominated","for","nine","Academy","Awards",",","and","won","five",":","Academy","Award","for","Best","Picture",",","Academy","Award","for","Best","Director","for","Cimino",",","Academy","Award","for","Best","Supporting","Actor","for","Walken",",","Academy","Award","for","Best","Sound","Mixing",",","and","Best","Film","Editing","."],"labels":["O","O","B-award","I-award","I-award","O","O","O","O","O","O","B-award","I-award","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","O","B-award","I-award","I-award","I-award","I-award","O","B-person","O","B-award","I-award","I-award","I-award","I-award","I-award","O","B-person","O","B-award","I-award","I-award","I-award","I-award","I-award","O","O","B-award","I-award","I-award","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, musical artist, music genre, event, person, album, award, band, musical instrument, location, song, country and O.\nSentence: At the 51st Academy Awards , it was nominated for nine Academy Awards , and won five : Academy Award for Best Picture , Academy Award for Best Director for Cimino , Academy Award for Best Supporting Actor for Walken , Academy Award for Best Sound Mixing , and Best Film Editing .","prompt_labels":"At(O) the(O) 51st(B-award) Academy(I-award) Awards(I-award) ,(O) it(O) was(O) nominated(O) for(O) nine(O) Academy(B-award) Awards(I-award) ,(O) and(O) won(O) five(O) :(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Picture(I-award) ,(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Director(I-award) for(O) Cimino(B-person) ,(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Supporting(I-award) Actor(I-award) for(O) Walken(B-person) ,(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Sound(I-award) Mixing(I-award) ,(O) and(O) Best(B-award) Film(I-award) Editing(I-award) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["award","song","person","musical artist","event","location","organization","album","music genre","country","band","musical instrument"],"instance":{"id":"159","words":["Biafra","was","also","working","with","a","band","known","as","Jello","Biafra","and","the","Guantanamo","School","of","Medicine",",","which","included","Ralph","Spight","of","Victims","Family","on","guitar","and","Billy","Gould","of","Faith","No","More","on","bass","."],"labels":["B-musical artist","O","O","O","O","O","O","O","O","B-band","I-band","I-band","I-band","I-band","I-band","I-band","I-band","O","O","O","B-musical artist","I-musical artist","O","B-band","I-band","O","B-musical instrument","O","B-musical artist","I-musical artist","O","B-band","I-band","I-band","O","B-musical instrument","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, song, person, musical artist, event, location, organization, album, music genre, country, band, musical instrument and O.\nSentence: Biafra was also working with a band known as Jello Biafra and the Guantanamo School of Medicine , which included Ralph Spight of Victims Family on guitar and Billy Gould of Faith No More on bass .","prompt_labels":"Biafra(B-musical artist) was(O) also(O) working(O) with(O) a(O) band(O) known(O) as(O) Jello(B-band) Biafra(I-band) and(I-band) the(I-band) Guantanamo(I-band) School(I-band) of(I-band) Medicine(I-band) ,(O) which(O) included(O) Ralph(B-musical artist) Spight(I-musical artist) of(O) Victims(B-band) Family(I-band) on(O) guitar(B-musical instrument) and(O) Billy(B-musical artist) Gould(I-musical artist) of(O) Faith(B-band) No(I-band) More(I-band) on(O) bass(B-musical instrument) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["event","organization","musical artist","song","musical instrument","location","person","album","country","band","award","music genre"],"instance":{"id":"160","words":["The","album","also","features","appearances","by","Damian","Marley",",","son","of","Bob","Marley",",","Prodigy","of","Mobb","Deep","and","producers","the","Alchemist","and","Fredwreck","."],"labels":["O","O","O","O","O","O","B-musical artist","I-musical artist","O","O","O","B-person","I-person","O","B-musical artist","O","B-band","I-band","O","O","B-musical artist","I-musical artist","O","B-musical artist","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, organization, musical artist, song, musical instrument, location, person, album, country, band, award, music genre and O.\nSentence: The album also features appearances by Damian Marley , son of Bob Marley , Prodigy of Mobb Deep and producers the Alchemist and Fredwreck .","prompt_labels":"The(O) album(O) also(O) features(O) appearances(O) by(O) Damian(B-musical artist) Marley(I-musical artist) ,(O) son(O) of(O) Bob(B-person) Marley(I-person) ,(O) Prodigy(B-musical artist) of(O) Mobb(B-band) Deep(I-band) and(O) producers(O) the(B-musical artist) Alchemist(I-musical artist) and(O) Fredwreck(B-musical artist) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["event","award","music genre","musical artist","person","band","musical instrument","album","song","country","organization","location"],"instance":{"id":"161","words":["The","three","venues","regarded","as","the","most","important","in","this","decade","were","the","Golden","Torch","in","Tunstall",",","Stoke-on-Trent","(","1971","to","1972",")",",","Blackpool","Mecca","(","1971","to","1979",")","and","Wigan","Casino","(","1973","to","1981",")","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","B-location","I-location","O","B-location","O","B-location","O","O","O","O","O","O","B-location","I-location","O","O","O","O","O","O","B-location","I-location","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, award, music genre, musical artist, person, band, musical instrument, album, song, country, organization, location and O.\nSentence: The three venues regarded as the most important in this decade were the Golden Torch in Tunstall , Stoke-on-Trent ( 1971 to 1972 ) , Blackpool Mecca ( 1971 to 1979 ) and Wigan Casino ( 1973 to 1981 ) .","prompt_labels":"The(O) three(O) venues(O) regarded(O) as(O) the(O) most(O) important(O) in(O) this(O) decade(O) were(O) the(O) Golden(B-location) Torch(I-location) in(O) Tunstall(B-location) ,(O) Stoke-on-Trent(B-location) ((O) 1971(O) to(O) 1972(O) )(O) ,(O) Blackpool(B-location) Mecca(I-location) ((O) 1971(O) to(O) 1979(O) )(O) and(O) Wigan(B-location) Casino(I-location) ((O) 1973(O) to(O) 1981(O) )(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["country","album","person","event","band","organization","musical instrument","award","song","location","musical artist","music genre"],"instance":{"id":"162","words":["Rebana","is","a","Malay","tambourine","that","is","used","in","Islamic","devotional","music","in","Southeast","Asia",",","particularly","in","Indonesia",",","Malaysia",",","Brunei",",","and","Singapore","."],"labels":["B-musical instrument","O","O","B-musical instrument","I-musical instrument","O","O","O","O","B-music genre","I-music genre","I-music genre","O","B-location","B-location","O","O","O","B-country","O","B-country","O","B-country","O","O","B-country","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, album, person, event, band, organization, musical instrument, award, song, location, musical artist, music genre and O.\nSentence: Rebana is a Malay tambourine that is used in Islamic devotional music in Southeast Asia , particularly in Indonesia , Malaysia , Brunei , and Singapore .","prompt_labels":"Rebana(B-musical instrument) is(O) a(O) Malay(B-musical instrument) tambourine(I-musical instrument) that(O) is(O) used(O) in(O) Islamic(B-music genre) devotional(I-music genre) music(I-music genre) in(O) Southeast(B-location) Asia(B-location) ,(O) particularly(O) in(O) Indonesia(B-country) ,(O) Malaysia(B-country) ,(O) Brunei(B-country) ,(O) and(O) Singapore(B-country) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["musical instrument","location","album","organization","musical artist","event","award","band","music genre","song","country","person"],"instance":{"id":"163","words":["Minogue","has","sold","70","million","records","worldwide","and","has","earned","numerous","awards","and","accolades",",","including","a","Grammy","Award",",","three","Brit","Awards",",","17","ARIA","Music","Awards",",","two","MTV","Europe","Music","Award","and","two","MTV","Video","Music","Award","."],"labels":["B-musical artist","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-award","I-award","O","O","B-award","I-award","O","O","B-award","I-award","I-award","O","O","B-award","I-award","I-award","I-award","O","O","B-award","I-award","I-award","I-award","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: musical instrument, location, album, organization, musical artist, event, award, band, music genre, song, country, person and O.\nSentence: Minogue has sold 70 million records worldwide and has earned numerous awards and accolades , including a Grammy Award , three Brit Awards , 17 ARIA Music Awards , two MTV Europe Music Award and two MTV Video Music Award .","prompt_labels":"Minogue(B-musical artist) has(O) sold(O) 70(O) million(O) records(O) worldwide(O) and(O) has(O) earned(O) numerous(O) awards(O) and(O) accolades(O) ,(O) including(O) a(O) Grammy(B-award) Award(I-award) ,(O) three(O) Brit(B-award) Awards(I-award) ,(O) 17(O) ARIA(B-award) Music(I-award) Awards(I-award) ,(O) two(O) MTV(B-award) Europe(I-award) Music(I-award) Award(I-award) and(O) two(O) MTV(B-award) Video(I-award) Music(I-award) Award(I-award) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["organization","country","band","album","person","location","song","musical instrument","musical artist","music genre","award","event"],"instance":{"id":"164","words":["The","festival","features","bands","from","different","places","in","Argentina",",","as","well","as","international","artists","from","Brazil",",","Uruguay",",","Chile",",","Peru","and","the","United","States","."],"labels":["O","O","O","O","O","O","O","O","B-country","O","O","O","O","O","O","O","B-country","O","B-country","O","B-country","O","B-country","O","O","B-country","I-country","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, country, band, album, person, location, song, musical instrument, musical artist, music genre, award, event and O.\nSentence: The festival features bands from different places in Argentina , as well as international artists from Brazil , Uruguay , Chile , Peru and the United States .","prompt_labels":"The(O) festival(O) features(O) bands(O) from(O) different(O) places(O) in(O) Argentina(B-country) ,(O) as(O) well(O) as(O) international(O) artists(O) from(O) Brazil(B-country) ,(O) Uruguay(B-country) ,(O) Chile(B-country) ,(O) Peru(B-country) and(O) the(O) United(B-country) States(I-country) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["song","musical instrument","music genre","event","musical artist","country","album","person","band","award","location","organization"],"instance":{"id":"165","words":["Top","artists","included","Tammy","Wynette",",","Lynn","Anderson","and","Charlie","Rich",",","as","well","as","such","former","hard","country","artists","as","Ray","Price","and","Marty","Robbins","."],"labels":["O","O","O","B-musical artist","I-musical artist","O","B-musical artist","I-musical artist","O","B-musical artist","I-musical artist","O","O","O","O","O","O","B-music genre","I-music genre","O","O","B-musical artist","I-musical artist","O","B-musical artist","I-musical artist","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, musical instrument, music genre, event, musical artist, country, album, person, band, award, location, organization and O.\nSentence: Top artists included Tammy Wynette , Lynn Anderson and Charlie Rich , as well as such former hard country artists as Ray Price and Marty Robbins .","prompt_labels":"Top(O) artists(O) included(O) Tammy(B-musical artist) Wynette(I-musical artist) ,(O) Lynn(B-musical artist) Anderson(I-musical artist) and(O) Charlie(B-musical artist) Rich(I-musical artist) ,(O) as(O) well(O) as(O) such(O) former(O) hard(B-music genre) country(I-music genre) artists(O) as(O) Ray(B-musical artist) Price(I-musical artist) and(O) Marty(B-musical artist) Robbins(I-musical artist) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["song","musical instrument","organization","music genre","award","band","person","event","musical artist","country","location","album"],"instance":{"id":"166","words":["A","critical","and","commercial","success","upon","release","and","nominated","for","four","Academy","Awards",",","including","for","Academy","Award","for","Best","Picture",",","Academy","Award","for","Best","Actor","(","for","De","Niro",")","and","Academy","Award","for","Best","Supporting","Actress","(","for","Foster",")",",","Taxi","Driver","won","the","Palme","d","'Or","at","the","1976","Cannes","Film","Festival","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","B-award","I-award","O","O","O","B-award","I-award","I-award","I-award","I-award","O","B-award","I-award","I-award","I-award","I-award","O","O","B-person","I-person","O","O","B-award","I-award","I-award","I-award","I-award","I-award","O","O","B-person","O","O","O","O","O","O","B-award","I-award","I-award","O","O","B-event","I-event","I-event","I-event","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, musical instrument, organization, music genre, award, band, person, event, musical artist, country, location, album and O.\nSentence: A critical and commercial success upon release and nominated for four Academy Awards , including for Academy Award for Best Picture , Academy Award for Best Actor ( for De Niro ) and Academy Award for Best Supporting Actress ( for Foster ) , Taxi Driver won the Palme d 'Or at the 1976 Cannes Film Festival .","prompt_labels":"A(O) critical(O) and(O) commercial(O) success(O) upon(O) release(O) and(O) nominated(O) for(O) four(O) Academy(B-award) Awards(I-award) ,(O) including(O) for(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Picture(I-award) ,(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Actor(I-award) ((O) for(O) De(B-person) Niro(I-person) )(O) and(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Supporting(I-award) Actress(I-award) ((O) for(O) Foster(B-person) )(O) ,(O) Taxi(O) Driver(O) won(O) the(O) Palme(B-award) d(I-award) 'Or(I-award) at(O) the(O) 1976(B-event) Cannes(I-event) Film(I-event) Festival(I-event) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["song","music genre","band","country","album","organization","musical artist","event","location","award","musical instrument","person"],"instance":{"id":"167","words":["It","is","generally","divided","into","two","major","subgenres",",","with","the","jazz","-influenced","New","Orleans","blues","based","on","the","musical","traditions","of","that","city","and","the","slower","tempo","swamp","blues","incorporating","influences","from","zydeco","and","Cajun","music","from","around","Baton","Rouge","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","B-music genre","O","B-music genre","I-music genre","I-music genre","O","O","O","O","O","O","O","O","O","O","O","O","B-music genre","I-music genre","O","O","O","B-music genre","O","B-music genre","I-music genre","O","O","B-location","I-location","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, music genre, band, country, album, organization, musical artist, event, location, award, musical instrument, person and O.\nSentence: It is generally divided into two major subgenres , with the jazz -influenced New Orleans blues based on the musical traditions of that city and the slower tempo swamp blues incorporating influences from zydeco and Cajun music from around Baton Rouge .","prompt_labels":"It(O) is(O) generally(O) divided(O) into(O) two(O) major(O) subgenres(O) ,(O) with(O) the(O) jazz(B-music genre) -influenced(O) New(B-music genre) Orleans(I-music genre) blues(I-music genre) based(O) on(O) the(O) musical(O) traditions(O) of(O) that(O) city(O) and(O) the(O) slower(O) tempo(O) swamp(B-music genre) blues(I-music genre) incorporating(O) influences(O) from(O) zydeco(B-music genre) and(O) Cajun(B-music genre) music(I-music genre) from(O) around(O) Baton(B-location) Rouge(I-location) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["musical artist","award","song","location","album","organization","music genre","event","band","musical instrument","person","country"],"instance":{"id":"168","words":["The","album","was","certified","gold","by","both","British","Phonographic","Industry","and","the","Recording","Industry","Association","of","America","in","December","2007","."],"labels":["O","O","O","O","O","O","O","B-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: musical artist, award, song, location, album, organization, music genre, event, band, musical instrument, person, country and O.\nSentence: The album was certified gold by both British Phonographic Industry and the Recording Industry Association of America in December 2007 .","prompt_labels":"The(O) album(O) was(O) certified(O) gold(O) by(O) both(O) British(B-organization) Phonographic(I-organization) Industry(I-organization) and(O) the(O) Recording(B-organization) Industry(I-organization) Association(I-organization) of(I-organization) America(I-organization) in(O) December(O) 2007(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["album","musical instrument","award","location","song","musical artist","organization","country","band","music genre","event","person"],"instance":{"id":"169","words":["The","total","playing","time","covered","three","sides","of","an","LP",",","so","they","decided","to","expand","it","into","a","double","by","including","previously","unreleased","tracks","from","the","sessions","for","the","earlier","albums","Led","Zeppelin","III",",","Led","Zeppelin","IV","and","Houses","of","the","Holy","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-album","I-album","I-album","O","B-album","I-album","I-album","O","B-album","I-album","I-album","I-album","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: album, musical instrument, award, location, song, musical artist, organization, country, band, music genre, event, person and O.\nSentence: The total playing time covered three sides of an LP , so they decided to expand it into a double by including previously unreleased tracks from the sessions for the earlier albums Led Zeppelin III , Led Zeppelin IV and Houses of the Holy .","prompt_labels":"The(O) total(O) playing(O) time(O) covered(O) three(O) sides(O) of(O) an(O) LP(O) ,(O) so(O) they(O) decided(O) to(O) expand(O) it(O) into(O) a(O) double(O) by(O) including(O) previously(O) unreleased(O) tracks(O) from(O) the(O) sessions(O) for(O) the(O) earlier(O) albums(O) Led(B-album) Zeppelin(I-album) III(I-album) ,(O) Led(B-album) Zeppelin(I-album) IV(I-album) and(O) Houses(B-album) of(I-album) the(I-album) Holy(I-album) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["album","country","location","song","musical artist","award","band","music genre","organization","person","musical instrument","event"],"instance":{"id":"170","words":["Some","of","the","early","stars","on","the","Opry","were","Uncle","Dave","Macon",",","Roy","Acuff","and","African","American","harmonica","player","DeFord","Bailey","."],"labels":["O","O","O","O","O","O","O","B-location","O","B-musical artist","I-musical artist","I-musical artist","O","B-musical artist","I-musical artist","O","O","O","B-musical instrument","O","B-musical artist","I-musical artist","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: album, country, location, song, musical artist, award, band, music genre, organization, person, musical instrument, event and O.\nSentence: Some of the early stars on the Opry were Uncle Dave Macon , Roy Acuff and African American harmonica player DeFord Bailey .","prompt_labels":"Some(O) of(O) the(O) early(O) stars(O) on(O) the(O) Opry(B-location) were(O) Uncle(B-musical artist) Dave(I-musical artist) Macon(I-musical artist) ,(O) Roy(B-musical artist) Acuff(I-musical artist) and(O) African(O) American(O) harmonica(B-musical instrument) player(O) DeFord(B-musical artist) Bailey(I-musical artist) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["musical artist","band","event","award","organization","music genre","person","musical instrument","country","location","song","album"],"instance":{"id":"171","words":["Juliana","Hatfield","is","an","American","musician","and","singer-songwriter","from","the","Boston","area",",","formerly","of","the","indie","rock","bands","Blake","Babies",",","Some","Girls",",","and","The","Lemonheads","."],"labels":["B-musical artist","I-musical artist","O","O","O","O","O","O","O","O","B-location","I-location","O","O","O","O","O","B-music genre","O","B-band","I-band","O","B-band","I-band","O","O","B-band","I-band","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: musical artist, band, event, award, organization, music genre, person, musical instrument, country, location, song, album and O.\nSentence: Juliana Hatfield is an American musician and singer-songwriter from the Boston area , formerly of the indie rock bands Blake Babies , Some Girls , and The Lemonheads .","prompt_labels":"Juliana(B-musical artist) Hatfield(I-musical artist) is(O) an(O) American(O) musician(O) and(O) singer-songwriter(O) from(O) the(O) Boston(B-location) area(I-location) ,(O) formerly(O) of(O) the(O) indie(O) rock(B-music genre) bands(O) Blake(B-band) Babies(I-band) ,(O) Some(B-band) Girls(I-band) ,(O) and(O) The(B-band) Lemonheads(I-band) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["musical artist","country","event","musical instrument","person","band","album","song","location","organization","music genre","award"],"instance":{"id":"172","words":["Bands","like","Flogging","Molly",",","Black","47",",","Dropkick","Murphys",",","The","Young","Dubliners",",","The","Tossers","introduced","a","hybrid","of","Celtic","rock",",","Punk","rock",",","reggae",",","Hardcore","punk","and","other","elements","in","the","1990s","that","has","become","popular","with","Irish-American","youth","."],"labels":["O","O","B-band","I-band","O","B-band","I-band","O","B-band","I-band","O","B-band","I-band","I-band","O","B-band","I-band","O","O","O","O","B-music genre","I-music genre","O","B-music genre","I-music genre","O","B-music genre","O","B-music genre","I-music genre","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: musical artist, country, event, musical instrument, person, band, album, song, location, organization, music genre, award and O.\nSentence: Bands like Flogging Molly , Black 47 , Dropkick Murphys , The Young Dubliners , The Tossers introduced a hybrid of Celtic rock , Punk rock , reggae , Hardcore punk and other elements in the 1990s that has become popular with Irish-American youth .","prompt_labels":"Bands(O) like(O) Flogging(B-band) Molly(I-band) ,(O) Black(B-band) 47(I-band) ,(O) Dropkick(B-band) Murphys(I-band) ,(O) The(B-band) Young(I-band) Dubliners(I-band) ,(O) The(B-band) Tossers(I-band) introduced(O) a(O) hybrid(O) of(O) Celtic(B-music genre) rock(I-music genre) ,(O) Punk(B-music genre) rock(I-music genre) ,(O) reggae(B-music genre) ,(O) Hardcore(B-music genre) punk(I-music genre) and(O) other(O) elements(O) in(O) the(O) 1990s(O) that(O) has(O) become(O) popular(O) with(O) Irish-American(O) youth(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["organization","music genre","musical artist","band","event","song","location","album","award","country","musical instrument","person"],"instance":{"id":"173","words":["Their","eighth","album",",","Hesitation","Marks","(","2013",")",",","was","followed","by","a","trilogy","consisting","of","the","EPs","Not","the","Actual","Events","(","2016",")","and","Add","Violence","(","2017",")","and","their","ninth","album","Bad","Witch","(","2018",")","."],"labels":["O","O","O","O","B-album","I-album","O","O","O","O","O","O","O","O","O","O","O","O","O","B-album","I-album","I-album","I-album","O","O","O","O","B-album","I-album","O","O","O","O","O","O","O","B-album","I-album","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, music genre, musical artist, band, event, song, location, album, award, country, musical instrument, person and O.\nSentence: Their eighth album , Hesitation Marks ( 2013 ) , was followed by a trilogy consisting of the EPs Not the Actual Events ( 2016 ) and Add Violence ( 2017 ) and their ninth album Bad Witch ( 2018 ) .","prompt_labels":"Their(O) eighth(O) album(O) ,(O) Hesitation(B-album) Marks(I-album) ((O) 2013(O) )(O) ,(O) was(O) followed(O) by(O) a(O) trilogy(O) consisting(O) of(O) the(O) EPs(O) Not(B-album) the(I-album) Actual(I-album) Events(I-album) ((O) 2016(O) )(O) and(O) Add(B-album) Violence(I-album) ((O) 2017(O) )(O) and(O) their(O) ninth(O) album(O) Bad(B-album) Witch(I-album) ((O) 2018(O) )(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["event","album","country","person","music genre","location","organization","song","award","musical artist","musical instrument","band"],"instance":{"id":"174","words":["He","has","appeared","as","a","featured","artist","on","many","other","songs","and","albums",",","having","collaborated","with","artists","such","as","Janet","Jackson",",","Kool","Moe","Dee",",","The","Dope","Poet","Society",",","Run-D.M.C.",",","Ice","Cube",",","Boom","Boom","Satellites",",","Rage","Against","the","Machine",",","Anthrax",",","John","Mellencamp","and","many","others","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-musical artist","I-musical artist","O","B-musical artist","I-musical artist","I-musical artist","O","B-band","I-band","I-band","I-band","O","B-band","O","B-musical artist","I-musical artist","O","B-band","I-band","I-band","O","B-band","I-band","I-band","I-band","O","B-band","O","B-musical artist","I-musical artist","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, album, country, person, music genre, location, organization, song, award, musical artist, musical instrument, band and O.\nSentence: He has appeared as a featured artist on many other songs and albums , having collaborated with artists such as Janet Jackson , Kool Moe Dee , The Dope Poet Society , Run-D.M.C. , Ice Cube , Boom Boom Satellites , Rage Against the Machine , Anthrax , John Mellencamp and many others .","prompt_labels":"He(O) has(O) appeared(O) as(O) a(O) featured(O) artist(O) on(O) many(O) other(O) songs(O) and(O) albums(O) ,(O) having(O) collaborated(O) with(O) artists(O) such(O) as(O) Janet(B-musical artist) Jackson(I-musical artist) ,(O) Kool(B-musical artist) Moe(I-musical artist) Dee(I-musical artist) ,(O) The(B-band) Dope(I-band) Poet(I-band) Society(I-band) ,(O) Run-D.M.C.(B-band) ,(O) Ice(B-musical artist) Cube(I-musical artist) ,(O) Boom(B-band) Boom(I-band) Satellites(I-band) ,(O) Rage(B-band) Against(I-band) the(I-band) Machine(I-band) ,(O) Anthrax(B-band) ,(O) John(B-musical artist) Mellencamp(I-musical artist) and(O) many(O) others(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["song","location","musical instrument","musical artist","album","event","band","person","music genre","award","country","organization"],"instance":{"id":"175","words":["Dimmu","Borgir","'s","following","full-length","albums","Spiritual","Black","Dimensions","in","1999","and","2001","'s","Puritanical","Euphoric","Misanthropia",",","both","met","critical","acclaim.","only","to","be","replaced","with","Nicholas","Barker","of","Cradle","of","Filth","."],"labels":["B-band","I-band","O","O","O","O","B-album","I-album","I-album","O","O","O","O","O","B-album","I-album","I-album","O","O","O","O","O","O","O","O","O","O","B-musical artist","I-musical artist","O","B-band","I-band","I-band","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, location, musical instrument, musical artist, album, event, band, person, music genre, award, country, organization and O.\nSentence: Dimmu Borgir 's following full-length albums Spiritual Black Dimensions in 1999 and 2001 's Puritanical Euphoric Misanthropia , both met critical acclaim. only to be replaced with Nicholas Barker of Cradle of Filth .","prompt_labels":"Dimmu(B-band) Borgir(I-band) 's(O) following(O) full-length(O) albums(O) Spiritual(B-album) Black(I-album) Dimensions(I-album) in(O) 1999(O) and(O) 2001(O) 's(O) Puritanical(B-album) Euphoric(I-album) Misanthropia(I-album) ,(O) both(O) met(O) critical(O) acclaim.(O) only(O) to(O) be(O) replaced(O) with(O) Nicholas(B-musical artist) Barker(I-musical artist) of(O) Cradle(B-band) of(I-band) Filth(I-band) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["event","band","award","musical artist","album","organization","musical instrument","person","country","location","music genre","song"],"instance":{"id":"176","words":["Besides","fronting","his","own","band","and","rap","projects",",","Ice-T","has","also","collaborated","with","other","hard","rock","and","metal","bands",",","such","as","Icepick",",","Motrhead",",","Slayer",",","Pro-Pain",",","and","Six","Feet","Under","."],"labels":["O","O","O","O","O","O","B-music genre","O","O","B-musical artist","O","O","O","O","O","B-music genre","I-music genre","O","B-music genre","O","O","O","O","B-band","O","B-band","O","B-band","O","B-band","O","O","B-band","I-band","I-band","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, band, award, musical artist, album, organization, musical instrument, person, country, location, music genre, song and O.\nSentence: Besides fronting his own band and rap projects , Ice-T has also collaborated with other hard rock and metal bands , such as Icepick , Motrhead , Slayer , Pro-Pain , and Six Feet Under .","prompt_labels":"Besides(O) fronting(O) his(O) own(O) band(O) and(O) rap(B-music genre) projects(O) ,(O) Ice-T(B-musical artist) has(O) also(O) collaborated(O) with(O) other(O) hard(B-music genre) rock(I-music genre) and(O) metal(B-music genre) bands(O) ,(O) such(O) as(O) Icepick(B-band) ,(O) Motrhead(B-band) ,(O) Slayer(B-band) ,(O) Pro-Pain(B-band) ,(O) and(O) Six(B-band) Feet(I-band) Under(I-band) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["music genre","band","person","award","album","organization","musical artist","location","musical instrument","event","country","song"],"instance":{"id":"177","words":["Alexander","von","Meilenwald","from","German","band","Nagelfar","considers","Ungod","'","s","1993","debut","Circle","of","the","Seven","Infernal","Pacts",",","Desaster","'","s","1994","demo","Lost","in","the","Ages",",","Tha-Norr","'","s","1995","album","Wolfenzeitalter",",","Lunar","Aurora","'","s","1996","debut","Weltengnger","and","Katharsis","'","s","2000","debut","666","Alexander","von","Meilenwald",":","5","Klassiker","."],"labels":["B-musical artist","I-musical artist","I-musical artist","O","O","O","B-band","O","B-album","O","O","O","O","B-album","I-album","I-album","I-album","I-album","I-album","O","B-band","O","O","O","O","B-album","I-album","I-album","I-album","O","B-band","O","O","O","O","B-album","O","B-band","I-band","O","O","O","O","B-album","O","B-band","O","O","O","O","B-album","B-musical artist","I-musical artist","I-musical artist","O","B-album","I-album","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: music genre, band, person, award, album, organization, musical artist, location, musical instrument, event, country, song and O.\nSentence: Alexander von Meilenwald from German band Nagelfar considers Ungod ' s 1993 debut Circle of the Seven Infernal Pacts , Desaster ' s 1994 demo Lost in the Ages , Tha-Norr ' s 1995 album Wolfenzeitalter , Lunar Aurora ' s 1996 debut Weltengnger and Katharsis ' s 2000 debut 666 Alexander von Meilenwald : 5 Klassiker .","prompt_labels":"Alexander(B-musical artist) von(I-musical artist) Meilenwald(I-musical artist) from(O) German(O) band(O) Nagelfar(B-band) considers(O) Ungod(B-album) '(O) s(O) 1993(O) debut(O) Circle(B-album) of(I-album) the(I-album) Seven(I-album) Infernal(I-album) Pacts(I-album) ,(O) Desaster(B-band) '(O) s(O) 1994(O) demo(O) Lost(B-album) in(I-album) the(I-album) Ages(I-album) ,(O) Tha-Norr(B-band) '(O) s(O) 1995(O) album(O) Wolfenzeitalter(B-album) ,(O) Lunar(B-band) Aurora(I-band) '(O) s(O) 1996(O) debut(O) Weltengnger(B-album) and(O) Katharsis(B-band) '(O) s(O) 2000(O) debut(O) 666(B-album) Alexander(B-musical artist) von(I-musical artist) Meilenwald(I-musical artist) :(O) 5(B-album) Klassiker(I-album) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["location","organization","song","event","band","musical instrument","album","award","music genre","musical artist","country","person"],"instance":{"id":"178","words":["Depeche","Mode","'s","releases","have","been","nominated","for","five","Grammy","Awards",":","Devotional","for","Grammy","Award","for","Best","Music","Film",";","I","Feel","Loved","and","Suffer","Well",",","both","for","Grammy","Award","for","Best","Dance","Recording",";","Sounds","of","the","Universe","for","Best","Alternative","Album",";","and","Wrong","for","Grammy","Award","for","Best","Music","Video","."],"labels":["B-band","O","O","O","O","O","O","O","O","B-award","I-award","O","B-song","O","B-award","I-award","I-award","I-award","I-award","I-award","O","B-song","I-song","I-song","O","B-song","I-song","O","O","O","B-award","I-award","I-award","I-award","I-award","I-award","O","B-album","I-album","I-album","I-album","O","B-award","I-award","I-award","O","O","B-song","O","B-award","I-award","I-award","I-award","I-award","I-award","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, organization, song, event, band, musical instrument, album, award, music genre, musical artist, country, person and O.\nSentence: Depeche Mode 's releases have been nominated for five Grammy Awards : Devotional for Grammy Award for Best Music Film ; I Feel Loved and Suffer Well , both for Grammy Award for Best Dance Recording ; Sounds of the Universe for Best Alternative Album ; and Wrong for Grammy Award for Best Music Video .","prompt_labels":"Depeche(B-band) Mode(O) 's(O) releases(O) have(O) been(O) nominated(O) for(O) five(O) Grammy(B-award) Awards(I-award) :(O) Devotional(B-song) for(O) Grammy(B-award) Award(I-award) for(I-award) Best(I-award) Music(I-award) Film(I-award) ;(O) I(B-song) Feel(I-song) Loved(I-song) and(O) Suffer(B-song) Well(I-song) ,(O) both(O) for(O) Grammy(B-award) Award(I-award) for(I-award) Best(I-award) Dance(I-award) Recording(I-award) ;(O) Sounds(B-album) of(I-album) the(I-album) Universe(I-album) for(O) Best(B-award) Alternative(I-award) Album(I-award) ;(O) and(O) Wrong(B-song) for(O) Grammy(B-award) Award(I-award) for(I-award) Best(I-award) Music(I-award) Video(I-award) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["musical artist","person","country","award","music genre","musical instrument","band","organization","event","song","location","album"],"instance":{"id":"179","words":["He","also","collected","in","Moldavia",",","Wallachia",",","and","(","in","1913",")","Algeria","."],"labels":["O","O","O","O","B-country","O","B-country","O","O","O","O","O","O","B-country","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: musical artist, person, country, award, music genre, musical instrument, band, organization, event, song, location, album and O.\nSentence: He also collected in Moldavia , Wallachia , and ( in 1913 ) Algeria .","prompt_labels":"He(O) also(O) collected(O) in(O) Moldavia(B-country) ,(O) Wallachia(B-country) ,(O) and(O) ((O) in(O) 1913(O) )(O) Algeria(B-country) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["music genre","band","country","musical instrument","song","location","event","person","album","award","musical artist","organization"],"instance":{"id":"180","words":["Alexander","von","Meilenwald","from","German","band","Nagelfar","considers","Ungod","'","s","1993","debut","Circle","of","the","Seven","Infernal","Pacts",",","Desaster","'","s","1994","demo","Lost","in","the","Ages",",","Tha-Norr","'","s","1995","album","Wolfenzeitalter",",","Lunar","Aurora","'","s","1996","debut","Weltengnger","and","Katharsis","'","s","2000","debut","666","Alexander","von","Meilenwald",":","5","Klassiker","."],"labels":["B-musical artist","I-musical artist","I-musical artist","O","B-country","O","B-band","O","B-band","O","O","O","O","B-album","I-album","I-album","I-album","I-album","I-album","O","B-band","O","O","O","O","B-album","I-album","I-album","I-album","O","B-band","O","O","O","O","B-album","O","B-band","I-band","O","O","O","O","B-album","O","B-band","O","O","O","O","B-album","B-musical artist","I-musical artist","I-musical artist","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: music genre, band, country, musical instrument, song, location, event, person, album, award, musical artist, organization and O.\nSentence: Alexander von Meilenwald from German band Nagelfar considers Ungod ' s 1993 debut Circle of the Seven Infernal Pacts , Desaster ' s 1994 demo Lost in the Ages , Tha-Norr ' s 1995 album Wolfenzeitalter , Lunar Aurora ' s 1996 debut Weltengnger and Katharsis ' s 2000 debut 666 Alexander von Meilenwald : 5 Klassiker .","prompt_labels":"Alexander(B-musical artist) von(I-musical artist) Meilenwald(I-musical artist) from(O) German(B-country) band(O) Nagelfar(B-band) considers(O) Ungod(B-band) '(O) s(O) 1993(O) debut(O) Circle(B-album) of(I-album) the(I-album) Seven(I-album) Infernal(I-album) Pacts(I-album) ,(O) Desaster(B-band) '(O) s(O) 1994(O) demo(O) Lost(B-album) in(I-album) the(I-album) Ages(I-album) ,(O) Tha-Norr(B-band) '(O) s(O) 1995(O) album(O) Wolfenzeitalter(B-album) ,(O) Lunar(B-band) Aurora(I-band) '(O) s(O) 1996(O) debut(O) Weltengnger(B-album) and(O) Katharsis(B-band) '(O) s(O) 2000(O) debut(O) 666(B-album) Alexander(B-musical artist) von(I-musical artist) Meilenwald(I-musical artist) :(O) 5(O) Klassiker(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["award","band","album","musical artist","song","organization","location","event","country","person","music genre","musical instrument"],"instance":{"id":"181","words":["The","festival","features","bands","from","different","places","in","Argentina",",","as","well","as","international","artists","from","Brazil",",","Uruguay",",","Chile",",","Peru","and","the","United","States","."],"labels":["O","O","O","O","O","O","O","O","B-country","O","O","O","O","O","O","O","B-country","O","B-country","O","B-country","O","B-country","O","O","B-country","I-country","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, band, album, musical artist, song, organization, location, event, country, person, music genre, musical instrument and O.\nSentence: The festival features bands from different places in Argentina , as well as international artists from Brazil , Uruguay , Chile , Peru and the United States .","prompt_labels":"The(O) festival(O) features(O) bands(O) from(O) different(O) places(O) in(O) Argentina(B-country) ,(O) as(O) well(O) as(O) international(O) artists(O) from(O) Brazil(B-country) ,(O) Uruguay(B-country) ,(O) Chile(B-country) ,(O) Peru(B-country) and(O) the(O) United(B-country) States(I-country) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["country","musical instrument","musical artist","band","organization","music genre","album","location","award","event","song","person"],"instance":{"id":"182","words":["In","the","early","1990s",",","the","rise","of","melodic","death","metal","was","recognized",",","with","Swedish","bands","such","as","Dark","Tranquillity",",","At","the","Gates",",","and","In","Flames","."],"labels":["O","O","O","O","O","O","O","O","B-music genre","I-music genre","I-music genre","O","O","O","O","O","O","O","O","B-band","I-band","O","B-band","I-band","I-band","O","O","B-band","I-band","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, musical instrument, musical artist, band, organization, music genre, album, location, award, event, song, person and O.\nSentence: In the early 1990s , the rise of melodic death metal was recognized , with Swedish bands such as Dark Tranquillity , At the Gates , and In Flames .","prompt_labels":"In(O) the(O) early(O) 1990s(O) ,(O) the(O) rise(O) of(O) melodic(B-music genre) death(I-music genre) metal(I-music genre) was(O) recognized(O) ,(O) with(O) Swedish(O) bands(O) such(O) as(O) Dark(B-band) Tranquillity(I-band) ,(O) At(B-band) the(I-band) Gates(I-band) ,(O) and(O) In(B-band) Flames(I-band) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["location","event","song","album","organization","band","award","person","music genre","musical artist","musical instrument","country"],"instance":{"id":"183","words":["In","February","1984",",","Queen","released","their","eleventh","studio","album",",","The","Works",",","which","included","the","successful","singles","Radio","Ga","Ga",",","Hammer","to","Fall","and","I","Want","to","Break","Free","."],"labels":["O","O","O","O","B-band","O","O","O","O","O","O","B-album","I-album","O","O","O","O","O","O","B-song","I-song","I-song","O","B-song","I-song","I-song","O","B-song","I-song","I-song","I-song","I-song","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, event, song, album, organization, band, award, person, music genre, musical artist, musical instrument, country and O.\nSentence: In February 1984 , Queen released their eleventh studio album , The Works , which included the successful singles Radio Ga Ga , Hammer to Fall and I Want to Break Free .","prompt_labels":"In(O) February(O) 1984(O) ,(O) Queen(B-band) released(O) their(O) eleventh(O) studio(O) album(O) ,(O) The(B-album) Works(I-album) ,(O) which(O) included(O) the(O) successful(O) singles(O) Radio(B-song) Ga(I-song) Ga(I-song) ,(O) Hammer(B-song) to(I-song) Fall(I-song) and(O) I(B-song) Want(I-song) to(I-song) Break(I-song) Free(I-song) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["band","organization","song","country","musical artist","event","person","location","album","music genre","musical instrument","award"],"instance":{"id":"184","words":["The","album","Jazz","from","Hell",",","released","in","1986",",","earned","Zappa","his","first","Grammy","Award","in","1988","for","Grammy","Award","for","Best","Rock","Instrumental","Performance","."],"labels":["O","O","B-album","I-album","I-album","O","O","O","O","O","O","B-musical artist","O","O","B-award","I-award","O","O","O","B-award","I-award","I-award","I-award","I-award","I-award","I-award","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: band, organization, song, country, musical artist, event, person, location, album, music genre, musical instrument, award and O.\nSentence: The album Jazz from Hell , released in 1986 , earned Zappa his first Grammy Award in 1988 for Grammy Award for Best Rock Instrumental Performance .","prompt_labels":"The(O) album(O) Jazz(B-album) from(I-album) Hell(I-album) ,(O) released(O) in(O) 1986(O) ,(O) earned(O) Zappa(B-musical artist) his(O) first(O) Grammy(B-award) Award(I-award) in(O) 1988(O) for(O) Grammy(B-award) Award(I-award) for(I-award) Best(I-award) Rock(I-award) Instrumental(I-award) Performance(I-award) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["musical artist","person","event","musical instrument","album","song","location","award","country","music genre","band","organization"],"instance":{"id":"185","words":["Switchfoot","has","been","involved","in","a","number","of","humanitarian","causes",",","including","DATA",",","the","ONE","Campaign",",","the","Keep","A","Breast","Foundation",",","Habitat","for","Humanity",",","Invisible","Children",",","and","To","Write","Love","on","Her","Arms","."],"labels":["B-band","O","O","O","O","O","O","O","O","O","O","O","B-organization","O","O","B-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","O","B-organization","I-organization","I-organization","O","B-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: musical artist, person, event, musical instrument, album, song, location, award, country, music genre, band, organization and O.\nSentence: Switchfoot has been involved in a number of humanitarian causes , including DATA , the ONE Campaign , the Keep A Breast Foundation , Habitat for Humanity , Invisible Children , and To Write Love on Her Arms .","prompt_labels":"Switchfoot(B-band) has(O) been(O) involved(O) in(O) a(O) number(O) of(O) humanitarian(O) causes(O) ,(O) including(O) DATA(B-organization) ,(O) the(O) ONE(B-organization) Campaign(I-organization) ,(O) the(O) Keep(B-organization) A(I-organization) Breast(I-organization) Foundation(I-organization) ,(O) Habitat(B-organization) for(I-organization) Humanity(I-organization) ,(O) Invisible(B-organization) Children(I-organization) ,(O) and(O) To(B-organization) Write(I-organization) Love(I-organization) on(I-organization) Her(I-organization) Arms(I-organization) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["album","musical artist","event","song","award","music genre","musical instrument","location","band","person","country","organization"],"instance":{"id":"186","words":["Nova","was","selected","as","the","official","voice","of","the","2013","Central","American","Games",",","San","Jos","2013",",","with","the","song","Arriba","Arriba","(","Get","Up",",","Get","Up",")","and","was","also","invited","to","participate","in","the","TEDx","Joven","Pura","Vida","(","Youth","Pure","Life",")","conference",",","where","she","shared","her","story",",","her","music","and","encouraged","young","people","to","follow","their","dreams","."],"labels":["B-person","O","O","O","O","O","O","O","O","B-event","I-event","I-event","I-event","O","B-location","I-location","O","O","O","O","O","B-song","I-song","O","B-song","I-song","I-song","I-song","I-song","O","O","O","O","O","O","O","O","O","B-organization","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: album, musical artist, event, song, award, music genre, musical instrument, location, band, person, country, organization and O.\nSentence: Nova was selected as the official voice of the 2013 Central American Games , San Jos 2013 , with the song Arriba Arriba ( Get Up , Get Up ) and was also invited to participate in the TEDx Joven Pura Vida ( Youth Pure Life ) conference , where she shared her story , her music and encouraged young people to follow their dreams .","prompt_labels":"Nova(B-person) was(O) selected(O) as(O) the(O) official(O) voice(O) of(O) the(O) 2013(B-event) Central(I-event) American(I-event) Games(I-event) ,(O) San(B-location) Jos(I-location) 2013(O) ,(O) with(O) the(O) song(O) Arriba(B-song) Arriba(I-song) ((O) Get(B-song) Up(I-song) ,(I-song) Get(I-song) Up(I-song) )(O) and(O) was(O) also(O) invited(O) to(O) participate(O) in(O) the(O) TEDx(B-organization) Joven(O) Pura(O) Vida(O) ((O) Youth(O) Pure(O) Life(O) )(O) conference(O) ,(O) where(O) she(O) shared(O) her(O) story(O) ,(O) her(O) music(O) and(O) encouraged(O) young(O) people(O) to(O) follow(O) their(O) dreams(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["person","song","music genre","award","album","musical instrument","event","country","band","musical artist","location","organization"],"instance":{"id":"187","words":["Fredriksson","returned","in","2006","with","an","album","of","Swedish","cover","songs",",","titled","Min","bste","vn","(","My","Best","Friend",")",",","while","Gessle","recorded","two","more","solo","albums",",","En","hndig","man","(","A","Handy","Man",")","(","2007",")","and","Party","Crasher","(","2008",")","."],"labels":["B-musical artist","O","O","O","O","O","O","O","O","O","O","O","O","B-album","I-album","I-album","O","B-album","I-album","I-album","O","O","O","B-musical artist","O","O","O","O","O","O","B-album","I-album","I-album","O","B-album","I-album","I-album","O","O","O","O","O","B-album","I-album","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, song, music genre, award, album, musical instrument, event, country, band, musical artist, location, organization and O.\nSentence: Fredriksson returned in 2006 with an album of Swedish cover songs , titled Min bste vn ( My Best Friend ) , while Gessle recorded two more solo albums , En hndig man ( A Handy Man ) ( 2007 ) and Party Crasher ( 2008 ) .","prompt_labels":"Fredriksson(B-musical artist) returned(O) in(O) 2006(O) with(O) an(O) album(O) of(O) Swedish(O) cover(O) songs(O) ,(O) titled(O) Min(B-album) bste(I-album) vn(I-album) ((O) My(B-album) Best(I-album) Friend(I-album) )(O) ,(O) while(O) Gessle(B-musical artist) recorded(O) two(O) more(O) solo(O) albums(O) ,(O) En(B-album) hndig(I-album) man(I-album) ((O) A(B-album) Handy(I-album) Man(I-album) )(O) ((O) 2007(O) )(O) and(O) Party(B-album) Crasher(I-album) ((O) 2008(O) )(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["band","person","organization","album","song","musical artist","event","music genre","location","award","country","musical instrument"],"instance":{"id":"188","words":["They","were","inducted","by","Chuck","D","and","LL","Cool","J","on","April","14",",","2012","therefore","the","group","didn","'t","perform",";","instead","Black","Thought",",","Travie","from","Gym","Class","Heroes","and","Kid","Rock","performed","a","medley","of","their","songs","."],"labels":["O","O","O","O","B-musical artist","I-musical artist","O","B-musical artist","I-musical artist","I-musical artist","O","O","O","O","O","O","O","O","O","O","O","O","O","B-musical artist","I-musical artist","O","B-musical artist","O","B-band","I-band","I-band","O","B-musical artist","I-musical artist","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: band, person, organization, album, song, musical artist, event, music genre, location, award, country, musical instrument and O.\nSentence: They were inducted by Chuck D and LL Cool J on April 14 , 2012 therefore the group didn 't perform ; instead Black Thought , Travie from Gym Class Heroes and Kid Rock performed a medley of their songs .","prompt_labels":"They(O) were(O) inducted(O) by(O) Chuck(B-musical artist) D(I-musical artist) and(O) LL(B-musical artist) Cool(I-musical artist) J(I-musical artist) on(O) April(O) 14(O) ,(O) 2012(O) therefore(O) the(O) group(O) didn(O) 't(O) perform(O) ;(O) instead(O) Black(B-musical artist) Thought(I-musical artist) ,(O) Travie(B-musical artist) from(O) Gym(B-band) Class(I-band) Heroes(I-band) and(O) Kid(B-musical artist) Rock(I-musical artist) performed(O) a(O) medley(O) of(O) their(O) songs(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["location","organization","award","person","musical artist","album","band","country","musical instrument","song","event","music genre"],"instance":{"id":"189","words":["Following","in","the","footsteps","of","Gene","Autry",",","Lydia","Mendoza",",","Roy","Rogers",",","and","Patsy","Montana","."],"labels":["O","O","O","O","O","B-musical artist","I-musical artist","O","B-musical artist","I-musical artist","O","B-person","I-person","O","O","B-musical artist","I-musical artist","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, organization, award, person, musical artist, album, band, country, musical instrument, song, event, music genre and O.\nSentence: Following in the footsteps of Gene Autry , Lydia Mendoza , Roy Rogers , and Patsy Montana .","prompt_labels":"Following(O) in(O) the(O) footsteps(O) of(O) Gene(B-musical artist) Autry(I-musical artist) ,(O) Lydia(B-musical artist) Mendoza(I-musical artist) ,(O) Roy(B-person) Rogers(I-person) ,(O) and(O) Patsy(B-musical artist) Montana(I-musical artist) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["band","person","musical instrument","musical artist","song","award","organization","location","event","album","country","music genre"],"instance":{"id":"190","words":["It","was","nominated","for","four","Academy","Awards",",","including","Academy","Award","for","Best","Picture","and","Academy","Award","for","Best","Actor","(","De","Niro",")",",","and","received","the","Palme","d","'Or","at","the","1976","Cannes","Film","Festival","."],"labels":["O","O","O","O","O","B-award","I-award","O","O","B-award","I-award","I-award","I-award","I-award","O","B-award","I-award","I-award","I-award","I-award","O","B-person","I-person","O","O","O","O","O","B-award","I-award","I-award","O","O","B-event","I-event","I-event","I-event","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: band, person, musical instrument, musical artist, song, award, organization, location, event, album, country, music genre and O.\nSentence: It was nominated for four Academy Awards , including Academy Award for Best Picture and Academy Award for Best Actor ( De Niro ) , and received the Palme d 'Or at the 1976 Cannes Film Festival .","prompt_labels":"It(O) was(O) nominated(O) for(O) four(O) Academy(B-award) Awards(I-award) ,(O) including(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Picture(I-award) and(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Actor(I-award) ((O) De(B-person) Niro(I-person) )(O) ,(O) and(O) received(O) the(O) Palme(B-award) d(I-award) 'Or(I-award) at(O) the(O) 1976(B-event) Cannes(I-event) Film(I-event) Festival(I-event) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["location","album","event","country","song","band","organization","musical instrument","award","musical artist","music genre","person"],"instance":{"id":"191","words":["It","was","designed","by","Kenzo","Tange","and","built","between","1961","and","1964","to","house","Swimming","at","the","1964","Summer","Olympics","and","Diving","at","the","1964","Summer","Olympics","events","in","the","1964","Summer","Olympics","."],"labels":["O","O","O","O","B-person","I-person","O","O","O","O","O","O","O","O","O","O","O","B-event","I-event","I-event","O","O","O","O","B-event","I-event","I-event","O","O","O","B-event","I-event","I-event","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, album, event, country, song, band, organization, musical instrument, award, musical artist, music genre, person and O.\nSentence: It was designed by Kenzo Tange and built between 1961 and 1964 to house Swimming at the 1964 Summer Olympics and Diving at the 1964 Summer Olympics events in the 1964 Summer Olympics .","prompt_labels":"It(O) was(O) designed(O) by(O) Kenzo(B-person) Tange(I-person) and(O) built(O) between(O) 1961(O) and(O) 1964(O) to(O) house(O) Swimming(O) at(O) the(O) 1964(B-event) Summer(I-event) Olympics(I-event) and(O) Diving(O) at(O) the(O) 1964(B-event) Summer(I-event) Olympics(I-event) events(O) in(O) the(O) 1964(B-event) Summer(I-event) Olympics(I-event) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["music genre","musical artist","organization","location","album","person","musical instrument","country","song","event","band","award"],"instance":{"id":"192","words":["Grunge","began","as","a","mixture","of","Heavy","metal","music",",","punk","rock","and","indie","rock","in","the","1980s","and","gained","mainstream","prominence","in","the","early","1990s","."],"labels":["B-music genre","O","O","O","O","O","B-music genre","I-music genre","I-music genre","O","B-music genre","I-music genre","O","B-music genre","I-music genre","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: music genre, musical artist, organization, location, album, person, musical instrument, country, song, event, band, award and O.\nSentence: Grunge began as a mixture of Heavy metal music , punk rock and indie rock in the 1980s and gained mainstream prominence in the early 1990s .","prompt_labels":"Grunge(B-music genre) began(O) as(O) a(O) mixture(O) of(O) Heavy(B-music genre) metal(I-music genre) music(I-music genre) ,(O) punk(B-music genre) rock(I-music genre) and(O) indie(B-music genre) rock(I-music genre) in(O) the(O) 1980s(O) and(O) gained(O) mainstream(O) prominence(O) in(O) the(O) early(O) 1990s(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["location","music genre","musical instrument","award","person","album","organization","country","song","musical artist","event","band"],"instance":{"id":"193","words":["Of","the","other","seven","songs","that","were","on","the","British","release",",","two","were","released","on","the","US","version","of","the","next","Beatles","album",",","Rubber","Soul",",","two","were","back-to-back","on","the","next","US","single","and","then","appeared","on","Yesterday","and","Today",",","and","three","had","already","been","on","Beatles","VI","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-country","O","O","O","O","B-band","O","O","B-album","I-album","O","O","O","O","O","O","O","B-country","O","O","O","O","O","B-album","I-album","I-album","O","O","O","O","O","O","O","B-album","I-album","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, music genre, musical instrument, award, person, album, organization, country, song, musical artist, event, band and O.\nSentence: Of the other seven songs that were on the British release , two were released on the US version of the next Beatles album , Rubber Soul , two were back-to-back on the next US single and then appeared on Yesterday and Today , and three had already been on Beatles VI .","prompt_labels":"Of(O) the(O) other(O) seven(O) songs(O) that(O) were(O) on(O) the(O) British(O) release(O) ,(O) two(O) were(O) released(O) on(O) the(O) US(B-country) version(O) of(O) the(O) next(O) Beatles(B-band) album(O) ,(O) Rubber(B-album) Soul(I-album) ,(O) two(O) were(O) back-to-back(O) on(O) the(O) next(O) US(B-country) single(O) and(O) then(O) appeared(O) on(O) Yesterday(B-album) and(I-album) Today(I-album) ,(O) and(O) three(O) had(O) already(O) been(O) on(O) Beatles(B-album) VI(I-album) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["album","band","country","song","location","award","person","musical artist","event","music genre","musical instrument","organization"],"instance":{"id":"194","words":["He","was","the","guitarist","for","the","1980s","Hi-NRG",",","Synth-pop","band",",","Frankie","Goes","to","Hollywood","."],"labels":["O","O","O","O","O","O","O","B-music genre","O","B-music genre","O","O","B-band","I-band","I-band","I-band","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: album, band, country, song, location, award, person, musical artist, event, music genre, musical instrument, organization and O.\nSentence: He was the guitarist for the 1980s Hi-NRG , Synth-pop band , Frankie Goes to Hollywood .","prompt_labels":"He(O) was(O) the(O) guitarist(O) for(O) the(O) 1980s(O) Hi-NRG(B-music genre) ,(O) Synth-pop(B-music genre) band(O) ,(O) Frankie(B-band) Goes(I-band) to(I-band) Hollywood(I-band) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["country","organization","award","music genre","musical artist","album","song","musical instrument","person","band","location","event"],"instance":{"id":"195","words":["In","Legends","of","Guitar","(","filmed","live","in","Spain","in","1991",")",",","with","B.B.","King",",","Les","Paul",",","Albert","Collins",",","and","George","Benson",",","among","others","."],"labels":["O","O","O","O","O","O","O","O","B-country","O","O","O","O","O","B-musical artist","I-musical artist","O","B-musical artist","I-musical artist","O","B-musical artist","I-musical artist","O","O","B-musical artist","I-musical artist","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, organization, award, music genre, musical artist, album, song, musical instrument, person, band, location, event and O.\nSentence: In Legends of Guitar ( filmed live in Spain in 1991 ) , with B.B. King , Les Paul , Albert Collins , and George Benson , among others .","prompt_labels":"In(O) Legends(O) of(O) Guitar(O) ((O) filmed(O) live(O) in(O) Spain(B-country) in(O) 1991(O) )(O) ,(O) with(O) B.B.(B-musical artist) King(I-musical artist) ,(O) Les(B-musical artist) Paul(I-musical artist) ,(O) Albert(B-musical artist) Collins(I-musical artist) ,(O) and(O) George(B-musical artist) Benson(I-musical artist) ,(O) among(O) others(O) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["musical artist","event","music genre","musical instrument","person","organization","song","location","band","album","country","award"],"instance":{"id":"196","words":["In","July","2010",",","Dayne","released","Facing","a","Miracle",",","the","official","theme","song","to","the","2010","Gay","Games","."],"labels":["O","O","O","O","B-musical artist","O","B-song","I-song","I-song","O","O","O","O","O","O","O","B-event","I-event","I-event","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: musical artist, event, music genre, musical instrument, person, organization, song, location, band, album, country, award and O.\nSentence: In July 2010 , Dayne released Facing a Miracle , the official theme song to the 2010 Gay Games .","prompt_labels":"In(O) July(O) 2010(O) ,(O) Dayne(B-musical artist) released(O) Facing(B-song) a(I-song) Miracle(I-song) ,(O) the(O) official(O) theme(O) song(O) to(O) the(O) 2010(B-event) Gay(I-event) Games(I-event) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["country","song","album","band","organization","award","location","event","musical artist","person","musical instrument","music genre"],"instance":{"id":"197","words":["Mercury","wrote","numerous","hits","for","Queen",",","including","Killer","Queen",",","Bohemian","Rhapsody",",","Somebody","to","Love",",","We","Are","the","Champions",",","Don","'t","Stop","Me","Now",",","and","Crazy","Little","Thing","Called","Love","."],"labels":["B-musical artist","O","O","O","O","B-band","O","O","B-song","I-song","O","B-song","I-song","O","B-song","I-song","I-song","O","B-song","I-song","I-song","I-song","O","B-song","I-song","I-song","I-song","I-song","O","O","B-song","I-song","I-song","I-song","I-song","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, song, album, band, organization, award, location, event, musical artist, person, musical instrument, music genre and O.\nSentence: Mercury wrote numerous hits for Queen , including Killer Queen , Bohemian Rhapsody , Somebody to Love , We Are the Champions , Don 't Stop Me Now , and Crazy Little Thing Called Love .","prompt_labels":"Mercury(B-musical artist) wrote(O) numerous(O) hits(O) for(O) Queen(B-band) ,(O) including(O) Killer(B-song) Queen(I-song) ,(O) Bohemian(B-song) Rhapsody(I-song) ,(O) Somebody(B-song) to(I-song) Love(I-song) ,(O) We(B-song) Are(I-song) the(I-song) Champions(I-song) ,(O) Don(B-song) 't(I-song) Stop(I-song) Me(I-song) Now(I-song) ,(O) and(O) Crazy(B-song) Little(I-song) Thing(I-song) Called(I-song) Love(I-song) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["music genre","musical instrument","band","musical artist","country","organization","location","person","song","event","award","album"],"instance":{"id":"198","words":["Also",",","Bon","Jovi","had","a","hit","single",",","Who","Says","You","Can","'t","Go","Home",",","with","Jennifer","Nettles","of","Sugarland","."],"labels":["O","O","B-band","I-band","O","O","O","O","O","B-song","I-song","I-song","I-song","I-song","I-song","I-song","O","O","B-musical artist","I-musical artist","O","B-band","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: music genre, musical instrument, band, musical artist, country, organization, location, person, song, event, award, album and O.\nSentence: Also , Bon Jovi had a hit single , Who Says You Can 't Go Home , with Jennifer Nettles of Sugarland .","prompt_labels":"Also(O) ,(O) Bon(B-band) Jovi(I-band) had(O) a(O) hit(O) single(O) ,(O) Who(B-song) Says(I-song) You(I-song) Can(I-song) 't(I-song) Go(I-song) Home(I-song) ,(O) with(O) Jennifer(B-musical artist) Nettles(I-musical artist) of(O) Sugarland(B-band) .(O)"}}
{"dataset":"crossner_music","split":"dev","label_list":["album","country","organization","location","music genre","person","musical instrument","award","band","song","event","musical artist"],"instance":{"id":"199","words":["Scandinavia","n","punk","was","propelled","early","on","by","tour","dates","by","bands","such","as","the","Clash","and","the","Ramones","(","both","in","Stockholm","in","May","1977",")",",","and","the","Sex","Pistols","'","tour","through","Denmark",",","Sweden","and","Norway","in","July","the","same","year","."],"labels":["B-country","O","B-music genre","O","O","O","O","O","O","O","O","O","O","O","O","B-band","O","O","B-band","O","O","O","B-location","O","O","O","O","O","O","O","B-band","I-band","O","O","O","B-country","O","B-country","O","B-country","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: album, country, organization, location, music genre, person, musical instrument, award, band, song, event, musical artist and O.\nSentence: Scandinavia n punk was propelled early on by tour dates by bands such as the Clash and the Ramones ( both in Stockholm in May 1977 ) , and the Sex Pistols ' tour through Denmark , Sweden and Norway in July the same year .","prompt_labels":"Scandinavia(B-country) n(O) punk(B-music genre) was(O) propelled(O) early(O) on(O) by(O) tour(O) dates(O) by(O) bands(O) such(O) as(O) the(O) Clash(B-band) and(O) the(O) Ramones(B-band) ((O) both(O) in(O) Stockholm(B-location) in(O) May(O) 1977(O) )(O) ,(O) and(O) the(O) Sex(B-band) Pistols(I-band) '(O) tour(O) through(O) Denmark(B-country) ,(O) Sweden(B-country) and(O) Norway(B-country) in(O) July(O) the(O) same(O) year(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["location","event","election","person","politician","political party","organization","country"],"instance":{"id":"0","words":["At","the","2001","Italian","general","election","the","Greens","formed","a","joint","list","with","the","Italian","Democratic","Socialists","(","SDI",")",":","The","Sunflower","."],"labels":["O","O","B-election","I-election","I-election","I-election","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","O","B-political party","O","O","B-political party","I-political party","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, event, election, person, politician, political party, organization, country and O.\nSentence: At the 2001 Italian general election the Greens formed a joint list with the Italian Democratic Socialists ( SDI ) : The Sunflower .","prompt_labels":"At(O) the(O) 2001(B-election) Italian(I-election) general(I-election) election(I-election) the(O) Greens(O) formed(O) a(O) joint(O) list(O) with(O) the(O) Italian(B-political party) Democratic(I-political party) Socialists(I-political party) ((O) SDI(B-political party) )(O) :(O) The(B-political party) Sunflower(I-political party) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["country","location","person","political party","politician","organization","election","event"],"instance":{"id":"1","words":["For","the","2009","European","Parliament","election","in","Italy","the","Greens","formed","a","joint","list","with","the","Movement","for","the","Left","(","MpS",")","-","a","moderate","split","from","the","PRC","-",",","the","Socialist","Party","(","PS",")","-","successor","of","the","SDI","-",",","SD","and","Unite","the","Left","(","UlS",")",":","Left","Ecology","Freedom","(","SL",")","."],"labels":["O","O","B-election","I-election","I-election","I-election","I-election","I-election","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","I-political party","O","B-political party","O","O","O","O","O","O","O","B-political party","O","O","O","B-political party","I-political party","O","B-political party","O","O","O","O","O","B-political party","O","O","B-political party","O","B-political party","I-political party","I-political party","O","B-political party","O","O","B-political party","I-political party","I-political party","O","B-political party","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, location, person, political party, politician, organization, election, event and O.\nSentence: For the 2009 European Parliament election in Italy the Greens formed a joint list with the Movement for the Left ( MpS ) - a moderate split from the PRC - , the Socialist Party ( PS ) - successor of the SDI - , SD and Unite the Left ( UlS ) : Left Ecology Freedom ( SL ) .","prompt_labels":"For(O) the(O) 2009(B-election) European(I-election) Parliament(I-election) election(I-election) in(I-election) Italy(I-election) the(O) Greens(O) formed(O) a(O) joint(O) list(O) with(O) the(O) Movement(B-political party) for(I-political party) the(I-political party) Left(I-political party) ((O) MpS(B-political party) )(O) -(O) a(O) moderate(O) split(O) from(O) the(O) PRC(B-political party) -(O) ,(O) the(O) Socialist(B-political party) Party(I-political party) ((O) PS(B-political party) )(O) -(O) successor(O) of(O) the(O) SDI(B-political party) -(O) ,(O) SD(B-political party) and(O) Unite(B-political party) the(I-political party) Left(I-political party) ((O) UlS(B-political party) )(O) :(O) Left(B-political party) Ecology(I-political party) Freedom(I-political party) ((O) SL(B-political party) )(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["location","political party","country","person","event","organization","politician","election"],"instance":{"id":"2","words":["Sitting","as","a","Liberal","Party","of","Canada","Member","of","Parliament","(","MP",")","for","Niagara","Falls",",","she","joined","the","Canadian","Cabinet","after","the","Liberals","defeated","the","Progressive","Conservative","Party","of","Canada","government","of","John","Diefenbaker","in","the","1963","Canadian","federal","election","."],"labels":["O","O","O","B-political party","I-political party","I-political party","I-political party","O","O","B-organization","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","O","O","B-politician","I-politician","O","O","B-election","I-election","I-election","I-election","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, political party, country, person, event, organization, politician, election and O.\nSentence: Sitting as a Liberal Party of Canada Member of Parliament ( MP ) for Niagara Falls , she joined the Canadian Cabinet after the Liberals defeated the Progressive Conservative Party of Canada government of John Diefenbaker in the 1963 Canadian federal election .","prompt_labels":"Sitting(O) as(O) a(O) Liberal(B-political party) Party(I-political party) of(I-political party) Canada(I-political party) Member(O) of(O) Parliament(B-organization) ((O) MP(O) )(O) for(O) Niagara(O) Falls(O) ,(O) she(O) joined(O) the(O) Canadian(O) Cabinet(O) after(O) the(O) Liberals(O) defeated(O) the(O) Progressive(B-political party) Conservative(I-political party) Party(I-political party) of(I-political party) Canada(I-political party) government(O) of(O) John(B-politician) Diefenbaker(I-politician) in(O) the(O) 1963(B-election) Canadian(I-election) federal(I-election) election(I-election) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["election","organization","person","country","political party","location","politician","event"],"instance":{"id":"3","words":["The","MRE","took","part","to","the","consolidation","of","The","Olive","Tree","as","a","joint","electoral","list","both","for","the","2004","European","Parliament","election","and","the","2006","Italian","general","election",",","along","with","the","Democrats","of","the","Left","and","Democracy","is","Freedom","-","The","Daisy","."],"labels":["O","B-political party","O","O","O","O","O","O","B-organization","I-organization","I-organization","O","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","O","O","B-election","I-election","I-election","I-election","O","O","O","O","B-political party","I-political party","I-political party","I-political party","O","B-political party","I-political party","I-political party","I-political party","I-political party","I-political party","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: election, organization, person, country, political party, location, politician, event and O.\nSentence: The MRE took part to the consolidation of The Olive Tree as a joint electoral list both for the 2004 European Parliament election and the 2006 Italian general election , along with the Democrats of the Left and Democracy is Freedom - The Daisy .","prompt_labels":"The(O) MRE(B-political party) took(O) part(O) to(O) the(O) consolidation(O) of(O) The(B-organization) Olive(I-organization) Tree(I-organization) as(O) a(O) joint(O) electoral(O) list(O) both(O) for(O) the(O) 2004(B-election) European(I-election) Parliament(I-election) election(I-election) and(O) the(O) 2006(B-election) Italian(I-election) general(I-election) election(I-election) ,(O) along(O) with(O) the(O) Democrats(B-political party) of(I-political party) the(I-political party) Left(I-political party) and(O) Democracy(B-political party) is(I-political party) Freedom(I-political party) -(I-political party) The(I-political party) Daisy(I-political party) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["organization","politician","person","event","political party","country","election","location"],"instance":{"id":"4","words":["They","include","the","records","of","the","Federal","Secretariats","of","the","Liberal","party",",","the","Australian","Labor","Party",",","the","Democrats",",","the","Returned","and","Services","League","of","Australia",",","the","Australian","Inland","Mission",",","the","Australian","Union","of","Students",",","The","Australian","Ballet",",","the","Australian","Elizabethan","Theatre","Trust",",","the","Australian","Institute","of","Urban","Studies",",","Australian","Industries","Protection","League",",","the","Australian","Conservation","Foundation",",","and","the","Australian","Council","of","National","Trusts","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-political party","I-political party","O","O","B-political party","I-political party","I-political party","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","O","O","B-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","B-organization","I-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, politician, person, event, political party, country, election, location and O.\nSentence: They include the records of the Federal Secretariats of the Liberal party , the Australian Labor Party , the Democrats , the Returned and Services League of Australia , the Australian Inland Mission , the Australian Union of Students , The Australian Ballet , the Australian Elizabethan Theatre Trust , the Australian Institute of Urban Studies , Australian Industries Protection League , the Australian Conservation Foundation , and the Australian Council of National Trusts .","prompt_labels":"They(O) include(O) the(O) records(O) of(O) the(O) Federal(O) Secretariats(O) of(O) the(O) Liberal(B-political party) party(I-political party) ,(O) the(O) Australian(B-political party) Labor(I-political party) Party(I-political party) ,(O) the(O) Democrats(O) ,(O) the(O) Returned(B-organization) and(I-organization) Services(I-organization) League(I-organization) of(I-organization) Australia(I-organization) ,(O) the(O) Australian(B-organization) Inland(I-organization) Mission(I-organization) ,(O) the(O) Australian(B-organization) Union(I-organization) of(I-organization) Students(I-organization) ,(O) The(O) Australian(B-organization) Ballet(I-organization) ,(O) the(O) Australian(B-organization) Elizabethan(I-organization) Theatre(I-organization) Trust(I-organization) ,(O) the(O) Australian(B-organization) Institute(I-organization) of(I-organization) Urban(I-organization) Studies(I-organization) ,(O) Australian(B-organization) Industries(I-organization) Protection(I-organization) League(I-organization) ,(O) the(O) Australian(B-organization) Conservation(I-organization) Foundation(I-organization) ,(O) and(O) the(O) Australian(B-organization) Council(I-organization) of(I-organization) National(I-organization) Trusts(I-organization) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["politician","country","organization","event","election","political party","location","person"],"instance":{"id":"5","words":["Prior","to","the","1992","elections","Shinui","merged","with","Shulamit","Aloni","'","s","Ratz","and","Zionist","-","socialist","Mapam","to","form","Meretz",",","a","dovish",",","social-democratic","liberal","party","."],"labels":["O","O","O","O","O","B-political party","O","O","B-person","I-person","O","O","B-political party","O","O","O","O","B-political party","O","O","B-political party","O","O","O","O","O","B-political party","I-political party","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: politician, country, organization, event, election, political party, location, person and O.\nSentence: Prior to the 1992 elections Shinui merged with Shulamit Aloni ' s Ratz and Zionist - socialist Mapam to form Meretz , a dovish , social-democratic liberal party .","prompt_labels":"Prior(O) to(O) the(O) 1992(O) elections(O) Shinui(B-political party) merged(O) with(O) Shulamit(B-person) Aloni(I-person) '(O) s(O) Ratz(B-political party) and(O) Zionist(O) -(O) socialist(O) Mapam(B-political party) to(O) form(O) Meretz(B-political party) ,(O) a(O) dovish(O) ,(O) social-democratic(O) liberal(B-political party) party(I-political party) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["location","country","political party","politician","organization","election","person","event"],"instance":{"id":"6","words":["Their","destinies","are","all","altered","and","shaped","by","the","historical","event","(","for","example",":","Simard","becomes","a","sovereigntist","and","will","leave","the","Quebec","Liberal","Party","for","the","Parti","Qubcois",";","Dumont","will","also","slam","the","Liberal","door","to","later","help","create","and","finally","become","leader","of","the","Action","dmocratique","du","Qubec",",","or","ADQ",",","and","support","the","Yes","side","of","the","1995","referendum","on","independence",")","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-politician","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","O","O","B-political party","I-political party","O","B-politician","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","I-political party","O","O","B-political party","O","O","O","O","O","O","O","O","B-event","I-event","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, country, political party, politician, organization, election, person, event and O.\nSentence: Their destinies are all altered and shaped by the historical event ( for example : Simard becomes a sovereigntist and will leave the Quebec Liberal Party for the Parti Qubcois ; Dumont will also slam the Liberal door to later help create and finally become leader of the Action dmocratique du Qubec , or ADQ , and support the Yes side of the 1995 referendum on independence ) .","prompt_labels":"Their(O) destinies(O) are(O) all(O) altered(O) and(O) shaped(O) by(O) the(O) historical(O) event(O) ((O) for(O) example(O) :(O) Simard(B-politician) becomes(O) a(O) sovereigntist(O) and(O) will(O) leave(O) the(O) Quebec(B-political party) Liberal(I-political party) Party(I-political party) for(O) the(O) Parti(B-political party) Qubcois(I-political party) ;(O) Dumont(B-politician) will(O) also(O) slam(O) the(O) Liberal(O) door(O) to(O) later(O) help(O) create(O) and(O) finally(O) become(O) leader(O) of(O) the(O) Action(B-political party) dmocratique(I-political party) du(I-political party) Qubec(I-political party) ,(O) or(O) ADQ(B-political party) ,(O) and(O) support(O) the(O) Yes(O) side(O) of(O) the(O) 1995(B-event) referendum(I-event) on(O) independence(O) )(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["person","political party","country","politician","election","location","event","organization"],"instance":{"id":"7","words":["Of","the","current","first","ministers",",","four","are","from","a","Liberal","Party",",","four","are","from","a","Progressive","Conservative","Party",",","and","one","is","from","a","New","Democratic","Party",";","three","others","are","from","local","parties","(","the","Coalition","Avenir","Qubec",",","the","Saskatchewan","Party",",","and","the","United","Conservative","Party",")","and","two","are","non-partisan","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-political party","I-political party","O","O","O","O","O","B-political party","I-political party","I-political party","O","O","O","O","O","O","B-political party","I-political party","I-political party","O","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","O","O","B-political party","I-political party","O","O","O","B-political party","I-political party","I-political party","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, political party, country, politician, election, location, event, organization and O.\nSentence: Of the current first ministers , four are from a Liberal Party , four are from a Progressive Conservative Party , and one is from a New Democratic Party ; three others are from local parties ( the Coalition Avenir Qubec , the Saskatchewan Party , and the United Conservative Party ) and two are non-partisan .","prompt_labels":"Of(O) the(O) current(O) first(O) ministers(O) ,(O) four(O) are(O) from(O) a(O) Liberal(B-political party) Party(I-political party) ,(O) four(O) are(O) from(O) a(O) Progressive(B-political party) Conservative(I-political party) Party(I-political party) ,(O) and(O) one(O) is(O) from(O) a(O) New(B-political party) Democratic(I-political party) Party(I-political party) ;(O) three(O) others(O) are(O) from(O) local(O) parties(O) ((O) the(O) Coalition(B-political party) Avenir(I-political party) Qubec(I-political party) ,(O) the(O) Saskatchewan(B-political party) Party(I-political party) ,(O) and(O) the(O) United(B-political party) Conservative(I-political party) Party(I-political party) )(O) and(O) two(O) are(O) non-partisan(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["event","country","election","location","politician","political party","person","organization"],"instance":{"id":"8","words":["MoveOn","also","joined","with","14","other","organization","to","form","the","Win","Without","War","coalition",",","which","also","included","the","National","Council","of","Churches",",","the","National","Association","for","the","Advancement","of","Colored","People",",","and","the","National","Organization","for","Women","."],"labels":["B-organization","O","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","O","O","B-organization","I-organization","I-organization","I-organization","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, country, election, location, politician, political party, person, organization and O.\nSentence: MoveOn also joined with 14 other organization to form the Win Without War coalition , which also included the National Council of Churches , the National Association for the Advancement of Colored People , and the National Organization for Women .","prompt_labels":"MoveOn(B-organization) also(O) joined(O) with(O) 14(O) other(O) organization(O) to(O) form(O) the(O) Win(B-organization) Without(I-organization) War(I-organization) coalition(O) ,(O) which(O) also(O) included(O) the(O) National(B-organization) Council(I-organization) of(I-organization) Churches(I-organization) ,(O) the(O) National(B-organization) Association(I-organization) for(I-organization) the(I-organization) Advancement(I-organization) of(I-organization) Colored(I-organization) People(I-organization) ,(O) and(O) the(O) National(B-organization) Organization(I-organization) for(I-organization) Women(I-organization) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["election","political party","organization","politician","event","location","person","country"],"instance":{"id":"9","words":["He","stood","for","the","Green","party","in","Oxford","West","and","Abingdon","in","the","1992","United","Kingdom","general","election",",","1997","United","Kingdom","general","election",",","and","2001","United","Kingdom","general","election","general","elections","."],"labels":["O","O","O","O","B-political party","I-political party","O","B-organization","I-organization","I-organization","I-organization","O","O","B-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","O","O","B-election","I-election","I-election","I-election","I-election","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: election, political party, organization, politician, event, location, person, country and O.\nSentence: He stood for the Green party in Oxford West and Abingdon in the 1992 United Kingdom general election , 1997 United Kingdom general election , and 2001 United Kingdom general election general elections .","prompt_labels":"He(O) stood(O) for(O) the(O) Green(B-political party) party(I-political party) in(O) Oxford(B-organization) West(I-organization) and(I-organization) Abingdon(I-organization) in(O) the(O) 1992(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) 1997(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) and(O) 2001(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) general(O) elections(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["country","organization","location","politician","political party","event","person","election"],"instance":{"id":"10","words":["He","was","a","trustee","of","the","Center","for","Strategic","and","International","Studies","and","The","Forum","for","International","Policy",",","and","was","a","member","of","the","Council","on","Foreign","Relations","and","the","Trilateral","Commission","."],"labels":["O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O","O","B-organization","I-organization","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, organization, location, politician, political party, event, person, election and O.\nSentence: He was a trustee of the Center for Strategic and International Studies and The Forum for International Policy , and was a member of the Council on Foreign Relations and the Trilateral Commission .","prompt_labels":"He(O) was(O) a(O) trustee(O) of(O) the(O) Center(B-organization) for(I-organization) Strategic(I-organization) and(I-organization) International(I-organization) Studies(I-organization) and(O) The(B-organization) Forum(I-organization) for(I-organization) International(I-organization) Policy(I-organization) ,(O) and(O) was(O) a(O) member(O) of(O) the(O) Council(B-organization) on(I-organization) Foreign(I-organization) Relations(I-organization) and(O) the(O) Trilateral(B-organization) Commission(I-organization) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["organization","country","election","person","politician","political party","event","location"],"instance":{"id":"11","words":["In","the","February","1974","United","Kingdom","general","election","a","number","of","Faulkner","'s","followers","(","including","several","sitting","MPs",")","stood","as","Pro-Assembly","Unionists","against","a","coalition","of","the","Ulster","Unionist","Party",",","the","Vanguard","Progressive","Unionist","Party","and","the","Democratic","Unionist","Party","."],"labels":["O","O","B-election","I-election","I-election","I-election","I-election","I-election","O","O","O","B-politician","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","O","O","B-political party","I-political party","I-political party","I-political party","O","O","B-political party","I-political party","I-political party","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, country, election, person, politician, political party, event, location and O.\nSentence: In the February 1974 United Kingdom general election a number of Faulkner 's followers ( including several sitting MPs ) stood as Pro-Assembly Unionists against a coalition of the Ulster Unionist Party , the Vanguard Progressive Unionist Party and the Democratic Unionist Party .","prompt_labels":"In(O) the(O) February(B-election) 1974(I-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) a(O) number(O) of(O) Faulkner(B-politician) 's(O) followers(O) ((O) including(O) several(O) sitting(O) MPs(O) )(O) stood(O) as(O) Pro-Assembly(O) Unionists(O) against(O) a(O) coalition(O) of(O) the(O) Ulster(B-political party) Unionist(I-political party) Party(I-political party) ,(O) the(O) Vanguard(B-political party) Progressive(I-political party) Unionist(I-political party) Party(I-political party) and(O) the(O) Democratic(B-political party) Unionist(I-political party) Party(I-political party) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["political party","organization","event","location","election","country","person","politician"],"instance":{"id":"12","words":["Examples","of","some","successful","testimonial","parties","are","the","Party","for","the","Animals",",","the","Reformed","Political","Party",",","or","the","former","Pacifist","Socialist","Party","."],"labels":["O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","I-political party","O","O","B-political party","I-political party","I-political party","O","O","O","O","B-political party","I-political party","I-political party","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: political party, organization, event, location, election, country, person, politician and O.\nSentence: Examples of some successful testimonial parties are the Party for the Animals , the Reformed Political Party , or the former Pacifist Socialist Party .","prompt_labels":"Examples(O) of(O) some(O) successful(O) testimonial(O) parties(O) are(O) the(O) Party(B-political party) for(I-political party) the(I-political party) Animals(I-political party) ,(O) the(O) Reformed(B-political party) Political(I-political party) Party(I-political party) ,(O) or(O) the(O) former(O) Pacifist(B-political party) Socialist(I-political party) Party(I-political party) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["person","politician","organization","location","political party","election","country","event"],"instance":{"id":"13","words":["In","Australia",",","a","number","of","single","issue","parties","have","been","elected","to","federal","and","state","parliaments","such","as","the","Animal","Justice","Party",",","Dignity","for","Disability",",","Australian","Motoring","Enthusiast","Party","and","the","Australian","Sex","Party","."],"labels":["O","B-country","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","O","B-political party","I-political party","I-political party","O","B-political party","I-political party","I-political party","I-political party","O","O","B-political party","I-political party","I-political party","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, politician, organization, location, political party, election, country, event and O.\nSentence: In Australia , a number of single issue parties have been elected to federal and state parliaments such as the Animal Justice Party , Dignity for Disability , Australian Motoring Enthusiast Party and the Australian Sex Party .","prompt_labels":"In(O) Australia(B-country) ,(O) a(O) number(O) of(O) single(O) issue(O) parties(O) have(O) been(O) elected(O) to(O) federal(O) and(O) state(O) parliaments(O) such(O) as(O) the(O) Animal(B-political party) Justice(I-political party) Party(I-political party) ,(O) Dignity(B-political party) for(I-political party) Disability(I-political party) ,(O) Australian(B-political party) Motoring(I-political party) Enthusiast(I-political party) Party(I-political party) and(O) the(O) Australian(B-political party) Sex(I-political party) Party(I-political party) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["election","country","politician","political party","person","event","organization","location"],"instance":{"id":"14","words":["In","the","United","States",",","such","voter","turnout","organizations","include","the","League","of","Women","Voters",",","Rock","the","Vote",",","The","Voter","Participation","Center","and","Vote.org",",","which","attempt","to","motivate","potential","voters","to","register","and","to","vote","in","the","belief","that","failure","of","any","eligible","voter","to","vote","in","any","election","is","a","loss","to","society","."],"labels":["O","O","B-country","I-country","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O","B-organization","I-organization","I-organization","O","B-organization","I-organization","I-organization","I-organization","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: election, country, politician, political party, person, event, organization, location and O.\nSentence: In the United States , such voter turnout organizations include the League of Women Voters , Rock the Vote , The Voter Participation Center and Vote.org , which attempt to motivate potential voters to register and to vote in the belief that failure of any eligible voter to vote in any election is a loss to society .","prompt_labels":"In(O) the(O) United(B-country) States(I-country) ,(O) such(O) voter(O) turnout(O) organizations(O) include(O) the(O) League(B-organization) of(I-organization) Women(I-organization) Voters(I-organization) ,(O) Rock(B-organization) the(I-organization) Vote(I-organization) ,(O) The(B-organization) Voter(I-organization) Participation(I-organization) Center(I-organization) and(O) Vote.org(O) ,(O) which(O) attempt(O) to(O) motivate(O) potential(O) voters(O) to(O) register(O) and(O) to(O) vote(O) in(O) the(O) belief(O) that(O) failure(O) of(O) any(O) eligible(O) voter(O) to(O) vote(O) in(O) any(O) election(O) is(O) a(O) loss(O) to(O) society(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["person","event","political party","politician","election","country","organization","location"],"instance":{"id":"15","words":["The","decline","was","evident","even","before","the","1981","Northern","Ireland","local","elections","as","4","of","the","12","UUUP","councillors","elected","in","1977","Northern","Ireland","local","elections","had","defected","to","other","Unionist","parties","(","2","to","UUP",",","1","to","DUP","and","1","to","the","Ulster","Popular","Unionist","Party",")","."],"labels":["O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","O","O","O","O","O","B-political party","O","O","O","B-election","I-election","I-election","I-election","I-election","O","O","O","O","O","O","O","O","O","B-political party","O","O","O","B-political party","B-political party","O","O","O","B-political party","I-political party","I-political party","I-political party","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, event, political party, politician, election, country, organization, location and O.\nSentence: The decline was evident even before the 1981 Northern Ireland local elections as 4 of the 12 UUUP councillors elected in 1977 Northern Ireland local elections had defected to other Unionist parties ( 2 to UUP , 1 to DUP and 1 to the Ulster Popular Unionist Party ) .","prompt_labels":"The(O) decline(O) was(O) evident(O) even(O) before(O) the(O) 1981(B-election) Northern(I-election) Ireland(I-election) local(I-election) elections(I-election) as(O) 4(O) of(O) the(O) 12(O) UUUP(B-political party) councillors(O) elected(O) in(O) 1977(B-election) Northern(I-election) Ireland(I-election) local(I-election) elections(I-election) had(O) defected(O) to(O) other(O) Unionist(O) parties(O) ((O) 2(O) to(O) UUP(B-political party) ,(O) 1(O) to(O) DUP(B-political party) and(B-political party) 1(O) to(O) the(O) Ulster(B-political party) Popular(I-political party) Unionist(I-political party) Party(I-political party) )(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["person","event","country","organization","politician","election","location","political party"],"instance":{"id":"16","words":["It","emerged","in","1992","when","the","old","Sammarinese","Communist","Party","evolved","into","the","Sammarinese","Democratic","Progressive","Party","and","some","members",",","on","the","example","of","the","Italian","Communist","Refoundation","Party",",","decided","not","to","join","the","new","party","."],"labels":["O","O","O","O","O","O","O","B-political party","I-political party","I-political party","O","O","O","B-political party","I-political party","I-political party","I-political party","O","O","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, event, country, organization, politician, election, location, political party and O.\nSentence: It emerged in 1992 when the old Sammarinese Communist Party evolved into the Sammarinese Democratic Progressive Party and some members , on the example of the Italian Communist Refoundation Party , decided not to join the new party .","prompt_labels":"It(O) emerged(O) in(O) 1992(O) when(O) the(O) old(O) Sammarinese(B-political party) Communist(I-political party) Party(I-political party) evolved(O) into(O) the(O) Sammarinese(B-political party) Democratic(I-political party) Progressive(I-political party) Party(I-political party) and(O) some(O) members(O) ,(O) on(O) the(O) example(O) of(O) the(O) Italian(O) Communist(B-political party) Refoundation(I-political party) Party(I-political party) ,(O) decided(O) not(O) to(O) join(O) the(O) new(O) party(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["country","event","organization","politician","location","person","political party","election"],"instance":{"id":"17","words":["The","Conservative","Party","of","Canada","took","back","this","historically","New","Democratic","Party","(","NDP",")","seat","in","2004","Canadian","federal","election","."],"labels":["O","B-political party","I-political party","I-political party","I-political party","O","O","O","O","B-political party","I-political party","I-political party","O","B-political party","O","O","O","B-election","I-election","I-election","I-election","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, event, organization, politician, location, person, political party, election and O.\nSentence: The Conservative Party of Canada took back this historically New Democratic Party ( NDP ) seat in 2004 Canadian federal election .","prompt_labels":"The(O) Conservative(B-political party) Party(I-political party) of(I-political party) Canada(I-political party) took(O) back(O) this(O) historically(O) New(B-political party) Democratic(I-political party) Party(I-political party) ((O) NDP(B-political party) )(O) seat(O) in(O) 2004(B-election) Canadian(I-election) federal(I-election) election(I-election) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["person","politician","organization","location","event","election","country","political party"],"instance":{"id":"18","words":["In","the","2012","Ukrainian","parliamentary","election",",","2014","Ukrainian","parliamentary","election","and","2019","Ukrainian","parliamentary","election","elections"],"labels":["O","O","B-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, politician, organization, location, event, election, country, political party and O.\nSentence: In the 2012 Ukrainian parliamentary election , 2014 Ukrainian parliamentary election and 2019 Ukrainian parliamentary election elections","prompt_labels":"In(O) the(O) 2012(B-election) Ukrainian(I-election) parliamentary(I-election) election(I-election) ,(O) 2014(B-election) Ukrainian(I-election) parliamentary(I-election) election(I-election) and(O) 2019(B-election) Ukrainian(I-election) parliamentary(I-election) election(I-election) elections(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["event","location","organization","political party","country","person","election","politician"],"instance":{"id":"19","words":["In","November","2017",",","the","RI","formed",",","along","with","Della","Vedova","'s","Forza","Europa","(","FE",")","and","some","members","of","the","Civics","and","Innovators","(","CI",")",",","More","Europe","(","+","Eu",")",",","a","pro-Europeanist","list","for","the","2018","Italian","general","election",",","led","by","Bonino","."],"labels":["O","O","O","O","O","B-political party","O","O","O","O","B-politician","I-politician","O","B-political party","I-political party","O","B-political party","O","O","O","O","O","O","B-political party","I-political party","I-political party","O","B-political party","O","O","B-political party","I-political party","O","B-political party","I-political party","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","O","O","O","B-politician","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, location, organization, political party, country, person, election, politician and O.\nSentence: In November 2017 , the RI formed , along with Della Vedova 's Forza Europa ( FE ) and some members of the Civics and Innovators ( CI ) , More Europe ( + Eu ) , a pro-Europeanist list for the 2018 Italian general election , led by Bonino .","prompt_labels":"In(O) November(O) 2017(O) ,(O) the(O) RI(B-political party) formed(O) ,(O) along(O) with(O) Della(B-politician) Vedova(I-politician) 's(O) Forza(B-political party) Europa(I-political party) ((O) FE(B-political party) )(O) and(O) some(O) members(O) of(O) the(O) Civics(B-political party) and(I-political party) Innovators(I-political party) ((O) CI(B-political party) )(O) ,(O) More(B-political party) Europe(I-political party) ((O) +(B-political party) Eu(I-political party) )(O) ,(O) a(O) pro-Europeanist(O) list(O) for(O) the(O) 2018(B-election) Italian(I-election) general(I-election) election(I-election) ,(O) led(O) by(O) Bonino(B-politician) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["country","person","event","election","politician","organization","location","political party"],"instance":{"id":"20","words":["LIBRA","then","ran","in","the","2003","Croatian","parliamentary","election","as","a","junior","partner","in","a","centre-left","coalition","with","Social","Democratic","Party","of","Croatia","(","SDP",")",",","Istrian","Democratic","Assembly","(","IDS",")","and","the","Liberal","Party","(","LS",")","."],"labels":["B-politician","O","O","O","O","B-election","I-election","I-election","I-election","O","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","O","B-political party","O","O","B-political party","I-political party","I-political party","O","B-political party","O","O","O","B-political party","I-political party","O","B-political party","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, person, event, election, politician, organization, location, political party and O.\nSentence: LIBRA then ran in the 2003 Croatian parliamentary election as a junior partner in a centre-left coalition with Social Democratic Party of Croatia ( SDP ) , Istrian Democratic Assembly ( IDS ) and the Liberal Party ( LS ) .","prompt_labels":"LIBRA(B-politician) then(O) ran(O) in(O) the(O) 2003(B-election) Croatian(I-election) parliamentary(I-election) election(I-election) as(O) a(O) junior(O) partner(O) in(O) a(O) centre-left(O) coalition(O) with(O) Social(B-political party) Democratic(I-political party) Party(I-political party) of(I-political party) Croatia(I-political party) ((O) SDP(B-political party) )(O) ,(O) Istrian(B-political party) Democratic(I-political party) Assembly(I-political party) ((O) IDS(B-political party) )(O) and(O) the(O) Liberal(B-political party) Party(I-political party) ((O) LS(B-political party) )(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["event","person","location","politician","organization","country","political party","election"],"instance":{"id":"21","words":["A","Blue","Tory","is",",","in","Canada","politics",",","a","conservative","who","advocates","free-market","or","economically","liberal","policies","..","The","term","has","been","applied","to","members","of","the","modern","Conservative","Party","of","Canada","and","provincial","Progressive","Conservative","parties",",","as","well","as","the","historical","Progressive","Conservative","Party","of","Canada",",","Reform","Party","of","Canada","and","Canadian","Alliance","."],"labels":["O","B-political party","I-political party","O","O","O","B-country","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","I-political party","O","O","O","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","O","B-political party","I-political party","I-political party","I-political party","O","B-political party","I-political party","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, person, location, politician, organization, country, political party, election and O.\nSentence: A Blue Tory is , in Canada politics , a conservative who advocates free-market or economically liberal policies .. The term has been applied to members of the modern Conservative Party of Canada and provincial Progressive Conservative parties , as well as the historical Progressive Conservative Party of Canada , Reform Party of Canada and Canadian Alliance .","prompt_labels":"A(O) Blue(B-political party) Tory(I-political party) is(O) ,(O) in(O) Canada(B-country) politics(O) ,(O) a(O) conservative(O) who(O) advocates(O) free-market(O) or(O) economically(O) liberal(O) policies(O) ..(O) The(O) term(O) has(O) been(O) applied(O) to(O) members(O) of(O) the(O) modern(O) Conservative(B-political party) Party(I-political party) of(I-political party) Canada(I-political party) and(O) provincial(O) Progressive(O) Conservative(O) parties(O) ,(O) as(O) well(O) as(O) the(O) historical(O) Progressive(B-political party) Conservative(I-political party) Party(I-political party) of(I-political party) Canada(I-political party) ,(O) Reform(B-political party) Party(I-political party) of(I-political party) Canada(I-political party) and(O) Canadian(B-political party) Alliance(I-political party) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["event","organization","politician","political party","person","country","election","location"],"instance":{"id":"22","words":["For","the","2016","Belarusian","parliamentary","election",",","the","party","formed","an","alliance","with","the","BPF","Party",",","the","Belarusian","Christian","Democracy",",","the","Social","Democratic","Party","(","Assembly",")",",","the","'","Za","svabodu","'","movement",",","the","Belarusian","Green","Party",",","the","Belarusian","Liberal","Party","of","Freedom","and","Progress",",","the","Trade","Union","of","Electric","Industry","and","independent","candidates","."],"labels":["O","O","B-election","I-election","I-election","I-election","O","O","O","O","O","O","O","O","B-political party","I-political party","O","O","B-political party","I-political party","I-political party","O","O","B-political party","I-political party","I-political party","O","B-political party","O","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","O","O","B-political party","I-political party","I-political party","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","I-political party","I-political party","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, organization, politician, political party, person, country, election, location and O.\nSentence: For the 2016 Belarusian parliamentary election , the party formed an alliance with the BPF Party , the Belarusian Christian Democracy , the Social Democratic Party ( Assembly ) , the ' Za svabodu ' movement , the Belarusian Green Party , the Belarusian Liberal Party of Freedom and Progress , the Trade Union of Electric Industry and independent candidates .","prompt_labels":"For(O) the(O) 2016(B-election) Belarusian(I-election) parliamentary(I-election) election(I-election) ,(O) the(O) party(O) formed(O) an(O) alliance(O) with(O) the(O) BPF(B-political party) Party(I-political party) ,(O) the(O) Belarusian(B-political party) Christian(I-political party) Democracy(I-political party) ,(O) the(O) Social(B-political party) Democratic(I-political party) Party(I-political party) ((O) Assembly(B-political party) )(O) ,(O) the(O) '(B-political party) Za(I-political party) svabodu(I-political party) '(I-political party) movement(I-political party) ,(O) the(O) Belarusian(B-political party) Green(I-political party) Party(I-political party) ,(O) the(O) Belarusian(B-political party) Liberal(I-political party) Party(I-political party) of(I-political party) Freedom(I-political party) and(I-political party) Progress(I-political party) ,(O) the(O) Trade(B-political party) Union(I-political party) of(I-political party) Electric(I-political party) Industry(I-political party) and(O) independent(O) candidates(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["location","country","organization","politician","political party","election","person","event"],"instance":{"id":"23","words":["It","was","succeeded","in","the","Flemish","Community","of","Belgium","by","the","Open","Vlaamse","Liberalen","en","Democraten","(","VLD",")","and","in","the","French","Community","by","the","Liberal","Reformist","Party",",","Parti","des","Rformes","et","des","Liberts","de","Wallonie","and","the","current-day","Mouvement","Rformateur","."],"labels":["O","O","O","O","O","B-organization","I-organization","O","B-location","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","O","B-political party","O","O","O","O","B-country","I-country","O","O","B-political party","I-political party","I-political party","O","B-political party","I-political party","I-political party","I-political party","I-political party","I-political party","I-political party","I-political party","O","O","O","B-political party","I-political party","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, country, organization, politician, political party, election, person, event and O.\nSentence: It was succeeded in the Flemish Community of Belgium by the Open Vlaamse Liberalen en Democraten ( VLD ) and in the French Community by the Liberal Reformist Party , Parti des Rformes et des Liberts de Wallonie and the current-day Mouvement Rformateur .","prompt_labels":"It(O) was(O) succeeded(O) in(O) the(O) Flemish(B-organization) Community(I-organization) of(O) Belgium(B-location) by(O) the(O) Open(B-political party) Vlaamse(I-political party) Liberalen(I-political party) en(I-political party) Democraten(I-political party) ((O) VLD(B-political party) )(O) and(O) in(O) the(O) French(B-country) Community(I-country) by(O) the(O) Liberal(B-political party) Reformist(I-political party) Party(I-political party) ,(O) Parti(B-political party) des(I-political party) Rformes(I-political party) et(I-political party) des(I-political party) Liberts(I-political party) de(I-political party) Wallonie(I-political party) and(O) the(O) current-day(O) Mouvement(B-political party) Rformateur(I-political party) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["politician","political party","election","country","location","organization","event","person"],"instance":{"id":"24","words":["In","March","2002","the","PRL","merged","with","the","German-speaking","Partei","fr","Freiheit","und","Fortschritt","(","PFF",")","of","the","East","Cantons",",","the","Democratic","Front","of","Francophones","(","FDF",")","and","the","Mouvement","des","Citoyens","pour","le","Changement","(","MCC",")","into","the","Mouvement","Rformateur","(","MR",")","."],"labels":["O","O","O","O","B-political party","O","O","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","O","B-political party","O","O","O","B-political party","I-political party","O","O","B-political party","I-political party","I-political party","I-political party","O","B-political party","O","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","I-political party","O","B-political party","O","O","O","B-political party","I-political party","O","B-political party","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: politician, political party, election, country, location, organization, event, person and O.\nSentence: In March 2002 the PRL merged with the German-speaking Partei fr Freiheit und Fortschritt ( PFF ) of the East Cantons , the Democratic Front of Francophones ( FDF ) and the Mouvement des Citoyens pour le Changement ( MCC ) into the Mouvement Rformateur ( MR ) .","prompt_labels":"In(O) March(O) 2002(O) the(O) PRL(B-political party) merged(O) with(O) the(O) German-speaking(O) Partei(B-political party) fr(I-political party) Freiheit(I-political party) und(I-political party) Fortschritt(I-political party) ((O) PFF(B-political party) )(O) of(O) the(O) East(B-political party) Cantons(I-political party) ,(O) the(O) Democratic(B-political party) Front(I-political party) of(I-political party) Francophones(I-political party) ((O) FDF(B-political party) )(O) and(O) the(O) Mouvement(B-political party) des(I-political party) Citoyens(I-political party) pour(I-political party) le(I-political party) Changement(I-political party) ((O) MCC(B-political party) )(O) into(O) the(O) Mouvement(B-political party) Rformateur(I-political party) ((O) MR(B-political party) )(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["event","political party","country","politician","organization","election","person","location"],"instance":{"id":"25","words":["When","the","seat","was","created","it","was","nominally","held","by","the","Democratic","Unionist","Party","(","DUP",")",",","based","on","mapping","the","1992","United","Kingdom","general","election","results","onto","the","new","boundaries",",","but","this","was","because","the","Ulster","Unionist","Party","(","UUP",")","had","not","contested","the","equivalent","area","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","O","B-political party","O","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","O","O","O","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","O","B-political party","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, political party, country, politician, organization, election, person, location and O.\nSentence: When the seat was created it was nominally held by the Democratic Unionist Party ( DUP ) , based on mapping the 1992 United Kingdom general election results onto the new boundaries , but this was because the Ulster Unionist Party ( UUP ) had not contested the equivalent area .","prompt_labels":"When(O) the(O) seat(O) was(O) created(O) it(O) was(O) nominally(O) held(O) by(O) the(O) Democratic(B-political party) Unionist(I-political party) Party(I-political party) ((O) DUP(B-political party) )(O) ,(O) based(O) on(O) mapping(O) the(O) 1992(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) results(O) onto(O) the(O) new(O) boundaries(O) ,(O) but(O) this(O) was(O) because(O) the(O) Ulster(B-political party) Unionist(I-political party) Party(I-political party) ((O) UUP(B-political party) )(O) had(O) not(O) contested(O) the(O) equivalent(O) area(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["election","event","political party","country","politician","person","location","organization"],"instance":{"id":"26","words":["The","American","Conservative","Union","consistently","rated","Jones","low","among","his","Republican","colleagues","for","support","of","the","conservative","political","platform",",","though","he","received","higher","ratings","from","the","Conservative","Review","and","Club","for","Growth","."],"labels":["O","B-organization","I-organization","I-organization","O","O","B-politician","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-organization","I-organization","O","B-organization","I-organization","I-organization","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: election, event, political party, country, politician, person, location, organization and O.\nSentence: The American Conservative Union consistently rated Jones low among his Republican colleagues for support of the conservative political platform , though he received higher ratings from the Conservative Review and Club for Growth .","prompt_labels":"The(O) American(B-organization) Conservative(I-organization) Union(I-organization) consistently(O) rated(O) Jones(B-politician) low(O) among(O) his(O) Republican(O) colleagues(O) for(O) support(O) of(O) the(O) conservative(O) political(O) platform(O) ,(O) though(O) he(O) received(O) higher(O) ratings(O) from(O) the(O) Conservative(B-organization) Review(I-organization) and(O) Club(B-organization) for(I-organization) Growth(I-organization) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["country","election","politician","event","person","location","political party","organization"],"instance":{"id":"27","words":["Ambrose","has","stated","that","though","she","supports","the","merger","of","the","Progressive","Conservative","Association","of","Alberta","and","the","Wildrose","Party",",","she","will","not","be","a","candidate","for","the","leadership","of","the","proposed","new","United","Conservative","Party","of","Alberta","."],"labels":["B-politician","O","O","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","O","O","B-political party","I-political party","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","O","B-location","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, election, politician, event, person, location, political party, organization and O.\nSentence: Ambrose has stated that though she supports the merger of the Progressive Conservative Association of Alberta and the Wildrose Party , she will not be a candidate for the leadership of the proposed new United Conservative Party of Alberta .","prompt_labels":"Ambrose(B-politician) has(O) stated(O) that(O) though(O) she(O) supports(O) the(O) merger(O) of(O) the(O) Progressive(B-political party) Conservative(I-political party) Association(I-political party) of(I-political party) Alberta(I-political party) and(O) the(O) Wildrose(B-political party) Party(I-political party) ,(O) she(O) will(O) not(O) be(O) a(O) candidate(O) for(O) the(O) leadership(O) of(O) the(O) proposed(O) new(O) United(B-political party) Conservative(I-political party) Party(I-political party) of(O) Alberta(B-location) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["event","location","person","organization","politician","political party","election","country"],"instance":{"id":"28","words":["Centre-right","liberalism","was","represented","by","the","pro-capitalist","party","Democratic","Choice","of","Russia","(","15.51","%","in","1993",")","and","its","successor",",","the","Union","of","Right","Forces","(","8.52","%","in","1999","Russian","legislative","election",")","."],"labels":["O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","I-political party","O","O","O","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","I-political party","O","O","O","O","B-election","I-election","I-election","I-election","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, location, person, organization, politician, political party, election, country and O.\nSentence: Centre-right liberalism was represented by the pro-capitalist party Democratic Choice of Russia ( 15.51 % in 1993 ) and its successor , the Union of Right Forces ( 8.52 % in 1999 Russian legislative election ) .","prompt_labels":"Centre-right(O) liberalism(O) was(O) represented(O) by(O) the(O) pro-capitalist(O) party(O) Democratic(B-political party) Choice(I-political party) of(I-political party) Russia(I-political party) ((O) 15.51(O) %(O) in(O) 1993(O) )(O) and(O) its(O) successor(O) ,(O) the(O) Union(B-political party) of(I-political party) Right(I-political party) Forces(I-political party) ((O) 8.52(O) %(O) in(O) 1999(B-election) Russian(I-election) legislative(I-election) election(I-election) )(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["political party","election","country","location","event","organization","person","politician"],"instance":{"id":"29","words":["As","they","had","done","while","campaigning","for","the","2004","Canadian","federal","election",",","the","New","Democratic","Party","and","Bloc","Qubcois","stated",",","during","the","leadup","to","the","2006","Canadian","federal","election",",","their","support","for","an","apology","and","redress","for","the","head","tax","."],"labels":["O","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","O","O","B-political party","I-political party","I-political party","O","B-political party","I-political party","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: political party, election, country, location, event, organization, person, politician and O.\nSentence: As they had done while campaigning for the 2004 Canadian federal election , the New Democratic Party and Bloc Qubcois stated , during the leadup to the 2006 Canadian federal election , their support for an apology and redress for the head tax .","prompt_labels":"As(O) they(O) had(O) done(O) while(O) campaigning(O) for(O) the(O) 2004(B-election) Canadian(I-election) federal(I-election) election(I-election) ,(O) the(O) New(B-political party) Democratic(I-political party) Party(I-political party) and(O) Bloc(B-political party) Qubcois(I-political party) stated(O) ,(O) during(O) the(O) leadup(O) to(O) the(O) 2006(B-election) Canadian(I-election) federal(I-election) election(I-election) ,(O) their(O) support(O) for(O) an(O) apology(O) and(O) redress(O) for(O) the(O) head(O) tax(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["country","organization","political party","election","politician","location","person","event"],"instance":{"id":"30","words":["In","that","election","he","defeated","William","Ross","of","the","Ulster","Unionist","Party","who","had","represented","East","Londonderry","since","1983","United","Kingdom","general","election","and","its","predecessor","seat","of","Londonderry","between","February","1974","United","Kingdom","general","election","and","1983","United","Kingdom","general","election","."],"labels":["O","O","O","O","O","B-politician","I-politician","O","O","B-political party","I-political party","I-political party","O","O","O","B-location","I-location","O","B-election","I-election","I-election","I-election","I-election","O","O","O","O","O","B-location","O","B-election","I-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, organization, political party, election, politician, location, person, event and O.\nSentence: In that election he defeated William Ross of the Ulster Unionist Party who had represented East Londonderry since 1983 United Kingdom general election and its predecessor seat of Londonderry between February 1974 United Kingdom general election and 1983 United Kingdom general election .","prompt_labels":"In(O) that(O) election(O) he(O) defeated(O) William(B-politician) Ross(I-politician) of(O) the(O) Ulster(B-political party) Unionist(I-political party) Party(I-political party) who(O) had(O) represented(O) East(B-location) Londonderry(I-location) since(O) 1983(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) and(O) its(O) predecessor(O) seat(O) of(O) Londonderry(B-location) between(O) February(B-election) 1974(I-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) and(O) 1983(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["election","person","political party","politician","location","country","event","organization"],"instance":{"id":"31","words":["Originally","a","member","of","the","Centre","of","Social","Democrats","(","CDS",")",",","the","Christian","Democrat","component","of","the","Union","for","French","Democracy","(","UDF",")","party",",","he","later","joined","the","Union","for","a","Popular","Movement","."],"labels":["O","O","O","O","O","B-political party","I-political party","I-political party","I-political party","O","B-political party","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","I-political party","O","B-political party","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: election, person, political party, politician, location, country, event, organization and O.\nSentence: Originally a member of the Centre of Social Democrats ( CDS ) , the Christian Democrat component of the Union for French Democracy ( UDF ) party , he later joined the Union for a Popular Movement .","prompt_labels":"Originally(O) a(O) member(O) of(O) the(O) Centre(B-political party) of(I-political party) Social(I-political party) Democrats(I-political party) ((O) CDS(B-political party) )(O) ,(O) the(O) Christian(O) Democrat(O) component(O) of(O) the(O) Union(B-political party) for(I-political party) French(I-political party) Democracy(I-political party) ((O) UDF(B-political party) )(O) party(O) ,(O) he(O) later(O) joined(O) the(O) Union(B-political party) for(I-political party) a(I-political party) Popular(I-political party) Movement(I-political party) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["event","organization","person","election","political party","location","country","politician"],"instance":{"id":"32","words":["The","party","was","founded","on","6","February","1994","as","the","legal","successor","of","the","Italian","Liberal","Party","(","PLI",")",":","In","the","1994","Italian","general","election","most","FdL","members","supported","Patto","Segni",",","while","Biondi","(","and","some","of","the","Liberals","gathered","in","the","Union","of","the","Centre",")","were","elected","with","Forza","Italia","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","O","B-political party","O","O","O","O","B-election","I-election","I-election","I-election","O","B-political party","O","O","B-politician","I-politician","O","O","B-politician","O","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","I-political party","O","O","O","O","B-political party","I-political party","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, organization, person, election, political party, location, country, politician and O.\nSentence: The party was founded on 6 February 1994 as the legal successor of the Italian Liberal Party ( PLI ) : In the 1994 Italian general election most FdL members supported Patto Segni , while Biondi ( and some of the Liberals gathered in the Union of the Centre ) were elected with Forza Italia .","prompt_labels":"The(O) party(O) was(O) founded(O) on(O) 6(O) February(O) 1994(O) as(O) the(O) legal(O) successor(O) of(O) the(O) Italian(B-political party) Liberal(I-political party) Party(I-political party) ((O) PLI(B-political party) )(O) :(O) In(O) the(O) 1994(B-election) Italian(I-election) general(I-election) election(I-election) most(O) FdL(B-political party) members(O) supported(O) Patto(B-politician) Segni(I-politician) ,(O) while(O) Biondi(B-politician) ((O) and(O) some(O) of(O) the(O) Liberals(O) gathered(O) in(O) the(O) Union(B-political party) of(I-political party) the(I-political party) Centre(I-political party) )(O) were(O) elected(O) with(O) Forza(B-political party) Italia(I-political party) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["election","political party","location","organization","person","country","event","politician"],"instance":{"id":"33","words":["In","the","2004","European","Parliament","election","in","Italy","Di","Pietro","teamed","up","with","Achille","Occhetto",",","a","former","leader","of","the","Italian","Communist","Party","(","PCI",")","and","the","Democratic","Party","of","the","Left","(","PDS",")",",","under","the","banner","Civil","Society","Di","Pietro-Occhetto","."],"labels":["O","O","B-election","I-election","I-election","I-election","I-election","I-election","B-politician","I-politician","O","O","O","B-politician","I-politician","O","O","O","O","O","O","B-political party","I-political party","I-political party","O","B-political party","O","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","O","B-political party","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: election, political party, location, organization, person, country, event, politician and O.\nSentence: In the 2004 European Parliament election in Italy Di Pietro teamed up with Achille Occhetto , a former leader of the Italian Communist Party ( PCI ) and the Democratic Party of the Left ( PDS ) , under the banner Civil Society Di Pietro-Occhetto .","prompt_labels":"In(O) the(O) 2004(B-election) European(I-election) Parliament(I-election) election(I-election) in(I-election) Italy(I-election) Di(B-politician) Pietro(I-politician) teamed(O) up(O) with(O) Achille(B-politician) Occhetto(I-politician) ,(O) a(O) former(O) leader(O) of(O) the(O) Italian(B-political party) Communist(I-political party) Party(I-political party) ((O) PCI(B-political party) )(O) and(O) the(O) Democratic(B-political party) Party(I-political party) of(I-political party) the(I-political party) Left(I-political party) ((O) PDS(B-political party) )(O) ,(O) under(O) the(O) banner(O) Civil(O) Society(O) Di(O) Pietro-Occhetto(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["election","person","event","location","politician","country","organization","political party"],"instance":{"id":"34","words":["In","December","2017","IdV","was","a","founding","member","of","the","Popular","Civic","List","(","CP",")",",","a","centrist","electoral","list","within","the","centre-left","coalition",",","along","with","Popular","Alternative","(","AP",")",",","the","Centrists","for","Europe","(","CpE",")",",","Solidary","Democracy","(","DemoS",")",",","the","Union","for","Trentino","(","UpT",")",",","Italy","is","Popular","(","IP",")","and","minor","parties","\/","groups","."],"labels":["O","O","O","B-political party","O","O","O","O","O","O","B-political party","I-political party","I-political party","O","B-political party","O","O","O","O","O","O","O","O","O","O","O","O","O","B-political party","I-political party","O","B-political party","O","O","O","B-political party","I-political party","I-political party","O","B-political party","O","O","B-political party","I-political party","O","B-political party","O","O","O","B-political party","I-political party","I-political party","O","B-political party","O","O","B-political party","I-political party","I-political party","O","B-political party","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: election, person, event, location, politician, country, organization, political party and O.\nSentence: In December 2017 IdV was a founding member of the Popular Civic List ( CP ) , a centrist electoral list within the centre-left coalition , along with Popular Alternative ( AP ) , the Centrists for Europe ( CpE ) , Solidary Democracy ( DemoS ) , the Union for Trentino ( UpT ) , Italy is Popular ( IP ) and minor parties \/ groups .","prompt_labels":"In(O) December(O) 2017(O) IdV(B-political party) was(O) a(O) founding(O) member(O) of(O) the(O) Popular(B-political party) Civic(I-political party) List(I-political party) ((O) CP(B-political party) )(O) ,(O) a(O) centrist(O) electoral(O) list(O) within(O) the(O) centre-left(O) coalition(O) ,(O) along(O) with(O) Popular(B-political party) Alternative(I-political party) ((O) AP(B-political party) )(O) ,(O) the(O) Centrists(B-political party) for(I-political party) Europe(I-political party) ((O) CpE(B-political party) )(O) ,(O) Solidary(B-political party) Democracy(I-political party) ((O) DemoS(B-political party) )(O) ,(O) the(O) Union(B-political party) for(I-political party) Trentino(I-political party) ((O) UpT(B-political party) )(O) ,(O) Italy(B-political party) is(I-political party) Popular(I-political party) ((O) IP(B-political party) )(O) and(O) minor(O) parties(O) \/(O) groups(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["politician","election","event","country","person","organization","political party","location"],"instance":{"id":"35","words":["The","party","includes","former","Italian","Communist","Party","and","former","Lega","Nord",",","as","well","as","former","Italian","Social","Movement","and","several","former","Christian","Democrats","."],"labels":["O","O","O","O","B-political party","I-political party","I-political party","O","O","B-political party","I-political party","O","O","O","O","O","B-political party","I-political party","I-political party","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: politician, election, event, country, person, organization, political party, location and O.\nSentence: The party includes former Italian Communist Party and former Lega Nord , as well as former Italian Social Movement and several former Christian Democrats .","prompt_labels":"The(O) party(O) includes(O) former(O) Italian(B-political party) Communist(I-political party) Party(I-political party) and(O) former(O) Lega(B-political party) Nord(I-political party) ,(O) as(O) well(O) as(O) former(O) Italian(B-political party) Social(I-political party) Movement(I-political party) and(O) several(O) former(O) Christian(O) Democrats(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["location","country","political party","election","organization","person","event","politician"],"instance":{"id":"36","words":["It","was","set","up","by","former","left-leaning","Christian","Democrats",",","(","former","Italian","Liberal","Party","and","former","Italian","Republican","Party",")",",","as","well","as","other","left-wing","politicians","from","the","former","Italian","Socialist","Party","and","Federation","of","the","Greens","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","O","O","B-political party","I-political party","I-political party","O","O","O","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","O","B-political party","I-political party","I-political party","I-political party","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, country, political party, election, organization, person, event, politician and O.\nSentence: It was set up by former left-leaning Christian Democrats , ( former Italian Liberal Party and former Italian Republican Party ) , as well as other left-wing politicians from the former Italian Socialist Party and Federation of the Greens .","prompt_labels":"It(O) was(O) set(O) up(O) by(O) former(O) left-leaning(O) Christian(O) Democrats(O) ,(O) ((O) former(O) Italian(B-political party) Liberal(I-political party) Party(I-political party) and(O) former(O) Italian(B-political party) Republican(I-political party) Party(I-political party) )(O) ,(O) as(O) well(O) as(O) other(O) left-wing(O) politicians(O) from(O) the(O) former(O) Italian(B-political party) Socialist(I-political party) Party(I-political party) and(O) Federation(B-political party) of(I-political party) the(I-political party) Greens(I-political party) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["event","location","election","person","politician","country","political party","organization"],"instance":{"id":"37","words":["After","the","2004","European","Parliament","election","in","Italy","the","new","party","decided","not","to","become","a","member","of","the","Alliance","of","Liberals","and","Democrats","for","Europe","Party","(","ELDR",")","or","of","the","European","People","'s","Party",",","but","founded","the","European","Democratic","Party","(","EDP",")","together","with","the","Union","for","French","Democracy","."],"labels":["O","O","B-election","I-election","I-election","I-election","I-election","I-election","O","O","O","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","I-political party","I-political party","I-political party","O","B-political party","O","O","O","O","B-political party","I-political party","I-political party","I-political party","O","O","O","O","B-political party","I-political party","I-political party","O","B-political party","O","O","O","O","B-political party","I-political party","I-political party","I-political party","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, location, election, person, politician, country, political party, organization and O.\nSentence: After the 2004 European Parliament election in Italy the new party decided not to become a member of the Alliance of Liberals and Democrats for Europe Party ( ELDR ) or of the European People 's Party , but founded the European Democratic Party ( EDP ) together with the Union for French Democracy .","prompt_labels":"After(O) the(O) 2004(B-election) European(I-election) Parliament(I-election) election(I-election) in(I-election) Italy(I-election) the(O) new(O) party(O) decided(O) not(O) to(O) become(O) a(O) member(O) of(O) the(O) Alliance(B-political party) of(I-political party) Liberals(I-political party) and(I-political party) Democrats(I-political party) for(I-political party) Europe(I-political party) Party(I-political party) ((O) ELDR(B-political party) )(O) or(O) of(O) the(O) European(B-political party) People(I-political party) 's(I-political party) Party(I-political party) ,(O) but(O) founded(O) the(O) European(B-political party) Democratic(I-political party) Party(I-political party) ((O) EDP(B-political party) )(O) together(O) with(O) the(O) Union(B-political party) for(I-political party) French(I-political party) Democracy(I-political party) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["person","event","election","organization","location","country","politician","political party"],"instance":{"id":"38","words":["Before","the","merger","of","the","Queensland","branches","of","the","Liberal","Party","of","Australia","and","Nationals","as","the","Liberal","National","Party","of","Queensland",",","the","National","Party","had","been","the","senior","partner","in","the","non-","Australian","Labor","Party","Coalition","since","1924","."],"labels":["O","O","O","O","O","B-location","O","O","O","B-political party","I-political party","I-political party","I-political party","O","O","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","O","O","O","O","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, event, election, organization, location, country, politician, political party and O.\nSentence: Before the merger of the Queensland branches of the Liberal Party of Australia and Nationals as the Liberal National Party of Queensland , the National Party had been the senior partner in the non- Australian Labor Party Coalition since 1924 .","prompt_labels":"Before(O) the(O) merger(O) of(O) the(O) Queensland(B-location) branches(O) of(O) the(O) Liberal(B-political party) Party(I-political party) of(I-political party) Australia(I-political party) and(O) Nationals(O) as(O) the(O) Liberal(B-political party) National(I-political party) Party(I-political party) of(I-political party) Queensland(I-political party) ,(O) the(O) National(O) Party(O) had(O) been(O) the(O) senior(O) partner(O) in(O) the(O) non-(O) Australian(B-political party) Labor(I-political party) Party(I-political party) Coalition(O) since(O) 1924(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["event","politician","election","person","organization","country","location","political party"],"instance":{"id":"39","words":["The","seat","was","initially","won","by","the","Irish","Nationalist","Party","in","1950","United","Kingdom","general","election","and","1951","United","Kingdom","general","election","then","by","Sinn","Fin","in","1955","United","Kingdom","general","election","."],"labels":["O","O","O","O","O","O","O","B-political party","I-political party","I-political party","O","B-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","O","O","B-political party","I-political party","O","B-election","I-election","I-election","I-election","I-election","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, politician, election, person, organization, country, location, political party and O.\nSentence: The seat was initially won by the Irish Nationalist Party in 1950 United Kingdom general election and 1951 United Kingdom general election then by Sinn Fin in 1955 United Kingdom general election .","prompt_labels":"The(O) seat(O) was(O) initially(O) won(O) by(O) the(O) Irish(B-political party) Nationalist(I-political party) Party(I-political party) in(O) 1950(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) and(O) 1951(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) then(O) by(O) Sinn(B-political party) Fin(I-political party) in(O) 1955(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["organization","location","politician","election","political party","person","country","event"],"instance":{"id":"40","words":["The","Social","Democratic","and","Labour","Party","(","SDLP",")","stood","a","candidate","against","her","in","the","February","1974","United","Kingdom","general","election","and","the","nationalist","vote","was","strongly","divided",",","allowing","John","Dunlop","of","the","Vanguard","Progressive","Unionist","Party","to","win","with","the","support","of","the","UUP","and","the","Democratic","Unionist","Party","(","DUP",")","."],"labels":["O","B-political party","I-political party","I-political party","I-political party","I-political party","O","B-political party","O","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","I-election","O","O","O","O","O","O","O","O","O","B-politician","I-politician","O","O","B-political party","I-political party","I-political party","I-political party","O","O","O","O","O","O","O","B-political party","O","O","B-political party","I-political party","I-political party","O","B-political party","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, location, politician, election, political party, person, country, event and O.\nSentence: The Social Democratic and Labour Party ( SDLP ) stood a candidate against her in the February 1974 United Kingdom general election and the nationalist vote was strongly divided , allowing John Dunlop of the Vanguard Progressive Unionist Party to win with the support of the UUP and the Democratic Unionist Party ( DUP ) .","prompt_labels":"The(O) Social(B-political party) Democratic(I-political party) and(I-political party) Labour(I-political party) Party(I-political party) ((O) SDLP(B-political party) )(O) stood(O) a(O) candidate(O) against(O) her(O) in(O) the(O) February(B-election) 1974(I-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) and(O) the(O) nationalist(O) vote(O) was(O) strongly(O) divided(O) ,(O) allowing(O) John(B-politician) Dunlop(I-politician) of(O) the(O) Vanguard(B-political party) Progressive(I-political party) Unionist(I-political party) Party(I-political party) to(O) win(O) with(O) the(O) support(O) of(O) the(O) UUP(B-political party) and(O) the(O) Democratic(B-political party) Unionist(I-political party) Party(I-political party) ((O) DUP(B-political party) )(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["event","organization","person","country","election","location","politician","political party"],"instance":{"id":"41","words":["In","1990","Australian","federal","election","Caldicott","unsuccessfully","contested","the","House","of","Representatives","New","South","Wales","seat","of","Richmond",",","a","seat","held","since","the","inaugural","1901","Australian","federal","election","by","conservatives",",","and","by","the","National","Party","of","Australia","since","it","first","contested","elections","at","the","1922","Australian","federal","election","."],"labels":["O","B-election","I-election","I-election","I-election","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","O","B-location","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","O","O","O","O","O","O","B-political party","I-political party","I-political party","I-political party","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, organization, person, country, election, location, politician, political party and O.\nSentence: In 1990 Australian federal election Caldicott unsuccessfully contested the House of Representatives New South Wales seat of Richmond , a seat held since the inaugural 1901 Australian federal election by conservatives , and by the National Party of Australia since it first contested elections at the 1922 Australian federal election .","prompt_labels":"In(O) 1990(B-election) Australian(I-election) federal(I-election) election(I-election) Caldicott(O) unsuccessfully(O) contested(O) the(O) House(B-organization) of(I-organization) Representatives(I-organization) New(I-organization) South(I-organization) Wales(I-organization) seat(O) of(O) Richmond(B-location) ,(O) a(O) seat(O) held(O) since(O) the(O) inaugural(O) 1901(B-election) Australian(I-election) federal(I-election) election(I-election) by(O) conservatives(O) ,(O) and(O) by(O) the(O) National(B-political party) Party(I-political party) of(I-political party) Australia(I-political party) since(O) it(O) first(O) contested(O) elections(O) at(O) the(O) 1922(B-election) Australian(I-election) federal(I-election) election(I-election) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["country","organization","event","politician","location","political party","person","election"],"instance":{"id":"42","words":["In","the","February","1974","United","Kingdom","general","election",",","however",",","the","Social","Democratic","and","Labour","Party","(","SDLP",")","contested","the","seat",",","dividing","the","nationalist","vote","and","allowing","Harry","West","of","the","UUP","to","win","with","the","support","of","the","Vanguard","Progressive","Unionist","Party","and","the","Democratic","Unionist","Party","."],"labels":["O","O","B-election","I-election","I-election","I-election","I-election","I-election","O","O","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","O","B-political party","O","O","O","O","O","O","O","O","O","O","O","B-politician","I-politician","O","O","B-political party","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","I-political party","O","O","B-political party","I-political party","I-political party","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, organization, event, politician, location, political party, person, election and O.\nSentence: In the February 1974 United Kingdom general election , however , the Social Democratic and Labour Party ( SDLP ) contested the seat , dividing the nationalist vote and allowing Harry West of the UUP to win with the support of the Vanguard Progressive Unionist Party and the Democratic Unionist Party .","prompt_labels":"In(O) the(O) February(B-election) 1974(I-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) however(O) ,(O) the(O) Social(B-political party) Democratic(I-political party) and(I-political party) Labour(I-political party) Party(I-political party) ((O) SDLP(B-political party) )(O) contested(O) the(O) seat(O) ,(O) dividing(O) the(O) nationalist(O) vote(O) and(O) allowing(O) Harry(B-politician) West(I-politician) of(O) the(O) UUP(B-political party) to(O) win(O) with(O) the(O) support(O) of(O) the(O) Vanguard(B-political party) Progressive(I-political party) Unionist(I-political party) Party(I-political party) and(O) the(O) Democratic(B-political party) Unionist(I-political party) Party(I-political party) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["political party","election","politician","organization","event","country","location","person"],"instance":{"id":"43","words":["Kardash","was","re-elected","in","the","1945",",","1949","Manitoba","general","election","and","1953","Manitoba","general","election","as","a","member","of","the","Labor-Progressive","Party","(","as","the","Communists","had","renamed","themselves",")","."],"labels":["B-politician","O","O","O","O","O","O","B-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","O","O","O","O","O","B-political party","I-political party","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: political party, election, politician, organization, event, country, location, person and O.\nSentence: Kardash was re-elected in the 1945 , 1949 Manitoba general election and 1953 Manitoba general election as a member of the Labor-Progressive Party ( as the Communists had renamed themselves ) .","prompt_labels":"Kardash(B-politician) was(O) re-elected(O) in(O) the(O) 1945(O) ,(O) 1949(B-election) Manitoba(I-election) general(I-election) election(I-election) and(O) 1953(B-election) Manitoba(I-election) general(I-election) election(I-election) as(O) a(O) member(O) of(O) the(O) Labor-Progressive(B-political party) Party(I-political party) ((O) as(O) the(O) Communists(O) had(O) renamed(O) themselves(O) )(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["political party","country","election","event","organization","location","politician","person"],"instance":{"id":"44","words":["The","party","did","do","quite","well","for","a","new","party",",","joining","the","opposition","led","by","the","Democratic","Party","of","Japan","(","DPJ",")","and","also","including","the","New","Kmeit",",","the","Social","Democratic","Party","and","Japanese","Communist","Party",",","and","thus","helped","contest","elections","against","the","ruling","conservative","Liberal","Democratic","Party","(","LDP",")","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","I-political party","O","B-political party","O","O","O","O","O","B-political party","I-political party","O","O","B-political party","I-political party","I-political party","O","B-political party","I-political party","I-political party","O","O","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","O","B-political party","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: political party, country, election, event, organization, location, politician, person and O.\nSentence: The party did do quite well for a new party , joining the opposition led by the Democratic Party of Japan ( DPJ ) and also including the New Kmeit , the Social Democratic Party and Japanese Communist Party , and thus helped contest elections against the ruling conservative Liberal Democratic Party ( LDP ) .","prompt_labels":"The(O) party(O) did(O) do(O) quite(O) well(O) for(O) a(O) new(O) party(O) ,(O) joining(O) the(O) opposition(O) led(O) by(O) the(O) Democratic(B-political party) Party(I-political party) of(I-political party) Japan(I-political party) ((O) DPJ(B-political party) )(O) and(O) also(O) including(O) the(O) New(B-political party) Kmeit(I-political party) ,(O) the(O) Social(B-political party) Democratic(I-political party) Party(I-political party) and(O) Japanese(B-political party) Communist(I-political party) Party(I-political party) ,(O) and(O) thus(O) helped(O) contest(O) elections(O) against(O) the(O) ruling(O) conservative(O) Liberal(B-political party) Democratic(I-political party) Party(I-political party) ((O) LDP(B-political party) )(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["politician","location","event","organization","political party","country","person","election"],"instance":{"id":"45","words":["For","the","2011","Peruvian","general","election",",","the","party","joined","forces","with","We","Are","Peru","and","Possible","Peru","to","form","the","Peru","Possible","Alliance","."],"labels":["O","O","B-election","I-election","I-election","I-election","O","O","O","O","O","O","B-political party","I-political party","I-political party","O","B-political party","I-political party","O","O","O","B-organization","I-organization","I-organization","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: politician, location, event, organization, political party, country, person, election and O.\nSentence: For the 2011 Peruvian general election , the party joined forces with We Are Peru and Possible Peru to form the Peru Possible Alliance .","prompt_labels":"For(O) the(O) 2011(B-election) Peruvian(I-election) general(I-election) election(I-election) ,(O) the(O) party(O) joined(O) forces(O) with(O) We(B-political party) Are(I-political party) Peru(I-political party) and(O) Possible(B-political party) Peru(I-political party) to(O) form(O) the(O) Peru(B-organization) Possible(I-organization) Alliance(I-organization) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["event","person","politician","political party","organization","election","location","country"],"instance":{"id":"46","words":["Of","the","five","main","political","parties","in","Northern","Ireland",",","four","(","the","Ulster","Unionist","Party",",","the","Democratic","Unionist","Party",",","the","Social","Democratic","and","Labour","Party","and","Sinn","Fin",")","all","have","relatively","strong","support","bases","and","routinely","poll","similar","results","."],"labels":["O","O","O","O","O","O","O","B-country","I-country","O","O","O","O","B-political party","I-political party","I-political party","O","O","B-political party","I-political party","I-political party","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","O","B-political party","I-political party","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, person, politician, political party, organization, election, location, country and O.\nSentence: Of the five main political parties in Northern Ireland , four ( the Ulster Unionist Party , the Democratic Unionist Party , the Social Democratic and Labour Party and Sinn Fin ) all have relatively strong support bases and routinely poll similar results .","prompt_labels":"Of(O) the(O) five(O) main(O) political(O) parties(O) in(O) Northern(B-country) Ireland(I-country) ,(O) four(O) ((O) the(O) Ulster(B-political party) Unionist(I-political party) Party(I-political party) ,(O) the(O) Democratic(B-political party) Unionist(I-political party) Party(I-political party) ,(O) the(O) Social(B-political party) Democratic(I-political party) and(I-political party) Labour(I-political party) Party(I-political party) and(O) Sinn(B-political party) Fin(I-political party) )(O) all(O) have(O) relatively(O) strong(O) support(O) bases(O) and(O) routinely(O) poll(O) similar(O) results(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["country","organization","location","election","event","politician","person","political party"],"instance":{"id":"47","words":["Other","parties","such","as","the","Alliance","Party","of","Northern","Ireland",",","Progressive","Unionist","Party",",","Unionist","Party","of","Northern","Ireland",",","Conservatives","and","the","Workers","'","Party","have","at","times","polled","significantly",",","as","have","independent","candidates",",","with","the","result","that","many","elections","have","been","won","on","comparatively","low","shares","of","the","vote","."],"labels":["O","O","O","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","O","B-political party","I-political party","I-political party","O","B-political party","I-political party","I-political party","I-political party","I-political party","O","B-political party","I-political party","I-political party","I-political party","I-political party","I-political party","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, organization, location, election, event, politician, person, political party and O.\nSentence: Other parties such as the Alliance Party of Northern Ireland , Progressive Unionist Party , Unionist Party of Northern Ireland , Conservatives and the Workers ' Party have at times polled significantly , as have independent candidates , with the result that many elections have been won on comparatively low shares of the vote .","prompt_labels":"Other(O) parties(O) such(O) as(O) the(O) Alliance(B-political party) Party(I-political party) of(I-political party) Northern(I-political party) Ireland(I-political party) ,(O) Progressive(B-political party) Unionist(I-political party) Party(I-political party) ,(O) Unionist(B-political party) Party(I-political party) of(I-political party) Northern(I-political party) Ireland(I-political party) ,(O) Conservatives(B-political party) and(I-political party) the(I-political party) Workers(I-political party) '(I-political party) Party(I-political party) have(O) at(O) times(O) polled(O) significantly(O) ,(O) as(O) have(O) independent(O) candidates(O) ,(O) with(O) the(O) result(O) that(O) many(O) elections(O) have(O) been(O) won(O) on(O) comparatively(O) low(O) shares(O) of(O) the(O) vote(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["political party","organization","country","event","location","politician","person","election"],"instance":{"id":"48","words":["In","the","February","1974","United","Kingdom","general","election","the","seat","was","won","by","John","Carson","of","the","Ulster","Unionist","Party","with","backing","by","the","Vanguard","Progressive","Unionist","Party","and","the","Democratic","Unionist","Party","on","a","united","slate","in","opposition","to","the","Sunningdale","Agreement","."],"labels":["O","O","B-election","I-election","I-election","I-election","I-election","I-election","O","O","O","O","O","B-politician","I-politician","O","O","B-political party","I-political party","I-political party","O","O","O","O","B-political party","I-political party","I-political party","I-political party","O","O","B-political party","I-political party","I-political party","O","O","O","O","O","O","O","O","B-organization","I-organization","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: political party, organization, country, event, location, politician, person, election and O.\nSentence: In the February 1974 United Kingdom general election the seat was won by John Carson of the Ulster Unionist Party with backing by the Vanguard Progressive Unionist Party and the Democratic Unionist Party on a united slate in opposition to the Sunningdale Agreement .","prompt_labels":"In(O) the(O) February(B-election) 1974(I-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) the(O) seat(O) was(O) won(O) by(O) John(B-politician) Carson(I-politician) of(O) the(O) Ulster(B-political party) Unionist(I-political party) Party(I-political party) with(O) backing(O) by(O) the(O) Vanguard(B-political party) Progressive(I-political party) Unionist(I-political party) Party(I-political party) and(O) the(O) Democratic(B-political party) Unionist(I-political party) Party(I-political party) on(O) a(O) united(O) slate(O) in(O) opposition(O) to(O) the(O) Sunningdale(B-organization) Agreement(I-organization) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["event","election","location","organization","person","politician","political party","country"],"instance":{"id":"49","words":["AP","was","born","as","an","anti-establishment","party","in","1993",",","in","parallel","with","the","rise","of","Lega","Nord","in","Italy",",","of","which","it","has","been","long","considered","the","Sanmarinese","counterpart",",","but","has","since","then","become","a","stable","political","force","in","San","Marino",",","participating","in","government","coalitions","with","the","centrist","Sammarinese","Christian","Democratic","Party","(","PDCS",")","as","well","as","with","the","centre-left","Party","of","Socialists","and","Democrats","(","PSD",")","since","2002","."],"labels":["B-political party","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-political party","I-political party","O","B-country","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-location","I-location","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","I-political party","O","B-political party","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","O","B-political party","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, election, location, organization, person, politician, political party, country and O.\nSentence: AP was born as an anti-establishment party in 1993 , in parallel with the rise of Lega Nord in Italy , of which it has been long considered the Sanmarinese counterpart , but has since then become a stable political force in San Marino , participating in government coalitions with the centrist Sammarinese Christian Democratic Party ( PDCS ) as well as with the centre-left Party of Socialists and Democrats ( PSD ) since 2002 .","prompt_labels":"AP(B-political party) was(O) born(O) as(O) an(O) anti-establishment(O) party(O) in(O) 1993(O) ,(O) in(O) parallel(O) with(O) the(O) rise(O) of(O) Lega(B-political party) Nord(I-political party) in(O) Italy(B-country) ,(O) of(O) which(O) it(O) has(O) been(O) long(O) considered(O) the(O) Sanmarinese(O) counterpart(O) ,(O) but(O) has(O) since(O) then(O) become(O) a(O) stable(O) political(O) force(O) in(O) San(B-location) Marino(I-location) ,(O) participating(O) in(O) government(O) coalitions(O) with(O) the(O) centrist(O) Sammarinese(B-political party) Christian(I-political party) Democratic(I-political party) Party(I-political party) ((O) PDCS(B-political party) )(O) as(O) well(O) as(O) with(O) the(O) centre-left(O) Party(B-political party) of(I-political party) Socialists(I-political party) and(I-political party) Democrats(I-political party) ((O) PSD(B-political party) )(O) since(O) 2002(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["country","location","politician","event","election","organization","political party","person"],"instance":{"id":"50","words":["In","1987","United","Kingdom","general","election","Adams","narrowly","held","his","seat",",","but","lost","it","in","the","1992","United","Kingdom","general","election","amidst","a","strong","tactical","voting","campaign","in","favour","of","Joe","Hendron","of","the","Social","Democratic","and","Labour","Party","by","unionists"],"labels":["O","B-election","I-election","I-election","I-election","I-election","B-politician","O","O","O","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","O","O","O","O","O","O","O","O","O","B-politician","I-politician","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, location, politician, event, election, organization, political party, person and O.\nSentence: In 1987 United Kingdom general election Adams narrowly held his seat , but lost it in the 1992 United Kingdom general election amidst a strong tactical voting campaign in favour of Joe Hendron of the Social Democratic and Labour Party by unionists","prompt_labels":"In(O) 1987(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) Adams(B-politician) narrowly(O) held(O) his(O) seat(O) ,(O) but(O) lost(O) it(O) in(O) the(O) 1992(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) amidst(O) a(O) strong(O) tactical(O) voting(O) campaign(O) in(O) favour(O) of(O) Joe(B-politician) Hendron(I-politician) of(O) the(O) Social(B-political party) Democratic(I-political party) and(I-political party) Labour(I-political party) Party(I-political party) by(O) unionists(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["organization","event","person","election","country","political party","location","politician"],"instance":{"id":"51","words":["In","1997","United","Kingdom","general","election","Adams","regained","the","seat","and","held","it","in","2001","United","Kingdom","general","election",",","2005","United","Kingdom","general","election","and","2010","United","Kingdom","general","election","."],"labels":["O","B-election","I-election","I-election","I-election","I-election","B-politician","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, event, person, election, country, political party, location, politician and O.\nSentence: In 1997 United Kingdom general election Adams regained the seat and held it in 2001 United Kingdom general election , 2005 United Kingdom general election and 2010 United Kingdom general election .","prompt_labels":"In(O) 1997(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) Adams(B-politician) regained(O) the(O) seat(O) and(O) held(O) it(O) in(O) 2001(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) 2005(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) and(O) 2010(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["person","politician","political party","country","organization","location","event","election"],"instance":{"id":"52","words":["Adams","previously","held","the","seat","from","1983","United","Kingdom","general","election","to","1992","United","Kingdom","general","election","when","he","lost","it","to","Joe","Hendron","of","the","Social","Democratic","and","Labour","Party","but","regained","it","in","1997","United","Kingdom","general","election","."],"labels":["B-politician","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","O","O","O","O","O","B-politician","I-politician","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","O","O","O","O","B-election","I-election","I-election","I-election","I-election","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, politician, political party, country, organization, location, event, election and O.\nSentence: Adams previously held the seat from 1983 United Kingdom general election to 1992 United Kingdom general election when he lost it to Joe Hendron of the Social Democratic and Labour Party but regained it in 1997 United Kingdom general election .","prompt_labels":"Adams(B-politician) previously(O) held(O) the(O) seat(O) from(O) 1983(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) to(O) 1992(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) when(O) he(O) lost(O) it(O) to(O) Joe(B-politician) Hendron(I-politician) of(O) the(O) Social(B-political party) Democratic(I-political party) and(I-political party) Labour(I-political party) Party(I-political party) but(O) regained(O) it(O) in(O) 1997(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["country","political party","organization","person","event","location","election","politician"],"instance":{"id":"53","words":["In","the","February","1974","United","Kingdom","general","election","the","seat","was","won","by","Robert","Bradford","of","the","Vanguard","Unionist","Progressive","Party","on","a","united","anti-","Sunningdale","Agreement","slate","with","the","Ulster","Unionist","Party","and","the","Democratic","Unionist","Party","."],"labels":["O","O","B-election","I-election","I-election","I-election","I-election","I-election","O","O","O","O","O","B-politician","I-politician","O","O","B-political party","I-political party","I-political party","I-political party","O","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","O","O","B-political party","I-political party","I-political party","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, political party, organization, person, event, location, election, politician and O.\nSentence: In the February 1974 United Kingdom general election the seat was won by Robert Bradford of the Vanguard Unionist Progressive Party on a united anti- Sunningdale Agreement slate with the Ulster Unionist Party and the Democratic Unionist Party .","prompt_labels":"In(O) the(O) February(B-election) 1974(I-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) the(O) seat(O) was(O) won(O) by(O) Robert(B-politician) Bradford(I-politician) of(O) the(O) Vanguard(B-political party) Unionist(I-political party) Progressive(I-political party) Party(I-political party) on(O) a(O) united(O) anti-(O) Sunningdale(O) Agreement(O) slate(O) with(O) the(O) Ulster(B-political party) Unionist(I-political party) Party(I-political party) and(O) the(O) Democratic(B-political party) Unionist(I-political party) Party(I-political party) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["person","location","politician","organization","event","country","election","political party"],"instance":{"id":"54","words":["The","Member","of","Parliament","since","the","2019","United","Kingdom","general","election","is","Claire","Hanna","of","the","Social","Democratic","and","Labour","Party",",","succeeding","Emma","Little-Pengelly","of","the","Democratic","Unionist","Party","."],"labels":["O","O","O","B-organization","O","O","B-election","I-election","I-election","I-election","I-election","O","B-politician","I-politician","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","O","O","B-politician","I-politician","O","O","B-political party","I-political party","I-political party","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, location, politician, organization, event, country, election, political party and O.\nSentence: The Member of Parliament since the 2019 United Kingdom general election is Claire Hanna of the Social Democratic and Labour Party , succeeding Emma Little-Pengelly of the Democratic Unionist Party .","prompt_labels":"The(O) Member(O) of(O) Parliament(B-organization) since(O) the(O) 2019(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) is(O) Claire(B-politician) Hanna(I-politician) of(O) the(O) Social(B-political party) Democratic(I-political party) and(I-political party) Labour(I-political party) Party(I-political party) ,(O) succeeding(O) Emma(B-politician) Little-Pengelly(I-politician) of(O) the(O) Democratic(B-political party) Unionist(I-political party) Party(I-political party) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["election","politician","organization","country","location","event","political party","person"],"instance":{"id":"55","words":["In","the","1979","United","Kingdom","general","election","the","constituency","witnessed","a","very","close","three-way","fight","between","Peter","Robinson","of","the","Democratic","Unionist","Party",",","William","Craig","for","the","UUP","and","Oliver","Napier","for","the","Alliance","Party","of","Northern","Ireland","."],"labels":["O","O","B-election","I-election","I-election","I-election","I-election","O","O","O","O","O","O","O","O","O","B-politician","I-politician","O","O","B-political party","I-political party","I-political party","O","B-politician","I-politician","O","O","B-political party","O","B-politician","I-politician","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: election, politician, organization, country, location, event, political party, person and O.\nSentence: In the 1979 United Kingdom general election the constituency witnessed a very close three-way fight between Peter Robinson of the Democratic Unionist Party , William Craig for the UUP and Oliver Napier for the Alliance Party of Northern Ireland .","prompt_labels":"In(O) the(O) 1979(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) the(O) constituency(O) witnessed(O) a(O) very(O) close(O) three-way(O) fight(O) between(O) Peter(B-politician) Robinson(I-politician) of(O) the(O) Democratic(B-political party) Unionist(I-political party) Party(I-political party) ,(O) William(B-politician) Craig(I-politician) for(O) the(O) UUP(B-political party) and(O) Oliver(B-politician) Napier(I-politician) for(O) the(O) Alliance(B-political party) Party(I-political party) of(I-political party) Northern(I-political party) Ireland(I-political party) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["person","organization","location","politician","election","event","political party","country"],"instance":{"id":"56","words":["The","constituency","is","majority","nationalist",",","though","initially","on","its","creation","in","1983","United","Kingdom","general","election","Jim","Nicholson","of","the","Ulster","Unionist","Party","won","the","seat","due","to","the","nationalist","vote","being","divided","between","the","Social","Democratic","and","Labour","Party","and","Sinn","Fin","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","B-politician","I-politician","O","O","B-political party","I-political party","I-political party","O","O","O","O","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","O","B-political party","I-political party","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, organization, location, politician, election, event, political party, country and O.\nSentence: The constituency is majority nationalist , though initially on its creation in 1983 United Kingdom general election Jim Nicholson of the Ulster Unionist Party won the seat due to the nationalist vote being divided between the Social Democratic and Labour Party and Sinn Fin .","prompt_labels":"The(O) constituency(O) is(O) majority(O) nationalist(O) ,(O) though(O) initially(O) on(O) its(O) creation(O) in(O) 1983(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) Jim(B-politician) Nicholson(I-politician) of(O) the(O) Ulster(B-political party) Unionist(I-political party) Party(I-political party) won(O) the(O) seat(O) due(O) to(O) the(O) nationalist(O) vote(O) being(O) divided(O) between(O) the(O) Social(B-political party) Democratic(I-political party) and(I-political party) Labour(I-political party) Party(I-political party) and(O) Sinn(B-political party) Fin(I-political party) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["political party","election","politician","person","organization","location","event","country"],"instance":{"id":"57","words":["Schaefer","served","four","terms","as","mayor",",","being","first","elected","in","1971","Baltimore","mayoral","election",",","then","re-elected","in","1975","Baltimore","mayoral","election",",","1979","Baltimore","mayoral","election","and","1983","Baltimore","mayoral","election",",","each","time","receiving","85","%","or","more","of","the","vote","."],"labels":["B-politician","O","O","O","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","O","O","O","O","B-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: political party, election, politician, person, organization, location, event, country and O.\nSentence: Schaefer served four terms as mayor , being first elected in 1971 Baltimore mayoral election , then re-elected in 1975 Baltimore mayoral election , 1979 Baltimore mayoral election and 1983 Baltimore mayoral election , each time receiving 85 % or more of the vote .","prompt_labels":"Schaefer(B-politician) served(O) four(O) terms(O) as(O) mayor(O) ,(O) being(O) first(O) elected(O) in(O) 1971(B-election) Baltimore(I-election) mayoral(I-election) election(I-election) ,(O) then(O) re-elected(O) in(O) 1975(B-election) Baltimore(I-election) mayoral(I-election) election(I-election) ,(O) 1979(B-election) Baltimore(I-election) mayoral(I-election) election(I-election) and(O) 1983(B-election) Baltimore(I-election) mayoral(I-election) election(I-election) ,(O) each(O) time(O) receiving(O) 85(O) %(O) or(O) more(O) of(O) the(O) vote(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["election","organization","country","event","politician","location","person","political party"],"instance":{"id":"58","words":["The","1936","election","produced","a","minority","government",",","with","23","Manitoba","Liberal","Party",",","16","Progressive","Conservative","Party","of","Manitoba",",","7","Independent","Labour","Party","members",",","the","5","Social","Crediters","and","4","others","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","O","O","B-political party","I-political party","I-political party","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: election, organization, country, event, politician, location, person, political party and O.\nSentence: The 1936 election produced a minority government , with 23 Manitoba Liberal Party , 16 Progressive Conservative Party of Manitoba , 7 Independent Labour Party members , the 5 Social Crediters and 4 others .","prompt_labels":"The(O) 1936(O) election(O) produced(O) a(O) minority(O) government(O) ,(O) with(O) 23(O) Manitoba(B-political party) Liberal(I-political party) Party(I-political party) ,(O) 16(O) Progressive(B-political party) Conservative(I-political party) Party(I-political party) of(I-political party) Manitoba(I-political party) ,(O) 7(O) Independent(B-political party) Labour(I-political party) Party(I-political party) members(O) ,(O) the(O) 5(O) Social(O) Crediters(O) and(O) 4(O) others(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["country","election","political party","person","event","organization","politician","location"],"instance":{"id":"59","words":["It","was","widely","expected","that","a","coalition","between","supporters","of","the","Orange","Movement","would","form","Ukraine","'s","next","government",",","but","after","three","months","of","negotiations","and","a","failure","to","reach","an","agreement","the","proposed","coalition","collapsed","following","the","decision","of","the","Socialist","Party","of","Ukraine","to","support","the","formation","of","the","anti-crisis","coalition","with","Party","of","Regions","and","the","Communist","Party","of","Ukraine","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","B-political party","I-political party","O","O","B-country","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","I-political party","O","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","O","O","B-political party","I-political party","I-political party","I-political party","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, election, political party, person, event, organization, politician, location and O.\nSentence: It was widely expected that a coalition between supporters of the Orange Movement would form Ukraine 's next government , but after three months of negotiations and a failure to reach an agreement the proposed coalition collapsed following the decision of the Socialist Party of Ukraine to support the formation of the anti-crisis coalition with Party of Regions and the Communist Party of Ukraine .","prompt_labels":"It(O) was(O) widely(O) expected(O) that(O) a(O) coalition(O) between(O) supporters(O) of(O) the(O) Orange(B-political party) Movement(I-political party) would(O) form(O) Ukraine(B-country) 's(O) next(O) government(O) ,(O) but(O) after(O) three(O) months(O) of(O) negotiations(O) and(O) a(O) failure(O) to(O) reach(O) an(O) agreement(O) the(O) proposed(O) coalition(O) collapsed(O) following(O) the(O) decision(O) of(O) the(O) Socialist(B-political party) Party(I-political party) of(I-political party) Ukraine(I-political party) to(O) support(O) the(O) formation(O) of(O) the(O) anti-crisis(O) coalition(O) with(O) Party(B-political party) of(I-political party) Regions(I-political party) and(O) the(O) Communist(B-political party) Party(I-political party) of(I-political party) Ukraine(I-political party) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["country","political party","politician","election","organization","location","event","person"],"instance":{"id":"60","words":["In","the","2001","United","Kingdom","general","election","the","votes","for","the","UUP",",","Democratic","Unionist","Party","and","Alliance","Party","of","Northern","Ireland","all","remained","remarkably","stable","compared","to","significant","shifts","elsewhere","in","Northern","Ireland","."],"labels":["O","O","B-election","I-election","I-election","I-election","I-election","O","O","O","O","B-political party","O","B-political party","I-political party","I-political party","O","B-political party","I-political party","I-political party","I-political party","I-political party","O","O","O","O","O","O","O","O","O","O","B-country","I-country","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, political party, politician, election, organization, location, event, person and O.\nSentence: In the 2001 United Kingdom general election the votes for the UUP , Democratic Unionist Party and Alliance Party of Northern Ireland all remained remarkably stable compared to significant shifts elsewhere in Northern Ireland .","prompt_labels":"In(O) the(O) 2001(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) the(O) votes(O) for(O) the(O) UUP(B-political party) ,(O) Democratic(B-political party) Unionist(I-political party) Party(I-political party) and(O) Alliance(B-political party) Party(I-political party) of(I-political party) Northern(I-political party) Ireland(I-political party) all(O) remained(O) remarkably(O) stable(O) compared(O) to(O) significant(O) shifts(O) elsewhere(O) in(O) Northern(B-country) Ireland(I-country) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["organization","location","person","election","event","politician","political party","country"],"instance":{"id":"61","words":["The","UUP","had","their","best","result","in","the","election",",","in","part","due","to","no","candidate","from","either","the","UK","Unionist","Party","or","Northern","Ireland","Unionist","Party","defending","one","of","the","seats","won","in","1998","Northern","Ireland","Assembly","election","."],"labels":["O","B-political party","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","O","B-political party","I-political party","I-political party","I-political party","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, location, person, election, event, politician, political party, country and O.\nSentence: The UUP had their best result in the election , in part due to no candidate from either the UK Unionist Party or Northern Ireland Unionist Party defending one of the seats won in 1998 Northern Ireland Assembly election .","prompt_labels":"The(O) UUP(B-political party) had(O) their(O) best(O) result(O) in(O) the(O) election(O) ,(O) in(O) part(O) due(O) to(O) no(O) candidate(O) from(O) either(O) the(O) UK(B-political party) Unionist(I-political party) Party(I-political party) or(O) Northern(B-political party) Ireland(I-political party) Unionist(I-political party) Party(I-political party) defending(O) one(O) of(O) the(O) seats(O) won(O) in(O) 1998(B-election) Northern(I-election) Ireland(I-election) Assembly(I-election) election(I-election) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["person","political party","politician","election","organization","country","event","location"],"instance":{"id":"62","words":["The","Member","of","Parliament","since","1997","United","Kingdom","general","election","is","Sir","Jeffrey","Donaldson","who","was","elected","as","a","member","of","the","Ulster","Unionist","Party","but","switched","to","the","Democratic","Unionist","Party","in","2004","."],"labels":["O","O","O","B-organization","O","B-election","I-election","I-election","I-election","I-election","O","B-politician","I-politician","I-politician","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","O","O","O","O","B-political party","I-political party","I-political party","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, political party, politician, election, organization, country, event, location and O.\nSentence: The Member of Parliament since 1997 United Kingdom general election is Sir Jeffrey Donaldson who was elected as a member of the Ulster Unionist Party but switched to the Democratic Unionist Party in 2004 .","prompt_labels":"The(O) Member(O) of(O) Parliament(B-organization) since(O) 1997(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) is(O) Sir(B-politician) Jeffrey(I-politician) Donaldson(I-politician) who(O) was(O) elected(O) as(O) a(O) member(O) of(O) the(O) Ulster(B-political party) Unionist(I-political party) Party(I-political party) but(O) switched(O) to(O) the(O) Democratic(B-political party) Unionist(I-political party) Party(I-political party) in(O) 2004(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["political party","organization","election","event","politician","person","country","location"],"instance":{"id":"63","words":["Farry","was","elected","to","the","position","in","the","2019","United","Kingdom","general","election",",","replacing","the","incumbent","Sylvia","Hermon",",","who","had","held","the","position","since","being","elected","to","it","in","the","2001","United","Kingdom","general","election",",","but","chose","not","to","contest","in","the","2019","United","Kingdom","general","election","."],"labels":["B-politician","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","O","O","O","O","B-politician","I-politician","O","O","O","O","O","O","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","O","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: political party, organization, election, event, politician, person, country, location and O.\nSentence: Farry was elected to the position in the 2019 United Kingdom general election , replacing the incumbent Sylvia Hermon , who had held the position since being elected to it in the 2001 United Kingdom general election , but chose not to contest in the 2019 United Kingdom general election .","prompt_labels":"Farry(B-politician) was(O) elected(O) to(O) the(O) position(O) in(O) the(O) 2019(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) replacing(O) the(O) incumbent(O) Sylvia(B-politician) Hermon(I-politician) ,(O) who(O) had(O) held(O) the(O) position(O) since(O) being(O) elected(O) to(O) it(O) in(O) the(O) 2001(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) but(O) chose(O) not(O) to(O) contest(O) in(O) the(O) 2019(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["event","person","political party","politician","organization","election","location","country"],"instance":{"id":"64","words":["Whereas","elsewhere","there","are","effectively","three","fundamental","battles","fought","in","elections","-","between","the","Ulster","Unionist","Party","and","the","Democratic","Unionist","Party","to","be","the","leading","unionist","party",",","between","the","Social","Democratic","and","Labour","Party","and","Sinn","Fin","to","be","the","leading","nationalist","party",",","and","between","unionism","and","nationalism","as","a","whole",",","North","Down","is","different","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","O","O","B-political party","I-political party","I-political party","O","O","O","O","B-political party","I-political party","O","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","O","B-political party","I-political party","O","O","O","O","B-political party","I-political party","O","O","O","O","O","O","O","O","O","O","B-location","I-location","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, person, political party, politician, organization, election, location, country and O.\nSentence: Whereas elsewhere there are effectively three fundamental battles fought in elections - between the Ulster Unionist Party and the Democratic Unionist Party to be the leading unionist party , between the Social Democratic and Labour Party and Sinn Fin to be the leading nationalist party , and between unionism and nationalism as a whole , North Down is different .","prompt_labels":"Whereas(O) elsewhere(O) there(O) are(O) effectively(O) three(O) fundamental(O) battles(O) fought(O) in(O) elections(O) -(O) between(O) the(O) Ulster(B-political party) Unionist(I-political party) Party(I-political party) and(O) the(O) Democratic(B-political party) Unionist(I-political party) Party(I-political party) to(O) be(O) the(O) leading(O) unionist(B-political party) party(I-political party) ,(O) between(O) the(O) Social(B-political party) Democratic(I-political party) and(I-political party) Labour(I-political party) Party(I-political party) and(O) Sinn(B-political party) Fin(I-political party) to(O) be(O) the(O) leading(O) nationalist(B-political party) party(I-political party) ,(O) and(O) between(O) unionism(O) and(O) nationalism(O) as(O) a(O) whole(O) ,(O) North(B-location) Down(I-location) is(O) different(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["location","country","person","election","organization","political party","event","politician"],"instance":{"id":"65","words":["Examples","of","regional","parties","that","do","not","generally","campaign","for","greater","autonomy","or","federalism","include","most","provincial","parties","in","Canada",",","most","regional","and","minority","parties","in","Europe",",","notably","including","the","Christian","Social","Union","in","Bavaria","in","Bavaria","(","Germany",")",",","most","parties","in","Belgium",",","most","parties","in","Northern","Ireland",",","the","Istrian","Democratic","Assembly","in","Istria","and","the","Alliance","of","Primorje-Gorski","Kotar","in","Primorje-Gorski","Kotar","(","both","counties","of","Croatia",")",",","and","most","political","parties","in","India","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-country","O","O","O","O","O","O","O","B-location","O","O","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","O","B-location","O","B-country","O","O","O","O","O","B-location","O","O","O","O","B-country","I-country","O","O","B-political party","I-political party","I-political party","O","B-location","O","O","B-political party","I-political party","I-political party","I-political party","O","B-location","I-location","O","O","O","O","B-country","O","O","O","O","O","O","O","B-country","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, country, person, election, organization, political party, event, politician and O.\nSentence: Examples of regional parties that do not generally campaign for greater autonomy or federalism include most provincial parties in Canada , most regional and minority parties in Europe , notably including the Christian Social Union in Bavaria in Bavaria ( Germany ) , most parties in Belgium , most parties in Northern Ireland , the Istrian Democratic Assembly in Istria and the Alliance of Primorje-Gorski Kotar in Primorje-Gorski Kotar ( both counties of Croatia ) , and most political parties in India .","prompt_labels":"Examples(O) of(O) regional(O) parties(O) that(O) do(O) not(O) generally(O) campaign(O) for(O) greater(O) autonomy(O) or(O) federalism(O) include(O) most(O) provincial(O) parties(O) in(O) Canada(B-country) ,(O) most(O) regional(O) and(O) minority(O) parties(O) in(O) Europe(B-location) ,(O) notably(O) including(O) the(O) Christian(B-political party) Social(I-political party) Union(I-political party) in(I-political party) Bavaria(I-political party) in(O) Bavaria(B-location) ((O) Germany(B-country) )(O) ,(O) most(O) parties(O) in(O) Belgium(B-location) ,(O) most(O) parties(O) in(O) Northern(B-country) Ireland(I-country) ,(O) the(O) Istrian(B-political party) Democratic(I-political party) Assembly(I-political party) in(O) Istria(B-location) and(O) the(O) Alliance(B-political party) of(I-political party) Primorje-Gorski(I-political party) Kotar(I-political party) in(O) Primorje-Gorski(B-location) Kotar(I-location) ((O) both(O) counties(O) of(O) Croatia(B-country) )(O) ,(O) and(O) most(O) political(O) parties(O) in(O) India(B-country) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["election","country","political party","organization","politician","person","location","event"],"instance":{"id":"66","words":["The","party","upholds","close","relations","with","the","Popular","Front","for","the","Liberation","of","Palestine",",","the","Communist","Party","of","the","Philippines",",","the","Workers","'","Party","of","Belgium",",","the","Communist","Party","of","Greece",",","the","Polisario","Front","and","others","."],"labels":["O","O","O","O","O","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","I-political party","I-political party","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","O","O","B-political party","I-political party","I-political party","I-political party","O","O","B-political party","I-political party","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: election, country, political party, organization, politician, person, location, event and O.\nSentence: The party upholds close relations with the Popular Front for the Liberation of Palestine , the Communist Party of the Philippines , the Workers ' Party of Belgium , the Communist Party of Greece , the Polisario Front and others .","prompt_labels":"The(O) party(O) upholds(O) close(O) relations(O) with(O) the(O) Popular(B-political party) Front(I-political party) for(I-political party) the(I-political party) Liberation(I-political party) of(I-political party) Palestine(I-political party) ,(O) the(O) Communist(B-political party) Party(I-political party) of(I-political party) the(I-political party) Philippines(I-political party) ,(O) the(O) Workers(B-political party) '(I-political party) Party(I-political party) of(I-political party) Belgium(I-political party) ,(O) the(O) Communist(B-political party) Party(I-political party) of(I-political party) Greece(I-political party) ,(O) the(O) Polisario(B-political party) Front(I-political party) and(O) others(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["event","person","location","politician","election","organization","political party","country"],"instance":{"id":"67","words":["Ayaan","Hirsi","Ali","is","a","Fellow","with","the","Hoover","Institution","at","Stanford","University",",","a","Fellow","with","the","Future","of","Diplomacy","Project","at","the","Belfer","Center","for","Science","and","International","Affairs","at","The","Harvard","Kennedy","School",",","a","visiting","scholar","at","the","American","Enterprise","Institute","in","Washington",",","D.C.",",","and","a","member","of","the","Council","on","Foreign","Relations","."],"labels":["B-politician","I-politician","I-politician","O","O","O","O","O","B-organization","I-organization","O","B-organization","I-organization","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","O","O","O","O","O","O","B-organization","I-organization","I-organization","O","B-location","I-location","I-location","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, person, location, politician, election, organization, political party, country and O.\nSentence: Ayaan Hirsi Ali is a Fellow with the Hoover Institution at Stanford University , a Fellow with the Future of Diplomacy Project at the Belfer Center for Science and International Affairs at The Harvard Kennedy School , a visiting scholar at the American Enterprise Institute in Washington , D.C. , and a member of the Council on Foreign Relations .","prompt_labels":"Ayaan(B-politician) Hirsi(I-politician) Ali(I-politician) is(O) a(O) Fellow(O) with(O) the(O) Hoover(B-organization) Institution(I-organization) at(O) Stanford(B-organization) University(I-organization) ,(O) a(O) Fellow(O) with(O) the(O) Future(B-organization) of(I-organization) Diplomacy(I-organization) Project(I-organization) at(O) the(O) Belfer(B-organization) Center(I-organization) for(I-organization) Science(I-organization) and(I-organization) International(I-organization) Affairs(I-organization) at(O) The(O) Harvard(B-organization) Kennedy(I-organization) School(I-organization) ,(O) a(O) visiting(O) scholar(O) at(O) the(O) American(B-organization) Enterprise(I-organization) Institute(I-organization) in(O) Washington(B-location) ,(I-location) D.C.(I-location) ,(O) and(O) a(O) member(O) of(O) the(O) Council(B-organization) on(I-organization) Foreign(I-organization) Relations(I-organization) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["location","politician","event","political party","country","person","election","organization"],"instance":{"id":"68","words":["Most","major","federal","political","parties",",","including","the","Liberal","Party","of","Canada",",","the","Conservative","Party","of","Canada",",","the","New","Democratic","Party","and","the","Green","Party","of","Canada","support","maintaining","the","status","quo","with","Quebec","remaining","part","of","Canada","."],"labels":["O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","I-political party","O","O","B-political party","I-political party","I-political party","I-political party","O","O","B-political party","I-political party","I-political party","O","O","B-political party","I-political party","I-political party","I-political party","O","O","O","O","O","O","B-location","O","O","O","B-country","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, politician, event, political party, country, person, election, organization and O.\nSentence: Most major federal political parties , including the Liberal Party of Canada , the Conservative Party of Canada , the New Democratic Party and the Green Party of Canada support maintaining the status quo with Quebec remaining part of Canada .","prompt_labels":"Most(O) major(O) federal(O) political(O) parties(O) ,(O) including(O) the(O) Liberal(B-political party) Party(I-political party) of(I-political party) Canada(I-political party) ,(O) the(O) Conservative(B-political party) Party(I-political party) of(I-political party) Canada(I-political party) ,(O) the(O) New(B-political party) Democratic(I-political party) Party(I-political party) and(O) the(O) Green(B-political party) Party(I-political party) of(I-political party) Canada(I-political party) support(O) maintaining(O) the(O) status(O) quo(O) with(O) Quebec(B-location) remaining(O) part(O) of(O) Canada(B-country) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["location","election","political party","politician","country","organization","person","event"],"instance":{"id":"69","words":["However",",","with","the","onset","of","the","Troubles",",","new","parties","emerged","that","appealed","to","the","party","'s","support","base",",","including","the","Social","Democratic","and","Labour","Party","(","SDLP",")",",","the","Alliance","Party","of","Northern","Ireland","and","the","Democratic","Unionist","Party","."],"labels":["O","O","O","O","O","O","B-event","I-event","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","O","B-political party","O","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","O","O","B-political party","I-political party","I-political party","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, election, political party, politician, country, organization, person, event and O.\nSentence: However , with the onset of the Troubles , new parties emerged that appealed to the party 's support base , including the Social Democratic and Labour Party ( SDLP ) , the Alliance Party of Northern Ireland and the Democratic Unionist Party .","prompt_labels":"However(O) ,(O) with(O) the(O) onset(O) of(O) the(B-event) Troubles(I-event) ,(O) new(O) parties(O) emerged(O) that(O) appealed(O) to(O) the(O) party(O) 's(O) support(O) base(O) ,(O) including(O) the(O) Social(B-political party) Democratic(I-political party) and(I-political party) Labour(I-political party) Party(I-political party) ((O) SDLP(B-political party) )(O) ,(O) the(O) Alliance(B-political party) Party(I-political party) of(I-political party) Northern(I-political party) Ireland(I-political party) and(O) the(O) Democratic(B-political party) Unionist(I-political party) Party(I-political party) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["election","political party","organization","country","person","politician","event","location"],"instance":{"id":"70","words":["President","Kim","Dae-jung","'","s","National","Congress","for","New","Politics","(","NCNP",")","re-branded","itself","to","Millennium","Democratic","Party","(","MDP",")","in","2000",",","but","was","struggling","as","it","had","defeated","by","the","Liberty","Korea","Party","(","GNP",")","both","the","2000","South","Korean","legislative","election","and","2002","South","Korean","local","elections","."],"labels":["O","B-politician","I-politician","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","O","B-political party","O","O","O","O","B-political party","I-political party","I-political party","O","B-political party","O","O","O","O","O","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","O","B-political party","O","O","O","B-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: election, political party, organization, country, person, politician, event, location and O.\nSentence: President Kim Dae-jung ' s National Congress for New Politics ( NCNP ) re-branded itself to Millennium Democratic Party ( MDP ) in 2000 , but was struggling as it had defeated by the Liberty Korea Party ( GNP ) both the 2000 South Korean legislative election and 2002 South Korean local elections .","prompt_labels":"President(O) Kim(B-politician) Dae-jung(I-politician) '(O) s(O) National(B-political party) Congress(I-political party) for(I-political party) New(I-political party) Politics(I-political party) ((O) NCNP(B-political party) )(O) re-branded(O) itself(O) to(O) Millennium(B-political party) Democratic(I-political party) Party(I-political party) ((O) MDP(B-political party) )(O) in(O) 2000(O) ,(O) but(O) was(O) struggling(O) as(O) it(O) had(O) defeated(O) by(O) the(O) Liberty(B-political party) Korea(I-political party) Party(I-political party) ((O) GNP(B-political party) )(O) both(O) the(O) 2000(B-election) South(I-election) Korean(I-election) legislative(I-election) election(I-election) and(O) 2002(B-election) South(I-election) Korean(I-election) local(I-election) elections(I-election) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["political party","event","country","politician","person","location","election","organization"],"instance":{"id":"71","words":["The","Freedom","Party","was","subsequently","expelled","from","the","Liberal","International",",","and","the","remaining","liberals","seceded","to","found","the","Liberal","Forum","(","Liberales","Forum",",","member","Liberal","International",",","Alliance","of","Liberals","and","Democrats","for","Europe","Party",")","in","1993","."],"labels":["O","B-political party","I-political party","O","O","O","O","O","B-organization","I-organization","O","O","O","O","O","O","O","O","O","B-political party","I-political party","O","B-political party","I-political party","O","O","B-organization","I-organization","O","B-political party","I-political party","I-political party","I-political party","I-political party","I-political party","I-political party","I-political party","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: political party, event, country, politician, person, location, election, organization and O.\nSentence: The Freedom Party was subsequently expelled from the Liberal International , and the remaining liberals seceded to found the Liberal Forum ( Liberales Forum , member Liberal International , Alliance of Liberals and Democrats for Europe Party ) in 1993 .","prompt_labels":"The(O) Freedom(B-political party) Party(I-political party) was(O) subsequently(O) expelled(O) from(O) the(O) Liberal(B-organization) International(I-organization) ,(O) and(O) the(O) remaining(O) liberals(O) seceded(O) to(O) found(O) the(O) Liberal(B-political party) Forum(I-political party) ((O) Liberales(B-political party) Forum(I-political party) ,(O) member(O) Liberal(B-organization) International(I-organization) ,(O) Alliance(B-political party) of(I-political party) Liberals(I-political party) and(I-political party) Democrats(I-political party) for(I-political party) Europe(I-political party) Party(I-political party) )(O) in(O) 1993(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["country","location","politician","election","event","organization","person","political party"],"instance":{"id":"72","words":["This","current","got","finally","divided","in","a","social","liberal","party",",","Danish","Social","Liberal","Party","(","Det","Radikale","Venstre",",","member","Liberal","International",",","Alliance","of","Liberals","and","Democrats","for","Europe","Party",")",",","and","a","conservative","liberal","party",",","Liberal","Party","(","Venstre","Danmarks","liberale","parti",",","member","Liberal","International",",","Alliance","of","Liberals","and","Democrats","for","Europe","Party",")","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","I-political party","O","B-political party","I-political party","I-political party","O","O","B-organization","I-organization","O","B-political party","I-political party","I-political party","I-political party","I-political party","I-political party","I-political party","I-political party","O","O","O","O","O","O","O","O","B-political party","I-political party","O","B-political party","I-political party","I-political party","I-political party","O","O","B-organization","I-organization","O","B-political party","I-political party","I-political party","I-political party","I-political party","I-political party","I-political party","I-political party","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, location, politician, election, event, organization, person, political party and O.\nSentence: This current got finally divided in a social liberal party , Danish Social Liberal Party ( Det Radikale Venstre , member Liberal International , Alliance of Liberals and Democrats for Europe Party ) , and a conservative liberal party , Liberal Party ( Venstre Danmarks liberale parti , member Liberal International , Alliance of Liberals and Democrats for Europe Party ) .","prompt_labels":"This(O) current(O) got(O) finally(O) divided(O) in(O) a(O) social(O) liberal(O) party(O) ,(O) Danish(B-political party) Social(I-political party) Liberal(I-political party) Party(I-political party) ((O) Det(B-political party) Radikale(I-political party) Venstre(I-political party) ,(O) member(O) Liberal(B-organization) International(I-organization) ,(O) Alliance(B-political party) of(I-political party) Liberals(I-political party) and(I-political party) Democrats(I-political party) for(I-political party) Europe(I-political party) Party(I-political party) )(O) ,(O) and(O) a(O) conservative(O) liberal(O) party(O) ,(O) Liberal(B-political party) Party(I-political party) ((O) Venstre(B-political party) Danmarks(I-political party) liberale(I-political party) parti(I-political party) ,(O) member(O) Liberal(B-organization) International(I-organization) ,(O) Alliance(B-political party) of(I-political party) Liberals(I-political party) and(I-political party) Democrats(I-political party) for(I-political party) Europe(I-political party) Party(I-political party) )(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["political party","organization","person","country","politician","election","event","location"],"instance":{"id":"73","words":["Liberalism","is","now","represented","by","the","mainly","Turkish","minority","party","Movement","for","Rights","and","Freedoms","(","Dvienie","za","prava","i","svobodi",",","observer","Liberal","International",",","member","Alliance","of","Liberals","and","Democrats","for","Europe","Party",")","and","the","National","Movement","for","Stability","and","Progress","(","Nacionalno","Dvienie","Simeon","Vtori",",","member","Liberal","International",",","Alliance","of","Liberals","and","Democrats","for","Europe","Party",")",",","both","taking","a","more","or","less","liberal","position","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","O","B-political party","I-political party","I-political party","I-political party","I-political party","O","O","B-organization","I-organization","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","I-political party","I-political party","I-political party","O","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","I-political party","O","B-political party","I-political party","I-political party","I-political party","O","O","B-organization","I-organization","O","B-political party","I-political party","I-political party","I-political party","I-political party","I-political party","I-political party","I-political party","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: political party, organization, person, country, politician, election, event, location and O.\nSentence: Liberalism is now represented by the mainly Turkish minority party Movement for Rights and Freedoms ( Dvienie za prava i svobodi , observer Liberal International , member Alliance of Liberals and Democrats for Europe Party ) and the National Movement for Stability and Progress ( Nacionalno Dvienie Simeon Vtori , member Liberal International , Alliance of Liberals and Democrats for Europe Party ) , both taking a more or less liberal position .","prompt_labels":"Liberalism(O) is(O) now(O) represented(O) by(O) the(O) mainly(O) Turkish(O) minority(O) party(O) Movement(B-political party) for(I-political party) Rights(I-political party) and(I-political party) Freedoms(I-political party) ((O) Dvienie(B-political party) za(I-political party) prava(I-political party) i(I-political party) svobodi(I-political party) ,(O) observer(O) Liberal(B-organization) International(I-organization) ,(O) member(O) Alliance(B-political party) of(I-political party) Liberals(I-political party) and(I-political party) Democrats(I-political party) for(I-political party) Europe(I-political party) Party(I-political party) )(O) and(O) the(O) National(B-political party) Movement(I-political party) for(I-political party) Stability(I-political party) and(I-political party) Progress(I-political party) ((O) Nacionalno(B-political party) Dvienie(I-political party) Simeon(I-political party) Vtori(I-political party) ,(O) member(O) Liberal(B-organization) International(I-organization) ,(O) Alliance(B-political party) of(I-political party) Liberals(I-political party) and(I-political party) Democrats(I-political party) for(I-political party) Europe(I-political party) Party(I-political party) )(O) ,(O) both(O) taking(O) a(O) more(O) or(O) less(O) liberal(O) position(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["person","country","location","event","election","politician","political party","organization"],"instance":{"id":"74","words":["The","main","line","of","conflict","in","France","during","the","19th","century","was","between","monarchists","(","mainly","Legitimists","and","Orlanist","s",",","but","also","Bonapartism",")","and","republicans","(","Radical-Socialists",",","Opportunist","Republicans",",","and","later","socialists",")","."],"labels":["O","O","O","O","O","O","B-country","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-organization","I-organization","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, country, location, event, election, politician, political party, organization and O.\nSentence: The main line of conflict in France during the 19th century was between monarchists ( mainly Legitimists and Orlanist s , but also Bonapartism ) and republicans ( Radical-Socialists , Opportunist Republicans , and later socialists ) .","prompt_labels":"The(O) main(O) line(O) of(O) conflict(O) in(O) France(B-country) during(O) the(O) 19th(O) century(O) was(O) between(O) monarchists(O) ((O) mainly(O) Legitimists(O) and(O) Orlanist(O) s(O) ,(O) but(O) also(O) Bonapartism(O) )(O) and(O) republicans(O) ((O) Radical-Socialists(O) ,(O) Opportunist(B-organization) Republicans(I-organization) ,(O) and(O) later(O) socialists(O) )(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["country","person","organization","politician","location","political party","election","event"],"instance":{"id":"75","words":["She","was","elected","to","the","Ontario","legislature","in","the","1995","Ontario","general","election",",","defeating","Ontario","Liberal","Party","Joe","Dickson","and","incumbent","Ontario","New","Democratic","Party","Jim","Wiseman","by","a","significant","margin","in","the","riding","of","Durham","West",",","east","of","Toronto","."],"labels":["O","O","O","O","O","B-organization","I-organization","O","O","B-election","I-election","I-election","I-election","O","O","B-political party","I-political party","I-political party","B-politician","I-politician","O","O","B-political party","I-political party","I-political party","I-political party","B-politician","I-politician","O","O","O","O","O","O","O","O","B-location","I-location","O","O","O","B-location","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, person, organization, politician, location, political party, election, event and O.\nSentence: She was elected to the Ontario legislature in the 1995 Ontario general election , defeating Ontario Liberal Party Joe Dickson and incumbent Ontario New Democratic Party Jim Wiseman by a significant margin in the riding of Durham West , east of Toronto .","prompt_labels":"She(O) was(O) elected(O) to(O) the(O) Ontario(B-organization) legislature(I-organization) in(O) the(O) 1995(B-election) Ontario(I-election) general(I-election) election(I-election) ,(O) defeating(O) Ontario(B-political party) Liberal(I-political party) Party(I-political party) Joe(B-politician) Dickson(I-politician) and(O) incumbent(O) Ontario(B-political party) New(I-political party) Democratic(I-political party) Party(I-political party) Jim(B-politician) Wiseman(I-politician) by(O) a(O) significant(O) margin(O) in(O) the(O) riding(O) of(O) Durham(B-location) West(I-location) ,(O) east(O) of(O) Toronto(B-location) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["country","person","location","election","politician","political party","organization","event"],"instance":{"id":"76","words":["Paulley","was","a","Co-operative","Commonwealth","Federation","candidate","for","St.","Boniface","in","the","1949","Canadian","federal","election",",","finishing","a","distant","second","to","Liberal","Party","of","Canada","Fernand","Viau","."],"labels":["B-politician","O","O","B-political party","I-political party","I-political party","O","O","B-person","I-person","O","O","B-election","I-election","I-election","I-election","O","O","O","O","O","O","B-political party","I-political party","I-political party","I-political party","B-politician","I-politician","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, person, location, election, politician, political party, organization, event and O.\nSentence: Paulley was a Co-operative Commonwealth Federation candidate for St. Boniface in the 1949 Canadian federal election , finishing a distant second to Liberal Party of Canada Fernand Viau .","prompt_labels":"Paulley(B-politician) was(O) a(O) Co-operative(B-political party) Commonwealth(I-political party) Federation(I-political party) candidate(O) for(O) St.(B-person) Boniface(I-person) in(O) the(O) 1949(B-election) Canadian(I-election) federal(I-election) election(I-election) ,(O) finishing(O) a(O) distant(O) second(O) to(O) Liberal(B-political party) Party(I-political party) of(I-political party) Canada(I-political party) Fernand(B-politician) Viau(I-politician) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["person","location","organization","political party","event","election","politician","country"],"instance":{"id":"77","words":["In","recent","years",",","the","Progressive","Conservative","Party","of","Canada","has","had","the","most","success","in","the","city",":","its","members","were","elected","in","all","but","four","elections","since","1953",":","1974","Canadian","federal","election",",","1980","Canadian","federal","election",",","2004","Canadian","federal","election",",","and","2006","Canadian","federal","election","."],"labels":["O","O","O","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","O","O","B-election","I-election","I-election","I-election","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, location, organization, political party, event, election, politician, country and O.\nSentence: In recent years , the Progressive Conservative Party of Canada has had the most success in the city : its members were elected in all but four elections since 1953 : 1974 Canadian federal election , 1980 Canadian federal election , 2004 Canadian federal election , and 2006 Canadian federal election .","prompt_labels":"In(O) recent(O) years(O) ,(O) the(O) Progressive(B-political party) Conservative(I-political party) Party(I-political party) of(I-political party) Canada(I-political party) has(O) had(O) the(O) most(O) success(O) in(O) the(O) city(O) :(O) its(O) members(O) were(O) elected(O) in(O) all(O) but(O) four(O) elections(O) since(O) 1953(O) :(O) 1974(B-election) Canadian(I-election) federal(I-election) election(I-election) ,(O) 1980(B-election) Canadian(I-election) federal(I-election) election(I-election) ,(O) 2004(B-election) Canadian(I-election) federal(I-election) election(I-election) ,(O) and(O) 2006(B-election) Canadian(I-election) federal(I-election) election(I-election) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["political party","person","location","organization","election","event","country","politician"],"instance":{"id":"78","words":["The","organization","was","founded","in","October","2002","during","the","build-up","to","the","United","States","'","2003","invasion","of","Iraq","by","dozens","of","groups","including","the","National","Organization","for","Women",",","National","Council","of","Churches",",","Peace","Action",",","the","American","Friends","Service","Committee",",","Black","Voices","for","Peace",",","Not","In","Our","Name",",","September","Eleventh","Families","for","Peaceful","Tomorrows",",","and","Veterans","for","Peace","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","B-country","I-country","O","B-event","I-event","I-event","I-event","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O","B-organization","I-organization","I-organization","I-organization","O","B-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","O","B-organization","I-organization","I-organization","I-organization","O","B-organization","I-organization","I-organization","I-organization","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: political party, person, location, organization, election, event, country, politician and O.\nSentence: The organization was founded in October 2002 during the build-up to the United States ' 2003 invasion of Iraq by dozens of groups including the National Organization for Women , National Council of Churches , Peace Action , the American Friends Service Committee , Black Voices for Peace , Not In Our Name , September Eleventh Families for Peaceful Tomorrows , and Veterans for Peace .","prompt_labels":"The(O) organization(O) was(O) founded(O) in(O) October(O) 2002(O) during(O) the(O) build-up(O) to(O) the(O) United(B-country) States(I-country) '(O) 2003(B-event) invasion(I-event) of(I-event) Iraq(I-event) by(O) dozens(O) of(O) groups(O) including(O) the(O) National(B-organization) Organization(I-organization) for(I-organization) Women(I-organization) ,(O) National(B-organization) Council(I-organization) of(I-organization) Churches(I-organization) ,(O) Peace(B-organization) Action(I-organization) ,(O) the(O) American(B-organization) Friends(I-organization) Service(I-organization) Committee(I-organization) ,(O) Black(B-organization) Voices(I-organization) for(I-organization) Peace(I-organization) ,(O) Not(B-organization) In(I-organization) Our(I-organization) Name(I-organization) ,(O) September(B-organization) Eleventh(I-organization) Families(I-organization) for(I-organization) Peaceful(I-organization) Tomorrows(I-organization) ,(O) and(O) Veterans(B-organization) for(I-organization) Peace(I-organization) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["organization","politician","location","election","person","event","political party","country"],"instance":{"id":"79","words":["He","was","the","American","Independent","Party","vice","presidential","nominee","under","John","G.","Schmitz","in","1972","United","States","presidential","election","and","the","American","Party","presidential","nominee","in","1976","United","States","presidential","election","."],"labels":["O","O","O","B-political party","I-political party","I-political party","O","O","O","O","B-politician","I-politician","I-politician","O","B-election","I-election","I-election","I-election","I-election","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, politician, location, election, person, event, political party, country and O.\nSentence: He was the American Independent Party vice presidential nominee under John G. Schmitz in 1972 United States presidential election and the American Party presidential nominee in 1976 United States presidential election .","prompt_labels":"He(O) was(O) the(O) American(B-political party) Independent(I-political party) Party(I-political party) vice(O) presidential(O) nominee(O) under(O) John(B-politician) G.(I-politician) Schmitz(I-politician) in(O) 1972(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election) and(O) the(O) American(O) Party(O) presidential(O) nominee(O) in(O) 1976(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["election","country","political party","location","event","politician","person","organization"],"instance":{"id":"80","words":["In","1997","Canadian","federal","election","and","again","in","2000","Canadian","federal","election","Timbrell","campaigned","for","a","seat","in","the","House","of","Commons","of","Canada","as","the","Progressive","Conservative","Party","of","Canada","candidate","in","the","eastern","Ontario","riding","of","Prince","Edward","-","Hastings","In","the","1997","federal","election",",","Timbrell","placed","second","to","Liberal","Lyle","Vanclief",",","with","21.5","%","of","the","vote","."],"labels":["O","B-election","I-election","I-election","I-election","O","O","O","B-election","I-election","I-election","I-election","B-politician","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","O","O","O","O","O","O","O","B-location","I-location","I-location","I-location","O","O","O","O","O","O","B-politician","O","O","O","O","B-politician","I-politician","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: election, country, political party, location, event, politician, person, organization and O.\nSentence: In 1997 Canadian federal election and again in 2000 Canadian federal election Timbrell campaigned for a seat in the House of Commons of Canada as the Progressive Conservative Party of Canada candidate in the eastern Ontario riding of Prince Edward - Hastings In the 1997 federal election , Timbrell placed second to Liberal Lyle Vanclief , with 21.5 % of the vote .","prompt_labels":"In(O) 1997(B-election) Canadian(I-election) federal(I-election) election(I-election) and(O) again(O) in(O) 2000(B-election) Canadian(I-election) federal(I-election) election(I-election) Timbrell(B-politician) campaigned(O) for(O) a(O) seat(O) in(O) the(O) House(B-organization) of(I-organization) Commons(I-organization) of(I-organization) Canada(I-organization) as(O) the(O) Progressive(B-political party) Conservative(I-political party) Party(I-political party) of(I-political party) Canada(I-political party) candidate(O) in(O) the(O) eastern(O) Ontario(O) riding(O) of(O) Prince(B-location) Edward(I-location) -(I-location) Hastings(I-location) In(O) the(O) 1997(O) federal(O) election(O) ,(O) Timbrell(B-politician) placed(O) second(O) to(O) Liberal(O) Lyle(B-politician) Vanclief(I-politician) ,(O) with(O) 21.5(O) %(O) of(O) the(O) vote(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["location","country","event","politician","political party","person","organization","election"],"instance":{"id":"81","words":["He","won","reelection","in","1997","as","a","Reform","Party","Member",",","in","2000","as","a","member","of","the","Canadian","Alliance","and","in","2004","as","a","member","of","the","Conservative","Party","of","Canada",",","until","Black","defeated","him","in","the","2006","Canadian","federal","election","."],"labels":["O","O","O","O","O","O","O","B-political party","I-political party","O","O","O","O","O","O","O","O","O","B-political party","I-political party","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","I-political party","O","O","B-politician","O","O","O","O","B-election","I-election","I-election","I-election","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, country, event, politician, political party, person, organization, election and O.\nSentence: He won reelection in 1997 as a Reform Party Member , in 2000 as a member of the Canadian Alliance and in 2004 as a member of the Conservative Party of Canada , until Black defeated him in the 2006 Canadian federal election .","prompt_labels":"He(O) won(O) reelection(O) in(O) 1997(O) as(O) a(O) Reform(B-political party) Party(I-political party) Member(O) ,(O) in(O) 2000(O) as(O) a(O) member(O) of(O) the(O) Canadian(B-political party) Alliance(I-political party) and(O) in(O) 2004(O) as(O) a(O) member(O) of(O) the(O) Conservative(B-political party) Party(I-political party) of(I-political party) Canada(I-political party) ,(O) until(O) Black(B-politician) defeated(O) him(O) in(O) the(O) 2006(B-election) Canadian(I-election) federal(I-election) election(I-election) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["person","politician","organization","political party","event","country","election","location"],"instance":{"id":"82","words":["Kmeit","did","quite","well",",","and","in","1993",",","when","the","LDP","was","for","the","first","time","declared","an","opposition","party",",","the","Kmeit","became","one","of","the","ruling","parties",",","headed","by","the","liberal","Japan","New","Party",",","but","which","also","included","the","Democratic","Socialist","Party",",","Japan","Renewal","Party",",","the","New","Party","Sakigake",",","and","the","Japan","Socialist","Party","."],"labels":["B-politician","O","O","O","O","O","O","O","O","O","O","B-political party","O","O","O","O","O","O","O","O","O","O","O","B-political party","O","O","O","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","O","O","O","O","O","O","B-political party","I-political party","I-political party","O","B-political party","I-political party","I-political party","O","O","B-political party","I-political party","I-political party","O","O","O","B-political party","I-political party","I-political party","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, politician, organization, political party, event, country, election, location and O.\nSentence: Kmeit did quite well , and in 1993 , when the LDP was for the first time declared an opposition party , the Kmeit became one of the ruling parties , headed by the liberal Japan New Party , but which also included the Democratic Socialist Party , Japan Renewal Party , the New Party Sakigake , and the Japan Socialist Party .","prompt_labels":"Kmeit(B-politician) did(O) quite(O) well(O) ,(O) and(O) in(O) 1993(O) ,(O) when(O) the(O) LDP(B-political party) was(O) for(O) the(O) first(O) time(O) declared(O) an(O) opposition(O) party(O) ,(O) the(O) Kmeit(B-political party) became(O) one(O) of(O) the(O) ruling(O) parties(O) ,(O) headed(O) by(O) the(O) liberal(O) Japan(B-political party) New(I-political party) Party(I-political party) ,(O) but(O) which(O) also(O) included(O) the(O) Democratic(B-political party) Socialist(I-political party) Party(I-political party) ,(O) Japan(B-political party) Renewal(I-political party) Party(I-political party) ,(O) the(O) New(B-political party) Party(I-political party) Sakigake(I-political party) ,(O) and(O) the(O) Japan(B-political party) Socialist(I-political party) Party(I-political party) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["organization","location","election","country","political party","event","person","politician"],"instance":{"id":"83","words":["The","five","parties","that","signed","the","agreement","were",":","Union","of","Democratic","Forces",",","Democrats","for","a","Strong","Bulgaria",",","Bulgaria","for","Citizens","Movement",",","People","'s","Party","Freedom","and","Dignity",",","and","the","Bulgarian","Agrarian","National","Union","."],"labels":["O","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","I-political party","O","B-political party","I-political party","I-political party","I-political party","I-political party","O","B-political party","I-political party","I-political party","I-political party","O","B-political party","I-political party","I-political party","I-political party","I-political party","I-political party","O","O","O","B-political party","I-political party","I-political party","I-political party","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, location, election, country, political party, event, person, politician and O.\nSentence: The five parties that signed the agreement were : Union of Democratic Forces , Democrats for a Strong Bulgaria , Bulgaria for Citizens Movement , People 's Party Freedom and Dignity , and the Bulgarian Agrarian National Union .","prompt_labels":"The(O) five(O) parties(O) that(O) signed(O) the(O) agreement(O) were(O) :(O) Union(B-political party) of(I-political party) Democratic(I-political party) Forces(I-political party) ,(O) Democrats(B-political party) for(I-political party) a(I-political party) Strong(I-political party) Bulgaria(I-political party) ,(O) Bulgaria(B-political party) for(I-political party) Citizens(I-political party) Movement(I-political party) ,(O) People(B-political party) 's(I-political party) Party(I-political party) Freedom(I-political party) and(I-political party) Dignity(I-political party) ,(O) and(O) the(O) Bulgarian(B-political party) Agrarian(I-political party) National(I-political party) Union(I-political party) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["organization","political party","event","politician","person","location","election","country"],"instance":{"id":"84","words":["Under","Terre","'Blanche",",","the","AWB","swore","to","use","violence","to","preserve","minority","rule",",","opposing","any","concessions","offered","to","the","African","National","Congress","-","an","organisation","AWB","supporters","repeatedly","branded","as","Marxist","terrorist","s","Immediately","prior","to","South","Africa","'s","1994","South","African","general","election",",","Terre","'Blanche","'s","followers","were","linked","to","a","number","of","bombings","and","assassinations","targeting","the","South","African","Communist","Party",";","armed","AWB","commandos","participated","in","the","crisis","in","Bophuthatswana","in","1994","."],"labels":["O","B-politician","I-politician","O","O","B-organization","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","O","O","O","B-organization","O","O","O","O","O","O","O","O","O","O","B-country","I-country","O","B-election","I-election","I-election","I-election","I-election","O","B-politician","I-politician","O","O","O","O","O","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","I-political party","O","O","B-organization","O","O","O","O","O","O","B-country","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, political party, event, politician, person, location, election, country and O.\nSentence: Under Terre 'Blanche , the AWB swore to use violence to preserve minority rule , opposing any concessions offered to the African National Congress - an organisation AWB supporters repeatedly branded as Marxist terrorist s Immediately prior to South Africa 's 1994 South African general election , Terre 'Blanche 's followers were linked to a number of bombings and assassinations targeting the South African Communist Party ; armed AWB commandos participated in the crisis in Bophuthatswana in 1994 .","prompt_labels":"Under(O) Terre(B-politician) 'Blanche(I-politician) ,(O) the(O) AWB(B-organization) swore(O) to(O) use(O) violence(O) to(O) preserve(O) minority(O) rule(O) ,(O) opposing(O) any(O) concessions(O) offered(O) to(O) the(O) African(B-political party) National(I-political party) Congress(I-political party) -(O) an(O) organisation(O) AWB(B-organization) supporters(O) repeatedly(O) branded(O) as(O) Marxist(O) terrorist(O) s(O) Immediately(O) prior(O) to(O) South(B-country) Africa(I-country) 's(O) 1994(B-election) South(I-election) African(I-election) general(I-election) election(I-election) ,(O) Terre(B-politician) 'Blanche(I-politician) 's(O) followers(O) were(O) linked(O) to(O) a(O) number(O) of(O) bombings(O) and(O) assassinations(O) targeting(O) the(O) South(B-political party) African(I-political party) Communist(I-political party) Party(I-political party) ;(O) armed(O) AWB(B-organization) commandos(O) participated(O) in(O) the(O) crisis(O) in(O) Bophuthatswana(B-country) in(O) 1994(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["politician","election","location","event","person","organization","country","political party"],"instance":{"id":"85","words":["She","was","a","candidate","in","the","1984","United","States","presidential","election",",","1992","United","States","presidential","election","(","339","votes",")",",","1996","United","States","presidential","election",",","and","2004","United","States","presidential","election","."],"labels":["O","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","O","O","B-election","I-election","I-election","I-election","I-election","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: politician, election, location, event, person, organization, country, political party and O.\nSentence: She was a candidate in the 1984 United States presidential election , 1992 United States presidential election ( 339 votes ) , 1996 United States presidential election , and 2004 United States presidential election .","prompt_labels":"She(O) was(O) a(O) candidate(O) in(O) the(O) 1984(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election) ,(O) 1992(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election) ((O) 339(O) votes(O) )(O) ,(O) 1996(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election) ,(O) and(O) 2004(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["location","politician","election","political party","country","event","person","organization"],"instance":{"id":"86","words":["He","subsequently","led","the","party","in","the","1999","Manitoba","general","election",",","2003","Manitoba","general","election","and","2007","Manitoba","general","election","."],"labels":["O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, politician, election, political party, country, event, person, organization and O.\nSentence: He subsequently led the party in the 1999 Manitoba general election , 2003 Manitoba general election and 2007 Manitoba general election .","prompt_labels":"He(O) subsequently(O) led(O) the(O) party(O) in(O) the(O) 1999(B-election) Manitoba(I-election) general(I-election) election(I-election) ,(O) 2003(B-election) Manitoba(I-election) general(I-election) election(I-election) and(O) 2007(B-election) Manitoba(I-election) general(I-election) election(I-election) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["political party","event","person","organization","politician","election","country","location"],"instance":{"id":"87","words":["FDR","would","win","Ohio","in","1932","United","States","presidential","election",",","1936","United","States","presidential","election",",","and","1940","United","States","presidential","election","."],"labels":["B-political party","O","O","B-location","O","B-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","O","O","B-election","I-election","I-election","I-election","I-election","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: political party, event, person, organization, politician, election, country, location and O.\nSentence: FDR would win Ohio in 1932 United States presidential election , 1936 United States presidential election , and 1940 United States presidential election .","prompt_labels":"FDR(B-political party) would(O) win(O) Ohio(B-location) in(O) 1932(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election) ,(O) 1936(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election) ,(O) and(O) 1940(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["political party","country","person","event","location","election","organization","politician"],"instance":{"id":"88","words":["He","ran","unsuccessfully","as","an","independent","Liberal","in","Saint-Jean","-","Iberville","-","Napierville","in","the","1957","Canadian","federal","election",",","but","was","successful","as","the","Liberal","Party","of","Canada","candidate","in","the","same","riding","in","the","1958","Canadian","federal","election","."],"labels":["O","O","O","O","O","O","O","O","B-location","I-location","I-location","I-location","I-location","O","O","B-election","I-election","I-election","I-election","O","O","O","O","O","O","B-political party","I-political party","I-political party","I-political party","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: political party, country, person, event, location, election, organization, politician and O.\nSentence: He ran unsuccessfully as an independent Liberal in Saint-Jean - Iberville - Napierville in the 1957 Canadian federal election , but was successful as the Liberal Party of Canada candidate in the same riding in the 1958 Canadian federal election .","prompt_labels":"He(O) ran(O) unsuccessfully(O) as(O) an(O) independent(O) Liberal(O) in(O) Saint-Jean(B-location) -(I-location) Iberville(I-location) -(I-location) Napierville(I-location) in(O) the(O) 1957(B-election) Canadian(I-election) federal(I-election) election(I-election) ,(O) but(O) was(O) successful(O) as(O) the(O) Liberal(B-political party) Party(I-political party) of(I-political party) Canada(I-political party) candidate(O) in(O) the(O) same(O) riding(O) in(O) the(O) 1958(B-election) Canadian(I-election) federal(I-election) election(I-election) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["event","election","political party","person","politician","country","location","organization"],"instance":{"id":"89","words":["He","defeated","Manitoba","Liberal","Party","incumbent","Avis","Gray","in","the","1990","Manitoba","general","election",",","and","was","re-elected","in","the","1995","Manitoba","general","election","."],"labels":["O","O","B-political party","I-political party","I-political party","O","B-politician","I-politician","O","O","B-election","I-election","I-election","I-election","O","O","O","O","O","O","B-election","I-election","I-election","I-election","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, election, political party, person, politician, country, location, organization and O.\nSentence: He defeated Manitoba Liberal Party incumbent Avis Gray in the 1990 Manitoba general election , and was re-elected in the 1995 Manitoba general election .","prompt_labels":"He(O) defeated(O) Manitoba(B-political party) Liberal(I-political party) Party(I-political party) incumbent(O) Avis(B-politician) Gray(I-politician) in(O) the(O) 1990(B-election) Manitoba(I-election) general(I-election) election(I-election) ,(O) and(O) was(O) re-elected(O) in(O) the(O) 1995(B-election) Manitoba(I-election) general(I-election) election(I-election) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["election","event","organization","political party","politician","person","location","country"],"instance":{"id":"90","words":["Other","political","parties","that","have","practiced","fusion","include","the","Conservative","Party","of","New","York","State",",","the","Working","Families","Party","and","the","Liberal","Party","of","New","York","."],"labels":["O","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","I-political party","O","O","B-political party","I-political party","I-political party","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: election, event, organization, political party, politician, person, location, country and O.\nSentence: Other political parties that have practiced fusion include the Conservative Party of New York State , the Working Families Party and the Liberal Party of New York .","prompt_labels":"Other(O) political(O) parties(O) that(O) have(O) practiced(O) fusion(O) include(O) the(O) Conservative(B-political party) Party(I-political party) of(I-political party) New(I-political party) York(I-political party) State(I-political party) ,(O) the(O) Working(B-political party) Families(I-political party) Party(I-political party) and(O) the(O) Liberal(B-political party) Party(I-political party) of(I-political party) New(I-political party) York(I-political party) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["location","organization","person","election","country","politician","event","political party"],"instance":{"id":"91","words":["Fry","has","been","re-elected","in","every","subsequent","election","(","1997","Canadian","federal","election",",","2000","Canadian","federal","election",",","2004","Canadian","federal","election",",","2006","Canadian","federal","election",",","2008","Canadian","federal","election",",","2011","Canadian","federal","election",",","2015","Canadian","federal","election","and","2019","Canadian","federal","election",")","."],"labels":["B-politician","O","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, organization, person, election, country, politician, event, political party and O.\nSentence: Fry has been re-elected in every subsequent election ( 1997 Canadian federal election , 2000 Canadian federal election , 2004 Canadian federal election , 2006 Canadian federal election , 2008 Canadian federal election , 2011 Canadian federal election , 2015 Canadian federal election and 2019 Canadian federal election ) .","prompt_labels":"Fry(B-politician) has(O) been(O) re-elected(O) in(O) every(O) subsequent(O) election(O) ((O) 1997(B-election) Canadian(I-election) federal(I-election) election(I-election) ,(O) 2000(B-election) Canadian(I-election) federal(I-election) election(I-election) ,(O) 2004(B-election) Canadian(I-election) federal(I-election) election(I-election) ,(O) 2006(B-election) Canadian(I-election) federal(I-election) election(I-election) ,(O) 2008(B-election) Canadian(I-election) federal(I-election) election(I-election) ,(O) 2011(B-election) Canadian(I-election) federal(I-election) election(I-election) ,(O) 2015(B-election) Canadian(I-election) federal(I-election) election(I-election) and(O) 2019(B-election) Canadian(I-election) federal(I-election) election(I-election) )(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["country","political party","location","person","election","organization","politician","event"],"instance":{"id":"92","words":["Supporters","of","the","campaign","included","Margo","Kingston","(","journalist",")",",","John","Valder","(","previous","president","of","Howard","'s","Liberal","Party","of","Australia",")",",","Brian","Deegan","(","former","magistrate",",","who","stood","against","Alexander","Downer",")",",","Andrew","Wilkie","(","Australian","Greens","candidate",")",",","Alex","Broun","playwright","and","Nicole","Campbell","(","Australian","Labor","Party","candidate",")","."],"labels":["O","O","O","O","O","B-person","I-person","O","O","O","O","B-politician","I-politician","O","O","O","O","O","O","B-political party","I-political party","I-political party","I-political party","O","O","B-person","I-person","O","O","O","O","O","O","O","B-politician","I-politician","O","O","B-politician","I-politician","O","B-political party","I-political party","O","O","O","B-person","I-person","O","O","B-politician","I-politician","O","B-political party","I-political party","I-political party","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, political party, location, person, election, organization, politician, event and O.\nSentence: Supporters of the campaign included Margo Kingston ( journalist ) , John Valder ( previous president of Howard 's Liberal Party of Australia ) , Brian Deegan ( former magistrate , who stood against Alexander Downer ) , Andrew Wilkie ( Australian Greens candidate ) , Alex Broun playwright and Nicole Campbell ( Australian Labor Party candidate ) .","prompt_labels":"Supporters(O) of(O) the(O) campaign(O) included(O) Margo(B-person) Kingston(I-person) ((O) journalist(O) )(O) ,(O) John(B-politician) Valder(I-politician) ((O) previous(O) president(O) of(O) Howard(O) 's(O) Liberal(B-political party) Party(I-political party) of(I-political party) Australia(I-political party) )(O) ,(O) Brian(B-person) Deegan(I-person) ((O) former(O) magistrate(O) ,(O) who(O) stood(O) against(O) Alexander(B-politician) Downer(I-politician) )(O) ,(O) Andrew(B-politician) Wilkie(I-politician) ((O) Australian(B-political party) Greens(I-political party) candidate(O) )(O) ,(O) Alex(B-person) Broun(I-person) playwright(O) and(O) Nicole(B-politician) Campbell(I-politician) ((O) Australian(B-political party) Labor(I-political party) Party(I-political party) candidate(O) )(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["politician","event","country","location","organization","political party","election","person"],"instance":{"id":"93","words":["Some","of","the","more","notable","past","and","present","members","of","the","Celtic","League","have","been","Plaid","Cymru","leaders","Gwynfor","Evans","and","J.","E.","Jones",",","Scottish","National","Party","leaders","Winnie","Ewing",",","Robert","McIntyre","and","Rob","Gibson",",","leader","of","Sinn","Fin","Ruair","","Brdaigh",",","prominent","Breton","exiles","Yann","Four","and","Alan","Heusaff",",","the","historian","and","writer","Peter","Berresford","Ellis",",","writer","Bernard","Le","Nail",",","and","Manx","language","revivalist","Brian","Stowell","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","B-organization","I-organization","O","O","B-political party","I-political party","O","B-politician","I-politician","O","B-politician","I-politician","I-politician","O","B-political party","I-political party","I-political party","O","B-politician","I-politician","O","B-politician","I-politician","O","B-politician","I-politician","O","O","O","B-political party","I-political party","B-politician","I-politician","I-politician","O","O","O","O","B-person","I-person","O","B-person","I-person","O","O","O","O","O","B-person","I-person","I-person","O","O","B-person","I-person","I-person","O","O","O","O","O","B-person","I-person","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: politician, event, country, location, organization, political party, election, person and O.\nSentence: Some of the more notable past and present members of the Celtic League have been Plaid Cymru leaders Gwynfor Evans and J. E. Jones , Scottish National Party leaders Winnie Ewing , Robert McIntyre and Rob Gibson , leader of Sinn Fin Ruair  Brdaigh , prominent Breton exiles Yann Four and Alan Heusaff , the historian and writer Peter Berresford Ellis , writer Bernard Le Nail , and Manx language revivalist Brian Stowell .","prompt_labels":"Some(O) of(O) the(O) more(O) notable(O) past(O) and(O) present(O) members(O) of(O) the(O) Celtic(B-organization) League(I-organization) have(O) been(O) Plaid(B-political party) Cymru(I-political party) leaders(O) Gwynfor(B-politician) Evans(I-politician) and(O) J.(B-politician) E.(I-politician) Jones(I-politician) ,(O) Scottish(B-political party) National(I-political party) Party(I-political party) leaders(O) Winnie(B-politician) Ewing(I-politician) ,(O) Robert(B-politician) McIntyre(I-politician) and(O) Rob(B-politician) Gibson(I-politician) ,(O) leader(O) of(O) Sinn(B-political party) Fin(I-political party) Ruair(B-politician) (I-politician) Brdaigh(I-politician) ,(O) prominent(O) Breton(O) exiles(O) Yann(B-person) Four(I-person) and(O) Alan(B-person) Heusaff(I-person) ,(O) the(O) historian(O) and(O) writer(O) Peter(B-person) Berresford(I-person) Ellis(I-person) ,(O) writer(O) Bernard(B-person) Le(I-person) Nail(I-person) ,(O) and(O) Manx(O) language(O) revivalist(O) Brian(B-person) Stowell(I-person) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["political party","event","organization","politician","country","location","election","person"],"instance":{"id":"94","words":["Following","the","2015","United","Kingdom","general","election",",","the","Liberal","Democrats","were","reduced","to","just","eight","seats","in","the","House","of","Commons",",","falling","into","joint","fourth","place","with","the","Democratic","Unionist","Party","behind","the","Scottish","National","Party","(","SNP",")","for","the","first","time","."],"labels":["O","O","B-election","I-election","I-election","I-election","I-election","O","O","O","O","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","O","O","B-political party","I-political party","I-political party","O","B-political party","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: political party, event, organization, politician, country, location, election, person and O.\nSentence: Following the 2015 United Kingdom general election , the Liberal Democrats were reduced to just eight seats in the House of Commons , falling into joint fourth place with the Democratic Unionist Party behind the Scottish National Party ( SNP ) for the first time .","prompt_labels":"Following(O) the(O) 2015(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) the(O) Liberal(O) Democrats(O) were(O) reduced(O) to(O) just(O) eight(O) seats(O) in(O) the(O) House(B-organization) of(I-organization) Commons(I-organization) ,(O) falling(O) into(O) joint(O) fourth(O) place(O) with(O) the(O) Democratic(B-political party) Unionist(I-political party) Party(I-political party) behind(O) the(O) Scottish(B-political party) National(I-political party) Party(I-political party) ((O) SNP(B-political party) )(O) for(O) the(O) first(O) time(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["person","political party","location","event","organization","politician","country","election"],"instance":{"id":"95","words":["The","elections","led","to","a","five-party","coalition","government","consisting","of","the","PvdA",",","the","Catholic","People","'s","Party",",","the","Anti-Revolutionary","Party",",","the","Political","Party","of","Radicals","and","Democrats","66","with","the","PvdA","'s","Joop","den","Uyl","as","Prime","Minister","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","B-political party","O","O","B-political party","I-political party","I-political party","I-political party","O","O","B-political party","I-political party","O","O","B-political party","I-political party","I-political party","I-political party","O","B-political party","I-political party","O","O","B-political party","O","B-politician","I-politician","I-politician","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, political party, location, event, organization, politician, country, election and O.\nSentence: The elections led to a five-party coalition government consisting of the PvdA , the Catholic People 's Party , the Anti-Revolutionary Party , the Political Party of Radicals and Democrats 66 with the PvdA 's Joop den Uyl as Prime Minister .","prompt_labels":"The(O) elections(O) led(O) to(O) a(O) five-party(O) coalition(O) government(O) consisting(O) of(O) the(O) PvdA(B-political party) ,(O) the(O) Catholic(B-political party) People(I-political party) 's(I-political party) Party(I-political party) ,(O) the(O) Anti-Revolutionary(B-political party) Party(I-political party) ,(O) the(O) Political(B-political party) Party(I-political party) of(I-political party) Radicals(I-political party) and(O) Democrats(B-political party) 66(I-political party) with(O) the(O) PvdA(B-political party) 's(O) Joop(B-politician) den(I-politician) Uyl(I-politician) as(O) Prime(O) Minister(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["organization","person","political party","politician","election","location","country","event"],"instance":{"id":"96","words":["Although","several","parties","are","typically","represented","in","parliament",",","Canada","has","historically","had","two","dominant","political","parties",":","the","Liberal","Party","of","Canada","and","the","Conservative","Party","of","Canada","(","preceded","by","the","Progressive","Conservative","Party","of","Canada","and","the","Conservative","Party","(","1867-1942",")",")","."],"labels":["O","O","O","O","O","O","O","O","O","B-country","O","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","I-political party","O","O","B-political party","I-political party","I-political party","I-political party","O","O","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","O","O","B-political party","I-political party","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, person, political party, politician, election, location, country, event and O.\nSentence: Although several parties are typically represented in parliament , Canada has historically had two dominant political parties : the Liberal Party of Canada and the Conservative Party of Canada ( preceded by the Progressive Conservative Party of Canada and the Conservative Party ( 1867-1942 ) ) .","prompt_labels":"Although(O) several(O) parties(O) are(O) typically(O) represented(O) in(O) parliament(O) ,(O) Canada(B-country) has(O) historically(O) had(O) two(O) dominant(O) political(O) parties(O) :(O) the(O) Liberal(B-political party) Party(I-political party) of(I-political party) Canada(I-political party) and(O) the(O) Conservative(B-political party) Party(I-political party) of(I-political party) Canada(I-political party) ((O) preceded(O) by(O) the(O) Progressive(B-political party) Conservative(I-political party) Party(I-political party) of(I-political party) Canada(I-political party) and(O) the(O) Conservative(B-political party) Party(I-political party) ((O) 1867-1942(O) )(O) )(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["election","political party","event","location","politician","organization","person","country"],"instance":{"id":"97","words":["The","1997","Canadian","federal","election",",","2000","Canadian","federal","election","and","2004","Canadian","federal","election","s","were","all","of","the","minimum","36","days","in","length","which","has","led","to","a","common","misconception","that","elections","must","be","36","days","long","."],"labels":["O","B-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: election, political party, event, location, politician, organization, person, country and O.\nSentence: The 1997 Canadian federal election , 2000 Canadian federal election and 2004 Canadian federal election s were all of the minimum 36 days in length which has led to a common misconception that elections must be 36 days long .","prompt_labels":"The(O) 1997(B-election) Canadian(I-election) federal(I-election) election(I-election) ,(O) 2000(B-election) Canadian(I-election) federal(I-election) election(I-election) and(O) 2004(B-election) Canadian(I-election) federal(I-election) election(I-election) s(O) were(O) all(O) of(O) the(O) minimum(O) 36(O) days(O) in(O) length(O) which(O) has(O) led(O) to(O) a(O) common(O) misconception(O) that(O) elections(O) must(O) be(O) 36(O) days(O) long(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["location","organization","politician","political party","event","person","election","country"],"instance":{"id":"98","words":["Hugo","Chvez",",","the","central","figure","of","the","Venezuelan","political","landscape","since","1998","Venezuelan","presidential","election","as","a","political","outsider",",","died","in","office","in","early","2013",",","and","was","succeeded","by","Nicols","Maduro",",","initially","as","interim","President",",","before","winning","2013","Venezuelan","presidential","election","and","re-election","in","2018","Venezuelan","presidential","election","."],"labels":["B-politician","I-politician","O","O","O","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-politician","I-politician","O","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","O","O","O","B-election","I-election","I-election","I-election","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, organization, politician, political party, event, person, election, country and O.\nSentence: Hugo Chvez , the central figure of the Venezuelan political landscape since 1998 Venezuelan presidential election as a political outsider , died in office in early 2013 , and was succeeded by Nicols Maduro , initially as interim President , before winning 2013 Venezuelan presidential election and re-election in 2018 Venezuelan presidential election .","prompt_labels":"Hugo(B-politician) Chvez(I-politician) ,(O) the(O) central(O) figure(O) of(O) the(O) Venezuelan(O) political(O) landscape(O) since(O) 1998(B-election) Venezuelan(I-election) presidential(I-election) election(I-election) as(O) a(O) political(O) outsider(O) ,(O) died(O) in(O) office(O) in(O) early(O) 2013(O) ,(O) and(O) was(O) succeeded(O) by(O) Nicols(B-politician) Maduro(I-politician) ,(O) initially(O) as(O) interim(O) President(O) ,(O) before(O) winning(O) 2013(B-election) Venezuelan(I-election) presidential(I-election) election(I-election) and(O) re-election(O) in(O) 2018(B-election) Venezuelan(I-election) presidential(I-election) election(I-election) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["country","event","location","person","political party","politician","organization","election"],"instance":{"id":"99","words":["Australia","has","a","de","facto","two-party","system",",","with","the","Australian","Labor","Party","and","the","Coalition","of","the","Liberal","Party","of","Australia",",","National","Party","of","Australia",",","the","Liberal","National","Party","of","Queensland","and","Country","Liberal","Party","dominating","Parliamentary","elections","."],"labels":["B-country","O","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","O","O","O","O","O","B-political party","I-political party","I-political party","I-political party","O","B-political party","I-political party","I-political party","I-political party","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","O","B-political party","I-political party","I-political party","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, event, location, person, political party, politician, organization, election and O.\nSentence: Australia has a de facto two-party system , with the Australian Labor Party and the Coalition of the Liberal Party of Australia , National Party of Australia , the Liberal National Party of Queensland and Country Liberal Party dominating Parliamentary elections .","prompt_labels":"Australia(B-country) has(O) a(O) de(O) facto(O) two-party(O) system(O) ,(O) with(O) the(O) Australian(B-political party) Labor(I-political party) Party(I-political party) and(O) the(O) Coalition(O) of(O) the(O) Liberal(B-political party) Party(I-political party) of(I-political party) Australia(I-political party) ,(O) National(B-political party) Party(I-political party) of(I-political party) Australia(I-political party) ,(O) the(O) Liberal(B-political party) National(I-political party) Party(I-political party) of(I-political party) Queensland(I-political party) and(O) Country(B-political party) Liberal(I-political party) Party(I-political party) dominating(O) Parliamentary(O) elections(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["event","person","country","election","politician","location","organization","political party"],"instance":{"id":"100","words":["ALP","=","Australian","Labor","Party",",","L","+","NP","=","grouping","of","Liberal","Party","of","Australia","\/","National","Party","of","Australia","\/","Liberal","National","Party","of","Queensland","\/","Country","Liberal","Party","Coalition","parties","(","and","predecessors",")",",","Oth","=","other","parties","and","independents","."],"labels":["B-political party","O","B-political party","I-political party","I-political party","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","I-political party","O","B-political party","I-political party","I-political party","I-political party","O","B-political party","I-political party","I-political party","I-political party","I-political party","O","B-political party","I-political party","I-political party","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, person, country, election, politician, location, organization, political party and O.\nSentence: ALP = Australian Labor Party , L + NP = grouping of Liberal Party of Australia \/ National Party of Australia \/ Liberal National Party of Queensland \/ Country Liberal Party Coalition parties ( and predecessors ) , Oth = other parties and independents .","prompt_labels":"ALP(B-political party) =(O) Australian(B-political party) Labor(I-political party) Party(I-political party) ,(O) L(O) +(O) NP(O) =(O) grouping(O) of(O) Liberal(B-political party) Party(I-political party) of(I-political party) Australia(I-political party) \/(O) National(B-political party) Party(I-political party) of(I-political party) Australia(I-political party) \/(O) Liberal(B-political party) National(I-political party) Party(I-political party) of(I-political party) Queensland(I-political party) \/(O) Country(B-political party) Liberal(I-political party) Party(I-political party) Coalition(O) parties(O) ((O) and(O) predecessors(O) )(O) ,(O) Oth(O) =(O) other(O) parties(O) and(O) independents(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["political party","politician","election","event","organization","location","country","person"],"instance":{"id":"101","words":["The","five","largest","parties","in","the","election","were","the","National","Party","of","Indonesia","(","Partai","Nasional","Indonesia",")",",","Masyumi",",","Nahdlatul","Ulama",",","the","Communist","Party","of","Indonesia","(","Partai","Komunis","Indonesia",",","PKI",")",",","and","the","Indonesian","Islamic","Union","Party","(","Partai","Sarekat","Islam","Indonesia",")","."],"labels":["O","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","I-political party","O","B-political party","I-political party","I-political party","O","O","B-political party","O","B-political party","I-political party","O","O","B-political party","I-political party","I-political party","I-political party","O","B-political party","I-political party","I-political party","O","B-political party","O","O","O","O","B-political party","I-political party","I-political party","I-political party","O","B-political party","I-political party","I-political party","I-political party","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: political party, politician, election, event, organization, location, country, person and O.\nSentence: The five largest parties in the election were the National Party of Indonesia ( Partai Nasional Indonesia ) , Masyumi , Nahdlatul Ulama , the Communist Party of Indonesia ( Partai Komunis Indonesia , PKI ) , and the Indonesian Islamic Union Party ( Partai Sarekat Islam Indonesia ) .","prompt_labels":"The(O) five(O) largest(O) parties(O) in(O) the(O) election(O) were(O) the(O) National(B-political party) Party(I-political party) of(I-political party) Indonesia(I-political party) ((O) Partai(B-political party) Nasional(I-political party) Indonesia(I-political party) )(O) ,(O) Masyumi(B-political party) ,(O) Nahdlatul(B-political party) Ulama(I-political party) ,(O) the(O) Communist(B-political party) Party(I-political party) of(I-political party) Indonesia(I-political party) ((O) Partai(B-political party) Komunis(I-political party) Indonesia(I-political party) ,(O) PKI(B-political party) )(O) ,(O) and(O) the(O) Indonesian(B-political party) Islamic(I-political party) Union(I-political party) Party(I-political party) ((O) Partai(B-political party) Sarekat(I-political party) Islam(I-political party) Indonesia(I-political party) )(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["organization","election","person","politician","location","event","country","political party"],"instance":{"id":"102","words":["The","five","largest","political","parties","were","Golkar",",","Nahdlatul","Ulama",",","the","Muslim","Party","of","Indonesia","(","Parmusi",")",",","the","Indonesian","National","Party","and","the","Indonesian","Islamic","Union","Party","."],"labels":["O","O","O","O","O","O","B-political party","O","B-political party","I-political party","O","O","B-political party","I-political party","I-political party","I-political party","O","B-political party","O","O","O","B-political party","I-political party","I-political party","O","O","B-political party","I-political party","I-political party","I-political party","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, election, person, politician, location, event, country, political party and O.\nSentence: The five largest political parties were Golkar , Nahdlatul Ulama , the Muslim Party of Indonesia ( Parmusi ) , the Indonesian National Party and the Indonesian Islamic Union Party .","prompt_labels":"The(O) five(O) largest(O) political(O) parties(O) were(O) Golkar(B-political party) ,(O) Nahdlatul(B-political party) Ulama(I-political party) ,(O) the(O) Muslim(B-political party) Party(I-political party) of(I-political party) Indonesia(I-political party) ((O) Parmusi(B-political party) )(O) ,(O) the(O) Indonesian(B-political party) National(I-political party) Party(I-political party) and(O) the(O) Indonesian(B-political party) Islamic(I-political party) Union(I-political party) Party(I-political party) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["person","event","organization","country","location","politician","election","political party"],"instance":{"id":"103","words":["There","are","numerous","other","groups",",","including","communists",",","European","Green","Party",",","European","Free","Alliance",",","conservatives",",","Alliance","of","Liberals","and","Democrats","for","Europe","and","eurosceptics","."],"labels":["O","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","O","B-political party","I-political party","I-political party","O","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","I-political party","I-political party","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, event, organization, country, location, politician, election, political party and O.\nSentence: There are numerous other groups , including communists , European Green Party , European Free Alliance , conservatives , Alliance of Liberals and Democrats for Europe and eurosceptics .","prompt_labels":"There(O) are(O) numerous(O) other(O) groups(O) ,(O) including(O) communists(O) ,(O) European(B-political party) Green(I-political party) Party(I-political party) ,(O) European(B-political party) Free(I-political party) Alliance(I-political party) ,(O) conservatives(O) ,(O) Alliance(B-political party) of(I-political party) Liberals(I-political party) and(I-political party) Democrats(I-political party) for(I-political party) Europe(I-political party) and(O) eurosceptics(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["political party","event","location","election","country","politician","person","organization"],"instance":{"id":"104","words":["Those","were","the","Croatian","Democratic","Union",",","the","Croatian","Peasant","Party",",","the","Croatian","People","'s","Party","-","Liberal","Democrats",",","the","Croatian","Social","Liberal","Party",",","Social","Democratic","Party","of","Croatia","and","the","Bridge","of","Independent","Lists","."],"labels":["O","O","O","B-political party","I-political party","I-political party","O","O","B-political party","I-political party","I-political party","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","I-political party","I-political party","O","O","B-political party","I-political party","I-political party","I-political party","O","B-political party","I-political party","I-political party","I-political party","I-political party","O","O","B-political party","I-political party","I-political party","I-political party","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: political party, event, location, election, country, politician, person, organization and O.\nSentence: Those were the Croatian Democratic Union , the Croatian Peasant Party , the Croatian People 's Party - Liberal Democrats , the Croatian Social Liberal Party , Social Democratic Party of Croatia and the Bridge of Independent Lists .","prompt_labels":"Those(O) were(O) the(O) Croatian(B-political party) Democratic(I-political party) Union(I-political party) ,(O) the(O) Croatian(B-political party) Peasant(I-political party) Party(I-political party) ,(O) the(O) Croatian(B-political party) People(I-political party) 's(I-political party) Party(I-political party) -(I-political party) Liberal(I-political party) Democrats(I-political party) ,(O) the(O) Croatian(B-political party) Social(I-political party) Liberal(I-political party) Party(I-political party) ,(O) Social(B-political party) Democratic(I-political party) Party(I-political party) of(I-political party) Croatia(I-political party) and(O) the(O) Bridge(B-political party) of(I-political party) Independent(I-political party) Lists(I-political party) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["political party","country","organization","person","event","location","politician","election"],"instance":{"id":"105","words":["Those","are","(","in","alphabetical","order",")",":","the","Alliance","of","Primorje-Gorski","Kotar","(","previously","known","as","the","Rijeka","Democratic","Alliance",")",",","the","Croatian","Christian","Democratic","Union",",","the","Croatian","Citizen","Party",",","the","Croatian","Democratic","Alliance","of","Slavonia","and","Baranja",",","the","Croatian","Democratic","Peasant","Party",",","the","Croatian","Independent","Democrats",",","the","Croatian","Party","of","Pensioners",",","the","Croatian","Party","of","Rights",",","the","."],"labels":["O","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","I-political party","O","O","O","O","O","B-political party","I-political party","I-political party","O","O","O","B-political party","I-political party","I-political party","I-political party","O","O","B-political party","I-political party","I-political party","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","I-political party","I-political party","O","O","B-political party","I-political party","I-political party","I-political party","O","O","B-political party","I-political party","I-political party","O","O","B-political party","I-political party","I-political party","I-political party","O","O","B-political party","I-political party","I-political party","I-political party","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: political party, country, organization, person, event, location, politician, election and O.\nSentence: Those are ( in alphabetical order ) : the Alliance of Primorje-Gorski Kotar ( previously known as the Rijeka Democratic Alliance ) , the Croatian Christian Democratic Union , the Croatian Citizen Party , the Croatian Democratic Alliance of Slavonia and Baranja , the Croatian Democratic Peasant Party , the Croatian Independent Democrats , the Croatian Party of Pensioners , the Croatian Party of Rights , the .","prompt_labels":"Those(O) are(O) ((O) in(O) alphabetical(O) order(O) )(O) :(O) the(O) Alliance(B-political party) of(I-political party) Primorje-Gorski(I-political party) Kotar(I-political party) ((O) previously(O) known(O) as(O) the(O) Rijeka(B-political party) Democratic(I-political party) Alliance(I-political party) )(O) ,(O) the(O) Croatian(B-political party) Christian(I-political party) Democratic(I-political party) Union(I-political party) ,(O) the(O) Croatian(B-political party) Citizen(I-political party) Party(I-political party) ,(O) the(O) Croatian(B-political party) Democratic(I-political party) Alliance(I-political party) of(I-political party) Slavonia(I-political party) and(I-political party) Baranja(I-political party) ,(O) the(O) Croatian(B-political party) Democratic(I-political party) Peasant(I-political party) Party(I-political party) ,(O) the(O) Croatian(B-political party) Independent(I-political party) Democrats(I-political party) ,(O) the(O) Croatian(B-political party) Party(I-political party) of(I-political party) Pensioners(I-political party) ,(O) the(O) Croatian(B-political party) Party(I-political party) of(I-political party) Rights(I-political party) ,(O) the(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["politician","country","election","location","organization","political party","event","person"],"instance":{"id":"106","words":["Ante","Starevi","Croatian","Party","of","Rights","dr",",","Dalmatian","Action",",","the","Democratic","Centre",",","the","Istrian","Democratic","Assembly",",","the","Liberal","Party",",","the","Party","of","Liberal","Democrats",",","the","Serb","Democratic","Party",",","the","Slavonia-Baranja","Croatian","Party","and","the","Social","Democratic","Action","of","Croatia","."],"labels":["B-politician","I-politician","B-political party","I-political party","I-political party","I-political party","I-political party","O","B-political party","I-political party","O","O","B-political party","I-political party","O","O","B-political party","I-political party","I-political party","O","O","B-political party","I-political party","O","O","B-political party","I-political party","I-political party","I-political party","O","O","B-political party","I-political party","I-political party","O","O","B-political party","I-political party","I-political party","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: politician, country, election, location, organization, political party, event, person and O.\nSentence: Ante Starevi Croatian Party of Rights dr , Dalmatian Action , the Democratic Centre , the Istrian Democratic Assembly , the Liberal Party , the Party of Liberal Democrats , the Serb Democratic Party , the Slavonia-Baranja Croatian Party and the Social Democratic Action of Croatia .","prompt_labels":"Ante(B-politician) Starevi(I-politician) Croatian(B-political party) Party(I-political party) of(I-political party) Rights(I-political party) dr(I-political party) ,(O) Dalmatian(B-political party) Action(I-political party) ,(O) the(O) Democratic(B-political party) Centre(I-political party) ,(O) the(O) Istrian(B-political party) Democratic(I-political party) Assembly(I-political party) ,(O) the(O) Liberal(B-political party) Party(I-political party) ,(O) the(O) Party(B-political party) of(I-political party) Liberal(I-political party) Democrats(I-political party) ,(O) the(O) Serb(B-political party) Democratic(I-political party) Party(I-political party) ,(O) the(O) Slavonia-Baranja(B-political party) Croatian(I-political party) Party(I-political party) and(O) the(O) Social(B-political party) Democratic(I-political party) Action(I-political party) of(I-political party) Croatia(I-political party) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["political party","election","politician","location","event","organization","person","country"],"instance":{"id":"107","words":["The","following","parties","have","won","the","special","seats","reserved","for","national","minority","representatives","(","also","in","alphabetical","order",")",":","the","Bosnian","Democratic","Party","of","Croatia",",","the","Democratic","Union","of","Hungarians","of","Croatia",",","the","German","People","'s","Union","-","National","Association","of","Danube","Swabians","in","Croatia",",","the","Independent","Democratic","Serb","Party",",","the","Party","of","Democratic","Action","of","Croatia","and","the","Serb","People","'s","Party","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","I-political party","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","I-political party","I-political party","I-political party","I-political party","I-political party","I-political party","I-political party","O","O","B-political party","I-political party","I-political party","I-political party","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","I-political party","O","O","B-political party","I-political party","I-political party","I-political party","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: political party, election, politician, location, event, organization, person, country and O.\nSentence: The following parties have won the special seats reserved for national minority representatives ( also in alphabetical order ) : the Bosnian Democratic Party of Croatia , the Democratic Union of Hungarians of Croatia , the German People 's Union - National Association of Danube Swabians in Croatia , the Independent Democratic Serb Party , the Party of Democratic Action of Croatia and the Serb People 's Party .","prompt_labels":"The(O) following(O) parties(O) have(O) won(O) the(O) special(O) seats(O) reserved(O) for(O) national(O) minority(O) representatives(O) ((O) also(O) in(O) alphabetical(O) order(O) )(O) :(O) the(O) Bosnian(B-political party) Democratic(I-political party) Party(I-political party) of(I-political party) Croatia(I-political party) ,(O) the(O) Democratic(B-political party) Union(I-political party) of(I-political party) Hungarians(I-political party) of(I-political party) Croatia(I-political party) ,(O) the(O) German(B-political party) People(I-political party) 's(I-political party) Union(I-political party) -(I-political party) National(I-political party) Association(I-political party) of(I-political party) Danube(I-political party) Swabians(I-political party) in(I-political party) Croatia(I-political party) ,(O) the(O) Independent(B-political party) Democratic(I-political party) Serb(I-political party) Party(I-political party) ,(O) the(O) Party(B-political party) of(I-political party) Democratic(I-political party) Action(I-political party) of(I-political party) Croatia(I-political party) and(O) the(O) Serb(B-political party) People(I-political party) 's(I-political party) Party(I-political party) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["political party","politician","person","location","organization","country","election","event"],"instance":{"id":"108","words":["Fine","Gael","(","or","its","predecessor","Cumann","na","nGaedheal",")","or","Fianna","Fil","have","led","every","government","since","independence","in","1922","."],"labels":["B-political party","I-political party","O","O","O","O","B-political party","I-political party","I-political party","O","O","B-political party","I-political party","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: political party, politician, person, location, organization, country, election, event and O.\nSentence: Fine Gael ( or its predecessor Cumann na nGaedheal ) or Fianna Fil have led every government since independence in 1922 .","prompt_labels":"Fine(B-political party) Gael(I-political party) ((O) or(O) its(O) predecessor(O) Cumann(B-political party) na(I-political party) nGaedheal(I-political party) )(O) or(O) Fianna(B-political party) Fil(I-political party) have(O) led(O) every(O) government(O) since(O) independence(O) in(O) 1922(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["event","location","country","organization","political party","election","person","politician"],"instance":{"id":"109","words":["The","last","elections","held","in","these","communities","were","in","2018","Andalusian","regional","election","in","December","2018",";","2016","Basque","regional","election","and","2016","Galician","regional","election","in","September","2016",";","2017","Catalan","regional","election","in","December","2017",";","and","2019","Valencian","regional","election","in","April","2019","(","for","the","first","time","separated","from","the","rest","of","regional","elections",",","although","at","the","same","date","that","the","snap","General","Election","for","that","year",")"],"labels":["O","O","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","O","O","O","O","B-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","O","O","O","O","B-election","I-election","I-election","I-election","O","O","O","O","O","B-election","I-election","I-election","I-election","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, location, country, organization, political party, election, person, politician and O.\nSentence: The last elections held in these communities were in 2018 Andalusian regional election in December 2018 ; 2016 Basque regional election and 2016 Galician regional election in September 2016 ; 2017 Catalan regional election in December 2017 ; and 2019 Valencian regional election in April 2019 ( for the first time separated from the rest of regional elections , although at the same date that the snap General Election for that year )","prompt_labels":"The(O) last(O) elections(O) held(O) in(O) these(O) communities(O) were(O) in(O) 2018(B-election) Andalusian(I-election) regional(I-election) election(I-election) in(O) December(O) 2018(O) ;(O) 2016(B-election) Basque(I-election) regional(I-election) election(I-election) and(O) 2016(B-election) Galician(I-election) regional(I-election) election(I-election) in(O) September(O) 2016(O) ;(O) 2017(B-election) Catalan(I-election) regional(I-election) election(I-election) in(O) December(O) 2017(O) ;(O) and(O) 2019(B-election) Valencian(I-election) regional(I-election) election(I-election) in(O) April(O) 2019(O) ((O) for(O) the(O) first(O) time(O) separated(O) from(O) the(O) rest(O) of(O) regional(O) elections(O) ,(O) although(O) at(O) the(O) same(O) date(O) that(O) the(O) snap(O) General(O) Election(O) for(O) that(O) year(O) )(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["election","organization","politician","person","location","country","political party","event"],"instance":{"id":"110","words":["Those","parties","are",":","the","Liberal","Democratic","Party","(","Partido","Liberal","Democrtico",",","observer","Liberal","International",")",",","the","Democratic","Solidarity","Party","(","Partido","Solidaridad","Democrtica",",","observer","Liberal","International",")","and","the","illegal","Cuban","Liberal","Movement","(","Movimiento","Liberal","Cubano",")","."],"labels":["O","O","O","O","O","B-political party","I-political party","I-political party","O","B-political party","I-political party","I-political party","O","O","B-organization","I-organization","O","O","O","B-political party","I-political party","I-political party","O","B-political party","I-political party","I-political party","O","O","B-organization","I-organization","O","O","O","O","B-event","I-event","I-event","O","B-event","I-event","I-event","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: election, organization, politician, person, location, country, political party, event and O.\nSentence: Those parties are : the Liberal Democratic Party ( Partido Liberal Democrtico , observer Liberal International ) , the Democratic Solidarity Party ( Partido Solidaridad Democrtica , observer Liberal International ) and the illegal Cuban Liberal Movement ( Movimiento Liberal Cubano ) .","prompt_labels":"Those(O) parties(O) are(O) :(O) the(O) Liberal(B-political party) Democratic(I-political party) Party(I-political party) ((O) Partido(B-political party) Liberal(I-political party) Democrtico(I-political party) ,(O) observer(O) Liberal(B-organization) International(I-organization) )(O) ,(O) the(O) Democratic(B-political party) Solidarity(I-political party) Party(I-political party) ((O) Partido(B-political party) Solidaridad(I-political party) Democrtica(I-political party) ,(O) observer(O) Liberal(B-organization) International(I-organization) )(O) and(O) the(O) illegal(O) Cuban(B-event) Liberal(I-event) Movement(I-event) ((O) Movimiento(B-event) Liberal(I-event) Cubano(I-event) )(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["political party","politician","organization","location","country","election","person","event"],"instance":{"id":"111","words":["Mazowiecki","remained","a","member","of","the","Sejm","until","1971",",","serving","his","1965","Polish","legislative","election",",","1969","Polish","legislative","election","and","1972","Polish","legislative","election","as","a","member","of","the","Catholic","party","."],"labels":["B-politician","O","O","O","O","O","B-organization","O","O","O","O","O","B-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","O","O","O","O","O","B-political party","I-political party","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: political party, politician, organization, location, country, election, person, event and O.\nSentence: Mazowiecki remained a member of the Sejm until 1971 , serving his 1965 Polish legislative election , 1969 Polish legislative election and 1972 Polish legislative election as a member of the Catholic party .","prompt_labels":"Mazowiecki(B-politician) remained(O) a(O) member(O) of(O) the(O) Sejm(B-organization) until(O) 1971(O) ,(O) serving(O) his(O) 1965(B-election) Polish(I-election) legislative(I-election) election(I-election) ,(O) 1969(B-election) Polish(I-election) legislative(I-election) election(I-election) and(O) 1972(B-election) Polish(I-election) legislative(I-election) election(I-election) as(O) a(O) member(O) of(O) the(O) Catholic(B-political party) party(I-political party) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["political party","election","politician","location","event","person","organization","country"],"instance":{"id":"112","words":["In","2017","Czech","legislative","election","Koruna","esk","together","with","Conservative","Party","and","Club","of","Committed","Non-Party","Members","agreed","on","joint","endorsement","of","TOP","9",",","while","TOP","9","added","candidates","of","the","smaller","parties","on","their","list","."],"labels":["O","B-election","I-election","I-election","I-election","B-politician","I-politician","O","O","B-political party","I-political party","O","B-political party","I-political party","I-political party","I-political party","I-political party","O","O","O","O","O","B-political party","I-political party","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: political party, election, politician, location, event, person, organization, country and O.\nSentence: In 2017 Czech legislative election Koruna esk together with Conservative Party and Club of Committed Non-Party Members agreed on joint endorsement of TOP 9 , while TOP 9 added candidates of the smaller parties on their list .","prompt_labels":"In(O) 2017(B-election) Czech(I-election) legislative(I-election) election(I-election) Koruna(B-politician) esk(I-politician) together(O) with(O) Conservative(B-political party) Party(I-political party) and(O) Club(B-political party) of(I-political party) Committed(I-political party) Non-Party(I-political party) Members(I-political party) agreed(O) on(O) joint(O) endorsement(O) of(O) TOP(B-political party) 9(I-political party) ,(O) while(O) TOP(O) 9(O) added(O) candidates(O) of(O) the(O) smaller(O) parties(O) on(O) their(O) list(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["location","event","country","political party","person","politician","election","organization"],"instance":{"id":"113","words":["During","this","period",",","despite","no","longer","being","in","charge","of","external","affairs",",","Ismail","expressed","strong","support","for","an","Association","of","Southeast","Asia",",","telling","the","media","that","We","look","forward","to","a","regional","association","embracing","Thailand",",","Burma",",","Indonesia",",","Singapore",",","Malaysia",",","Philippines",",","Cambodia",",","Laos","and","Vietnam","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-person","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O","O","O","O","O","O","O","O","O","O","O","O","O","B-country","O","B-country","O","B-country","O","B-country","O","B-country","O","B-country","O","B-country","O","B-country","O","B-country","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, event, country, political party, person, politician, election, organization and O.\nSentence: During this period , despite no longer being in charge of external affairs , Ismail expressed strong support for an Association of Southeast Asia , telling the media that We look forward to a regional association embracing Thailand , Burma , Indonesia , Singapore , Malaysia , Philippines , Cambodia , Laos and Vietnam .","prompt_labels":"During(O) this(O) period(O) ,(O) despite(O) no(O) longer(O) being(O) in(O) charge(O) of(O) external(O) affairs(O) ,(O) Ismail(B-person) expressed(O) strong(O) support(O) for(O) an(O) Association(B-organization) of(I-organization) Southeast(I-organization) Asia(I-organization) ,(O) telling(O) the(O) media(O) that(O) We(O) look(O) forward(O) to(O) a(O) regional(O) association(O) embracing(O) Thailand(B-country) ,(O) Burma(B-country) ,(O) Indonesia(B-country) ,(O) Singapore(B-country) ,(O) Malaysia(B-country) ,(O) Philippines(B-country) ,(O) Cambodia(B-country) ,(O) Laos(B-country) and(O) Vietnam(B-country) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["organization","person","politician","country","election","location","event","political party"],"instance":{"id":"114","words":["Hisense","has","13","manufacturing","facilities","in","China","(","located","in","the","provinces","\/","cities","of",":","Guangdong",",","Guizhou",",","Huzhou",",","Jiangsu",",","Liaoning",",","Linyi",",","Shandong",",","Sichuan",",","Yangzhou",",","Yingkou",",","Xinjiang",",","Zibo","and","the","municipality","of","Beijing",")","and","several","outside","China",",","namely","in","Hungary",",","South","Africa",",","Egypt",",","Algeria",",","Slovenia",",","France","and","Mexico","."],"labels":["B-organization","O","O","O","O","O","B-country","O","O","O","O","O","O","O","O","O","B-location","O","B-location","O","B-location","O","B-location","O","B-location","O","B-location","O","B-location","O","B-location","O","B-location","O","B-location","O","B-location","O","B-location","O","O","O","O","B-location","O","O","O","O","O","O","O","O","B-country","O","B-country","I-country","O","B-country","O","B-country","O","B-country","O","B-country","O","B-country","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, person, politician, country, election, location, event, political party and O.\nSentence: Hisense has 13 manufacturing facilities in China ( located in the provinces \/ cities of : Guangdong , Guizhou , Huzhou , Jiangsu , Liaoning , Linyi , Shandong , Sichuan , Yangzhou , Yingkou , Xinjiang , Zibo and the municipality of Beijing ) and several outside China , namely in Hungary , South Africa , Egypt , Algeria , Slovenia , France and Mexico .","prompt_labels":"Hisense(B-organization) has(O) 13(O) manufacturing(O) facilities(O) in(O) China(B-country) ((O) located(O) in(O) the(O) provinces(O) \/(O) cities(O) of(O) :(O) Guangdong(B-location) ,(O) Guizhou(B-location) ,(O) Huzhou(B-location) ,(O) Jiangsu(B-location) ,(O) Liaoning(B-location) ,(O) Linyi(B-location) ,(O) Shandong(B-location) ,(O) Sichuan(B-location) ,(O) Yangzhou(B-location) ,(O) Yingkou(B-location) ,(O) Xinjiang(B-location) ,(O) Zibo(B-location) and(O) the(O) municipality(O) of(O) Beijing(B-location) )(O) and(O) several(O) outside(O) China(O) ,(O) namely(O) in(O) Hungary(B-country) ,(O) South(B-country) Africa(I-country) ,(O) Egypt(B-country) ,(O) Algeria(B-country) ,(O) Slovenia(B-country) ,(O) France(B-country) and(O) Mexico(B-country) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["election","event","country","person","politician","location","organization","political party"],"instance":{"id":"115","words":["In","1463",",","Bagrat","allied","himself","with","other","oppositionist","royal","subjects",",","dukes","(","eristavi",")","of","Principality","of","Mingrelia",",","Principality","of","Guria",",","Principality","of","Svaneti","and","Principality","of","Abkhazia","."],"labels":["O","O","O","B-politician","O","O","O","O","O","O","O","O","O","O","O","O","O","B-country","I-country","I-country","O","B-country","I-country","I-country","O","B-country","I-country","I-country","O","B-country","I-country","I-country","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: election, event, country, person, politician, location, organization, political party and O.\nSentence: In 1463 , Bagrat allied himself with other oppositionist royal subjects , dukes ( eristavi ) of Principality of Mingrelia , Principality of Guria , Principality of Svaneti and Principality of Abkhazia .","prompt_labels":"In(O) 1463(O) ,(O) Bagrat(B-politician) allied(O) himself(O) with(O) other(O) oppositionist(O) royal(O) subjects(O) ,(O) dukes(O) ((O) eristavi(O) )(O) of(O) Principality(B-country) of(I-country) Mingrelia(I-country) ,(O) Principality(B-country) of(I-country) Guria(I-country) ,(O) Principality(B-country) of(I-country) Svaneti(I-country) and(O) Principality(B-country) of(I-country) Abkhazia(I-country) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["election","politician","political party","event","person","location","country","organization"],"instance":{"id":"116","words":["A","Central","Committee","was","elected",",","composed","of","nine","members",":","Giacomo","Montalto","for","the","province","of","Trapani",",","Nicola","Petrina","for","the","province","of","Messina",",","Giuseppe","De","Felice","Giuffrida","for","the","province","of","Catania",",","Luigi","Leone","for","the","province","of","Siracusa",",","Antonio","Licata","for","the","province","of","Agrigento",",","Agostino","Lo","Piano","Pomar","for","the","province","of","Caltanissetta",",","Rosario","Garibaldi","Bosco",",","Nicola","Barbato","and","Bernardino","Verro","for","the","province","of","Palermo","."],"labels":["O","B-organization","I-organization","O","O","O","O","O","O","O","O","B-politician","I-politician","O","O","B-location","I-location","I-location","O","B-politician","I-politician","O","O","B-location","I-location","I-location","O","B-politician","I-politician","I-politician","I-politician","O","O","B-location","I-location","I-location","O","B-politician","I-politician","O","O","B-location","I-location","I-location","O","B-politician","I-politician","O","O","B-location","I-location","I-location","O","B-politician","I-politician","I-politician","I-politician","O","O","B-location","I-location","I-location","O","B-politician","I-politician","I-politician","O","B-politician","I-politician","O","B-politician","I-politician","O","O","B-location","I-location","I-location","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: election, politician, political party, event, person, location, country, organization and O.\nSentence: A Central Committee was elected , composed of nine members : Giacomo Montalto for the province of Trapani , Nicola Petrina for the province of Messina , Giuseppe De Felice Giuffrida for the province of Catania , Luigi Leone for the province of Siracusa , Antonio Licata for the province of Agrigento , Agostino Lo Piano Pomar for the province of Caltanissetta , Rosario Garibaldi Bosco , Nicola Barbato and Bernardino Verro for the province of Palermo .","prompt_labels":"A(O) Central(B-organization) Committee(I-organization) was(O) elected(O) ,(O) composed(O) of(O) nine(O) members(O) :(O) Giacomo(B-politician) Montalto(I-politician) for(O) the(O) province(B-location) of(I-location) Trapani(I-location) ,(O) Nicola(B-politician) Petrina(I-politician) for(O) the(O) province(B-location) of(I-location) Messina(I-location) ,(O) Giuseppe(B-politician) De(I-politician) Felice(I-politician) Giuffrida(I-politician) for(O) the(O) province(B-location) of(I-location) Catania(I-location) ,(O) Luigi(B-politician) Leone(I-politician) for(O) the(O) province(B-location) of(I-location) Siracusa(I-location) ,(O) Antonio(B-politician) Licata(I-politician) for(O) the(O) province(B-location) of(I-location) Agrigento(I-location) ,(O) Agostino(B-politician) Lo(I-politician) Piano(I-politician) Pomar(I-politician) for(O) the(O) province(B-location) of(I-location) Caltanissetta(I-location) ,(O) Rosario(B-politician) Garibaldi(I-politician) Bosco(I-politician) ,(O) Nicola(B-politician) Barbato(I-politician) and(O) Bernardino(B-politician) Verro(I-politician) for(O) the(O) province(B-location) of(I-location) Palermo(I-location) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["event","political party","organization","country","person","location","election","politician"],"instance":{"id":"117","words":["When","Wendell","Willkie","withdrew","from","the","race","for","the","1944","Republican","Party","presidential","primaries","on","April","5",",","following","his","complete","loss","of","the","Wisconsin","primary","in","which","New","York","Governor","Thomas","E.","Dewey",",","Harold","Stassen",",","and","General","Douglas","MacArthur","claimed","all","the","delegates",",","Associated","Press",",","Willkie","Admits","Defeat",",","Quits","Campaign",",","The","San","Bernardino","Daily","Sun",",","San","Bernardino",",","California",",","Thursday","6","April","1944",",","Volume","50",",","page","1","."],"labels":["O","B-politician","I-politician","O","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","O","O","O","O","O","O","O","O","O","O","B-location","O","O","O","B-location","I-location","O","B-politician","I-politician","I-politician","O","B-politician","I-politician","O","O","O","B-person","I-person","O","O","O","O","O","B-organization","I-organization","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","B-location","I-location","O","B-location","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, political party, organization, country, person, location, election, politician and O.\nSentence: When Wendell Willkie withdrew from the race for the 1944 Republican Party presidential primaries on April 5 , following his complete loss of the Wisconsin primary in which New York Governor Thomas E. Dewey , Harold Stassen , and General Douglas MacArthur claimed all the delegates , Associated Press , Willkie Admits Defeat , Quits Campaign , The San Bernardino Daily Sun , San Bernardino , California , Thursday 6 April 1944 , Volume 50 , page 1 .","prompt_labels":"When(O) Wendell(B-politician) Willkie(I-politician) withdrew(O) from(O) the(O) race(O) for(O) the(O) 1944(B-election) Republican(I-election) Party(I-election) presidential(I-election) primaries(I-election) on(O) April(O) 5(O) ,(O) following(O) his(O) complete(O) loss(O) of(O) the(O) Wisconsin(B-location) primary(O) in(O) which(O) New(B-location) York(I-location) Governor(O) Thomas(B-politician) E.(I-politician) Dewey(I-politician) ,(O) Harold(B-politician) Stassen(I-politician) ,(O) and(O) General(O) Douglas(B-person) MacArthur(I-person) claimed(O) all(O) the(O) delegates(O) ,(O) Associated(B-organization) Press(I-organization) ,(O) Willkie(O) Admits(O) Defeat(O) ,(O) Quits(O) Campaign(O) ,(O) The(B-organization) San(I-organization) Bernardino(I-organization) Daily(I-organization) Sun(I-organization) ,(O) San(B-location) Bernardino(I-location) ,(O) California(B-location) ,(O) Thursday(O) 6(O) April(O) 1944(O) ,(O) Volume(O) 50(O) ,(O) page(O) 1(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["person","country","organization","location","politician","election","political party","event"],"instance":{"id":"118","words":["Vice","presidents","Chen","Cheng",",","Yen","Chia-kan",",","and","Lien","Chan","all","served","as","premier","concurrently","as","vice","president","during","part","of","their","terms",",","and","vice","president","Annette","Lu","has","at","times","been","mentioned","as","a","possible","candidate","for","premiership","."],"labels":["O","O","B-politician","I-politician","O","B-politician","I-politician","O","O","B-politician","I-politician","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-politician","I-politician","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, country, organization, location, politician, election, political party, event and O.\nSentence: Vice presidents Chen Cheng , Yen Chia-kan , and Lien Chan all served as premier concurrently as vice president during part of their terms , and vice president Annette Lu has at times been mentioned as a possible candidate for premiership .","prompt_labels":"Vice(O) presidents(O) Chen(B-politician) Cheng(I-politician) ,(O) Yen(B-politician) Chia-kan(I-politician) ,(O) and(O) Lien(B-politician) Chan(I-politician) all(O) served(O) as(O) premier(O) concurrently(O) as(O) vice(O) president(O) during(O) part(O) of(O) their(O) terms(O) ,(O) and(O) vice(O) president(O) Annette(B-politician) Lu(I-politician) has(O) at(O) times(O) been(O) mentioned(O) as(O) a(O) possible(O) candidate(O) for(O) premiership(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["event","election","political party","person","location","politician","country","organization"],"instance":{"id":"119","words":["Peninsular","Malaysia","shares","a","land","and","maritime","border","with","Thailand","and","maritime","borders","with","Singapore",",","Vietnam",",","and","Indonesia","."],"labels":["B-location","I-location","O","O","O","O","O","O","O","B-country","O","O","O","O","B-country","O","B-country","O","O","B-country","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, election, political party, person, location, politician, country, organization and O.\nSentence: Peninsular Malaysia shares a land and maritime border with Thailand and maritime borders with Singapore , Vietnam , and Indonesia .","prompt_labels":"Peninsular(B-location) Malaysia(I-location) shares(O) a(O) land(O) and(O) maritime(O) border(O) with(O) Thailand(B-country) and(O) maritime(O) borders(O) with(O) Singapore(B-country) ,(O) Vietnam(B-country) ,(O) and(O) Indonesia(B-country) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["election","politician","country","political party","person","event","location","organization"],"instance":{"id":"120","words":["Malaya","united","with","Crown","Colony","of","North","Borneo",",","Crown","Colony","of","Sarawak",",","and","Colony","of","Singapore","on","16","September","1963","to","become","Malaysia","."],"labels":["B-country","O","O","B-country","I-country","I-country","I-country","I-country","O","B-country","I-country","I-country","I-country","O","O","B-country","I-country","I-country","O","O","O","O","O","O","B-country","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: election, politician, country, political party, person, event, location, organization and O.\nSentence: Malaya united with Crown Colony of North Borneo , Crown Colony of Sarawak , and Colony of Singapore on 16 September 1963 to become Malaysia .","prompt_labels":"Malaya(B-country) united(O) with(O) Crown(B-country) Colony(I-country) of(I-country) North(I-country) Borneo(I-country) ,(O) Crown(B-country) Colony(I-country) of(I-country) Sarawak(I-country) ,(O) and(O) Colony(B-country) of(I-country) Singapore(I-country) on(O) 16(O) September(O) 1963(O) to(O) become(O) Malaysia(B-country) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["organization","location","person","politician","election","political party","event","country"],"instance":{"id":"121","words":["It","is","a","founding","member","of","ASEAN",",","EAS",",","Organisation","of","Islamic","Cooperation","and","a","member","of","Asia-Pacific","Economic","Cooperation",",","the","Commonwealth","of","Nations","and","the","Non-Aligned","Movement","."],"labels":["O","O","O","O","O","O","B-organization","O","B-organization","O","B-organization","I-organization","I-organization","I-organization","O","O","O","O","B-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","O","O","B-organization","I-organization","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, location, person, politician, election, political party, event, country and O.\nSentence: It is a founding member of ASEAN , EAS , Organisation of Islamic Cooperation and a member of Asia-Pacific Economic Cooperation , the Commonwealth of Nations and the Non-Aligned Movement .","prompt_labels":"It(O) is(O) a(O) founding(O) member(O) of(O) ASEAN(B-organization) ,(O) EAS(B-organization) ,(O) Organisation(B-organization) of(I-organization) Islamic(I-organization) Cooperation(I-organization) and(O) a(O) member(O) of(O) Asia-Pacific(B-organization) Economic(I-organization) Cooperation(I-organization) ,(O) the(O) Commonwealth(B-organization) of(I-organization) Nations(I-organization) and(O) the(O) Non-Aligned(B-organization) Movement(I-organization) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["location","country","person","organization","event","political party","politician","election"],"instance":{"id":"122","words":["Stanley","(","then","known","as","the","Honourable","Edward","Lyulph","Stanley",")","contested","Oldham",",","in","the","Liberal","interest",",","at","elections","in","1872",",","1874","United","Kingdom","general","election",",","1880","United","Kingdom","general","election","and","1885","United","Kingdom","general","election","."],"labels":["B-politician","O","O","O","O","O","O","B-politician","I-politician","I-politician","O","O","B-location","O","O","O","B-political party","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, country, person, organization, event, political party, politician, election and O.\nSentence: Stanley ( then known as the Honourable Edward Lyulph Stanley ) contested Oldham , in the Liberal interest , at elections in 1872 , 1874 United Kingdom general election , 1880 United Kingdom general election and 1885 United Kingdom general election .","prompt_labels":"Stanley(B-politician) ((O) then(O) known(O) as(O) the(O) Honourable(O) Edward(B-politician) Lyulph(I-politician) Stanley(I-politician) )(O) contested(O) Oldham(B-location) ,(O) in(O) the(O) Liberal(B-political party) interest(O) ,(O) at(O) elections(O) in(O) 1872(O) ,(O) 1874(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) 1880(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) and(O) 1885(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["organization","country","politician","election","political party","event","person","location"],"instance":{"id":"123","words":["Malagodi","managed","to","draw","some","votes","from","the","Italian","Social","Movement",",","the","Monarchist","National","Party","and","especially","Christian","Democracy",",","whose","electoral","base","was","composed","also","by","conservatives","suspicious","of","the","Socialists",",","increasing","the","party","'s","share","to","a","historical","record","of","7.0","%","in","the","1963","Italian","general","election","."],"labels":["B-politician","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","O","O","B-political party","I-political party","I-political party","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, country, politician, election, political party, event, person, location and O.\nSentence: Malagodi managed to draw some votes from the Italian Social Movement , the Monarchist National Party and especially Christian Democracy , whose electoral base was composed also by conservatives suspicious of the Socialists , increasing the party 's share to a historical record of 7.0 % in the 1963 Italian general election .","prompt_labels":"Malagodi(B-politician) managed(O) to(O) draw(O) some(O) votes(O) from(O) the(O) Italian(B-political party) Social(I-political party) Movement(I-political party) ,(O) the(O) Monarchist(B-political party) National(I-political party) Party(I-political party) and(O) especially(O) Christian(O) Democracy(O) ,(O) whose(O) electoral(O) base(O) was(O) composed(O) also(O) by(O) conservatives(O) suspicious(O) of(O) the(O) Socialists(O) ,(O) increasing(O) the(O) party(O) 's(O) share(O) to(O) a(O) historical(O) record(O) of(O) 7.0(O) %(O) in(O) the(O) 1963(B-election) Italian(I-election) general(I-election) election(I-election) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["person","country","political party","location","organization","politician","election","event"],"instance":{"id":"124","words":["In","1983","the","PLI","finally","joined","the","pentapartito","coalition","composed","also","of","the","Christian","Democracy","(","DC",")",",","the","Italian","Socialist","Party","(","PSI",")",",","the","Italian","Democratic","Socialist","Party","(","PSDI",")","and","the","Italian","Republican","Party","(","PRI",")","."],"labels":["O","O","O","B-organization","O","O","O","B-political party","O","O","O","O","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","O","B-political party","O","O","O","B-political party","I-political party","I-political party","I-political party","O","B-political party","O","O","O","B-political party","I-political party","I-political party","O","B-political party","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, country, political party, location, organization, politician, election, event and O.\nSentence: In 1983 the PLI finally joined the pentapartito coalition composed also of the Christian Democracy ( DC ) , the Italian Socialist Party ( PSI ) , the Italian Democratic Socialist Party ( PSDI ) and the Italian Republican Party ( PRI ) .","prompt_labels":"In(O) 1983(O) the(O) PLI(B-organization) finally(O) joined(O) the(O) pentapartito(B-political party) coalition(O) composed(O) also(O) of(O) the(O) Christian(O) Democracy(O) ((O) DC(O) )(O) ,(O) the(O) Italian(B-political party) Socialist(I-political party) Party(I-political party) ((O) PSI(B-political party) )(O) ,(O) the(O) Italian(B-political party) Democratic(I-political party) Socialist(I-political party) Party(I-political party) ((O) PSDI(B-political party) )(O) and(O) the(O) Italian(B-political party) Republican(I-political party) Party(I-political party) ((O) PRI(B-political party) )(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["person","organization","country","location","politician","political party","event","election"],"instance":{"id":"125","words":["As","the","other","parties","of","the","pentapartito","coalition","(","Christian","Democrats",",","Italian","Socialist","Party",",","Italian","Republican","Party","and","Italian","Democratic","Socialist","Party",")",",","the","Liberals","strengthened","their","grip","on","the","South",",","while","in","the","North","they","lost","some","of","their","residual","votes","to","Lega","Nord","and","its","precursors","."],"labels":["O","O","O","O","O","O","B-political party","O","O","O","O","O","B-political party","I-political party","I-political party","O","B-political party","I-political party","I-political party","O","B-political party","I-political party","I-political party","I-political party","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-political party","I-political party","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, organization, country, location, politician, political party, event, election and O.\nSentence: As the other parties of the pentapartito coalition ( Christian Democrats , Italian Socialist Party , Italian Republican Party and Italian Democratic Socialist Party ) , the Liberals strengthened their grip on the South , while in the North they lost some of their residual votes to Lega Nord and its precursors .","prompt_labels":"As(O) the(O) other(O) parties(O) of(O) the(O) pentapartito(B-political party) coalition(O) ((O) Christian(O) Democrats(O) ,(O) Italian(B-political party) Socialist(I-political party) Party(I-political party) ,(O) Italian(B-political party) Republican(I-political party) Party(I-political party) and(O) Italian(B-political party) Democratic(I-political party) Socialist(I-political party) Party(I-political party) )(O) ,(O) the(O) Liberals(O) strengthened(O) their(O) grip(O) on(O) the(O) South(O) ,(O) while(O) in(O) the(O) North(O) they(O) lost(O) some(O) of(O) their(O) residual(O) votes(O) to(O) Lega(B-political party) Nord(I-political party) and(O) its(O) precursors(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["political party","location","event","person","politician","organization","election","country"],"instance":{"id":"126","words":["For","the","2018","Pakistani","general","election",",","PML-F","lead","a","new","coalition","named","Grand","Democratic","Alliance","with","Awami","Tahreek",",","National","Peoples","Party",",","Pakistan","Peoples","Party","Workers","and","Pakistan","Peoples","Muslim","League","."],"labels":["O","O","B-election","I-election","I-election","I-election","O","B-political party","O","O","O","O","O","B-political party","I-political party","I-political party","O","B-political party","I-political party","O","B-political party","I-political party","I-political party","O","B-political party","I-political party","I-political party","I-political party","O","B-political party","I-political party","I-political party","I-political party","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: political party, location, event, person, politician, organization, election, country and O.\nSentence: For the 2018 Pakistani general election , PML-F lead a new coalition named Grand Democratic Alliance with Awami Tahreek , National Peoples Party , Pakistan Peoples Party Workers and Pakistan Peoples Muslim League .","prompt_labels":"For(O) the(O) 2018(B-election) Pakistani(I-election) general(I-election) election(I-election) ,(O) PML-F(B-political party) lead(O) a(O) new(O) coalition(O) named(O) Grand(B-political party) Democratic(I-political party) Alliance(I-political party) with(O) Awami(B-political party) Tahreek(I-political party) ,(O) National(B-political party) Peoples(I-political party) Party(I-political party) ,(O) Pakistan(B-political party) Peoples(I-political party) Party(I-political party) Workers(I-political party) and(O) Pakistan(B-political party) Peoples(I-political party) Muslim(I-political party) League(I-political party) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["organization","politician","location","country","person","event","political party","election"],"instance":{"id":"127","words":["They","would","win","a","small","12-seat","majority","in","2015","United","Kingdom","general","election",",","only","to","lose","it","again","at","the","2017","United","Kingdom","general","election","but","would","win","in","a","landslide","in","the","2019","United","Kingdom","general","election","."],"labels":["O","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","O","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","O","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, politician, location, country, person, event, political party, election and O.\nSentence: They would win a small 12-seat majority in 2015 United Kingdom general election , only to lose it again at the 2017 United Kingdom general election but would win in a landslide in the 2019 United Kingdom general election .","prompt_labels":"They(O) would(O) win(O) a(O) small(O) 12-seat(O) majority(O) in(O) 2015(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) only(O) to(O) lose(O) it(O) again(O) at(O) the(O) 2017(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) but(O) would(O) win(O) in(O) a(O) landslide(O) in(O) the(O) 2019(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["person","country","political party","politician","event","organization","location","election"],"instance":{"id":"128","words":["The","Progressive","Conservative","Party","of","Canada","government","of","the","time",",","headed","by","Prime","Minister","John","Diefenbaker",",","did","not","accept","the","invitation","to","establish","a","new","Canadian","flag",",","so","Pearson","made","it","Liberal","Party","of","Canada","policy","in","1961",",","and","part","of","the","party","'s","election","platform","in","the","1962","Canadian","federal","election","and","1963","Canadian","federal","election","."],"labels":["O","B-political party","I-political party","I-political party","I-political party","I-political party","O","O","O","O","O","O","O","O","O","B-politician","I-politician","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-politician","O","O","B-political party","I-political party","I-political party","I-political party","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, country, political party, politician, event, organization, location, election and O.\nSentence: The Progressive Conservative Party of Canada government of the time , headed by Prime Minister John Diefenbaker , did not accept the invitation to establish a new Canadian flag , so Pearson made it Liberal Party of Canada policy in 1961 , and part of the party 's election platform in the 1962 Canadian federal election and 1963 Canadian federal election .","prompt_labels":"The(O) Progressive(B-political party) Conservative(I-political party) Party(I-political party) of(I-political party) Canada(I-political party) government(O) of(O) the(O) time(O) ,(O) headed(O) by(O) Prime(O) Minister(O) John(B-politician) Diefenbaker(I-politician) ,(O) did(O) not(O) accept(O) the(O) invitation(O) to(O) establish(O) a(O) new(O) Canadian(O) flag(O) ,(O) so(O) Pearson(B-politician) made(O) it(O) Liberal(B-political party) Party(I-political party) of(I-political party) Canada(I-political party) policy(O) in(O) 1961(O) ,(O) and(O) part(O) of(O) the(O) party(O) 's(O) election(O) platform(O) in(O) the(O) 1962(B-election) Canadian(I-election) federal(I-election) election(I-election) and(O) 1963(B-election) Canadian(I-election) federal(I-election) election(I-election) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["person","election","event","organization","politician","location","country","political party"],"instance":{"id":"129","words":["He","ran","as","a","Conservative","Party","of","Canada","in","the","1911","Canadian","federal","election",",","finishing","second","of","three","candidates","in","the","riding","of","Edmonton","(","the","victorious","candidate","was","Liberal","Party","of","Canada","Frank","Oliver",")","."],"labels":["O","O","O","O","B-political party","I-political party","I-political party","I-political party","O","O","B-election","I-election","I-election","I-election","O","O","O","O","O","O","O","O","O","O","B-location","O","O","O","O","O","B-political party","I-political party","I-political party","I-political party","B-politician","I-politician","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, election, event, organization, politician, location, country, political party and O.\nSentence: He ran as a Conservative Party of Canada in the 1911 Canadian federal election , finishing second of three candidates in the riding of Edmonton ( the victorious candidate was Liberal Party of Canada Frank Oliver ) .","prompt_labels":"He(O) ran(O) as(O) a(O) Conservative(B-political party) Party(I-political party) of(I-political party) Canada(I-political party) in(O) the(O) 1911(B-election) Canadian(I-election) federal(I-election) election(I-election) ,(O) finishing(O) second(O) of(O) three(O) candidates(O) in(O) the(O) riding(O) of(O) Edmonton(B-location) ((O) the(O) victorious(O) candidate(O) was(O) Liberal(B-political party) Party(I-political party) of(I-political party) Canada(I-political party) Frank(B-politician) Oliver(I-politician) )(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["organization","country","political party","person","event","election","politician","location"],"instance":{"id":"130","words":["He","contested","Cardiff","North","in","October","1974","United","Kingdom","general","election","and","1979","United","Kingdom","general","election","for","the","Liberals",",","before","fighting","Cardiff","Central","in","1983","United","Kingdom","general","election","and","1987","United","Kingdom","general","election","for","the","SDP-Liberal","Alliance",",","but","was","unsuccessful","on","each","occasion","."],"labels":["O","O","B-politician","I-politician","O","B-election","I-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","O","O","B-political party","O","O","O","B-politician","I-politician","O","B-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","O","O","B-political party","I-political party","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, country, political party, person, event, election, politician, location and O.\nSentence: He contested Cardiff North in October 1974 United Kingdom general election and 1979 United Kingdom general election for the Liberals , before fighting Cardiff Central in 1983 United Kingdom general election and 1987 United Kingdom general election for the SDP-Liberal Alliance , but was unsuccessful on each occasion .","prompt_labels":"He(O) contested(O) Cardiff(B-politician) North(I-politician) in(O) October(B-election) 1974(I-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) and(O) 1979(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) for(O) the(O) Liberals(B-political party) ,(O) before(O) fighting(O) Cardiff(B-politician) Central(I-politician) in(O) 1983(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) and(O) 1987(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) for(O) the(O) SDP-Liberal(B-political party) Alliance(I-political party) ,(O) but(O) was(O) unsuccessful(O) on(O) each(O) occasion(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["election","location","politician","country","organization","political party","person","event"],"instance":{"id":"131","words":["She","was","first","elected","in","the","2000","Canadian","federal","election","by","68","votes","over","incumbent","Dennis","Gruending","of","the","New","Democratic","Party","in","the","riding","of","Saskatoon","-","Rosetown","-","Biggar",",","as","a","member","of","the","Canadian","Alliance","."],"labels":["O","O","O","O","O","O","B-election","I-election","I-election","I-election","O","O","O","O","O","B-politician","I-politician","O","O","B-political party","I-political party","I-political party","O","O","O","O","B-location","I-location","I-location","I-location","I-location","O","O","O","O","O","O","B-political party","I-political party","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: election, location, politician, country, organization, political party, person, event and O.\nSentence: She was first elected in the 2000 Canadian federal election by 68 votes over incumbent Dennis Gruending of the New Democratic Party in the riding of Saskatoon - Rosetown - Biggar , as a member of the Canadian Alliance .","prompt_labels":"She(O) was(O) first(O) elected(O) in(O) the(O) 2000(B-election) Canadian(I-election) federal(I-election) election(I-election) by(O) 68(O) votes(O) over(O) incumbent(O) Dennis(B-politician) Gruending(I-politician) of(O) the(O) New(B-political party) Democratic(I-political party) Party(I-political party) in(O) the(O) riding(O) of(O) Saskatoon(B-location) -(I-location) Rosetown(I-location) -(I-location) Biggar(I-location) ,(O) as(O) a(O) member(O) of(O) the(O) Canadian(B-political party) Alliance(I-political party) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["election","political party","politician","organization","country","location","person","event"],"instance":{"id":"132","words":["She","was","re-elected","in","the","federal","general","elections","of","1997","Canadian","federal","election",",","2000","Canadian","federal","election",",","2004","Canadian","federal","election",",","2006","Canadian","federal","election",",","and","2008","Canadian","federal","election","."],"labels":["O","O","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","O","O","B-election","I-election","I-election","I-election","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: election, political party, politician, organization, country, location, person, event and O.\nSentence: She was re-elected in the federal general elections of 1997 Canadian federal election , 2000 Canadian federal election , 2004 Canadian federal election , 2006 Canadian federal election , and 2008 Canadian federal election .","prompt_labels":"She(O) was(O) re-elected(O) in(O) the(O) federal(O) general(O) elections(O) of(O) 1997(B-election) Canadian(I-election) federal(I-election) election(I-election) ,(O) 2000(B-election) Canadian(I-election) federal(I-election) election(I-election) ,(O) 2004(B-election) Canadian(I-election) federal(I-election) election(I-election) ,(O) 2006(B-election) Canadian(I-election) federal(I-election) election(I-election) ,(O) and(O) 2008(B-election) Canadian(I-election) federal(I-election) election(I-election) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["person","country","politician","event","organization","political party","election","location"],"instance":{"id":"133","words":["Since","1952",",","control","of","the","House","has","changed","hands","five","times",",","all","of","which","were","in","midterm","elections","(","1954","United","States","House","of","Representatives","elections",",","1994","United","States","House","of","Representatives","elections",",","2006","United","States","House","of","Representatives","elections",",","2010","United","States","House","of","Representatives","elections","and","2018","United","States","House","of","Representatives","elections",")","and","all","of","which","were","at","the","expense","of","the","incumbent","President","'s","party","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","I-election","I-election","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, country, politician, event, organization, political party, election, location and O.\nSentence: Since 1952 , control of the House has changed hands five times , all of which were in midterm elections ( 1954 United States House of Representatives elections , 1994 United States House of Representatives elections , 2006 United States House of Representatives elections , 2010 United States House of Representatives elections and 2018 United States House of Representatives elections ) and all of which were at the expense of the incumbent President 's party .","prompt_labels":"Since(O) 1952(O) ,(O) control(O) of(O) the(O) House(O) has(O) changed(O) hands(O) five(O) times(O) ,(O) all(O) of(O) which(O) were(O) in(O) midterm(O) elections(O) ((O) 1954(B-election) United(I-election) States(I-election) House(I-election) of(I-election) Representatives(I-election) elections(I-election) ,(O) 1994(B-election) United(I-election) States(I-election) House(I-election) of(I-election) Representatives(I-election) elections(I-election) ,(O) 2006(B-election) United(I-election) States(I-election) House(I-election) of(I-election) Representatives(I-election) elections(I-election) ,(O) 2010(B-election) United(I-election) States(I-election) House(I-election) of(I-election) Representatives(I-election) elections(I-election) and(O) 2018(B-election) United(I-election) States(I-election) House(I-election) of(I-election) Representatives(I-election) elections(I-election) )(O) and(O) all(O) of(O) which(O) were(O) at(O) the(O) expense(O) of(O) the(O) incumbent(O) President(O) 's(O) party(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["location","organization","country","political party","event","election","politician","person"],"instance":{"id":"134","words":["In","May","2012","the","Likeminded","Group","formed","an","alliance","with","the","PML","(","N",")","in","a","bid","to","unite","all","Pakistan","Muslim","League","factions","under","the","leadership","of","Nawaz","Sharif",",","with","the","aim","of","defeating","the","Pakistan","Tehreek-e-Insaf","and","the","ruling","coalition","of","Pakistan","Peoples","Party","and","PML","(","Q",")","in","the","upcoming","2013","Pakistani","general","election","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","B-political party","O","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","O","O","O","O","O","B-politician","I-politician","O","O","O","O","O","O","O","B-political party","I-political party","O","O","O","O","O","B-political party","I-political party","I-political party","O","B-political party","O","O","O","O","O","O","B-election","I-election","I-election","I-election","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, organization, country, political party, event, election, politician, person and O.\nSentence: In May 2012 the Likeminded Group formed an alliance with the PML ( N ) in a bid to unite all Pakistan Muslim League factions under the leadership of Nawaz Sharif , with the aim of defeating the Pakistan Tehreek-e-Insaf and the ruling coalition of Pakistan Peoples Party and PML ( Q ) in the upcoming 2013 Pakistani general election .","prompt_labels":"In(O) May(O) 2012(O) the(O) Likeminded(O) Group(O) formed(O) an(O) alliance(O) with(O) the(O) PML(B-political party) ((O) N(O) )(O) in(O) a(O) bid(O) to(O) unite(O) all(O) Pakistan(B-political party) Muslim(I-political party) League(I-political party) factions(O) under(O) the(O) leadership(O) of(O) Nawaz(B-politician) Sharif(I-politician) ,(O) with(O) the(O) aim(O) of(O) defeating(O) the(O) Pakistan(B-political party) Tehreek-e-Insaf(I-political party) and(O) the(O) ruling(O) coalition(O) of(O) Pakistan(B-political party) Peoples(I-political party) Party(I-political party) and(O) PML(B-political party) ((O) Q(O) )(O) in(O) the(O) upcoming(O) 2013(B-election) Pakistani(I-election) general(I-election) election(I-election) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["politician","election","political party","person","country","location","event","organization"],"instance":{"id":"135","words":["The","original","participating","parties","were",":","the","Soqosoqo","Duavata","ni","Lewenivanua","(","SDL",")","and","the","Conservative","Alliance-Matanitu","Vanua","(","CAMV",")","(","these","two","parties","were","already","in","coalition",",","comprising","bulk","of","the","present","government",")",",","the","Soqosoqo","ni","Vakavulewa","ni","Taukei","(","SVT",")","(","which","led","Fiji","'s","governments","from","1992","to","1999",")",",","the","Nationalist","Vanua","Tako","Lavo","Party","(","NVTL",")",",","and","the","People","'s","National","Party","(","PNP",")","."],"labels":["O","O","O","O","O","O","O","B-political party","I-political party","I-political party","I-political party","O","B-political party","O","O","O","B-political party","I-political party","I-political party","O","B-political party","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","O","B-political party","O","O","O","O","B-country","O","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","O","B-political party","O","O","O","O","B-political party","I-political party","I-political party","I-political party","O","B-political party","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: politician, election, political party, person, country, location, event, organization and O.\nSentence: The original participating parties were : the Soqosoqo Duavata ni Lewenivanua ( SDL ) and the Conservative Alliance-Matanitu Vanua ( CAMV ) ( these two parties were already in coalition , comprising bulk of the present government ) , the Soqosoqo ni Vakavulewa ni Taukei ( SVT ) ( which led Fiji 's governments from 1992 to 1999 ) , the Nationalist Vanua Tako Lavo Party ( NVTL ) , and the People 's National Party ( PNP ) .","prompt_labels":"The(O) original(O) participating(O) parties(O) were(O) :(O) the(O) Soqosoqo(B-political party) Duavata(I-political party) ni(I-political party) Lewenivanua(I-political party) ((O) SDL(B-political party) )(O) and(O) the(O) Conservative(B-political party) Alliance-Matanitu(I-political party) Vanua(I-political party) ((O) CAMV(B-political party) )(O) ((O) these(O) two(O) parties(O) were(O) already(O) in(O) coalition(O) ,(O) comprising(O) bulk(O) of(O) the(O) present(O) government(O) )(O) ,(O) the(O) Soqosoqo(B-political party) ni(I-political party) Vakavulewa(I-political party) ni(I-political party) Taukei(I-political party) ((O) SVT(B-political party) )(O) ((O) which(O) led(O) Fiji(B-country) 's(O) governments(O) from(O) 1992(O) to(O) 1999(O) )(O) ,(O) the(O) Nationalist(B-political party) Vanua(I-political party) Tako(I-political party) Lavo(I-political party) Party(I-political party) ((O) NVTL(B-political party) )(O) ,(O) and(O) the(O) People(B-political party) 's(I-political party) National(I-political party) Party(I-political party) ((O) PNP(B-political party) )(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["political party","politician","country","organization","event","person","election","location"],"instance":{"id":"136","words":["In","2016",",","Shorten","led","Labor","to","gain","14","seats","at","the","2016","Australian","federal","election","when","Malcolm","Turnbull","and","the","Liberal","Party","of","Australia","-","National","Party","of","Australia","Coalition","retained","majority","government","by","a","single","seat","."],"labels":["O","O","O","B-politician","O","B-political party","O","O","O","O","O","O","B-election","I-election","I-election","I-election","O","B-politician","I-politician","O","O","B-political party","I-political party","I-political party","I-political party","O","B-political party","I-political party","I-political party","I-political party","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: political party, politician, country, organization, event, person, election, location and O.\nSentence: In 2016 , Shorten led Labor to gain 14 seats at the 2016 Australian federal election when Malcolm Turnbull and the Liberal Party of Australia - National Party of Australia Coalition retained majority government by a single seat .","prompt_labels":"In(O) 2016(O) ,(O) Shorten(B-politician) led(O) Labor(B-political party) to(O) gain(O) 14(O) seats(O) at(O) the(O) 2016(B-election) Australian(I-election) federal(I-election) election(I-election) when(O) Malcolm(B-politician) Turnbull(I-politician) and(O) the(O) Liberal(B-political party) Party(I-political party) of(I-political party) Australia(I-political party) -(O) National(B-political party) Party(I-political party) of(I-political party) Australia(I-political party) Coalition(O) retained(O) majority(O) government(O) by(O) a(O) single(O) seat(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["event","person","politician","country","organization","election","location","political party"],"instance":{"id":"137","words":["Park","won","re-election","in","the","1967","South","Korean","presidential","election",",","and","the","National","Assembly","passed","a","constitutional","amendment","that","allowed","him","to","serve","a","third","term",",","which","he","narrowly","won","in","the","1971","South","Korean","presidential","election","against","Kim","Dae-jung","of","the","New","Democratic","Party","."],"labels":["B-politician","O","O","O","O","B-election","I-election","I-election","I-election","I-election","O","O","O","B-organization","I-organization","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","O","B-politician","I-politician","O","O","B-political party","I-political party","I-political party","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, person, politician, country, organization, election, location, political party and O.\nSentence: Park won re-election in the 1967 South Korean presidential election , and the National Assembly passed a constitutional amendment that allowed him to serve a third term , which he narrowly won in the 1971 South Korean presidential election against Kim Dae-jung of the New Democratic Party .","prompt_labels":"Park(B-politician) won(O) re-election(O) in(O) the(O) 1967(B-election) South(I-election) Korean(I-election) presidential(I-election) election(I-election) ,(O) and(O) the(O) National(B-organization) Assembly(I-organization) passed(O) a(O) constitutional(O) amendment(O) that(O) allowed(O) him(O) to(O) serve(O) a(O) third(O) term(O) ,(O) which(O) he(O) narrowly(O) won(O) in(O) the(O) 1971(B-election) South(I-election) Korean(I-election) presidential(I-election) election(I-election) against(O) Kim(B-politician) Dae-jung(I-politician) of(O) the(O) New(B-political party) Democratic(I-political party) Party(I-political party) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["election","event","organization","location","political party","person","country","politician"],"instance":{"id":"138","words":["However",",","in","the","2004","Canadian","federal","election",",","2006","Canadian","federal","election",",","2008","Canadian","federal","election","and","2011","Canadian","federal","election",",","the","entire","region",",","incrementally","swung","away","from","the","Liberals","to","support","the","Conservative","Party","of","Canada",",","including","in","London",",","where","three-way","vote-splitting","resulted","in","two","ridings","switching","from","Liberal","to","Conservative","."],"labels":["O","O","O","O","B-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","O","O","O","O","O","O","O","O","O","O","B-political party","O","O","O","B-political party","I-political party","I-political party","I-political party","O","O","O","B-location","O","O","O","O","O","O","O","O","O","O","B-political party","O","B-political party","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: election, event, organization, location, political party, person, country, politician and O.\nSentence: However , in the 2004 Canadian federal election , 2006 Canadian federal election , 2008 Canadian federal election and 2011 Canadian federal election , the entire region , incrementally swung away from the Liberals to support the Conservative Party of Canada , including in London , where three-way vote-splitting resulted in two ridings switching from Liberal to Conservative .","prompt_labels":"However(O) ,(O) in(O) the(O) 2004(B-election) Canadian(I-election) federal(I-election) election(I-election) ,(O) 2006(B-election) Canadian(I-election) federal(I-election) election(I-election) ,(O) 2008(B-election) Canadian(I-election) federal(I-election) election(I-election) and(O) 2011(B-election) Canadian(I-election) federal(I-election) election(I-election) ,(O) the(O) entire(O) region(O) ,(O) incrementally(O) swung(O) away(O) from(O) the(O) Liberals(B-political party) to(O) support(O) the(O) Conservative(B-political party) Party(I-political party) of(I-political party) Canada(I-political party) ,(O) including(O) in(O) London(B-location) ,(O) where(O) three-way(O) vote-splitting(O) resulted(O) in(O) two(O) ridings(O) switching(O) from(O) Liberal(B-political party) to(O) Conservative(B-political party) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["political party","election","organization","location","event","politician","person","country"],"instance":{"id":"139","words":["The","Commune","was","formed","by","85","Social","Revolutionaries","and","Left","Socialist-Revolutionaries",",","48","Bolsheviks",",","36","Dashnaks",",","18","Musavat","ists","and","13","Mensheviks","."],"labels":["O","O","O","O","O","O","B-political party","I-political party","O","B-political party","I-political party","O","O","B-political party","O","O","B-political party","O","O","B-political party","O","O","O","B-political party","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: political party, election, organization, location, event, politician, person, country and O.\nSentence: The Commune was formed by 85 Social Revolutionaries and Left Socialist-Revolutionaries , 48 Bolsheviks , 36 Dashnaks , 18 Musavat ists and 13 Mensheviks .","prompt_labels":"The(O) Commune(O) was(O) formed(O) by(O) 85(O) Social(B-political party) Revolutionaries(I-political party) and(O) Left(B-political party) Socialist-Revolutionaries(I-political party) ,(O) 48(O) Bolsheviks(B-political party) ,(O) 36(O) Dashnaks(B-political party) ,(O) 18(O) Musavat(B-political party) ists(O) and(O) 13(O) Mensheviks(B-political party) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["location","country","person","event","politician","election","organization","political party"],"instance":{"id":"140","words":["This","election","was","the","first","that","the","New","Democratic","Party","contested","as","a","provincial","party","on","PEI",",","and","the","first","third","party","to","run","candidates","since","the","Co-operative","Commonwealth","Federation",",","the","NDP","'s","predecessor",",","contested","their","last","election","in","1951","Prince","Edward","Island","general","election","."],"labels":["O","O","O","O","O","O","O","B-political party","I-political party","I-political party","O","O","O","O","O","O","B-location","O","O","O","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","O","O","B-political party","O","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","I-election","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, country, person, event, politician, election, organization, political party and O.\nSentence: This election was the first that the New Democratic Party contested as a provincial party on PEI , and the first third party to run candidates since the Co-operative Commonwealth Federation , the NDP 's predecessor , contested their last election in 1951 Prince Edward Island general election .","prompt_labels":"This(O) election(O) was(O) the(O) first(O) that(O) the(O) New(B-political party) Democratic(I-political party) Party(I-political party) contested(O) as(O) a(O) provincial(O) party(O) on(O) PEI(B-location) ,(O) and(O) the(O) first(O) third(O) party(O) to(O) run(O) candidates(O) since(O) the(O) Co-operative(B-political party) Commonwealth(I-political party) Federation(I-political party) ,(O) the(O) NDP(B-political party) 's(O) predecessor(O) ,(O) contested(O) their(O) last(O) election(O) in(O) 1951(B-election) Prince(I-election) Edward(I-election) Island(I-election) general(I-election) election(I-election) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["organization","political party","event","location","person","politician","election","country"],"instance":{"id":"141","words":["During","her","visit","she","met","representatives","from","the","National","Center","for","Transgender","Equality",",","the","National","Association","of","LGBT","Community","Centers",",","the","National","Gay","and","Lesbian","Task","Force",",","Freedom","to","Marry","and","the","Stonewall","Democrats","."],"labels":["O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","B-organization","I-organization","I-organization","O","O","B-organization","I-organization","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, political party, event, location, person, politician, election, country and O.\nSentence: During her visit she met representatives from the National Center for Transgender Equality , the National Association of LGBT Community Centers , the National Gay and Lesbian Task Force , Freedom to Marry and the Stonewall Democrats .","prompt_labels":"During(O) her(O) visit(O) she(O) met(O) representatives(O) from(O) the(O) National(B-organization) Center(I-organization) for(I-organization) Transgender(I-organization) Equality(I-organization) ,(O) the(O) National(B-organization) Association(I-organization) of(I-organization) LGBT(I-organization) Community(I-organization) Centers(I-organization) ,(O) the(O) National(B-organization) Gay(I-organization) and(I-organization) Lesbian(I-organization) Task(I-organization) Force(I-organization) ,(O) Freedom(B-organization) to(I-organization) Marry(I-organization) and(O) the(O) Stonewall(B-organization) Democrats(I-organization) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["location","political party","person","country","election","organization","event","politician"],"instance":{"id":"142","words":["He","had","been","targeted","by","the","radical","democrats",",","including","Albert","Chan","of","the","People","Power","in","the","2011","Hong","Kong","local","elections","who","opposed","Democrats","'","compromise","with","the","Beijing","officials","on","the","2012","constitutional","reform","proposals","and","in","the","2015","Hong","Kong","local","elections","by","Civic","Passion","'","s","Cheng","Chung-tai","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-politician","I-politician","O","O","B-political party","I-political party","O","O","B-election","I-election","I-election","I-election","I-election","O","O","O","O","O","O","O","B-location","O","O","O","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","O","B-political party","I-political party","O","O","B-politician","I-politician","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, political party, person, country, election, organization, event, politician and O.\nSentence: He had been targeted by the radical democrats , including Albert Chan of the People Power in the 2011 Hong Kong local elections who opposed Democrats ' compromise with the Beijing officials on the 2012 constitutional reform proposals and in the 2015 Hong Kong local elections by Civic Passion ' s Cheng Chung-tai .","prompt_labels":"He(O) had(O) been(O) targeted(O) by(O) the(O) radical(O) democrats(O) ,(O) including(O) Albert(B-politician) Chan(I-politician) of(O) the(O) People(B-political party) Power(I-political party) in(O) the(O) 2011(B-election) Hong(I-election) Kong(I-election) local(I-election) elections(I-election) who(O) opposed(O) Democrats(O) '(O) compromise(O) with(O) the(O) Beijing(B-location) officials(O) on(O) the(O) 2012(O) constitutional(O) reform(O) proposals(O) and(O) in(O) the(O) 2015(B-election) Hong(I-election) Kong(I-election) local(I-election) elections(I-election) by(O) Civic(B-political party) Passion(I-political party) '(O) s(O) Cheng(B-politician) Chung-tai(I-politician) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["politician","location","event","country","political party","person","election","organization"],"instance":{"id":"143","words":["Prominent","members","of","the","SPL","joined","the","new","Communist","Party","of","America",",","which","eventually","merged","with","the","Communist","Labor","Party","of","America","to","form","first","the","Workers","Party","of","America","and","eventually","the","Communist","Party","USA","."],"labels":["O","O","O","O","B-political party","O","O","O","B-political party","I-political party","I-political party","I-political party","O","O","O","O","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","O","O","O","O","B-political party","I-political party","I-political party","I-political party","O","O","O","B-political party","I-political party","I-political party","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: politician, location, event, country, political party, person, election, organization and O.\nSentence: Prominent members of the SPL joined the new Communist Party of America , which eventually merged with the Communist Labor Party of America to form first the Workers Party of America and eventually the Communist Party USA .","prompt_labels":"Prominent(O) members(O) of(O) the(O) SPL(B-political party) joined(O) the(O) new(O) Communist(B-political party) Party(I-political party) of(I-political party) America(I-political party) ,(O) which(O) eventually(O) merged(O) with(O) the(O) Communist(B-political party) Labor(I-political party) Party(I-political party) of(I-political party) America(I-political party) to(O) form(O) first(O) the(O) Workers(B-political party) Party(I-political party) of(I-political party) America(I-political party) and(O) eventually(O) the(O) Communist(B-political party) Party(I-political party) USA(I-political party) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["politician","event","location","election","political party","organization","person","country"],"instance":{"id":"144","words":["He","contested","the","seat","of","St","Marylebone","for","the","Labour","Party","at","the","1950","United","Kingdom","general","election",",","West","Woolwich","in","1951","United","Kingdom","general","election","and","South","Nottingham","in","1959","United","Kingdom","general","election","."],"labels":["O","O","O","O","O","B-location","I-location","O","O","B-political party","I-political party","O","O","B-election","I-election","I-election","I-election","I-election","O","B-organization","I-organization","O","B-election","I-election","I-election","I-election","I-election","O","B-organization","I-organization","O","B-election","I-election","I-election","I-election","I-election","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: politician, event, location, election, political party, organization, person, country and O.\nSentence: He contested the seat of St Marylebone for the Labour Party at the 1950 United Kingdom general election , West Woolwich in 1951 United Kingdom general election and South Nottingham in 1959 United Kingdom general election .","prompt_labels":"He(O) contested(O) the(O) seat(O) of(O) St(B-location) Marylebone(I-location) for(O) the(O) Labour(B-political party) Party(I-political party) at(O) the(O) 1950(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) West(B-organization) Woolwich(I-organization) in(O) 1951(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) and(O) South(B-organization) Nottingham(I-organization) in(O) 1959(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["organization","country","political party","politician","event","election","person","location"],"instance":{"id":"145","words":["Christian","Voice","was","the","first","of","the","Christian","Right","groups",",","pre-dating","the","Christian","Coalition","of","America",",","American","Coalition","for","Traditional","Values",",","Concerned","Women","for","America",",","Moral","Majority",",","Family","Research","Council",",","and","other","Christian","political","groups","."],"labels":["B-organization","I-organization","O","O","O","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","B-organization","I-organization","I-organization","I-organization","O","B-organization","I-organization","O","B-organization","I-organization","I-organization","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, country, political party, politician, event, election, person, location and O.\nSentence: Christian Voice was the first of the Christian Right groups , pre-dating the Christian Coalition of America , American Coalition for Traditional Values , Concerned Women for America , Moral Majority , Family Research Council , and other Christian political groups .","prompt_labels":"Christian(B-organization) Voice(I-organization) was(O) the(O) first(O) of(O) the(O) Christian(O) Right(O) groups(O) ,(O) pre-dating(O) the(O) Christian(B-organization) Coalition(I-organization) of(I-organization) America(I-organization) ,(O) American(B-organization) Coalition(I-organization) for(I-organization) Traditional(I-organization) Values(I-organization) ,(O) Concerned(B-organization) Women(I-organization) for(I-organization) America(I-organization) ,(O) Moral(B-organization) Majority(I-organization) ,(O) Family(B-organization) Research(I-organization) Council(I-organization) ,(O) and(O) other(O) Christian(O) political(O) groups(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["organization","politician","event","country","location","political party","election","person"],"instance":{"id":"146","words":["In","Kota","Kinabalu",",","United","Pasokmomogun","Kadazandusun","Murut","Organisation","(","UPKO",")","led","by","its","Secretary-General","Datuk","Wilfred","Madius","Tangau",",","on","23","September","2008",",","joined","its","3","other","Barisan","Nasional","(","BN",")","counterparts","Malaysian","Chinese","Association",",","Parti","Gerakan","Rakyat","Malaysia","and","Malaysian","Indian","Congress",",","petitioning","Government","review","of","ISA","."],"labels":["O","B-location","I-location","O","B-political party","I-political party","I-political party","I-political party","I-political party","O","B-political party","O","O","O","O","O","O","B-politician","I-politician","I-politician","O","O","O","O","O","O","O","O","O","O","B-political party","I-political party","O","B-political party","O","O","B-political party","I-political party","I-political party","O","B-political party","I-political party","I-political party","I-political party","O","B-political party","I-political party","I-political party","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, politician, event, country, location, political party, election, person and O.\nSentence: In Kota Kinabalu , United Pasokmomogun Kadazandusun Murut Organisation ( UPKO ) led by its Secretary-General Datuk Wilfred Madius Tangau , on 23 September 2008 , joined its 3 other Barisan Nasional ( BN ) counterparts Malaysian Chinese Association , Parti Gerakan Rakyat Malaysia and Malaysian Indian Congress , petitioning Government review of ISA .","prompt_labels":"In(O) Kota(B-location) Kinabalu(I-location) ,(O) United(B-political party) Pasokmomogun(I-political party) Kadazandusun(I-political party) Murut(I-political party) Organisation(I-political party) ((O) UPKO(B-political party) )(O) led(O) by(O) its(O) Secretary-General(O) Datuk(O) Wilfred(B-politician) Madius(I-politician) Tangau(I-politician) ,(O) on(O) 23(O) September(O) 2008(O) ,(O) joined(O) its(O) 3(O) other(O) Barisan(B-political party) Nasional(I-political party) ((O) BN(B-political party) )(O) counterparts(O) Malaysian(B-political party) Chinese(I-political party) Association(I-political party) ,(O) Parti(B-political party) Gerakan(I-political party) Rakyat(I-political party) Malaysia(I-political party) and(O) Malaysian(B-political party) Indian(I-political party) Congress(I-political party) ,(O) petitioning(O) Government(O) review(O) of(O) ISA(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["country","election","politician","political party","location","person","organization","event"],"instance":{"id":"147","words":["In","the","1969","Malaysian","general","election",",","MCA","lost","more","than","half","its","seats","to","the","new",",","mainly","Chinese","Malaysian",",","opposition","parties","Democratic","Action","Party","(","DAP",")","and","Parti","Gerakan","Rakyat","Malaysia","(","Gerakan",")","."],"labels":["O","O","B-election","I-election","I-election","I-election","O","B-political party","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","O","B-political party","O","O","B-political party","I-political party","I-political party","I-political party","O","B-political party","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, election, politician, political party, location, person, organization, event and O.\nSentence: In the 1969 Malaysian general election , MCA lost more than half its seats to the new , mainly Chinese Malaysian , opposition parties Democratic Action Party ( DAP ) and Parti Gerakan Rakyat Malaysia ( Gerakan ) .","prompt_labels":"In(O) the(O) 1969(B-election) Malaysian(I-election) general(I-election) election(I-election) ,(O) MCA(B-political party) lost(O) more(O) than(O) half(O) its(O) seats(O) to(O) the(O) new(O) ,(O) mainly(O) Chinese(O) Malaysian(O) ,(O) opposition(O) parties(O) Democratic(B-political party) Action(I-political party) Party(I-political party) ((O) DAP(B-political party) )(O) and(O) Parti(B-political party) Gerakan(I-political party) Rakyat(I-political party) Malaysia(I-political party) ((O) Gerakan(B-political party) )(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["location","election","organization","person","political party","event","country","politician"],"instance":{"id":"148","words":["Political","scientists","see","European","political","parties","such","as","Ecolo","and","Groen","in","Belgium",",","Alliance","90","\/","The","Greens","in","Germany",",","or","the","Green","Progressive","Accord","and","GroenLinks","in","the","Netherlands","as","coming","out","of","the","New","Left","and","emphasizing","spontaneous","self-organization",",","participatory","democracy",",","decentralization","and","voluntarism",",","being","contrasted","to","the","bureaucratic","or","statist","approach","."],"labels":["O","O","O","O","O","O","O","O","B-political party","O","B-political party","O","B-country","O","B-political party","I-political party","O","B-political party","I-political party","O","B-country","O","O","O","B-political party","I-political party","I-political party","O","B-political party","O","O","B-country","O","O","O","O","O","B-event","I-event","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, election, organization, person, political party, event, country, politician and O.\nSentence: Political scientists see European political parties such as Ecolo and Groen in Belgium , Alliance 90 \/ The Greens in Germany , or the Green Progressive Accord and GroenLinks in the Netherlands as coming out of the New Left and emphasizing spontaneous self-organization , participatory democracy , decentralization and voluntarism , being contrasted to the bureaucratic or statist approach .","prompt_labels":"Political(O) scientists(O) see(O) European(O) political(O) parties(O) such(O) as(O) Ecolo(B-political party) and(O) Groen(B-political party) in(O) Belgium(B-country) ,(O) Alliance(B-political party) 90(I-political party) \/(O) The(B-political party) Greens(I-political party) in(O) Germany(B-country) ,(O) or(O) the(O) Green(B-political party) Progressive(I-political party) Accord(I-political party) and(O) GroenLinks(B-political party) in(O) the(O) Netherlands(B-country) as(O) coming(O) out(O) of(O) the(O) New(B-event) Left(I-event) and(O) emphasizing(O) spontaneous(O) self-organization(O) ,(O) participatory(O) democracy(O) ,(O) decentralization(O) and(O) voluntarism(O) ,(O) being(O) contrasted(O) to(O) the(O) bureaucratic(O) or(O) statist(O) approach(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["election","political party","politician","person","organization","country","event","location"],"instance":{"id":"149","words":["Patteson","was","a","member","of","the","Board","of","Trustees","of","West","Virginia","Wesleyan",",","and","of","a","number","of","societies",":","Free","mason","s",",","Knights","Templar",",","Moose","International",",","Lions","Clubs","International",",","Chamber","of","Commerce",",","American","Legion",",","Sons","of","the","American","Revolution","and","Benevolent","and","Protective","Order","of","Elks","."],"labels":["B-person","O","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","O","O","O","O","O","O","O","O","B-organization","I-organization","O","O","B-organization","I-organization","O","B-organization","I-organization","O","B-organization","I-organization","I-organization","O","B-organization","I-organization","I-organization","O","B-organization","I-organization","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: election, political party, politician, person, organization, country, event, location and O.\nSentence: Patteson was a member of the Board of Trustees of West Virginia Wesleyan , and of a number of societies : Free mason s , Knights Templar , Moose International , Lions Clubs International , Chamber of Commerce , American Legion , Sons of the American Revolution and Benevolent and Protective Order of Elks .","prompt_labels":"Patteson(B-person) was(O) a(O) member(O) of(O) the(O) Board(O) of(O) Trustees(O) of(O) West(B-organization) Virginia(I-organization) Wesleyan(I-organization) ,(O) and(O) of(O) a(O) number(O) of(O) societies(O) :(O) Free(B-organization) mason(I-organization) s(O) ,(O) Knights(B-organization) Templar(I-organization) ,(O) Moose(B-organization) International(I-organization) ,(O) Lions(B-organization) Clubs(I-organization) International(I-organization) ,(O) Chamber(B-organization) of(I-organization) Commerce(I-organization) ,(O) American(B-organization) Legion(I-organization) ,(O) Sons(B-organization) of(I-organization) the(I-organization) American(I-organization) Revolution(I-organization) and(O) Benevolent(B-organization) and(I-organization) Protective(I-organization) Order(I-organization) of(I-organization) Elks(I-organization) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["election","politician","country","person","political party","organization","event","location"],"instance":{"id":"150","words":["The","party","lost","its","four","seats","in","the","2008","Meghalaya","Legislative","Assembly","election",",","was","unable","to","win","any","seats","in","the","2013","Meghalaya","Legislative","Assembly","election","and","did","not","field","any","candidates","in","the","2018","Meghalaya","Legislative","Assembly","election","."],"labels":["O","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","O","O","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","O","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: election, politician, country, person, political party, organization, event, location and O.\nSentence: The party lost its four seats in the 2008 Meghalaya Legislative Assembly election , was unable to win any seats in the 2013 Meghalaya Legislative Assembly election and did not field any candidates in the 2018 Meghalaya Legislative Assembly election .","prompt_labels":"The(O) party(O) lost(O) its(O) four(O) seats(O) in(O) the(O) 2008(B-election) Meghalaya(I-election) Legislative(I-election) Assembly(I-election) election(I-election) ,(O) was(O) unable(O) to(O) win(O) any(O) seats(O) in(O) the(O) 2013(B-election) Meghalaya(I-election) Legislative(I-election) Assembly(I-election) election(I-election) and(O) did(O) not(O) field(O) any(O) candidates(O) in(O) the(O) 2018(B-election) Meghalaya(I-election) Legislative(I-election) Assembly(I-election) election(I-election) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["politician","election","event","country","organization","person","political party","location"],"instance":{"id":"151","words":["Before","the","2000","United","States","presidential","election",",","West","Virginia","had","been","won","by","the","Democratic","nominee","every","time","since","1932","(","except","for","the","Republican","landslides","of","1956","United","States","presidential","election",",","1972","United","States","presidential","election",",","and","1984","United","States","presidential","election",")","."],"labels":["O","O","B-election","I-election","I-election","I-election","I-election","O","B-location","I-location","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","O","O","B-election","I-election","I-election","I-election","I-election","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: politician, election, event, country, organization, person, political party, location and O.\nSentence: Before the 2000 United States presidential election , West Virginia had been won by the Democratic nominee every time since 1932 ( except for the Republican landslides of 1956 United States presidential election , 1972 United States presidential election , and 1984 United States presidential election ) .","prompt_labels":"Before(O) the(O) 2000(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election) ,(O) West(B-location) Virginia(I-location) had(O) been(O) won(O) by(O) the(O) Democratic(O) nominee(O) every(O) time(O) since(O) 1932(O) ((O) except(O) for(O) the(O) Republican(O) landslides(O) of(O) 1956(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election) ,(O) 1972(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election) ,(O) and(O) 1984(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election) )(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["election","organization","event","politician","country","location","person","political party"],"instance":{"id":"152","words":["Molloy","ran","for","the","Canadian","House","of","Commons","in","the","1921","Canadian","federal","election","as","a","candidate","of","the","Liberal","Party","of","Canada",",","and","lost","to","Progressive","Party","of","Canada","candidate","Robert","Alexander","Hoey","by","1,397","votes","in","the","riding","of","Springfield","."],"labels":["B-politician","O","O","O","B-organization","I-organization","I-organization","I-organization","O","O","B-election","I-election","I-election","I-election","O","O","O","O","O","B-political party","I-political party","I-political party","I-political party","O","O","O","O","B-political party","I-political party","I-political party","I-political party","O","B-politician","I-politician","I-politician","O","O","O","O","O","O","O","B-location","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: election, organization, event, politician, country, location, person, political party and O.\nSentence: Molloy ran for the Canadian House of Commons in the 1921 Canadian federal election as a candidate of the Liberal Party of Canada , and lost to Progressive Party of Canada candidate Robert Alexander Hoey by 1,397 votes in the riding of Springfield .","prompt_labels":"Molloy(B-politician) ran(O) for(O) the(O) Canadian(B-organization) House(I-organization) of(I-organization) Commons(I-organization) in(O) the(O) 1921(B-election) Canadian(I-election) federal(I-election) election(I-election) as(O) a(O) candidate(O) of(O) the(O) Liberal(B-political party) Party(I-political party) of(I-political party) Canada(I-political party) ,(O) and(O) lost(O) to(O) Progressive(B-political party) Party(I-political party) of(I-political party) Canada(I-political party) candidate(O) Robert(B-politician) Alexander(I-politician) Hoey(I-politician) by(O) 1,397(O) votes(O) in(O) the(O) riding(O) of(O) Springfield(B-location) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["location","organization","political party","election","country","politician","event","person"],"instance":{"id":"153","words":["On","August","3",",","2012","the","party","(","which","had","no","member","in","the","lower","house",")","in","concert","with","six","other","minor","opposition","parties","(","People","'s","Life","First",",","Kizuna","Party",",","Social","Democratic","Party",",","Your","Party",",","Japanese","Communist","Party","and","the","New","Renaissance","Party",")","agreed","to","submit","a","no","confidence","motion","against","Prime","Minister","Yoshihiko","Noda","in","an","effort","to","block","the","passage","of","the","bill","raising","Japan","'s","consumption","tax","from","5","%","to","10","%","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","I-political party","O","B-political party","I-political party","O","B-political party","I-political party","I-political party","O","B-political party","I-political party","O","B-political party","I-political party","I-political party","O","O","B-political party","I-political party","I-political party","O","O","O","O","O","O","O","O","O","O","O","B-politician","I-politician","O","O","O","O","O","O","O","O","O","O","O","B-country","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, organization, political party, election, country, politician, event, person and O.\nSentence: On August 3 , 2012 the party ( which had no member in the lower house ) in concert with six other minor opposition parties ( People 's Life First , Kizuna Party , Social Democratic Party , Your Party , Japanese Communist Party and the New Renaissance Party ) agreed to submit a no confidence motion against Prime Minister Yoshihiko Noda in an effort to block the passage of the bill raising Japan 's consumption tax from 5 % to 10 % .","prompt_labels":"On(O) August(O) 3(O) ,(O) 2012(O) the(O) party(O) ((O) which(O) had(O) no(O) member(O) in(O) the(O) lower(O) house(O) )(O) in(O) concert(O) with(O) six(O) other(O) minor(O) opposition(O) parties(O) ((O) People(B-political party) 's(I-political party) Life(I-political party) First(I-political party) ,(O) Kizuna(B-political party) Party(I-political party) ,(O) Social(B-political party) Democratic(I-political party) Party(I-political party) ,(O) Your(B-political party) Party(I-political party) ,(O) Japanese(B-political party) Communist(I-political party) Party(I-political party) and(O) the(O) New(B-political party) Renaissance(I-political party) Party(I-political party) )(O) agreed(O) to(O) submit(O) a(O) no(O) confidence(O) motion(O) against(O) Prime(O) Minister(O) Yoshihiko(B-politician) Noda(I-politician) in(O) an(O) effort(O) to(O) block(O) the(O) passage(O) of(O) the(O) bill(O) raising(O) Japan(B-country) 's(O) consumption(O) tax(O) from(O) 5(O) %(O) to(O) 10(O) %(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["location","politician","election","political party","person","country","event","organization"],"instance":{"id":"154","words":["For","the","next","two","years",",","Villalpando","was","a","prolific","activist","in","both","Republican","and","Hispanic","circles",",","serving","on","the","boards","of","the","Texas","Federation","of","Republican","Women",",","the","Southwest","Voter","Registration","Education","Project",",","the","League","of","United","Latin","American","Citizens",",","and","the","American","GI","Forum","."],"labels":["O","O","O","O","O","O","B-politician","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-location","B-organization","I-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","O","O","B-organization","I-organization","I-organization","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, politician, election, political party, person, country, event, organization and O.\nSentence: For the next two years , Villalpando was a prolific activist in both Republican and Hispanic circles , serving on the boards of the Texas Federation of Republican Women , the Southwest Voter Registration Education Project , the League of United Latin American Citizens , and the American GI Forum .","prompt_labels":"For(O) the(O) next(O) two(O) years(O) ,(O) Villalpando(B-politician) was(O) a(O) prolific(O) activist(O) in(O) both(O) Republican(O) and(O) Hispanic(O) circles(O) ,(O) serving(O) on(O) the(O) boards(O) of(O) the(O) Texas(B-location) Federation(B-organization) of(I-organization) Republican(I-organization) Women(I-organization) ,(O) the(O) Southwest(B-organization) Voter(I-organization) Registration(I-organization) Education(I-organization) Project(I-organization) ,(O) the(O) League(B-organization) of(I-organization) United(I-organization) Latin(I-organization) American(I-organization) Citizens(I-organization) ,(O) and(O) the(O) American(B-organization) GI(I-organization) Forum(I-organization) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["politician","election","person","organization","country","political party","event","location"],"instance":{"id":"155","words":["He","was","elected","to","the","Parliament","of","Norway","from","Vest-Agder","in","1993","Norwegian","parliamentary","election",",","and","was","re-elected","on","the","two","following","occasions","in","1997","Norwegian","parliamentary","election","and","2001","Norwegian","parliamentary","election","."],"labels":["O","O","O","O","O","B-organization","I-organization","I-organization","O","B-location","O","B-election","I-election","I-election","I-election","O","O","O","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: politician, election, person, organization, country, political party, event, location and O.\nSentence: He was elected to the Parliament of Norway from Vest-Agder in 1993 Norwegian parliamentary election , and was re-elected on the two following occasions in 1997 Norwegian parliamentary election and 2001 Norwegian parliamentary election .","prompt_labels":"He(O) was(O) elected(O) to(O) the(O) Parliament(B-organization) of(I-organization) Norway(I-organization) from(O) Vest-Agder(B-location) in(O) 1993(B-election) Norwegian(I-election) parliamentary(I-election) election(I-election) ,(O) and(O) was(O) re-elected(O) on(O) the(O) two(O) following(O) occasions(O) in(O) 1997(B-election) Norwegian(I-election) parliamentary(I-election) election(I-election) and(O) 2001(B-election) Norwegian(I-election) parliamentary(I-election) election(I-election) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["politician","event","election","person","political party","location","country","organization"],"instance":{"id":"156","words":["In","the","following","table",",","gains","for","the","Australian","Labor","Party","are","highlighted","in","red",",","for","the","Liberal","Party","of","Australia","and","its","predecessors","(","including","the","Protectionist","Party",")","in","blue",",","for","the","National","Party","of","Australia","and","its","predecessors","as","well","as","the","unrelated","Australian","Greens","in","green","!","--","The","National","'s","little","colour","block","is","green","too","in","this","article",",","and","I","think","it","makes","it","confusing","."],"labels":["O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","I-political party","O","O","O","O","O","O","B-political party","I-political party","O","O","O","O","O","O","B-political party","I-political party","I-political party","I-political party","O","O","O","O","O","O","O","O","B-political party","I-political party","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: politician, event, election, person, political party, location, country, organization and O.\nSentence: In the following table , gains for the Australian Labor Party are highlighted in red , for the Liberal Party of Australia and its predecessors ( including the Protectionist Party ) in blue , for the National Party of Australia and its predecessors as well as the unrelated Australian Greens in green ! -- The National 's little colour block is green too in this article , and I think it makes it confusing .","prompt_labels":"In(O) the(O) following(O) table(O) ,(O) gains(O) for(O) the(O) Australian(B-political party) Labor(I-political party) Party(I-political party) are(O) highlighted(O) in(O) red(O) ,(O) for(O) the(O) Liberal(B-political party) Party(I-political party) of(I-political party) Australia(I-political party) and(O) its(O) predecessors(O) ((O) including(O) the(O) Protectionist(B-political party) Party(I-political party) )(O) in(O) blue(O) ,(O) for(O) the(O) National(B-political party) Party(I-political party) of(I-political party) Australia(I-political party) and(O) its(O) predecessors(O) as(O) well(O) as(O) the(O) unrelated(O) Australian(B-political party) Greens(I-political party) in(O) green(O) !(O) --(O) The(O) National(O) 's(O) little(O) colour(O) block(O) is(O) green(O) too(O) in(O) this(O) article(O) ,(O) and(O) I(O) think(O) it(O) makes(O) it(O) confusing(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["organization","election","politician","political party","event","location","person","country"],"instance":{"id":"157","words":["Despite","the","unsuccessful","attempt","at","the","1987","Sarawak","state","election",",","Abdul","Rahman","continued","his","struggle","with","his","allies",",","Sarawak","Dayak","People","'s","Party","against","Taib","'s","led","Sarawak","Barisan","Nasional","until","1991","Sarawak","state","election","when","Taib","'s","coalition","won","an","overwhelming","majority","of","49","out","of","56","seats","in","the","state","assembly","."],"labels":["O","O","O","O","O","O","B-election","I-election","I-election","I-election","O","B-politician","I-politician","O","O","O","O","O","O","O","B-location","B-political party","I-political party","I-political party","I-political party","O","B-politician","O","O","B-location","B-political party","I-political party","O","B-election","I-election","I-election","I-election","O","B-politician","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, election, politician, political party, event, location, person, country and O.\nSentence: Despite the unsuccessful attempt at the 1987 Sarawak state election , Abdul Rahman continued his struggle with his allies , Sarawak Dayak People 's Party against Taib 's led Sarawak Barisan Nasional until 1991 Sarawak state election when Taib 's coalition won an overwhelming majority of 49 out of 56 seats in the state assembly .","prompt_labels":"Despite(O) the(O) unsuccessful(O) attempt(O) at(O) the(O) 1987(B-election) Sarawak(I-election) state(I-election) election(I-election) ,(O) Abdul(B-politician) Rahman(I-politician) continued(O) his(O) struggle(O) with(O) his(O) allies(O) ,(O) Sarawak(B-location) Dayak(B-political party) People(I-political party) 's(I-political party) Party(I-political party) against(O) Taib(B-politician) 's(O) led(O) Sarawak(B-location) Barisan(B-political party) Nasional(I-political party) until(O) 1991(B-election) Sarawak(I-election) state(I-election) election(I-election) when(O) Taib(B-politician) 's(O) coalition(O) won(O) an(O) overwhelming(O) majority(O) of(O) 49(O) out(O) of(O) 56(O) seats(O) in(O) the(O) state(O) assembly(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["political party","organization","election","politician","location","country","event","person"],"instance":{"id":"158","words":["In","British","Columbia",",","the","British","Columbia","Social","Credit","Party","was","replaced","as","the","party","of","the","centre-right","by","the","British","Columbia","Liberal","Party",",","and","in","Alberta","the","Alberta","Social","Credit","Party","were","completely","annihilated","by","the","more","moderate","Alberta","Progressive","Conservative","Party",",","leaving","both","parties","as","marginal","political","forces","."],"labels":["O","B-location","I-location","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","O","O","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","I-political party","O","O","O","B-location","O","B-political party","I-political party","I-political party","I-political party","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","I-political party","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: political party, organization, election, politician, location, country, event, person and O.\nSentence: In British Columbia , the British Columbia Social Credit Party was replaced as the party of the centre-right by the British Columbia Liberal Party , and in Alberta the Alberta Social Credit Party were completely annihilated by the more moderate Alberta Progressive Conservative Party , leaving both parties as marginal political forces .","prompt_labels":"In(O) British(B-location) Columbia(I-location) ,(O) the(O) British(B-political party) Columbia(I-political party) Social(I-political party) Credit(I-political party) Party(I-political party) was(O) replaced(O) as(O) the(O) party(O) of(O) the(O) centre-right(O) by(O) the(O) British(B-political party) Columbia(I-political party) Liberal(I-political party) Party(I-political party) ,(O) and(O) in(O) Alberta(B-location) the(O) Alberta(B-political party) Social(I-political party) Credit(I-political party) Party(I-political party) were(O) completely(O) annihilated(O) by(O) the(O) more(O) moderate(O) Alberta(B-political party) Progressive(I-political party) Conservative(I-political party) Party(I-political party) ,(O) leaving(O) both(O) parties(O) as(O) marginal(O) political(O) forces(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["election","person","organization","political party","location","politician","event","country"],"instance":{"id":"159","words":["AD","members","were","mainly","former","Italian","Republican","Party","and","former","Italian","Socialist","Party",",","was","a","former","member","of","the","Italian","Communist","Party","and","the","Democratic","Party","of","the","Left","."],"labels":["B-political party","O","O","O","O","B-political party","I-political party","I-political party","O","O","B-political party","I-political party","I-political party","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: election, person, organization, political party, location, politician, event, country and O.\nSentence: AD members were mainly former Italian Republican Party and former Italian Socialist Party , was a former member of the Italian Communist Party and the Democratic Party of the Left .","prompt_labels":"AD(B-political party) members(O) were(O) mainly(O) former(O) Italian(B-political party) Republican(I-political party) Party(I-political party) and(O) former(O) Italian(B-political party) Socialist(I-political party) Party(I-political party) ,(O) was(O) a(O) former(O) member(O) of(O) the(O) Italian(B-political party) Communist(I-political party) Party(I-political party) and(O) the(O) Democratic(B-political party) Party(I-political party) of(I-political party) the(I-political party) Left(I-political party) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["person","political party","event","politician","location","country","organization","election"],"instance":{"id":"160","words":["The","party","ran","in","the","1994","Italian","general","election","within","the","Alliance","of","Progressives","and","obtained","a","mere","1.2","%","of","the","vote",",","due","to","the","uneasy","alliance","with","the","traditional","left","and","the","competition","by","Silvio","Berlusconi","'","s","Forza","Italia",",","which","embraced","most","of","AD","'s","policies","."],"labels":["O","O","O","O","O","B-election","I-election","I-election","I-election","O","O","B-political party","I-political party","I-political party","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-politician","I-politician","O","O","B-political party","I-political party","O","O","O","O","O","B-political party","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, political party, event, politician, location, country, organization, election and O.\nSentence: The party ran in the 1994 Italian general election within the Alliance of Progressives and obtained a mere 1.2 % of the vote , due to the uneasy alliance with the traditional left and the competition by Silvio Berlusconi ' s Forza Italia , which embraced most of AD 's policies .","prompt_labels":"The(O) party(O) ran(O) in(O) the(O) 1994(B-election) Italian(I-election) general(I-election) election(I-election) within(O) the(O) Alliance(B-political party) of(I-political party) Progressives(I-political party) and(O) obtained(O) a(O) mere(O) 1.2(O) %(O) of(O) the(O) vote(O) ,(O) due(O) to(O) the(O) uneasy(O) alliance(O) with(O) the(O) traditional(O) left(O) and(O) the(O) competition(O) by(O) Silvio(B-politician) Berlusconi(I-politician) '(O) s(O) Forza(B-political party) Italia(I-political party) ,(O) which(O) embraced(O) most(O) of(O) AD(B-political party) 's(O) policies(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["political party","person","event","location","country","election","politician","organization"],"instance":{"id":"161","words":["In","the","1995","Italian","regional","elections","AD","was","part","of","the","Pact","of","Democrats","electoral","alliance","with","the","Segni","Pact","and","the","Italian","Socialists","."],"labels":["O","O","B-election","I-election","I-election","I-election","B-political party","O","O","O","O","O","O","O","O","O","O","O","B-political party","I-political party","O","O","B-political party","I-political party","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: political party, person, event, location, country, election, politician, organization and O.\nSentence: In the 1995 Italian regional elections AD was part of the Pact of Democrats electoral alliance with the Segni Pact and the Italian Socialists .","prompt_labels":"In(O) the(O) 1995(B-election) Italian(I-election) regional(I-election) elections(I-election) AD(B-political party) was(O) part(O) of(O) the(O) Pact(O) of(O) Democrats(O) electoral(O) alliance(O) with(O) the(O) Segni(B-political party) Pact(I-political party) and(O) the(O) Italian(B-political party) Socialists(I-political party) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["organization","political party","person","country","event","location","politician","election"],"instance":{"id":"162","words":["Windsor","Star",",","November","18",",","2006","continued","to","anchor","provincial","election","coverage","for","that","service","in","2003","Ontario","general","election",",","2007","Ontario","general","election",",","2011","Ontario","general","election","and","2014","Ontario","general","election",",","and","filed","occasional","science","news","reports",",","under","the","pseudonym","Dr.","Robert",",","for","the","network","'s","flagship","interview","program","As","It","Happens","."],"labels":["B-organization","I-organization","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, political party, person, country, event, location, politician, election and O.\nSentence: Windsor Star , November 18 , 2006 continued to anchor provincial election coverage for that service in 2003 Ontario general election , 2007 Ontario general election , 2011 Ontario general election and 2014 Ontario general election , and filed occasional science news reports , under the pseudonym Dr. Robert , for the network 's flagship interview program As It Happens .","prompt_labels":"Windsor(B-organization) Star(I-organization) ,(O) November(O) 18(O) ,(O) 2006(O) continued(O) to(O) anchor(O) provincial(O) election(O) coverage(O) for(O) that(O) service(O) in(O) 2003(B-election) Ontario(I-election) general(I-election) election(I-election) ,(O) 2007(B-election) Ontario(I-election) general(I-election) election(I-election) ,(O) 2011(B-election) Ontario(I-election) general(I-election) election(I-election) and(O) 2014(B-election) Ontario(I-election) general(I-election) election(I-election) ,(O) and(O) filed(O) occasional(O) science(O) news(O) reports(O) ,(O) under(O) the(O) pseudonym(O) Dr.(O) Robert(O) ,(O) for(O) the(O) network(O) 's(O) flagship(O) interview(O) program(O) As(O) It(O) Happens(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["person","country","event","election","organization","location","political party","politician"],"instance":{"id":"163","words":["The","Unionist","Party","(",",","UP",")","was","a","pre-apartheid","South","African","political","party",",","which","contested","elections","to","the","Union","of","South","Africa","parliament","from","the","1910","South","African","general","election","until","its","merger","into","the","South","African","Party","just","before","the","1921","South","African","general","election","."],"labels":["O","B-political party","I-political party","O","O","B-political party","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-country","I-country","I-country","I-country","O","O","O","B-election","I-election","I-election","I-election","I-election","O","O","O","O","O","B-political party","I-political party","I-political party","O","O","O","B-election","I-election","I-election","I-election","I-election","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, country, event, election, organization, location, political party, politician and O.\nSentence: The Unionist Party ( , UP ) was a pre-apartheid South African political party , which contested elections to the Union of South Africa parliament from the 1910 South African general election until its merger into the South African Party just before the 1921 South African general election .","prompt_labels":"The(O) Unionist(B-political party) Party(I-political party) ((O) ,(O) UP(B-political party) )(O) was(O) a(O) pre-apartheid(O) South(O) African(O) political(O) party(O) ,(O) which(O) contested(O) elections(O) to(O) the(O) Union(B-country) of(I-country) South(I-country) Africa(I-country) parliament(O) from(O) the(O) 1910(B-election) South(I-election) African(I-election) general(I-election) election(I-election) until(O) its(O) merger(O) into(O) the(O) South(B-political party) African(I-political party) Party(I-political party) just(O) before(O) the(O) 1921(B-election) South(I-election) African(I-election) general(I-election) election(I-election) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["politician","person","organization","country","location","election","political party","event"],"instance":{"id":"164","words":["The","Socialist","Party","of","the","United","States","(","SPUS",")","-","its","name","inspired","by","co-thinkers","in","the","Socialist","Party","of","Great","Britain","(","SPGB",")","and","the","original","(","non-WSM",")","Socialist","Party","of","Canada","(","SPC",")","-","was","established","on","July","7",",","1916","by","42","defecting","members","of","Local","Detroit","of","the","Socialist","Party","of","America","(","SPA",")","."],"labels":["O","B-political party","I-political party","I-political party","I-political party","I-political party","I-political party","O","B-political party","O","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","O","B-political party","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","I-political party","O","B-political party","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-location","I-location","O","O","B-political party","I-political party","I-political party","I-political party","O","B-political party","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: politician, person, organization, country, location, election, political party, event and O.\nSentence: The Socialist Party of the United States ( SPUS ) - its name inspired by co-thinkers in the Socialist Party of Great Britain ( SPGB ) and the original ( non-WSM ) Socialist Party of Canada ( SPC ) - was established on July 7 , 1916 by 42 defecting members of Local Detroit of the Socialist Party of America ( SPA ) .","prompt_labels":"The(O) Socialist(B-political party) Party(I-political party) of(I-political party) the(I-political party) United(I-political party) States(I-political party) ((O) SPUS(B-political party) )(O) -(O) its(O) name(O) inspired(O) by(O) co-thinkers(O) in(O) the(O) Socialist(B-political party) Party(I-political party) of(I-political party) Great(I-political party) Britain(I-political party) ((O) SPGB(B-political party) )(O) and(O) the(O) original(O) ((O) non-WSM(O) )(O) Socialist(B-political party) Party(I-political party) of(I-political party) Canada(I-political party) ((O) SPC(B-political party) )(O) -(O) was(O) established(O) on(O) July(O) 7(O) ,(O) 1916(O) by(O) 42(O) defecting(O) members(O) of(O) Local(B-location) Detroit(I-location) of(O) the(O) Socialist(B-political party) Party(I-political party) of(I-political party) America(I-political party) ((O) SPA(B-political party) )(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["country","organization","location","politician","person","political party","election","event"],"instance":{"id":"165","words":["He","was","elected","as","a","Social","Credit","MLA","in","Vancouver","South","in","1975","British","Columbia","general","election",",","1979","British","Columbia","general","election",",","1983","British","Columbia","general","election","and","1986","British","Columbia","general","election","."],"labels":["O","O","O","O","O","B-organization","I-organization","I-organization","O","B-location","I-location","O","B-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, organization, location, politician, person, political party, election, event and O.\nSentence: He was elected as a Social Credit MLA in Vancouver South in 1975 British Columbia general election , 1979 British Columbia general election , 1983 British Columbia general election and 1986 British Columbia general election .","prompt_labels":"He(O) was(O) elected(O) as(O) a(O) Social(B-organization) Credit(I-organization) MLA(I-organization) in(O) Vancouver(B-location) South(I-location) in(O) 1975(B-election) British(I-election) Columbia(I-election) general(I-election) election(I-election) ,(O) 1979(B-election) British(I-election) Columbia(I-election) general(I-election) election(I-election) ,(O) 1983(B-election) British(I-election) Columbia(I-election) general(I-election) election(I-election) and(O) 1986(B-election) British(I-election) Columbia(I-election) general(I-election) election(I-election) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["political party","organization","politician","event","election","person","country","location"],"instance":{"id":"166","words":["He","ran","as","the","Conservative","Party","of","Canada","candidate","for","the","riding","of","Vancouver","Quadra","in","the","2004","Canadian","federal","election","and","again","in","2006","Canadian","federal","election",",","losing","both","times","to","Liberal","Stephen","Owen","."],"labels":["O","O","O","O","B-political party","I-political party","I-political party","I-political party","O","O","O","O","O","B-location","I-location","O","O","B-election","I-election","I-election","I-election","O","O","O","B-election","I-election","I-election","I-election","O","O","O","O","O","O","B-politician","I-politician","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: political party, organization, politician, event, election, person, country, location and O.\nSentence: He ran as the Conservative Party of Canada candidate for the riding of Vancouver Quadra in the 2004 Canadian federal election and again in 2006 Canadian federal election , losing both times to Liberal Stephen Owen .","prompt_labels":"He(O) ran(O) as(O) the(O) Conservative(B-political party) Party(I-political party) of(I-political party) Canada(I-political party) candidate(O) for(O) the(O) riding(O) of(O) Vancouver(B-location) Quadra(I-location) in(O) the(O) 2004(B-election) Canadian(I-election) federal(I-election) election(I-election) and(O) again(O) in(O) 2006(B-election) Canadian(I-election) federal(I-election) election(I-election) ,(O) losing(O) both(O) times(O) to(O) Liberal(O) Stephen(B-politician) Owen(I-politician) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["election","politician","political party","country","event","organization","location","person"],"instance":{"id":"167","words":["During","the","2005","German","federal","election","campaign",",","Angela","Merkel",",","leader","of","the","Christian","Democratic","Union","of","Germany","\/","Christian","Social","Union","in","Bavaria",",","announced","that","Kirchhof","would","serve","as","minister","of","finance","if","she","formed","a","government","."],"labels":["O","O","B-election","I-election","I-election","I-election","O","O","B-politician","I-politician","O","O","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","O","B-political party","I-political party","I-political party","I-political party","I-political party","O","O","O","B-politician","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: election, politician, political party, country, event, organization, location, person and O.\nSentence: During the 2005 German federal election campaign , Angela Merkel , leader of the Christian Democratic Union of Germany \/ Christian Social Union in Bavaria , announced that Kirchhof would serve as minister of finance if she formed a government .","prompt_labels":"During(O) the(O) 2005(B-election) German(I-election) federal(I-election) election(I-election) campaign(O) ,(O) Angela(B-politician) Merkel(I-politician) ,(O) leader(O) of(O) the(O) Christian(B-political party) Democratic(I-political party) Union(I-political party) of(I-political party) Germany(I-political party) \/(O) Christian(B-political party) Social(I-political party) Union(I-political party) in(I-political party) Bavaria(I-political party) ,(O) announced(O) that(O) Kirchhof(B-politician) would(O) serve(O) as(O) minister(O) of(O) finance(O) if(O) she(O) formed(O) a(O) government(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["person","politician","political party","election","country","event","organization","location"],"instance":{"id":"168","words":["Being","a","political","club","with","the","intent","of","assuring","a","strong","left-wing","presence","in","a","party","and","to","influence","it",",","its","nature","is","notably","reminiscent","of","the","New","Democratic","Party","'","s","New","Politics","Initiative","or",",","to","a","lesser","extent",",","of","the","New","Democratic","Party","Socialist","Caucus","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","O","O","B-political party","I-political party","I-political party","O","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, politician, political party, election, country, event, organization, location and O.\nSentence: Being a political club with the intent of assuring a strong left-wing presence in a party and to influence it , its nature is notably reminiscent of the New Democratic Party ' s New Politics Initiative or , to a lesser extent , of the New Democratic Party Socialist Caucus .","prompt_labels":"Being(O) a(O) political(O) club(O) with(O) the(O) intent(O) of(O) assuring(O) a(O) strong(O) left-wing(O) presence(O) in(O) a(O) party(O) and(O) to(O) influence(O) it(O) ,(O) its(O) nature(O) is(O) notably(O) reminiscent(O) of(O) the(O) New(B-political party) Democratic(I-political party) Party(I-political party) '(O) s(O) New(B-political party) Politics(I-political party) Initiative(I-political party) or(O) ,(O) to(O) a(O) lesser(O) extent(O) ,(O) of(O) the(O) New(B-organization) Democratic(I-organization) Party(I-organization) Socialist(I-organization) Caucus(I-organization) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["country","location","person","event","election","politician","political party","organization"],"instance":{"id":"169","words":["During","the","course","of","the","office",",","elections","were","held","in","1994","Belarusian","presidential","election",",","2001","Belarusian","presidential","election",",","2006","Belarusian","presidential","election",",","2010","Belarusian","presidential","election","and","on","2015","Belarusian","presidential","election","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","O","O","B-election","I-election","I-election","I-election","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, location, person, event, election, politician, political party, organization and O.\nSentence: During the course of the office , elections were held in 1994 Belarusian presidential election , 2001 Belarusian presidential election , 2006 Belarusian presidential election , 2010 Belarusian presidential election and on 2015 Belarusian presidential election .","prompt_labels":"During(O) the(O) course(O) of(O) the(O) office(O) ,(O) elections(O) were(O) held(O) in(O) 1994(B-election) Belarusian(I-election) presidential(I-election) election(I-election) ,(O) 2001(B-election) Belarusian(I-election) presidential(I-election) election(I-election) ,(O) 2006(B-election) Belarusian(I-election) presidential(I-election) election(I-election) ,(O) 2010(B-election) Belarusian(I-election) presidential(I-election) election(I-election) and(O) on(O) 2015(B-election) Belarusian(I-election) presidential(I-election) election(I-election) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["person","country","organization","politician","event","location","election","political party"],"instance":{"id":"170","words":["The","seat","was","retained","in","elections","in","1990","Costa","Rican","general","election","and","1994","Costa","Rican","general","election",",","but","a","loss","of","support","in","the","1998","Costa","Rican","general","election","saw","its","share","of","the","vote","drop","to","0.5","%",",","resulting","in","it","losing","its","solitary","seat","."],"labels":["O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","O","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, country, organization, politician, event, location, election, political party and O.\nSentence: The seat was retained in elections in 1990 Costa Rican general election and 1994 Costa Rican general election , but a loss of support in the 1998 Costa Rican general election saw its share of the vote drop to 0.5 % , resulting in it losing its solitary seat .","prompt_labels":"The(O) seat(O) was(O) retained(O) in(O) elections(O) in(O) 1990(B-election) Costa(I-election) Rican(I-election) general(I-election) election(I-election) and(O) 1994(B-election) Costa(I-election) Rican(I-election) general(I-election) election(I-election) ,(O) but(O) a(O) loss(O) of(O) support(O) in(O) the(O) 1998(B-election) Costa(I-election) Rican(I-election) general(I-election) election(I-election) saw(O) its(O) share(O) of(O) the(O) vote(O) drop(O) to(O) 0.5(O) %(O) ,(O) resulting(O) in(O) it(O) losing(O) its(O) solitary(O) seat(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["political party","politician","country","organization","location","election","person","event"],"instance":{"id":"171","words":["Conversely",",","many","Indo-Fijian","supporters","of","the","National","Federation","Party","(","NFP",")","in","the","2001","Fijian","general","election","may","not","have","been","aware","that","votes","for","NFP","candidates",",","all","of","whom","lost",",","were","to","be","transferred","to","the","indigenous-dominated","Soqosoqo","Duavata","ni","Lewenivanua","(","SDL",")","."],"labels":["O","O","O","O","O","O","O","B-political party","I-political party","I-political party","O","B-political party","O","O","O","B-election","I-election","I-election","I-election","O","O","O","O","O","O","O","O","B-political party","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","I-political party","O","B-political party","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: political party, politician, country, organization, location, election, person, event and O.\nSentence: Conversely , many Indo-Fijian supporters of the National Federation Party ( NFP ) in the 2001 Fijian general election may not have been aware that votes for NFP candidates , all of whom lost , were to be transferred to the indigenous-dominated Soqosoqo Duavata ni Lewenivanua ( SDL ) .","prompt_labels":"Conversely(O) ,(O) many(O) Indo-Fijian(O) supporters(O) of(O) the(O) National(B-political party) Federation(I-political party) Party(I-political party) ((O) NFP(B-political party) )(O) in(O) the(O) 2001(B-election) Fijian(I-election) general(I-election) election(I-election) may(O) not(O) have(O) been(O) aware(O) that(O) votes(O) for(O) NFP(B-political party) candidates(O) ,(O) all(O) of(O) whom(O) lost(O) ,(O) were(O) to(O) be(O) transferred(O) to(O) the(O) indigenous-dominated(O) Soqosoqo(B-political party) Duavata(I-political party) ni(I-political party) Lewenivanua(I-political party) ((O) SDL(B-political party) )(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["person","politician","location","election","political party","event","organization","country"],"instance":{"id":"172","words":["Following","the","2014","European","Parliament","election","in","Germany",",","both","governing","parties","in","Germany","-","the","Christian","Democratic","Union","of","Germany","(","CDU",")","and","the","Social","Democratic","Party","(","SPD",")","-","backed","Oettinger","to","remain","as","the","German","EU","Commissioner","in","the","incoming","European","Commission","."],"labels":["O","O","B-election","I-election","I-election","I-election","I-election","I-election","O","O","O","O","O","B-country","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","O","B-political party","O","O","O","B-political party","I-political party","I-political party","O","B-political party","O","O","O","O","O","O","O","O","O","B-organization","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, politician, location, election, political party, event, organization, country and O.\nSentence: Following the 2014 European Parliament election in Germany , both governing parties in Germany - the Christian Democratic Union of Germany ( CDU ) and the Social Democratic Party ( SPD ) - backed Oettinger to remain as the German EU Commissioner in the incoming European Commission .","prompt_labels":"Following(O) the(O) 2014(B-election) European(I-election) Parliament(I-election) election(I-election) in(I-election) Germany(I-election) ,(O) both(O) governing(O) parties(O) in(O) Germany(B-country) -(O) the(O) Christian(B-political party) Democratic(I-political party) Union(I-political party) of(I-political party) Germany(I-political party) ((O) CDU(B-political party) )(O) and(O) the(O) Social(B-political party) Democratic(I-political party) Party(I-political party) ((O) SPD(B-political party) )(O) -(O) backed(O) Oettinger(O) to(O) remain(O) as(O) the(O) German(O) EU(B-organization) Commissioner(O) in(O) the(O) incoming(O) European(O) Commission(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["location","person","election","politician","political party","country","organization","event"],"instance":{"id":"173","words":["Palestinian","groups","that","have","been","involved","in","politically","motivated","violence","include","the","Palestinian","Liberation","Organization","(","PLO",")",",","Fatah",",","the","Popular","Front","for","the","Liberation","of","Palestine","(","PFLP",")",",","the","Popular","Front","for","the","Liberation","of","Palestine","-","General","Command","(","PFLP-GC",")",",","the","Democratic","Front","for","the","Liberation","of","Palestine",",","the","Abu","Nidal","Organization",",","the","Palestinian","Islamic","Jihad",",","and","Hamas","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","O","B-organization","O","O","B-political party","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","I-political party","I-political party","O","B-political party","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","B-organization","O","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","I-political party","I-political party","O","O","B-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","O","O","B-organization","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, person, election, politician, political party, country, organization, event and O.\nSentence: Palestinian groups that have been involved in politically motivated violence include the Palestinian Liberation Organization ( PLO ) , Fatah , the Popular Front for the Liberation of Palestine ( PFLP ) , the Popular Front for the Liberation of Palestine - General Command ( PFLP-GC ) , the Democratic Front for the Liberation of Palestine , the Abu Nidal Organization , the Palestinian Islamic Jihad , and Hamas .","prompt_labels":"Palestinian(O) groups(O) that(O) have(O) been(O) involved(O) in(O) politically(O) motivated(O) violence(O) include(O) the(O) Palestinian(B-organization) Liberation(I-organization) Organization(I-organization) ((O) PLO(B-organization) )(O) ,(O) Fatah(B-political party) ,(O) the(O) Popular(B-political party) Front(I-political party) for(I-political party) the(I-political party) Liberation(I-political party) of(I-political party) Palestine(I-political party) ((O) PFLP(B-political party) )(O) ,(O) the(O) Popular(B-organization) Front(I-organization) for(I-organization) the(I-organization) Liberation(I-organization) of(I-organization) Palestine(I-organization) -(I-organization) General(I-organization) Command(I-organization) ((O) PFLP-GC(B-organization) )(O) ,(O) the(O) Democratic(B-political party) Front(I-political party) for(I-political party) the(I-political party) Liberation(I-political party) of(I-political party) Palestine(I-political party) ,(O) the(O) Abu(B-organization) Nidal(I-organization) Organization(I-organization) ,(O) the(O) Palestinian(B-organization) Islamic(I-organization) Jihad(I-organization) ,(O) and(O) Hamas(B-organization) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["election","country","event","person","location","politician","political party","organization"],"instance":{"id":"174","words":["The","body","thus","oversaw","the","activities","of","the","Bulgarian","Communist","Party","(","BKP",")",",","the","League","of","Communists","of","Yugoslavia","(","KPJ",")",",","the","Communist","Party","of","Greece","(","KKE",")",",","the","Communist","Party","of","Turkey","(","TKP",")",",","and",",","to","a","certain","measure",",","those","of","the","Romanian","Communist","Party","(","PCdR",")","."],"labels":["O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","O","B-political party","O","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","O","B-political party","O","O","O","B-political party","I-political party","I-political party","I-political party","O","B-political party","O","O","O","B-political party","I-political party","I-political party","I-political party","O","B-political party","O","O","O","O","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","O","B-political party","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: election, country, event, person, location, politician, political party, organization and O.\nSentence: The body thus oversaw the activities of the Bulgarian Communist Party ( BKP ) , the League of Communists of Yugoslavia ( KPJ ) , the Communist Party of Greece ( KKE ) , the Communist Party of Turkey ( TKP ) , and , to a certain measure , those of the Romanian Communist Party ( PCdR ) .","prompt_labels":"The(O) body(O) thus(O) oversaw(O) the(O) activities(O) of(O) the(O) Bulgarian(B-political party) Communist(I-political party) Party(I-political party) ((O) BKP(B-political party) )(O) ,(O) the(O) League(B-political party) of(I-political party) Communists(I-political party) of(I-political party) Yugoslavia(I-political party) ((O) KPJ(B-political party) )(O) ,(O) the(O) Communist(B-political party) Party(I-political party) of(I-political party) Greece(I-political party) ((O) KKE(B-political party) )(O) ,(O) the(O) Communist(B-political party) Party(I-political party) of(I-political party) Turkey(I-political party) ((O) TKP(B-political party) )(O) ,(O) and(O) ,(O) to(O) a(O) certain(O) measure(O) ,(O) those(O) of(O) the(O) Romanian(B-political party) Communist(I-political party) Party(I-political party) ((O) PCdR(B-political party) )(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["organization","location","person","political party","country","event","election","politician"],"instance":{"id":"175","words":["Page","'s","party","affiliation","remained","with","different","facets","of","the","Democratic","Party",",","and","moved","over","time","from","the","Democratic-Republican","Party","to","the","Jacksonian","democracy","to","the","Democrats","to","the","Free","Soil","Party","."],"labels":["B-political party","I-political party","I-political party","O","O","O","O","O","O","O","B-political party","I-political party","O","O","O","O","O","O","O","B-political party","I-political party","O","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, location, person, political party, country, event, election, politician and O.\nSentence: Page 's party affiliation remained with different facets of the Democratic Party , and moved over time from the Democratic-Republican Party to the Jacksonian democracy to the Democrats to the Free Soil Party .","prompt_labels":"Page(B-political party) 's(I-political party) party(I-political party) affiliation(O) remained(O) with(O) different(O) facets(O) of(O) the(O) Democratic(B-political party) Party(I-political party) ,(O) and(O) moved(O) over(O) time(O) from(O) the(O) Democratic-Republican(B-political party) Party(I-political party) to(O) the(O) Jacksonian(O) democracy(O) to(O) the(O) Democrats(O) to(O) the(O) Free(B-political party) Soil(I-political party) Party(I-political party) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["political party","location","country","person","politician","organization","event","election"],"instance":{"id":"176","words":["Williams","stood","unsuccessfully","for","Labour","in","Coventry","at","the","1923","United","Kingdom","general","election","and","1924","United","Kingdom","general","election","s",",","but","was","elected","to","the","National","Executive","Committee","of","the","party",",","serving","as","its","chair","in","1925","."],"labels":["B-politician","O","O","O","B-political party","O","B-location","O","O","B-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: political party, location, country, person, politician, organization, event, election and O.\nSentence: Williams stood unsuccessfully for Labour in Coventry at the 1923 United Kingdom general election and 1924 United Kingdom general election s , but was elected to the National Executive Committee of the party , serving as its chair in 1925 .","prompt_labels":"Williams(B-politician) stood(O) unsuccessfully(O) for(O) Labour(B-political party) in(O) Coventry(B-location) at(O) the(O) 1923(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) and(O) 1924(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) s(O) ,(O) but(O) was(O) elected(O) to(O) the(O) National(B-organization) Executive(I-organization) Committee(I-organization) of(O) the(O) party(O) ,(O) serving(O) as(O) its(O) chair(O) in(O) 1925(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["political party","country","location","election","person","event","politician","organization"],"instance":{"id":"177","words":["Prominent","politicians","from","Sinn","Fin",",","the","Social","Democratic","and","Labour","Party","(","SDLP",")","and","the","centrist","Alliance","Party","of","Northern","Ireland","joined","the","protest","."],"labels":["O","O","O","B-political party","I-political party","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","O","B-political party","O","O","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: political party, country, location, election, person, event, politician, organization and O.\nSentence: Prominent politicians from Sinn Fin , the Social Democratic and Labour Party ( SDLP ) and the centrist Alliance Party of Northern Ireland joined the protest .","prompt_labels":"Prominent(O) politicians(O) from(O) Sinn(B-political party) Fin(I-political party) ,(O) the(O) Social(B-political party) Democratic(I-political party) and(I-political party) Labour(I-political party) Party(I-political party) ((O) SDLP(B-political party) )(O) and(O) the(O) centrist(O) Alliance(B-political party) Party(I-political party) of(I-political party) Northern(I-political party) Ireland(I-political party) joined(O) the(O) protest(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["country","organization","political party","person","election","politician","location","event"],"instance":{"id":"178","words":["A","cash","book","kept","by","Flick","company","accountant","Rudolph","Diehl","listed","that","next","to","other","transfers",",","250,000","Deutschemark","was","transferred","to","Christian","Social","Union","in","Bavaria","chairman","Franz","Josef","Strauss","and","565,000","Deutschemark","were","transferred","to","Christian","Democratic","Union","of","Germany","chairman","Helmut","Kohl",",","as","well","as","payments","to","FDP","and","Social","Democratic","Party","of","Germany","politicians","."],"labels":["O","O","O","O","O","B-organization","I-organization","O","B-person","I-person","O","O","O","O","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","O","B-politician","I-politician","I-politician","O","O","O","O","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","O","B-politician","I-politician","O","O","O","O","O","O","B-political party","O","B-political party","I-political party","I-political party","I-political party","I-political party","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, organization, political party, person, election, politician, location, event and O.\nSentence: A cash book kept by Flick company accountant Rudolph Diehl listed that next to other transfers , 250,000 Deutschemark was transferred to Christian Social Union in Bavaria chairman Franz Josef Strauss and 565,000 Deutschemark were transferred to Christian Democratic Union of Germany chairman Helmut Kohl , as well as payments to FDP and Social Democratic Party of Germany politicians .","prompt_labels":"A(O) cash(O) book(O) kept(O) by(O) Flick(B-organization) company(I-organization) accountant(O) Rudolph(B-person) Diehl(I-person) listed(O) that(O) next(O) to(O) other(O) transfers(O) ,(O) 250,000(O) Deutschemark(O) was(O) transferred(O) to(O) Christian(B-political party) Social(I-political party) Union(I-political party) in(I-political party) Bavaria(I-political party) chairman(O) Franz(B-politician) Josef(I-politician) Strauss(I-politician) and(O) 565,000(O) Deutschemark(O) were(O) transferred(O) to(O) Christian(B-political party) Democratic(I-political party) Union(I-political party) of(I-political party) Germany(I-political party) chairman(O) Helmut(B-politician) Kohl(I-politician) ,(O) as(O) well(O) as(O) payments(O) to(O) FDP(B-political party) and(O) Social(B-political party) Democratic(I-political party) Party(I-political party) of(I-political party) Germany(I-political party) politicians(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["political party","election","country","person","organization","event","location","politician"],"instance":{"id":"179","words":["Two","years","of","proceedings","clarified","that","between","1969","and","1989",",","politicians","of","all","major","parties","(","Christian","Democratic","Union","of","Germany",",","Christian","Social","Union","in","Bavaria",",","FDP",",","and","Social","Democratic","Party","of","Germany",")","had","received","money","from","the","Flick","company",":","a","total","of","25","million","Deutschemark","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","O","B-political party","I-political party","I-political party","I-political party","I-political party","O","B-political party","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","O","O","O","O","O","O","B-organization","I-organization","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: political party, election, country, person, organization, event, location, politician and O.\nSentence: Two years of proceedings clarified that between 1969 and 1989 , politicians of all major parties ( Christian Democratic Union of Germany , Christian Social Union in Bavaria , FDP , and Social Democratic Party of Germany ) had received money from the Flick company : a total of 25 million Deutschemark .","prompt_labels":"Two(O) years(O) of(O) proceedings(O) clarified(O) that(O) between(O) 1969(O) and(O) 1989(O) ,(O) politicians(O) of(O) all(O) major(O) parties(O) ((O) Christian(B-political party) Democratic(I-political party) Union(I-political party) of(I-political party) Germany(I-political party) ,(O) Christian(B-political party) Social(I-political party) Union(I-political party) in(I-political party) Bavaria(I-political party) ,(O) FDP(B-political party) ,(O) and(O) Social(B-political party) Democratic(I-political party) Party(I-political party) of(I-political party) Germany(I-political party) )(O) had(O) received(O) money(O) from(O) the(O) Flick(B-organization) company(I-organization) :(O) a(O) total(O) of(O) 25(O) million(O) Deutschemark(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["person","event","country","political party","politician","location","organization","election"],"instance":{"id":"180","words":["The","group","'s","School","Risk","Audit","program","was","conducted","jointly","by","Mission","America",",","the","American","Family","Association",",","Concerned","Women","for","America",",","the","Family","Research","Council",",","and","other","groups","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","B-organization","I-organization","O","O","B-organization","I-organization","I-organization","O","B-organization","I-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, event, country, political party, politician, location, organization, election and O.\nSentence: The group 's School Risk Audit program was conducted jointly by Mission America , the American Family Association , Concerned Women for America , the Family Research Council , and other groups .","prompt_labels":"The(O) group(O) 's(O) School(O) Risk(O) Audit(O) program(O) was(O) conducted(O) jointly(O) by(O) Mission(B-organization) America(I-organization) ,(O) the(O) American(B-organization) Family(I-organization) Association(I-organization) ,(O) Concerned(B-organization) Women(I-organization) for(I-organization) America(I-organization) ,(O) the(O) Family(B-organization) Research(I-organization) Council(I-organization) ,(O) and(O) other(O) groups(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["country","politician","person","election","organization","location","event","political party"],"instance":{"id":"181","words":["Their","primary","opponents",",","the","National","Republican","Party",",","were","coalescing","and","unifying","as","the","Whig","Party",",","reducing","the","influence","of","single-issue","parties",",","the","Anti-Masonic","Party","(","an","anti-Masonry","movement",")","and","the","Nullifier","Party","(","a","John","C.","Calhoun","-led","states","'","rights","party","that","supported","South","Carolina","during","the","Nullification","Crisis","in","1832","and","1833",")","."],"labels":["O","O","O","O","O","B-political party","I-political party","I-political party","O","O","O","O","O","O","O","B-political party","I-political party","O","O","O","O","O","O","O","O","O","B-political party","I-political party","O","O","B-political party","I-political party","O","O","O","B-political party","I-political party","O","O","B-politician","I-politician","I-politician","O","B-political party","I-political party","I-political party","I-political party","O","O","B-location","I-location","O","O","B-event","I-event","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, politician, person, election, organization, location, event, political party and O.\nSentence: Their primary opponents , the National Republican Party , were coalescing and unifying as the Whig Party , reducing the influence of single-issue parties , the Anti-Masonic Party ( an anti-Masonry movement ) and the Nullifier Party ( a John C. Calhoun -led states ' rights party that supported South Carolina during the Nullification Crisis in 1832 and 1833 ) .","prompt_labels":"Their(O) primary(O) opponents(O) ,(O) the(O) National(B-political party) Republican(I-political party) Party(I-political party) ,(O) were(O) coalescing(O) and(O) unifying(O) as(O) the(O) Whig(B-political party) Party(I-political party) ,(O) reducing(O) the(O) influence(O) of(O) single-issue(O) parties(O) ,(O) the(O) Anti-Masonic(B-political party) Party(I-political party) ((O) an(O) anti-Masonry(B-political party) movement(I-political party) )(O) and(O) the(O) Nullifier(B-political party) Party(I-political party) ((O) a(O) John(B-politician) C.(I-politician) Calhoun(I-politician) -led(O) states(B-political party) '(I-political party) rights(I-political party) party(I-political party) that(O) supported(O) South(B-location) Carolina(I-location) during(O) the(O) Nullification(B-event) Crisis(I-event) in(O) 1832(O) and(O) 1833(O) )(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["politician","country","political party","organization","election","person","event","location"],"instance":{"id":"182","words":["President","John","Adams",",","a","Federalist","Party","elected","two","years","prior","in","the","1796","United","States","presidential","election",",","remained","popular","during","a","time","of","national","economic","growth",",","and","the","Federalists","made","a","modest","gain","of","three","seats","at","the","expense","of","the","opposition","Democratic-Republican","Party",",","the","party","of","Vice","President","and","future","President","Thomas","Jefferson","."],"labels":["O","B-politician","I-politician","O","O","B-political party","I-political party","O","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-political party","I-political party","O","O","O","O","O","O","O","O","O","B-politician","I-politician","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: politician, country, political party, organization, election, person, event, location and O.\nSentence: President John Adams , a Federalist Party elected two years prior in the 1796 United States presidential election , remained popular during a time of national economic growth , and the Federalists made a modest gain of three seats at the expense of the opposition Democratic-Republican Party , the party of Vice President and future President Thomas Jefferson .","prompt_labels":"President(O) John(B-politician) Adams(I-politician) ,(O) a(O) Federalist(B-political party) Party(I-political party) elected(O) two(O) years(O) prior(O) in(O) the(O) 1796(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election) ,(O) remained(O) popular(O) during(O) a(O) time(O) of(O) national(O) economic(O) growth(O) ,(O) and(O) the(O) Federalists(O) made(O) a(O) modest(O) gain(O) of(O) three(O) seats(O) at(O) the(O) expense(O) of(O) the(O) opposition(O) Democratic-Republican(B-political party) Party(I-political party) ,(O) the(O) party(O) of(O) Vice(O) President(O) and(O) future(O) President(O) Thomas(B-politician) Jefferson(I-politician) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["country","election","political party","event","politician","organization","person","location"],"instance":{"id":"183","words":["She","was","the","lead","Senate","candidate","at","the","2007","Australian","federal","election",",","again","at","the","2010","Australian","federal","election",",","in","which","she","became","the","first","Greens","candidate","elected","in","Queensland",",","and","the","2019","Australian","federal","election","."],"labels":["O","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","O","O","O","O","B-election","I-election","I-election","I-election","O","O","O","O","O","O","O","B-political party","O","O","O","B-location","O","O","O","B-election","I-election","I-election","I-election","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, election, political party, event, politician, organization, person, location and O.\nSentence: She was the lead Senate candidate at the 2007 Australian federal election , again at the 2010 Australian federal election , in which she became the first Greens candidate elected in Queensland , and the 2019 Australian federal election .","prompt_labels":"She(O) was(O) the(O) lead(O) Senate(O) candidate(O) at(O) the(O) 2007(B-election) Australian(I-election) federal(I-election) election(I-election) ,(O) again(O) at(O) the(O) 2010(B-election) Australian(I-election) federal(I-election) election(I-election) ,(O) in(O) which(O) she(O) became(O) the(O) first(O) Greens(B-political party) candidate(O) elected(O) in(O) Queensland(B-location) ,(O) and(O) the(O) 2019(B-election) Australian(I-election) federal(I-election) election(I-election) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["political party","election","organization","country","person","event","location","politician"],"instance":{"id":"184","words":["The","Queensland","Greens","enjoyed","growing","support","in","state","elections",",","increasing","their","vote","from","2.5","per","cent","at","the","2001","Queensland","state","election","(","when","they","contested","31","of","the","Parliament","'s","89","seats",")",",","to","6.76","per","cent","in","2004","Queensland","state","election","(","from","72","seats",")",",","to","7.99","per","cent","in","2006","Queensland","state","election","(","from","75","seats",")",","],"labels":["O","B-political party","I-political party","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","O","O","O","O","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: political party, election, organization, country, person, event, location, politician and O.\nSentence: The Queensland Greens enjoyed growing support in state elections , increasing their vote from 2.5 per cent at the 2001 Queensland state election ( when they contested 31 of the Parliament 's 89 seats ) , to 6.76 per cent in 2004 Queensland state election ( from 72 seats ) , to 7.99 per cent in 2006 Queensland state election ( from 75 seats ) ,","prompt_labels":"The(O) Queensland(B-political party) Greens(I-political party) enjoyed(O) growing(O) support(O) in(O) state(O) elections(O) ,(O) increasing(O) their(O) vote(O) from(O) 2.5(O) per(O) cent(O) at(O) the(O) 2001(B-election) Queensland(I-election) state(I-election) election(I-election) ((O) when(O) they(O) contested(O) 31(O) of(O) the(O) Parliament(O) 's(O) 89(O) seats(O) )(O) ,(O) to(O) 6.76(O) per(O) cent(O) in(O) 2004(B-election) Queensland(I-election) state(I-election) election(I-election) ((O) from(O) 72(O) seats(O) )(O) ,(O) to(O) 7.99(O) per(O) cent(O) in(O) 2006(B-election) Queensland(I-election) state(I-election) election(I-election) ((O) from(O) 75(O) seats(O) )(O) ,(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["person","political party","election","location","country","organization","event","politician"],"instance":{"id":"185","words":["The","Australian","Greens","in","Queensland","have","traditionally","polled","strongest","in","the","usually","Labor","-held","seats","of","Mount","Coot-tha","and","South","Brisbane",",","as","well","as","the","usually","Liberal","National","Party","of","Queensland","-held","seat","of","Noosa",",","polling","over","20","%","of","the","primary","vote","in","these","seats","at","the","2015","Queensland","state","election","."],"labels":["O","B-political party","I-political party","O","B-location","O","O","O","O","O","O","O","B-political party","O","O","O","B-location","I-location","O","B-location","I-location","O","O","O","O","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","O","O","O","B-location","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, political party, election, location, country, organization, event, politician and O.\nSentence: The Australian Greens in Queensland have traditionally polled strongest in the usually Labor -held seats of Mount Coot-tha and South Brisbane , as well as the usually Liberal National Party of Queensland -held seat of Noosa , polling over 20 % of the primary vote in these seats at the 2015 Queensland state election .","prompt_labels":"The(O) Australian(B-political party) Greens(I-political party) in(O) Queensland(B-location) have(O) traditionally(O) polled(O) strongest(O) in(O) the(O) usually(O) Labor(B-political party) -held(O) seats(O) of(O) Mount(B-location) Coot-tha(I-location) and(O) South(B-location) Brisbane(I-location) ,(O) as(O) well(O) as(O) the(O) usually(O) Liberal(B-political party) National(I-political party) Party(I-political party) of(I-political party) Queensland(I-political party) -held(O) seat(O) of(O) Noosa(B-location) ,(O) polling(O) over(O) 20(O) %(O) of(O) the(O) primary(O) vote(O) in(O) these(O) seats(O) at(O) the(O) 2015(B-election) Queensland(I-election) state(I-election) election(I-election) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["political party","organization","event","country","person","election","politician","location"],"instance":{"id":"186","words":["A","significant","number","of","Straight","Left","faction","members","had","developed","close","personal","friendships","with","members","of","fraternal","communist","parties",",","particularly","the","Tudeh","Party","of","Iran",",","Iraqi","Communist","Party",",","South","African","and","Communist","Party","of","Greece","parties",",","who","were","well","organised","on","most","British","University","campuses","."],"labels":["O","O","O","O","B-organization","I-organization","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","I-political party","O","B-political party","I-political party","I-political party","O","O","O","O","B-political party","I-political party","I-political party","I-political party","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: political party, organization, event, country, person, election, politician, location and O.\nSentence: A significant number of Straight Left faction members had developed close personal friendships with members of fraternal communist parties , particularly the Tudeh Party of Iran , Iraqi Communist Party , South African and Communist Party of Greece parties , who were well organised on most British University campuses .","prompt_labels":"A(O) significant(O) number(O) of(O) Straight(B-organization) Left(I-organization) faction(O) members(O) had(O) developed(O) close(O) personal(O) friendships(O) with(O) members(O) of(O) fraternal(O) communist(O) parties(O) ,(O) particularly(O) the(O) Tudeh(B-political party) Party(I-political party) of(I-political party) Iran(I-political party) ,(O) Iraqi(B-political party) Communist(I-political party) Party(I-political party) ,(O) South(O) African(O) and(O) Communist(B-political party) Party(I-political party) of(I-political party) Greece(I-political party) parties(O) ,(O) who(O) were(O) well(O) organised(O) on(O) most(O) British(O) University(O) campuses(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["person","organization","event","political party","election","country","politician","location"],"instance":{"id":"187","words":["The","main","opponent","of","Future","Movement","is","the","March","8","Alliance",",","most","important","parts","being","Free","Patriotic","Movement","(","FPM",")","led","by","General","Michel","Aoun","and","the","Shia","Hezbollah","and","Amal","Movement","Movements","."],"labels":["O","O","O","O","B-political party","I-political party","O","O","B-political party","I-political party","I-political party","O","O","O","O","O","B-political party","I-political party","I-political party","O","B-political party","O","O","O","O","B-politician","I-politician","O","O","O","B-political party","O","B-political party","I-political party","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, organization, event, political party, election, country, politician, location and O.\nSentence: The main opponent of Future Movement is the March 8 Alliance , most important parts being Free Patriotic Movement ( FPM ) led by General Michel Aoun and the Shia Hezbollah and Amal Movement Movements .","prompt_labels":"The(O) main(O) opponent(O) of(O) Future(B-political party) Movement(I-political party) is(O) the(O) March(B-political party) 8(I-political party) Alliance(I-political party) ,(O) most(O) important(O) parts(O) being(O) Free(B-political party) Patriotic(I-political party) Movement(I-political party) ((O) FPM(B-political party) )(O) led(O) by(O) General(O) Michel(B-politician) Aoun(I-politician) and(O) the(O) Shia(O) Hezbollah(B-political party) and(O) Amal(B-political party) Movement(I-political party) Movements(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["organization","country","event","location","person","politician","election","political party"],"instance":{"id":"188","words":["He","was","voted","into","Parliament","with","the","Liberal","Democratic","Union",",","in","the","1956","Greek","legislative","election","s",",","but","in","the","1958","Greek","legislative","election","s",",","as","head","of","the","Union","of","Populars",",","he","failed","to","be","elected","."],"labels":["O","O","O","O","O","O","O","B-political party","I-political party","I-political party","O","O","O","B-election","I-election","I-election","I-election","O","O","O","O","O","B-election","I-election","I-election","I-election","O","O","O","O","O","O","B-political party","I-political party","I-political party","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, country, event, location, person, politician, election, political party and O.\nSentence: He was voted into Parliament with the Liberal Democratic Union , in the 1956 Greek legislative election s , but in the 1958 Greek legislative election s , as head of the Union of Populars , he failed to be elected .","prompt_labels":"He(O) was(O) voted(O) into(O) Parliament(O) with(O) the(O) Liberal(B-political party) Democratic(I-political party) Union(I-political party) ,(O) in(O) the(O) 1956(B-election) Greek(I-election) legislative(I-election) election(I-election) s(O) ,(O) but(O) in(O) the(O) 1958(B-election) Greek(I-election) legislative(I-election) election(I-election) s(O) ,(O) as(O) head(O) of(O) the(O) Union(B-political party) of(I-political party) Populars(I-political party) ,(O) he(O) failed(O) to(O) be(O) elected(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["country","event","election","politician","organization","political party","location","person"],"instance":{"id":"189","words":["Other","groups","supporting","their","repeal","include","the","National","Conference","of","Insurance","Legislators",",","the","American","Bar","Association",",","the","American","College","of","Emergency","Physicians",",","Mothers","Against","Drunk","Driving",",","the","National","Commission","Against","Drunk","Driving",",","and","the","American","Medical","Association","."],"labels":["O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","B-organization","I-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","O","O","B-organization","I-organization","I-organization","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, event, election, politician, organization, political party, location, person and O.\nSentence: Other groups supporting their repeal include the National Conference of Insurance Legislators , the American Bar Association , the American College of Emergency Physicians , Mothers Against Drunk Driving , the National Commission Against Drunk Driving , and the American Medical Association .","prompt_labels":"Other(O) groups(O) supporting(O) their(O) repeal(O) include(O) the(O) National(B-organization) Conference(I-organization) of(I-organization) Insurance(I-organization) Legislators(I-organization) ,(O) the(O) American(B-organization) Bar(I-organization) Association(I-organization) ,(O) the(O) American(B-organization) College(I-organization) of(I-organization) Emergency(I-organization) Physicians(I-organization) ,(O) Mothers(B-organization) Against(I-organization) Drunk(I-organization) Driving(I-organization) ,(O) the(O) National(B-organization) Commission(I-organization) Against(I-organization) Drunk(I-organization) Driving(I-organization) ,(O) and(O) the(O) American(B-organization) Medical(I-organization) Association(I-organization) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["political party","politician","election","organization","country","event","location","person"],"instance":{"id":"190","words":["Grande","was","elected","to","the","Ontario","legislature","in","the","1975","Ontario","general","election",",","and","re-elected","in","1977","Ontario","general","election",",","1981","Ontario","general","election","and","1985","Ontario","general","election","."],"labels":["B-person","O","O","O","O","B-organization","I-organization","O","O","B-election","I-election","I-election","I-election","O","O","O","O","B-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: political party, politician, election, organization, country, event, location, person and O.\nSentence: Grande was elected to the Ontario legislature in the 1975 Ontario general election , and re-elected in 1977 Ontario general election , 1981 Ontario general election and 1985 Ontario general election .","prompt_labels":"Grande(B-person) was(O) elected(O) to(O) the(O) Ontario(B-organization) legislature(I-organization) in(O) the(O) 1975(B-election) Ontario(I-election) general(I-election) election(I-election) ,(O) and(O) re-elected(O) in(O) 1977(B-election) Ontario(I-election) general(I-election) election(I-election) ,(O) 1981(B-election) Ontario(I-election) general(I-election) election(I-election) and(O) 1985(B-election) Ontario(I-election) general(I-election) election(I-election) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["election","politician","person","political party","location","event","country","organization"],"instance":{"id":"191","words":["1950","boundaries","were","used","also","for","the","general","elections","of","1951","United","Kingdom","general","election",",","1955","United","Kingdom","general","election",",","1959","United","Kingdom","general","election",",","1964","United","Kingdom","general","election",",","1966","United","Kingdom","general","election","and","1970","United","Kingdom","general","election","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: election, politician, person, political party, location, event, country, organization and O.\nSentence: 1950 boundaries were used also for the general elections of 1951 United Kingdom general election , 1955 United Kingdom general election , 1959 United Kingdom general election , 1964 United Kingdom general election , 1966 United Kingdom general election and 1970 United Kingdom general election .","prompt_labels":"1950(O) boundaries(O) were(O) used(O) also(O) for(O) the(O) general(O) elections(O) of(O) 1951(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) 1955(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) 1959(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) 1964(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) 1966(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) and(O) 1970(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["location","organization","election","politician","political party","country","event","person"],"instance":{"id":"192","words":["The","Scottish","National","Party",",","the","Scottish","Socialist","Party","and","the","Scottish","Green","Party","all","oppose","the","deployment","of","nuclear","weapons",",","although","the","Scottish","National","Party","have","claimed","that","they","would","retain","the","base","for","the","servicing","of","conventionally","armed","and","powered","naval","units","."],"labels":["O","B-political party","I-political party","I-political party","O","O","B-political party","I-political party","I-political party","O","O","B-political party","I-political party","I-political party","O","O","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, organization, election, politician, political party, country, event, person and O.\nSentence: The Scottish National Party , the Scottish Socialist Party and the Scottish Green Party all oppose the deployment of nuclear weapons , although the Scottish National Party have claimed that they would retain the base for the servicing of conventionally armed and powered naval units .","prompt_labels":"The(O) Scottish(B-political party) National(I-political party) Party(I-political party) ,(O) the(O) Scottish(B-political party) Socialist(I-political party) Party(I-political party) and(O) the(O) Scottish(B-political party) Green(I-political party) Party(I-political party) all(O) oppose(O) the(O) deployment(O) of(O) nuclear(O) weapons(O) ,(O) although(O) the(O) Scottish(B-political party) National(I-political party) Party(I-political party) have(O) claimed(O) that(O) they(O) would(O) retain(O) the(O) base(O) for(O) the(O) servicing(O) of(O) conventionally(O) armed(O) and(O) powered(O) naval(O) units(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["location","politician","country","person","political party","organization","event","election"],"instance":{"id":"193","words":["As","a","result",",","OI","policy","positions","are","often","more","socially","left-wing","than","factions","such","as","the","Labour","Students","or","Union","of","Jewish","Students",",","but","tend","to","avoid","non-education","policy","areas","prioritised","by","Student","Left","Network","or","Liberation","Left","such","as","economic","or","foreign","policy","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-organization","I-organization","O","B-organization","I-organization","I-organization","I-organization","O","O","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","O","B-organization","I-organization","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, politician, country, person, political party, organization, event, election and O.\nSentence: As a result , OI policy positions are often more socially left-wing than factions such as the Labour Students or Union of Jewish Students , but tend to avoid non-education policy areas prioritised by Student Left Network or Liberation Left such as economic or foreign policy .","prompt_labels":"As(O) a(O) result(O) ,(O) OI(O) policy(O) positions(O) are(O) often(O) more(O) socially(O) left-wing(O) than(O) factions(O) such(O) as(O) the(O) Labour(B-organization) Students(I-organization) or(O) Union(B-organization) of(I-organization) Jewish(I-organization) Students(I-organization) ,(O) but(O) tend(O) to(O) avoid(O) non-education(O) policy(O) areas(O) prioritised(O) by(O) Student(B-organization) Left(I-organization) Network(I-organization) or(O) Liberation(B-organization) Left(I-organization) such(O) as(O) economic(O) or(O) foreign(O) policy(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["person","organization","politician","country","event","location","political party","election"],"instance":{"id":"194","words":["In","December","2019",",","the","party","merged","with","the","Afar","National","Democratic","Party","(","ANDP",")",",","the","Amhara","Democratic","Party","(","ADP",")",",","the","Ethiopian","Somali","People","'s","Democratic","Party","(","ESPDP",")",",","the","Gambela","People","'s","Democratic","Movement","(","GPDM",")",",","the","Hareri","National","League","(","HNL",")",",","the","Oromo","Democratic","Party","(","ODP",")","and","the","Southern","Ethiopian","People","'s","Democratic","Movement","(","SEPDM",")","to","form","the","Prosperity","Party","."],"labels":["O","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","I-political party","O","B-political party","O","O","O","B-political party","I-political party","I-political party","O","B-political party","O","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","I-political party","O","B-political party","O","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","O","B-political party","O","O","O","B-political party","I-political party","I-political party","O","B-political party","O","O","O","B-political party","I-political party","I-political party","O","B-political party","O","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","I-political party","O","B-political party","O","O","O","O","B-political party","I-political party","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, organization, politician, country, event, location, political party, election and O.\nSentence: In December 2019 , the party merged with the Afar National Democratic Party ( ANDP ) , the Amhara Democratic Party ( ADP ) , the Ethiopian Somali People 's Democratic Party ( ESPDP ) , the Gambela People 's Democratic Movement ( GPDM ) , the Hareri National League ( HNL ) , the Oromo Democratic Party ( ODP ) and the Southern Ethiopian People 's Democratic Movement ( SEPDM ) to form the Prosperity Party .","prompt_labels":"In(O) December(O) 2019(O) ,(O) the(O) party(O) merged(O) with(O) the(O) Afar(B-political party) National(I-political party) Democratic(I-political party) Party(I-political party) ((O) ANDP(B-political party) )(O) ,(O) the(O) Amhara(B-political party) Democratic(I-political party) Party(I-political party) ((O) ADP(B-political party) )(O) ,(O) the(O) Ethiopian(B-political party) Somali(I-political party) People(I-political party) 's(I-political party) Democratic(I-political party) Party(I-political party) ((O) ESPDP(B-political party) )(O) ,(O) the(O) Gambela(B-political party) People(I-political party) 's(I-political party) Democratic(I-political party) Movement(I-political party) ((O) GPDM(B-political party) )(O) ,(O) the(O) Hareri(B-political party) National(I-political party) League(I-political party) ((O) HNL(B-political party) )(O) ,(O) the(O) Oromo(B-political party) Democratic(I-political party) Party(I-political party) ((O) ODP(B-political party) )(O) and(O) the(O) Southern(B-political party) Ethiopian(I-political party) People(I-political party) 's(I-political party) Democratic(I-political party) Movement(I-political party) ((O) SEPDM(B-political party) )(O) to(O) form(O) the(O) Prosperity(B-political party) Party(I-political party) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["politician","political party","event","location","country","organization","election","person"],"instance":{"id":"195","words":["In","Belgian","politics",",","the","term","Jamaica","coalition","refers","to","a","coalition","of","Christian","democrats","(","Christen-Democratisch","en","Vlaams","and","Centre","dmocrate","humaniste",")",",","liberals","(","Open","Vlaamse","Liberalen","en","Democraten","and","Mouvement","Rformateur",")","and","greens","(","Groen","and","Ecolo",")","."],"labels":["O","O","O","O","O","O","B-country","O","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","O","B-political party","I-political party","I-political party","O","O","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","O","B-political party","I-political party","O","O","O","O","B-political party","O","B-political party","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: politician, political party, event, location, country, organization, election, person and O.\nSentence: In Belgian politics , the term Jamaica coalition refers to a coalition of Christian democrats ( Christen-Democratisch en Vlaams and Centre dmocrate humaniste ) , liberals ( Open Vlaamse Liberalen en Democraten and Mouvement Rformateur ) and greens ( Groen and Ecolo ) .","prompt_labels":"In(O) Belgian(O) politics(O) ,(O) the(O) term(O) Jamaica(B-country) coalition(O) refers(O) to(O) a(O) coalition(O) of(O) Christian(O) democrats(O) ((O) Christen-Democratisch(B-political party) en(I-political party) Vlaams(I-political party) and(O) Centre(B-political party) dmocrate(I-political party) humaniste(I-political party) )(O) ,(O) liberals(O) ((O) Open(B-political party) Vlaamse(I-political party) Liberalen(I-political party) en(I-political party) Democraten(I-political party) and(O) Mouvement(B-political party) Rformateur(I-political party) )(O) and(O) greens(O) ((O) Groen(B-political party) and(O) Ecolo(B-political party) )(O) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["person","election","location","politician","event","country","organization","political party"],"instance":{"id":"196","words":["The","same","boundaries","were","used","in","the","1922","United","Kingdom","general","election",",","the","1923","United","Kingdom","general","election",",","the","1924","United","Kingdom","general","election",",","the","1929","United","Kingdom","general","election",",","the","1931","United","Kingdom","general","election",",","the","1935","United","Kingdom","general","election","and","the","1945","United","Kingdom","general","election","."],"labels":["O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","O","O","B-election","I-election","I-election","I-election","I-election","O","O","B-election","I-election","I-election","I-election","I-election","O","O","B-election","I-election","I-election","I-election","I-election","O","O","B-election","I-election","I-election","I-election","I-election","O","O","B-election","I-election","I-election","I-election","I-election","O","O","B-election","I-election","I-election","I-election","I-election","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, election, location, politician, event, country, organization, political party and O.\nSentence: The same boundaries were used in the 1922 United Kingdom general election , the 1923 United Kingdom general election , the 1924 United Kingdom general election , the 1929 United Kingdom general election , the 1931 United Kingdom general election , the 1935 United Kingdom general election and the 1945 United Kingdom general election .","prompt_labels":"The(O) same(O) boundaries(O) were(O) used(O) in(O) the(O) 1922(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) the(O) 1923(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) the(O) 1924(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) the(O) 1929(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) the(O) 1931(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) the(O) 1935(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) and(O) the(O) 1945(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["politician","location","organization","person","country","event","election","political party"],"instance":{"id":"197","words":["1885","boundaries","were","also","used","in","the","1886","United","Kingdom","general","election",",","the","1892","United","Kingdom","general","election",",","the","1895","United","Kingdom","general","election",",","the","1900","United","Kingdom","general","election",",","the","1906","United","Kingdom","general","election",",","the","January","1910","United","Kingdom","general","election","and","the","December","1910","United","Kingdom","general","election","."],"labels":["O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","O","O","B-election","I-election","I-election","I-election","I-election","O","O","B-election","I-election","I-election","I-election","I-election","O","O","B-election","I-election","I-election","I-election","I-election","O","O","B-election","I-election","I-election","I-election","I-election","O","O","B-election","I-election","I-election","I-election","I-election","I-election","O","O","B-election","I-election","I-election","I-election","I-election","I-election","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: politician, location, organization, person, country, event, election, political party and O.\nSentence: 1885 boundaries were also used in the 1886 United Kingdom general election , the 1892 United Kingdom general election , the 1895 United Kingdom general election , the 1900 United Kingdom general election , the 1906 United Kingdom general election , the January 1910 United Kingdom general election and the December 1910 United Kingdom general election .","prompt_labels":"1885(O) boundaries(O) were(O) also(O) used(O) in(O) the(O) 1886(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) the(O) 1892(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) the(O) 1895(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) the(O) 1900(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) the(O) 1906(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) the(O) January(B-election) 1910(I-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) and(O) the(O) December(B-election) 1910(I-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["organization","election","political party","event","location","person","country","politician"],"instance":{"id":"198","words":["East","Aberdeenshire","retained","the","same","boundaries","for","the","1959","United","Kingdom","general","election",",","the","1964","United","Kingdom","general","election",",","the","1966","United","Kingdom","general","election",",","the","1970","United","Kingdom","general","election",",","the","February","1974","United","Kingdom","general","election","and","the","October","1974","United","Kingdom","general","election","."],"labels":["B-location","I-location","O","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","O","O","B-election","I-election","I-election","I-election","I-election","O","O","B-election","I-election","I-election","I-election","I-election","O","O","B-election","I-election","I-election","I-election","I-election","O","O","B-election","I-election","I-election","I-election","I-election","I-election","O","O","B-election","I-election","I-election","I-election","I-election","I-election","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, election, political party, event, location, person, country, politician and O.\nSentence: East Aberdeenshire retained the same boundaries for the 1959 United Kingdom general election , the 1964 United Kingdom general election , the 1966 United Kingdom general election , the 1970 United Kingdom general election , the February 1974 United Kingdom general election and the October 1974 United Kingdom general election .","prompt_labels":"East(B-location) Aberdeenshire(I-location) retained(O) the(O) same(O) boundaries(O) for(O) the(O) 1959(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) the(O) 1964(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) the(O) 1966(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) the(O) 1970(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) the(O) February(B-election) 1974(I-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) and(O) the(O) October(B-election) 1974(I-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) .(O)"}}
{"dataset":"crossner_politics","split":"dev","label_list":["person","event","country","location","politician","political party","organization","election"],"instance":{"id":"199","words":["1885","boundaries","were","also","used","in","the","1886","United","Kingdom","general","election",",","the","1892","United","Kingdom","general","election",",","the","1895","United","Kingdom","general","election",",","the","1900","United","Kingdom","general","election",",","the","1906","United","Kingdom","general","election",",","the","January","1910","United","Kingdom","general","election","and","the","December","1910","United","Kingdom","general","election","."],"labels":["O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","O","O","B-election","I-election","I-election","I-election","I-election","O","O","B-election","I-election","I-election","I-election","I-election","O","O","B-election","I-election","I-election","I-election","I-election","O","O","B-election","I-election","I-election","I-election","I-election","O","O","B-election","I-election","I-election","I-election","I-election","I-election","O","O","B-election","I-election","I-election","I-election","I-election","I-election","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, event, country, location, politician, political party, organization, election and O.\nSentence: 1885 boundaries were also used in the 1886 United Kingdom general election , the 1892 United Kingdom general election , the 1895 United Kingdom general election , the 1900 United Kingdom general election , the 1906 United Kingdom general election , the January 1910 United Kingdom general election and the December 1910 United Kingdom general election .","prompt_labels":"1885(O) boundaries(O) were(O) also(O) used(O) in(O) the(O) 1886(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) the(O) 1892(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) the(O) 1895(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) the(O) 1900(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) the(O) 1906(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) the(O) January(B-election) 1910(I-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) and(O) the(O) December(B-election) 1910(I-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["chemical compound","chemical element","university","protein","award","astronomical object","academic journal","country","discipline","theory","event","location","person","organization","enzyme","scientist"],"instance":{"id":"0","words":["Between","2006","and","2019",",","ICRANet","has","released","over","1800","scientific","publications","in","refereed","journals","such","as","Physical","Review",",","the","The","Astrophysical","Journal",",","Astronomy","and","Astrophysics","etc","."],"labels":["O","O","O","O","O","B-organization","O","O","O","O","O","O","O","O","O","O","O","B-academic journal","I-academic journal","O","O","B-academic journal","I-academic journal","I-academic journal","O","B-academic journal","I-academic journal","I-academic journal","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: chemical compound, chemical element, university, protein, award, astronomical object, academic journal, country, discipline, theory, event, location, person, organization, enzyme, scientist and O.\nSentence: Between 2006 and 2019 , ICRANet has released over 1800 scientific publications in refereed journals such as Physical Review , the The Astrophysical Journal , Astronomy and Astrophysics etc .","prompt_labels":"Between(O) 2006(O) and(O) 2019(O) ,(O) ICRANet(B-organization) has(O) released(O) over(O) 1800(O) scientific(O) publications(O) in(O) refereed(O) journals(O) such(O) as(O) Physical(B-academic journal) Review(I-academic journal) ,(O) the(O) The(B-academic journal) Astrophysical(I-academic journal) Journal(I-academic journal) ,(O) Astronomy(B-academic journal) and(I-academic journal) Astrophysics(I-academic journal) etc(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["country","person","astronomical object","academic journal","scientist","protein","enzyme","location","organization","university","chemical element","award","event","chemical compound","theory","discipline"],"instance":{"id":"1","words":["Scheele","discovered","organic","acids","Tartaric","acid",",","Oxalic","acid",",","Uric","acid",",","Lactic","acid",",","and","Citric","acid",",","as","well","as","Hydrofluoric","acid",",","hydrocyanic",",","and","Arsenic","acid","acids",".","Richard","Myers",",","(","2003",")","He","preferred","speaking","German","to","Swedish","his","whole","life",",","as","German","was","commonly","spoken","among","Swedish","pharmacists","."],"labels":["B-scientist","O","O","O","B-chemical compound","I-chemical compound","O","B-chemical compound","I-chemical compound","O","B-chemical compound","I-chemical compound","O","B-chemical compound","I-chemical compound","O","O","B-chemical compound","I-chemical compound","O","O","O","O","B-chemical compound","I-chemical compound","O","B-chemical compound","O","O","B-chemical compound","I-chemical compound","O","O","B-scientist","I-scientist","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, person, astronomical object, academic journal, scientist, protein, enzyme, location, organization, university, chemical element, award, event, chemical compound, theory, discipline and O.\nSentence: Scheele discovered organic acids Tartaric acid , Oxalic acid , Uric acid , Lactic acid , and Citric acid , as well as Hydrofluoric acid , hydrocyanic , and Arsenic acid acids . Richard Myers , ( 2003 ) He preferred speaking German to Swedish his whole life , as German was commonly spoken among Swedish pharmacists .","prompt_labels":"Scheele(B-scientist) discovered(O) organic(O) acids(O) Tartaric(B-chemical compound) acid(I-chemical compound) ,(O) Oxalic(B-chemical compound) acid(I-chemical compound) ,(O) Uric(B-chemical compound) acid(I-chemical compound) ,(O) Lactic(B-chemical compound) acid(I-chemical compound) ,(O) and(O) Citric(B-chemical compound) acid(I-chemical compound) ,(O) as(O) well(O) as(O) Hydrofluoric(B-chemical compound) acid(I-chemical compound) ,(O) hydrocyanic(B-chemical compound) ,(O) and(O) Arsenic(B-chemical compound) acid(I-chemical compound) acids(O) .(O) Richard(B-scientist) Myers(I-scientist) ,(O) ((O) 2003(O) )(O) He(O) preferred(O) speaking(O) German(O) to(O) Swedish(O) his(O) whole(O) life(O) ,(O) as(O) German(O) was(O) commonly(O) spoken(O) among(O) Swedish(O) pharmacists(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["astronomical object","discipline","scientist","event","protein","chemical element","university","chemical compound","country","location","person","award","organization","enzyme","theory","academic journal"],"instance":{"id":"2","words":["Labeled","genomic","DNA","is","extracted","from","nuclei","and","fragmented","by","HaeIII","digestion","and","sonication","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: astronomical object, discipline, scientist, event, protein, chemical element, university, chemical compound, country, location, person, award, organization, enzyme, theory, academic journal and O.\nSentence: Labeled genomic DNA is extracted from nuclei and fragmented by HaeIII digestion and sonication .","prompt_labels":"Labeled(O) genomic(O) DNA(O) is(O) extracted(O) from(O) nuclei(O) and(O) fragmented(O) by(O) HaeIII(O) digestion(O) and(O) sonication(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["chemical compound","award","protein","scientist","theory","organization","astronomical object","academic journal","event","person","university","chemical element","discipline","enzyme","country","location"],"instance":{"id":"3","words":["He","attended","the","U.S.","Air","Force","Institute","of","Technology","for","a","year",",","earning","a","bachelor","'s","degree","in","aeromechanics",",","and","received","his","test","pilot","training","at","Edwards","Air","Force","Base","in","California","before","his","assignment","as","a","test","pilot","at","Wright-Patterson","Air","Force","Base","in","Ohio","."],"labels":["O","O","O","B-university","I-university","I-university","I-university","I-university","I-university","O","O","O","O","O","O","O","O","O","O","B-discipline","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O","B-location","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O","B-location","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: chemical compound, award, protein, scientist, theory, organization, astronomical object, academic journal, event, person, university, chemical element, discipline, enzyme, country, location and O.\nSentence: He attended the U.S. Air Force Institute of Technology for a year , earning a bachelor 's degree in aeromechanics , and received his test pilot training at Edwards Air Force Base in California before his assignment as a test pilot at Wright-Patterson Air Force Base in Ohio .","prompt_labels":"He(O) attended(O) the(O) U.S.(B-university) Air(I-university) Force(I-university) Institute(I-university) of(I-university) Technology(I-university) for(O) a(O) year(O) ,(O) earning(O) a(O) bachelor(O) 's(O) degree(O) in(O) aeromechanics(B-discipline) ,(O) and(O) received(O) his(O) test(O) pilot(O) training(O) at(O) Edwards(B-organization) Air(I-organization) Force(I-organization) Base(I-organization) in(O) California(B-location) before(O) his(O) assignment(O) as(O) a(O) test(O) pilot(O) at(O) Wright-Patterson(B-organization) Air(I-organization) Force(I-organization) Base(I-organization) in(O) Ohio(B-location) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["location","scientist","astronomical object","academic journal","chemical element","organization","event","person","discipline","protein","country","enzyme","theory","university","chemical compound","award"],"instance":{"id":"4","words":["This","binding","results","in","the","activation","of","a","signalling","pathway","which","allows","for","the","transcription","factor","NF-B","to","enter","the","nucleus","of","the","macrophage","and","initiate","the","transcription","and","eventual","secretion","of","various","cytokines","such","as","Il-8",",","Interleukin-1","family",",","and","TNF","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-protein","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-protein","O","B-protein","I-protein","O","O","B-protein","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, scientist, astronomical object, academic journal, chemical element, organization, event, person, discipline, protein, country, enzyme, theory, university, chemical compound, award and O.\nSentence: This binding results in the activation of a signalling pathway which allows for the transcription factor NF-B to enter the nucleus of the macrophage and initiate the transcription and eventual secretion of various cytokines such as Il-8 , Interleukin-1 family , and TNF .","prompt_labels":"This(O) binding(O) results(O) in(O) the(O) activation(O) of(O) a(O) signalling(O) pathway(O) which(O) allows(O) for(O) the(O) transcription(O) factor(O) NF-B(B-protein) to(O) enter(O) the(O) nucleus(O) of(O) the(O) macrophage(O) and(O) initiate(O) the(O) transcription(O) and(O) eventual(O) secretion(O) of(O) various(O) cytokines(O) such(O) as(O) Il-8(B-protein) ,(O) Interleukin-1(B-protein) family(I-protein) ,(O) and(O) TNF(B-protein) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["scientist","theory","enzyme","organization","academic journal","astronomical object","location","country","discipline","university","person","event","chemical element","award","chemical compound","protein"],"instance":{"id":"5","words":["In","addition",",","there","would","probably","have","been","simple","hydride","s","such","as","those","now","found","in","gas","giants","like","Jupiter","and","Saturn",",","notably","water","vapor",",","methane",",","and","ammonia","."],"labels":["O","O","O","O","O","O","O","O","O","B-chemical compound","O","O","O","O","O","O","O","O","O","O","B-astronomical object","O","B-astronomical object","O","O","B-chemical compound","I-chemical compound","O","B-chemical compound","O","O","B-chemical compound","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: scientist, theory, enzyme, organization, academic journal, astronomical object, location, country, discipline, university, person, event, chemical element, award, chemical compound, protein and O.\nSentence: In addition , there would probably have been simple hydride s such as those now found in gas giants like Jupiter and Saturn , notably water vapor , methane , and ammonia .","prompt_labels":"In(O) addition(O) ,(O) there(O) would(O) probably(O) have(O) been(O) simple(O) hydride(B-chemical compound) s(O) such(O) as(O) those(O) now(O) found(O) in(O) gas(O) giants(O) like(O) Jupiter(B-astronomical object) and(O) Saturn(B-astronomical object) ,(O) notably(O) water(B-chemical compound) vapor(I-chemical compound) ,(O) methane(B-chemical compound) ,(O) and(O) ammonia(B-chemical compound) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["event","academic journal","discipline","university","protein","organization","chemical compound","chemical element","award","astronomical object","enzyme","theory","location","person","scientist","country"],"instance":{"id":"6","words":["Like","aluminium",",","According","to","the","International","Resource","Panel","'","s","Metal","Stocks","in","Society","report",",","the","global","per","capita","stock","of","copper","in","use","in","society","is","35-55","kg","."],"labels":["O","B-chemical element","O","O","O","O","B-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, academic journal, discipline, university, protein, organization, chemical compound, chemical element, award, astronomical object, enzyme, theory, location, person, scientist, country and O.\nSentence: Like aluminium , According to the International Resource Panel ' s Metal Stocks in Society report , the global per capita stock of copper in use in society is 35-55 kg .","prompt_labels":"Like(O) aluminium(B-chemical element) ,(O) According(O) to(O) the(O) International(B-organization) Resource(I-organization) Panel(I-organization) '(O) s(O) Metal(B-organization) Stocks(I-organization) in(I-organization) Society(I-organization) report(O) ,(O) the(O) global(O) per(O) capita(O) stock(O) of(O) copper(O) in(O) use(O) in(O) society(O) is(O) 35-55(O) kg(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["chemical compound","award","country","protein","enzyme","person","scientist","chemical element","university","organization","academic journal","theory","event","location","astronomical object","discipline"],"instance":{"id":"7","words":["The","Olympic","golf","course","is","a","new","venue","built","for","the","Golf","at","the","2016","Summer","Olympics","."],"labels":["O","B-location","I-location","I-location","O","O","O","O","O","O","O","O","O","O","B-event","I-event","I-event","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: chemical compound, award, country, protein, enzyme, person, scientist, chemical element, university, organization, academic journal, theory, event, location, astronomical object, discipline and O.\nSentence: The Olympic golf course is a new venue built for the Golf at the 2016 Summer Olympics .","prompt_labels":"The(O) Olympic(B-location) golf(I-location) course(I-location) is(O) a(O) new(O) venue(O) built(O) for(O) the(O) Golf(O) at(O) the(O) 2016(B-event) Summer(I-event) Olympics(I-event) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["enzyme","theory","chemical compound","country","organization","chemical element","protein","person","event","award","astronomical object","scientist","university","location","academic journal","discipline"],"instance":{"id":"8","words":["Removing","a","TAD","boundary","(","for","example",",","using","CRISPR","to","delete","the","relevant","region","of","the","genome",")","can","allow","new","promoter-enhancer","contacts","to","form","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: enzyme, theory, chemical compound, country, organization, chemical element, protein, person, event, award, astronomical object, scientist, university, location, academic journal, discipline and O.\nSentence: Removing a TAD boundary ( for example , using CRISPR to delete the relevant region of the genome ) can allow new promoter-enhancer contacts to form .","prompt_labels":"Removing(O) a(O) TAD(O) boundary(O) ((O) for(O) example(O) ,(O) using(O) CRISPR(O) to(O) delete(O) the(O) relevant(O) region(O) of(O) the(O) genome(O) )(O) can(O) allow(O) new(O) promoter-enhancer(O) contacts(O) to(O) form(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["protein","organization","discipline","astronomical object","scientist","award","university","country","enzyme","chemical element","theory","location","person","event","chemical compound","academic journal"],"instance":{"id":"9","words":["The","1982","Commonwealth","Games","in","Brisbane","left","Tasmania","off","the","map","of","Australia","during","the","opening","ceremony",",","as","did","the","designs","of","the","Australian","Swim","Team","uniform","for","the","2014","Commonwealth","Games","."],"labels":["O","B-event","I-event","I-event","O","B-location","O","B-location","O","O","O","O","B-location","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-event","I-event","I-event","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: protein, organization, discipline, astronomical object, scientist, award, university, country, enzyme, chemical element, theory, location, person, event, chemical compound, academic journal and O.\nSentence: The 1982 Commonwealth Games in Brisbane left Tasmania off the map of Australia during the opening ceremony , as did the designs of the Australian Swim Team uniform for the 2014 Commonwealth Games .","prompt_labels":"The(O) 1982(B-event) Commonwealth(I-event) Games(I-event) in(O) Brisbane(B-location) left(O) Tasmania(B-location) off(O) the(O) map(O) of(O) Australia(B-location) during(O) the(O) opening(O) ceremony(O) ,(O) as(O) did(O) the(O) designs(O) of(O) the(O) Australian(O) Swim(O) Team(O) uniform(O) for(O) the(O) 2014(B-event) Commonwealth(I-event) Games(I-event) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["event","protein","award","location","organization","scientist","astronomical object","country","discipline","chemical element","academic journal","chemical compound","enzyme","theory","person","university"],"instance":{"id":"10","words":["He","is","currently","Director","of","the","Yale","Center","for","the","Study","of","Globalization","at","Yale","University",",","is","the","Latin","American","co-chair","of","the","Inter-American","Dialogue",",","and","is","on","the","board","of","directors","of","Citigroup","."],"labels":["O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","B-university","I-university","O","O","O","O","O","O","O","O","B-organization","I-organization","O","O","O","O","O","O","O","O","O","B-organization","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, protein, award, location, organization, scientist, astronomical object, country, discipline, chemical element, academic journal, chemical compound, enzyme, theory, person, university and O.\nSentence: He is currently Director of the Yale Center for the Study of Globalization at Yale University , is the Latin American co-chair of the Inter-American Dialogue , and is on the board of directors of Citigroup .","prompt_labels":"He(O) is(O) currently(O) Director(O) of(O) the(O) Yale(B-organization) Center(I-organization) for(I-organization) the(I-organization) Study(I-organization) of(I-organization) Globalization(I-organization) at(O) Yale(B-university) University(I-university) ,(O) is(O) the(O) Latin(O) American(O) co-chair(O) of(O) the(O) Inter-American(B-organization) Dialogue(I-organization) ,(O) and(O) is(O) on(O) the(O) board(O) of(O) directors(O) of(O) Citigroup(B-organization) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["award","theory","academic journal","chemical compound","scientist","enzyme","location","organization","country","chemical element","protein","event","astronomical object","person","discipline","university"],"instance":{"id":"11","words":["Saturn","is","usually","depicted","with","a","scythe","or","sickle",",","and","the","planetary","symbol","has","apparently","evolved","from","a","picture","of","this","attribute",",","in","Kamateros","(","12th","century",")","shown","in","a","shape","similar","to","the","letter","eta","",",","with","the","horizontal","stroke","added","along","with","the","Christianization","of","the","other","symbols","in","the","early","16th","century",",","Saturn","(","U","+","2644",")","."],"labels":["B-astronomical object","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-astronomical object","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, theory, academic journal, chemical compound, scientist, enzyme, location, organization, country, chemical element, protein, event, astronomical object, person, discipline, university and O.\nSentence: Saturn is usually depicted with a scythe or sickle , and the planetary symbol has apparently evolved from a picture of this attribute , in Kamateros ( 12th century ) shown in a shape similar to the letter eta  , with the horizontal stroke added along with the Christianization of the other symbols in the early 16th century , Saturn ( U + 2644 ) .","prompt_labels":"Saturn(B-astronomical object) is(O) usually(O) depicted(O) with(O) a(O) scythe(O) or(O) sickle(O) ,(O) and(O) the(O) planetary(O) symbol(O) has(O) apparently(O) evolved(O) from(O) a(O) picture(O) of(O) this(O) attribute(O) ,(O) in(O) Kamateros(O) ((O) 12th(O) century(O) )(O) shown(O) in(O) a(O) shape(O) similar(O) to(O) the(O) letter(O) eta(O) (O) ,(O) with(O) the(O) horizontal(O) stroke(O) added(O) along(O) with(O) the(O) Christianization(O) of(O) the(O) other(O) symbols(O) in(O) the(O) early(O) 16th(O) century(O) ,(O) Saturn(B-astronomical object) ((O) U(O) +(O) 2644(O) )(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["location","award","discipline","chemical element","organization","country","protein","event","scientist","theory","academic journal","person","chemical compound","enzyme","university","astronomical object"],"instance":{"id":"12","words":["The","traditional","precursor","is","N-Nitroso-N-methylurea",",","but","this","compound","is","itself","somewhat","unstable",",","and","nowadays","compounds","such","as","Methylnitronitrosoguanidine","(","MNNG",")","and","Diazald","(","Diazald",")","are","preferred","."],"labels":["O","O","O","O","B-chemical compound","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-chemical compound","O","B-chemical compound","O","O","B-chemical compound","O","B-chemical compound","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, award, discipline, chemical element, organization, country, protein, event, scientist, theory, academic journal, person, chemical compound, enzyme, university, astronomical object and O.\nSentence: The traditional precursor is N-Nitroso-N-methylurea , but this compound is itself somewhat unstable , and nowadays compounds such as Methylnitronitrosoguanidine ( MNNG ) and Diazald ( Diazald ) are preferred .","prompt_labels":"The(O) traditional(O) precursor(O) is(O) N-Nitroso-N-methylurea(B-chemical compound) ,(O) but(O) this(O) compound(O) is(O) itself(O) somewhat(O) unstable(O) ,(O) and(O) nowadays(O) compounds(O) such(O) as(O) Methylnitronitrosoguanidine(B-chemical compound) ((O) MNNG(B-chemical compound) )(O) and(O) Diazald(B-chemical compound) ((O) Diazald(B-chemical compound) )(O) are(O) preferred(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["country","enzyme","scientist","university","chemical compound","award","chemical element","astronomical object","theory","location","protein","discipline","event","academic journal","person","organization"],"instance":{"id":"13","words":["In","addition","to","his","steady","research","output",",","Naqvi","has","manifested","his","commitment","to","teaching","by","contributing","to","journals","devoted","to","didactical","aspects","of","science","(","American","Journal","of","Physics",",","European","Journal","of","Physics",",","Journal","of","Chemical","Education",")","."],"labels":["O","O","O","O","O","O","O","O","B-scientist","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-academic journal","I-academic journal","I-academic journal","I-academic journal","O","B-academic journal","I-academic journal","I-academic journal","I-academic journal","O","B-academic journal","I-academic journal","I-academic journal","I-academic journal","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, enzyme, scientist, university, chemical compound, award, chemical element, astronomical object, theory, location, protein, discipline, event, academic journal, person, organization and O.\nSentence: In addition to his steady research output , Naqvi has manifested his commitment to teaching by contributing to journals devoted to didactical aspects of science ( American Journal of Physics , European Journal of Physics , Journal of Chemical Education ) .","prompt_labels":"In(O) addition(O) to(O) his(O) steady(O) research(O) output(O) ,(O) Naqvi(B-scientist) has(O) manifested(O) his(O) commitment(O) to(O) teaching(O) by(O) contributing(O) to(O) journals(O) devoted(O) to(O) didactical(O) aspects(O) of(O) science(O) ((O) American(B-academic journal) Journal(I-academic journal) of(I-academic journal) Physics(I-academic journal) ,(O) European(B-academic journal) Journal(I-academic journal) of(I-academic journal) Physics(I-academic journal) ,(O) Journal(B-academic journal) of(I-academic journal) Chemical(I-academic journal) Education(I-academic journal) )(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["location","country","event","chemical compound","theory","astronomical object","university","scientist","person","organization","academic journal","discipline","chemical element","award","enzyme","protein"],"instance":{"id":"14","words":["Most","of","the","outer","irregular","moon","s","of","Jupiter","and","Saturn","also","have","retrograde","orbits",",","as","do","some","of","Uranus","'","s","outer","moons","."],"labels":["O","O","O","O","O","O","O","O","B-astronomical object","O","B-astronomical object","O","O","O","O","O","O","O","O","O","B-astronomical object","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, country, event, chemical compound, theory, astronomical object, university, scientist, person, organization, academic journal, discipline, chemical element, award, enzyme, protein and O.\nSentence: Most of the outer irregular moon s of Jupiter and Saturn also have retrograde orbits , as do some of Uranus ' s outer moons .","prompt_labels":"Most(O) of(O) the(O) outer(O) irregular(O) moon(O) s(O) of(O) Jupiter(B-astronomical object) and(O) Saturn(B-astronomical object) also(O) have(O) retrograde(O) orbits(O) ,(O) as(O) do(O) some(O) of(O) Uranus(B-astronomical object) '(O) s(O) outer(O) moons(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["award","event","location","chemical element","academic journal","theory","chemical compound","astronomical object","university","enzyme","person","country","scientist","organization","protein","discipline"],"instance":{"id":"15","words":["For","example",",","that","ancestor","had","at","least","7","Pax","genes","for","transcription","factor","s","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, event, location, chemical element, academic journal, theory, chemical compound, astronomical object, university, enzyme, person, country, scientist, organization, protein, discipline and O.\nSentence: For example , that ancestor had at least 7 Pax genes for transcription factor s .","prompt_labels":"For(O) example(O) ,(O) that(O) ancestor(O) had(O) at(O) least(O) 7(O) Pax(O) genes(O) for(O) transcription(O) factor(O) s(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["astronomical object","award","university","person","chemical compound","protein","scientist","enzyme","discipline","theory","academic journal","location","organization","country","chemical element","event"],"instance":{"id":"16","words":["In","most","cases",",","planets","named","with","Bayer",",","Flamsteed",",","and","or","Variable","star","designation","have","a","space",",","but","usage","with","other","designations","varies","e.g.","WASP-12b","but","HD","209458","b","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-astronomical object","O","B-astronomical object","I-astronomical object","I-astronomical object","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: astronomical object, award, university, person, chemical compound, protein, scientist, enzyme, discipline, theory, academic journal, location, organization, country, chemical element, event and O.\nSentence: In most cases , planets named with Bayer , Flamsteed , and or Variable star designation have a space , but usage with other designations varies e.g. WASP-12b but HD 209458 b .","prompt_labels":"In(O) most(O) cases(O) ,(O) planets(O) named(O) with(O) Bayer(O) ,(O) Flamsteed(O) ,(O) and(O) or(O) Variable(O) star(O) designation(O) have(O) a(O) space(O) ,(O) but(O) usage(O) with(O) other(O) designations(O) varies(O) e.g.(O) WASP-12b(B-astronomical object) but(O) HD(B-astronomical object) 209458(I-astronomical object) b(I-astronomical object) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["theory","country","award","chemical element","event","organization","enzyme","astronomical object","chemical compound","academic journal","location","university","discipline","scientist","person","protein"],"instance":{"id":"17","words":["Schirra","was","a","33rd","Degree","Mason","and","part","of","the","American","Institute","of","Aeronautics","and","Astronautics",",","as","well","as","a","fellow","of","the","American","Astronautical","Society","."],"labels":["B-person","O","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","I-award","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: theory, country, award, chemical element, event, organization, enzyme, astronomical object, chemical compound, academic journal, location, university, discipline, scientist, person, protein and O.\nSentence: Schirra was a 33rd Degree Mason and part of the American Institute of Aeronautics and Astronautics , as well as a fellow of the American Astronautical Society .","prompt_labels":"Schirra(B-person) was(O) a(O) 33rd(O) Degree(O) Mason(O) and(O) part(O) of(O) the(O) American(B-organization) Institute(I-organization) of(I-organization) Aeronautics(I-organization) and(I-organization) Astronautics(I-organization) ,(O) as(O) well(O) as(O) a(O) fellow(B-award) of(I-award) the(I-award) American(I-award) Astronautical(I-award) Society(I-award) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["scientist","academic journal","enzyme","location","chemical element","astronomical object","event","country","university","person","chemical compound","award","discipline","theory","organization","protein"],"instance":{"id":"18","words":["Gerty","Theresa","Cori","(","ne","Radnitz",";","August","15",",","1896","-","October","26",",","1957",")","was","a","Austria-Hungary","-","American","biochemist","who","in","1947","was","the","third","woman","-","and","first","American","woman","-","to","win","a","Nobel","Prize","in","science",",","and","the","first","woman","to","be","awarded","the","Nobel","Prize","in","Physiology","or","Medicine",",","for","her","role","in","the","discovery","of","glycogen","metabolism","."],"labels":["B-scientist","I-scientist","I-scientist","O","B-scientist","I-scientist","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-award","I-award","O","O","O","O","O","O","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","I-award","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: scientist, academic journal, enzyme, location, chemical element, astronomical object, event, country, university, person, chemical compound, award, discipline, theory, organization, protein and O.\nSentence: Gerty Theresa Cori ( ne Radnitz ; August 15 , 1896 - October 26 , 1957 ) was a Austria-Hungary - American biochemist who in 1947 was the third woman - and first American woman - to win a Nobel Prize in science , and the first woman to be awarded the Nobel Prize in Physiology or Medicine , for her role in the discovery of glycogen metabolism .","prompt_labels":"Gerty(B-scientist) Theresa(I-scientist) Cori(I-scientist) ((O) ne(B-scientist) Radnitz(I-scientist) ;(O) August(O) 15(O) ,(O) 1896(O) -(O) October(O) 26(O) ,(O) 1957(O) )(O) was(O) a(O) Austria-Hungary(O) -(O) American(O) biochemist(O) who(O) in(O) 1947(O) was(O) the(O) third(O) woman(O) -(O) and(O) first(O) American(O) woman(O) -(O) to(O) win(O) a(O) Nobel(B-award) Prize(I-award) in(O) science(O) ,(O) and(O) the(O) first(O) woman(O) to(O) be(O) awarded(O) the(O) Nobel(B-award) Prize(I-award) in(I-award) Physiology(I-award) or(I-award) Medicine(I-award) ,(O) for(O) her(O) role(O) in(O) the(O) discovery(O) of(O) glycogen(O) metabolism(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["chemical compound","theory","academic journal","scientist","protein","organization","university","award","chemical element","discipline","country","astronomical object","event","location","person","enzyme"],"instance":{"id":"19","words":["PCH1","reduces","hypocotyl","growth","during","long","nights","by","preferentially","binding","and","stabilizing","the","active","form","of","Phytochrome","(","phyB",")",",","prolonging","its","activity","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: chemical compound, theory, academic journal, scientist, protein, organization, university, award, chemical element, discipline, country, astronomical object, event, location, person, enzyme and O.\nSentence: PCH1 reduces hypocotyl growth during long nights by preferentially binding and stabilizing the active form of Phytochrome ( phyB ) , prolonging its activity .","prompt_labels":"PCH1(O) reduces(O) hypocotyl(O) growth(O) during(O) long(O) nights(O) by(O) preferentially(O) binding(O) and(O) stabilizing(O) the(O) active(O) form(O) of(O) Phytochrome(O) ((O) phyB(O) )(O) ,(O) prolonging(O) its(O) activity(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["scientist","academic journal","chemical element","location","enzyme","protein","organization","theory","astronomical object","award","event","discipline","person","country","university","chemical compound"],"instance":{"id":"20","words":["Generally",",","Potassium","cyanide","or","its","less","toxic","surrogate","Zinc","cyanide","are","used","as","nucleophilic","cyanide","sources","."],"labels":["O","O","B-chemical compound","I-chemical compound","O","O","O","O","O","B-chemical compound","I-chemical compound","O","O","O","B-chemical compound","I-chemical compound","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: scientist, academic journal, chemical element, location, enzyme, protein, organization, theory, astronomical object, award, event, discipline, person, country, university, chemical compound and O.\nSentence: Generally , Potassium cyanide or its less toxic surrogate Zinc cyanide are used as nucleophilic cyanide sources .","prompt_labels":"Generally(O) ,(O) Potassium(B-chemical compound) cyanide(I-chemical compound) or(O) its(O) less(O) toxic(O) surrogate(O) Zinc(B-chemical compound) cyanide(I-chemical compound) are(O) used(O) as(O) nucleophilic(B-chemical compound) cyanide(I-chemical compound) sources(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["protein","university","discipline","astronomical object","enzyme","event","theory","award","scientist","location","person","chemical compound","academic journal","country","chemical element","organization"],"instance":{"id":"21","words":["Somatic","enrichment","for","transversion","mutations","(","G",":","CT",":","A",")","has","been","associated","with","base","excision","repair","(","BER",")","deficiency","and","linked","to","defective","MUTYH",",","a","DNA","glycosylase",",","in","colorectal","cancer","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-enzyme","I-enzyme","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: protein, university, discipline, astronomical object, enzyme, event, theory, award, scientist, location, person, chemical compound, academic journal, country, chemical element, organization and O.\nSentence: Somatic enrichment for transversion mutations ( G : CT : A ) has been associated with base excision repair ( BER ) deficiency and linked to defective MUTYH , a DNA glycosylase , in colorectal cancer .","prompt_labels":"Somatic(O) enrichment(O) for(O) transversion(O) mutations(O) ((O) G(O) :(O) CT(O) :(O) A(O) )(O) has(O) been(O) associated(O) with(O) base(O) excision(O) repair(O) ((O) BER(O) )(O) deficiency(O) and(O) linked(O) to(O) defective(O) MUTYH(O) ,(O) a(O) DNA(B-enzyme) glycosylase(I-enzyme) ,(O) in(O) colorectal(O) cancer(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["protein","person","chemical element","scientist","university","event","chemical compound","organization","discipline","theory","award","enzyme","country","academic journal","astronomical object","location"],"instance":{"id":"22","words":["The","process","is","highly","endergonic","until","it","is","coupled","to","the","hydrolysis","of","Adenosine","triphosphate","or","Guanosine","triphosphate",",","effectively","making","the","process","exergonic","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","B-chemical compound","I-chemical compound","O","B-chemical compound","I-chemical compound","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: protein, person, chemical element, scientist, university, event, chemical compound, organization, discipline, theory, award, enzyme, country, academic journal, astronomical object, location and O.\nSentence: The process is highly endergonic until it is coupled to the hydrolysis of Adenosine triphosphate or Guanosine triphosphate , effectively making the process exergonic .","prompt_labels":"The(O) process(O) is(O) highly(O) endergonic(O) until(O) it(O) is(O) coupled(O) to(O) the(O) hydrolysis(O) of(O) Adenosine(B-chemical compound) triphosphate(I-chemical compound) or(O) Guanosine(B-chemical compound) triphosphate(I-chemical compound) ,(O) effectively(O) making(O) the(O) process(O) exergonic(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["event","academic journal","country","organization","award","theory","person","protein","chemical element","location","university","chemical compound","scientist","enzyme","discipline","astronomical object"],"instance":{"id":"23","words":["Other","notable","German","scientists",",","who","worked","on","the","Soviet","atomic","bomb","project","and","joined","Rexer","at","the","Technische","Hochschule","Dresden","were","Heinz","Pose","and","two","other","physicists",",","Werner","Hartmann","and","Heinz","Barwich",",","who","had","been","at","Gustav","Hertz","'s","Institute","G",",","in","Agudseri","(","Agudzery",")","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-scientist","O","O","B-university","I-university","I-university","O","B-scientist","I-scientist","O","O","O","O","O","B-scientist","I-scientist","O","B-scientist","I-scientist","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","O","B-location","O","B-location","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, academic journal, country, organization, award, theory, person, protein, chemical element, location, university, chemical compound, scientist, enzyme, discipline, astronomical object and O.\nSentence: Other notable German scientists , who worked on the Soviet atomic bomb project and joined Rexer at the Technische Hochschule Dresden were Heinz Pose and two other physicists , Werner Hartmann and Heinz Barwich , who had been at Gustav Hertz 's Institute G , in Agudseri ( Agudzery ) .","prompt_labels":"Other(O) notable(O) German(O) scientists(O) ,(O) who(O) worked(O) on(O) the(O) Soviet(O) atomic(O) bomb(O) project(O) and(O) joined(O) Rexer(B-scientist) at(O) the(O) Technische(B-university) Hochschule(I-university) Dresden(I-university) were(O) Heinz(B-scientist) Pose(I-scientist) and(O) two(O) other(O) physicists(O) ,(O) Werner(B-scientist) Hartmann(I-scientist) and(O) Heinz(B-scientist) Barwich(I-scientist) ,(O) who(O) had(O) been(O) at(O) Gustav(B-organization) Hertz(I-organization) 's(I-organization) Institute(I-organization) G(I-organization) ,(O) in(O) Agudseri(B-location) ((O) Agudzery(B-location) )(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["location","scientist","organization","person","protein","enzyme","discipline","award","chemical compound","university","country","academic journal","theory","event","chemical element","astronomical object"],"instance":{"id":"24","words":["He","received","the","Society","of","Experimental","Test","Pilots","(","SETP",")","James","H.","Doolittle","Award","in","1972","and","the","SETP","Iven","C.","Kincheloe","Award","."],"labels":["O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","B-organization","O","B-award","I-award","I-award","I-award","O","O","O","O","B-organization","B-award","I-award","I-award","I-award","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, scientist, organization, person, protein, enzyme, discipline, award, chemical compound, university, country, academic journal, theory, event, chemical element, astronomical object and O.\nSentence: He received the Society of Experimental Test Pilots ( SETP ) James H. Doolittle Award in 1972 and the SETP Iven C. Kincheloe Award .","prompt_labels":"He(O) received(O) the(O) Society(B-organization) of(I-organization) Experimental(I-organization) Test(I-organization) Pilots(I-organization) ((O) SETP(B-organization) )(O) James(B-award) H.(I-award) Doolittle(I-award) Award(I-award) in(O) 1972(O) and(O) the(O) SETP(B-organization) Iven(B-award) C.(I-award) Kincheloe(I-award) Award(I-award) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["chemical compound","event","award","astronomical object","protein","organization","academic journal","discipline","chemical element","university","scientist","person","enzyme","location","theory","country"],"instance":{"id":"25","words":["Such","mass","wasting","occurs","on","both","terrestrial","and","submarine","slopes",",","and","has","been","observed","on","Earth",",","Mars",",","Venus",",","Titan","and","Iapetus","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-astronomical object","O","B-astronomical object","O","B-astronomical object","O","B-astronomical object","O","B-astronomical object","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: chemical compound, event, award, astronomical object, protein, organization, academic journal, discipline, chemical element, university, scientist, person, enzyme, location, theory, country and O.\nSentence: Such mass wasting occurs on both terrestrial and submarine slopes , and has been observed on Earth , Mars , Venus , Titan and Iapetus .","prompt_labels":"Such(O) mass(O) wasting(O) occurs(O) on(O) both(O) terrestrial(O) and(O) submarine(O) slopes(O) ,(O) and(O) has(O) been(O) observed(O) on(O) Earth(B-astronomical object) ,(O) Mars(B-astronomical object) ,(O) Venus(B-astronomical object) ,(O) Titan(B-astronomical object) and(O) Iapetus(B-astronomical object) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["event","academic journal","protein","astronomical object","award","theory","chemical compound","university","chemical element","discipline","location","country","person","scientist","organization","enzyme"],"instance":{"id":"26","words":["Jingji","has","been","voiced","by","Yukimasa","Kishino",",","Akio","tsuka",",","Jrta","Kosugi",",","and","Kaoru","Kat",";","Yko","by","Tsumugi","sawa",",","Yko","Sait",",","Fumiko","Orikasa",",","Kazue","Nakamoto",",","Seiko","Yoshida",",","and","Mamiko","Noto",";","and","Sanz","by","Fumihiko","Tachiki",",","Kji","Ishii",",","Masaaki","Tsukada",",","and","Naomi","Otome","."],"labels":["B-location","O","O","O","O","B-person","I-person","O","B-person","I-person","O","B-person","I-person","O","O","B-person","I-person","O","B-person","O","B-person","I-person","O","B-person","I-person","O","B-person","I-person","O","B-person","I-person","O","B-person","I-person","O","O","B-person","I-person","O","O","B-person","O","B-person","I-person","O","B-person","I-person","O","B-person","I-person","O","O","B-person","I-person","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, academic journal, protein, astronomical object, award, theory, chemical compound, university, chemical element, discipline, location, country, person, scientist, organization, enzyme and O.\nSentence: Jingji has been voiced by Yukimasa Kishino , Akio tsuka , Jrta Kosugi , and Kaoru Kat ; Yko by Tsumugi sawa , Yko Sait , Fumiko Orikasa , Kazue Nakamoto , Seiko Yoshida , and Mamiko Noto ; and Sanz by Fumihiko Tachiki , Kji Ishii , Masaaki Tsukada , and Naomi Otome .","prompt_labels":"Jingji(B-location) has(O) been(O) voiced(O) by(O) Yukimasa(B-person) Kishino(I-person) ,(O) Akio(B-person) tsuka(I-person) ,(O) Jrta(B-person) Kosugi(I-person) ,(O) and(O) Kaoru(B-person) Kat(I-person) ;(O) Yko(B-person) by(O) Tsumugi(B-person) sawa(I-person) ,(O) Yko(B-person) Sait(I-person) ,(O) Fumiko(B-person) Orikasa(I-person) ,(O) Kazue(B-person) Nakamoto(I-person) ,(O) Seiko(B-person) Yoshida(I-person) ,(O) and(O) Mamiko(B-person) Noto(I-person) ;(O) and(O) Sanz(B-person) by(O) Fumihiko(B-person) Tachiki(I-person) ,(O) Kji(B-person) Ishii(I-person) ,(O) Masaaki(B-person) Tsukada(I-person) ,(O) and(O) Naomi(B-person) Otome(I-person) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["location","academic journal","country","scientist","event","theory","astronomical object","enzyme","organization","person","chemical element","award","chemical compound","protein","university","discipline"],"instance":{"id":"27","words":["He","is","known","for","his","studies","on","DNA","and","RNA","polymerase","s","."],"labels":["O","O","O","O","O","O","O","O","O","B-enzyme","I-enzyme","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, academic journal, country, scientist, event, theory, astronomical object, enzyme, organization, person, chemical element, award, chemical compound, protein, university, discipline and O.\nSentence: He is known for his studies on DNA and RNA polymerase s .","prompt_labels":"He(O) is(O) known(O) for(O) his(O) studies(O) on(O) DNA(O) and(O) RNA(B-enzyme) polymerase(I-enzyme) s(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["chemical element","organization","academic journal","person","theory","event","country","chemical compound","astronomical object","award","scientist","location","protein","discipline","enzyme","university"],"instance":{"id":"28","words":["He","has","served","on","scientific","journal","editorial","boards","including","American","Scientist",",","Physics","of","Fluids",",","Journal","of","Fluid","Mechanics",",","Physical","Review","E",",","Physical","Review","Letters",",","Journal","of","Theoretical","and","Computational","Fluid","Dynamics",","],"labels":["O","O","O","O","O","O","O","O","O","B-academic journal","I-academic journal","O","B-academic journal","I-academic journal","I-academic journal","O","B-academic journal","I-academic journal","I-academic journal","I-academic journal","O","B-academic journal","I-academic journal","I-academic journal","O","B-academic journal","I-academic journal","I-academic journal","O","B-academic journal","I-academic journal","I-academic journal","I-academic journal","I-academic journal","I-academic journal","I-academic journal","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: chemical element, organization, academic journal, person, theory, event, country, chemical compound, astronomical object, award, scientist, location, protein, discipline, enzyme, university and O.\nSentence: He has served on scientific journal editorial boards including American Scientist , Physics of Fluids , Journal of Fluid Mechanics , Physical Review E , Physical Review Letters , Journal of Theoretical and Computational Fluid Dynamics ,","prompt_labels":"He(O) has(O) served(O) on(O) scientific(O) journal(O) editorial(O) boards(O) including(O) American(B-academic journal) Scientist(I-academic journal) ,(O) Physics(B-academic journal) of(I-academic journal) Fluids(I-academic journal) ,(O) Journal(B-academic journal) of(I-academic journal) Fluid(I-academic journal) Mechanics(I-academic journal) ,(O) Physical(B-academic journal) Review(I-academic journal) E(I-academic journal) ,(O) Physical(B-academic journal) Review(I-academic journal) Letters(I-academic journal) ,(O) Journal(B-academic journal) of(I-academic journal) Theoretical(I-academic journal) and(I-academic journal) Computational(I-academic journal) Fluid(I-academic journal) Dynamics(I-academic journal) ,(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["astronomical object","scientist","discipline","chemical compound","location","person","event","country","theory","award","organization","protein","academic journal","university","chemical element","enzyme"],"instance":{"id":"29","words":["This","led","to","a","vigorous","debate","between","the","biometricians",",","who","supported","Galton","'s","ideas",",","as","Walter","Weldon",",","Arthur","Dukinfield","Darbishire","and","Karl","Pearson",",","and","Mendelians",",","who","supported","Bateson","'s","(","and","Mendel","'s",")","ideas",",","such","as","Charles","Davenport","and","Wilhelm","Johannsen","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","B-scientist","O","O","O","O","B-scientist","I-scientist","O","B-scientist","I-scientist","I-scientist","O","B-scientist","I-scientist","O","O","O","O","O","O","B-scientist","O","O","O","B-scientist","O","O","O","O","O","O","B-scientist","I-scientist","O","B-scientist","I-scientist","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: astronomical object, scientist, discipline, chemical compound, location, person, event, country, theory, award, organization, protein, academic journal, university, chemical element, enzyme and O.\nSentence: This led to a vigorous debate between the biometricians , who supported Galton 's ideas , as Walter Weldon , Arthur Dukinfield Darbishire and Karl Pearson , and Mendelians , who supported Bateson 's ( and Mendel 's ) ideas , such as Charles Davenport and Wilhelm Johannsen .","prompt_labels":"This(O) led(O) to(O) a(O) vigorous(O) debate(O) between(O) the(O) biometricians(O) ,(O) who(O) supported(O) Galton(B-scientist) 's(O) ideas(O) ,(O) as(O) Walter(B-scientist) Weldon(I-scientist) ,(O) Arthur(B-scientist) Dukinfield(I-scientist) Darbishire(I-scientist) and(O) Karl(B-scientist) Pearson(I-scientist) ,(O) and(O) Mendelians(O) ,(O) who(O) supported(O) Bateson(B-scientist) 's(O) ((O) and(O) Mendel(B-scientist) 's(O) )(O) ideas(O) ,(O) such(O) as(O) Charles(B-scientist) Davenport(I-scientist) and(O) Wilhelm(B-scientist) Johannsen(I-scientist) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["academic journal","award","university","theory","enzyme","protein","country","person","organization","location","chemical element","chemical compound","scientist","event","astronomical object","discipline"],"instance":{"id":"30","words":["His","Nobel","Prize","is","now","kept","on","display","at","the","International","Red","Cross","and","Red","Crescent","Movement","in","Geneva","."],"labels":["O","B-award","I-award","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","B-location","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: academic journal, award, university, theory, enzyme, protein, country, person, organization, location, chemical element, chemical compound, scientist, event, astronomical object, discipline and O.\nSentence: His Nobel Prize is now kept on display at the International Red Cross and Red Crescent Movement in Geneva .","prompt_labels":"His(O) Nobel(B-award) Prize(I-award) is(O) now(O) kept(O) on(O) display(O) at(O) the(O) International(B-organization) Red(I-organization) Cross(I-organization) and(I-organization) Red(I-organization) Crescent(I-organization) Movement(I-organization) in(O) Geneva(B-location) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["chemical element","astronomical object","theory","event","university","location","academic journal","enzyme","chemical compound","scientist","country","person","award","protein","discipline","organization"],"instance":{"id":"31","words":["Usually",",","in","the","presence","of","NADPH","dehydrogenase","or","NADH","dehydrogenase","as","the","enzyme",",","NADPH","or","NADH","is","the","reductant","that","converts","resazurin","to","resorufin","."],"labels":["O","O","O","O","O","O","B-enzyme","I-enzyme","O","B-enzyme","I-enzyme","O","O","O","O","B-chemical compound","O","B-chemical compound","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: chemical element, astronomical object, theory, event, university, location, academic journal, enzyme, chemical compound, scientist, country, person, award, protein, discipline, organization and O.\nSentence: Usually , in the presence of NADPH dehydrogenase or NADH dehydrogenase as the enzyme , NADPH or NADH is the reductant that converts resazurin to resorufin .","prompt_labels":"Usually(O) ,(O) in(O) the(O) presence(O) of(O) NADPH(B-enzyme) dehydrogenase(I-enzyme) or(O) NADH(B-enzyme) dehydrogenase(I-enzyme) as(O) the(O) enzyme(O) ,(O) NADPH(B-chemical compound) or(O) NADH(B-chemical compound) is(O) the(O) reductant(O) that(O) converts(O) resazurin(O) to(O) resorufin(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["academic journal","chemical compound","discipline","university","scientist","location","enzyme","event","organization","theory","protein","chemical element","astronomical object","country","person","award"],"instance":{"id":"32","words":["The","minor","planet","is","named","after","the","Leakey","'s",",","a","family","of","Kenyan","paleoanthropologist","s",":","Mary","Leakey","(","1913-1996",")",",","her","husband","Louis","Leakey","(","1903-1972",")",",","and","their","son","Richard","Leakey","(","born","1944",")","."],"labels":["O","O","O","O","O","O","O","B-scientist","O","O","O","O","O","B-country","O","O","O","B-scientist","I-scientist","O","O","O","O","O","O","B-scientist","I-scientist","O","O","O","O","O","O","O","B-scientist","I-scientist","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: academic journal, chemical compound, discipline, university, scientist, location, enzyme, event, organization, theory, protein, chemical element, astronomical object, country, person, award and O.\nSentence: The minor planet is named after the Leakey 's , a family of Kenyan paleoanthropologist s : Mary Leakey ( 1913-1996 ) , her husband Louis Leakey ( 1903-1972 ) , and their son Richard Leakey ( born 1944 ) .","prompt_labels":"The(O) minor(O) planet(O) is(O) named(O) after(O) the(O) Leakey(B-scientist) 's(O) ,(O) a(O) family(O) of(O) Kenyan(B-country) paleoanthropologist(O) s(O) :(O) Mary(B-scientist) Leakey(I-scientist) ((O) 1913-1996(O) )(O) ,(O) her(O) husband(O) Louis(B-scientist) Leakey(I-scientist) ((O) 1903-1972(O) )(O) ,(O) and(O) their(O) son(O) Richard(B-scientist) Leakey(I-scientist) ((O) born(O) 1944(O) )(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["academic journal","theory","scientist","award","country","chemical compound","discipline","event","university","person","location","astronomical object","enzyme","organization","protein","chemical element"],"instance":{"id":"33","words":["In","1880",",","Hall","'s","experimentation","was","published","as","a","doctoral","thesis","in","the","American","Journal","of","Science","and","in","the","Philosophical","Magazine","."],"labels":["O","O","O","B-person","O","O","O","O","O","O","O","O","O","O","B-academic journal","I-academic journal","I-academic journal","I-academic journal","O","O","O","B-academic journal","I-academic journal","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: academic journal, theory, scientist, award, country, chemical compound, discipline, event, university, person, location, astronomical object, enzyme, organization, protein, chemical element and O.\nSentence: In 1880 , Hall 's experimentation was published as a doctoral thesis in the American Journal of Science and in the Philosophical Magazine .","prompt_labels":"In(O) 1880(O) ,(O) Hall(B-person) 's(O) experimentation(O) was(O) published(O) as(O) a(O) doctoral(O) thesis(O) in(O) the(O) American(B-academic journal) Journal(I-academic journal) of(I-academic journal) Science(I-academic journal) and(O) in(O) the(O) Philosophical(B-academic journal) Magazine(I-academic journal) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["location","award","enzyme","academic journal","astronomical object","theory","person","protein","scientist","organization","chemical element","country","event","university","discipline","chemical compound"],"instance":{"id":"34","words":["Helicase","s","unwind","the","strands","to","facilitate","the","advance","of","sequence-reading","enzymes","such","as","DNA","polymerase","."],"labels":["B-enzyme","O","O","O","O","O","O","O","O","O","O","O","O","O","B-enzyme","I-enzyme","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, award, enzyme, academic journal, astronomical object, theory, person, protein, scientist, organization, chemical element, country, event, university, discipline, chemical compound and O.\nSentence: Helicase s unwind the strands to facilitate the advance of sequence-reading enzymes such as DNA polymerase .","prompt_labels":"Helicase(B-enzyme) s(O) unwind(O) the(O) strands(O) to(O) facilitate(O) the(O) advance(O) of(O) sequence-reading(O) enzymes(O) such(O) as(O) DNA(B-enzyme) polymerase(I-enzyme) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["university","scientist","theory","chemical element","chemical compound","event","academic journal","astronomical object","location","award","country","enzyme","discipline","person","organization","protein"],"instance":{"id":"35","words":["The","album","was","nominated","at","the","41st","Annual","Grammy","Awards","for","Grammy","Award","for","Best","Rap","Album","."],"labels":["O","O","O","O","O","O","B-award","I-award","I-award","I-award","O","B-award","I-award","I-award","I-award","I-award","I-award","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: university, scientist, theory, chemical element, chemical compound, event, academic journal, astronomical object, location, award, country, enzyme, discipline, person, organization, protein and O.\nSentence: The album was nominated at the 41st Annual Grammy Awards for Grammy Award for Best Rap Album .","prompt_labels":"The(O) album(O) was(O) nominated(O) at(O) the(O) 41st(B-award) Annual(I-award) Grammy(I-award) Awards(I-award) for(O) Grammy(B-award) Award(I-award) for(I-award) Best(I-award) Rap(I-award) Album(I-award) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["award","astronomical object","chemical element","person","protein","theory","discipline","chemical compound","location","enzyme","country","organization","university","event","academic journal","scientist"],"instance":{"id":"36","words":["Lincoln","looks","much","as","it","did","during","the","Lincoln","County","War","(","1878-1881",")","when","its","single","street","was","peopled","with","characters","like","Billy","the","Kid",",","John","Chisum","and","Lawrence","Murphy","."],"labels":["B-person","O","O","O","O","O","O","O","B-event","I-event","I-event","O","O","O","O","O","O","O","O","O","O","O","O","B-person","I-person","I-person","O","B-person","I-person","O","B-person","I-person","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, astronomical object, chemical element, person, protein, theory, discipline, chemical compound, location, enzyme, country, organization, university, event, academic journal, scientist and O.\nSentence: Lincoln looks much as it did during the Lincoln County War ( 1878-1881 ) when its single street was peopled with characters like Billy the Kid , John Chisum and Lawrence Murphy .","prompt_labels":"Lincoln(B-person) looks(O) much(O) as(O) it(O) did(O) during(O) the(O) Lincoln(B-event) County(I-event) War(I-event) ((O) 1878-1881(O) )(O) when(O) its(O) single(O) street(O) was(O) peopled(O) with(O) characters(O) like(O) Billy(B-person) the(I-person) Kid(I-person) ,(O) John(B-person) Chisum(I-person) and(O) Lawrence(B-person) Murphy(I-person) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["astronomical object","location","academic journal","organization","person","enzyme","scientist","theory","country","protein","discipline","chemical compound","award","chemical element","university","event"],"instance":{"id":"37","words":["British","observers","allegedly","exclaimed",",","Maxwell","should","have","seen","this","!","Of","the","eleven","diplmes","d","'honneur",",","seven","went","to","non-French","exhibitors",",","including","Werner","Siemens",",","Thomas","Edison",",","Alexander","Graham","Bell","and","William","Thomson","."],"labels":["O","O","O","O","O","B-person","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-scientist","I-scientist","O","B-scientist","I-scientist","O","B-scientist","I-scientist","I-scientist","O","B-scientist","I-scientist","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: astronomical object, location, academic journal, organization, person, enzyme, scientist, theory, country, protein, discipline, chemical compound, award, chemical element, university, event and O.\nSentence: British observers allegedly exclaimed , Maxwell should have seen this ! Of the eleven diplmes d 'honneur , seven went to non-French exhibitors , including Werner Siemens , Thomas Edison , Alexander Graham Bell and William Thomson .","prompt_labels":"British(O) observers(O) allegedly(O) exclaimed(O) ,(O) Maxwell(B-person) should(O) have(O) seen(O) this(O) !(O) Of(O) the(O) eleven(O) diplmes(O) d(O) 'honneur(O) ,(O) seven(O) went(O) to(O) non-French(O) exhibitors(O) ,(O) including(O) Werner(B-scientist) Siemens(I-scientist) ,(O) Thomas(B-scientist) Edison(I-scientist) ,(O) Alexander(B-scientist) Graham(I-scientist) Bell(I-scientist) and(O) William(B-scientist) Thomson(I-scientist) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["academic journal","location","country","organization","scientist","enzyme","protein","university","event","chemical compound","discipline","award","chemical element","theory","astronomical object","person"],"instance":{"id":"38","words":["One","aspect",",","the","idea","of","modelling","atomic","behaviour","under","incident","electromagnetic","radiation","using","virtual","oscillators","at","the","absorption","and","emission","frequencies",",","rather","than","the","(","different",")","apparent","frequencies","of","the","Bohr","orbits",",","significantly","led","Max","Born",",","Werner","Heisenberg","and","Kramers","to","explore","mathematics","that","strongly","inspired","the","subsequent","development","of","matrix","mechanics",",","the","first","form","of","modern","quantum","mechanics","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-theory","I-theory","O","O","O","B-scientist","I-scientist","O","B-scientist","I-scientist","O","B-scientist","O","O","B-discipline","O","O","O","O","O","O","O","B-discipline","I-discipline","O","O","O","O","O","O","B-discipline","I-discipline","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: academic journal, location, country, organization, scientist, enzyme, protein, university, event, chemical compound, discipline, award, chemical element, theory, astronomical object, person and O.\nSentence: One aspect , the idea of modelling atomic behaviour under incident electromagnetic radiation using virtual oscillators at the absorption and emission frequencies , rather than the ( different ) apparent frequencies of the Bohr orbits , significantly led Max Born , Werner Heisenberg and Kramers to explore mathematics that strongly inspired the subsequent development of matrix mechanics , the first form of modern quantum mechanics .","prompt_labels":"One(O) aspect(O) ,(O) the(O) idea(O) of(O) modelling(O) atomic(O) behaviour(O) under(O) incident(O) electromagnetic(O) radiation(O) using(O) virtual(O) oscillators(O) at(O) the(O) absorption(O) and(O) emission(O) frequencies(O) ,(O) rather(O) than(O) the(O) ((O) different(O) )(O) apparent(O) frequencies(O) of(O) the(O) Bohr(B-theory) orbits(I-theory) ,(O) significantly(O) led(O) Max(B-scientist) Born(I-scientist) ,(O) Werner(B-scientist) Heisenberg(I-scientist) and(O) Kramers(B-scientist) to(O) explore(O) mathematics(B-discipline) that(O) strongly(O) inspired(O) the(O) subsequent(O) development(O) of(O) matrix(B-discipline) mechanics(I-discipline) ,(O) the(O) first(O) form(O) of(O) modern(O) quantum(B-discipline) mechanics(I-discipline) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["protein","person","location","enzyme","country","chemical element","theory","astronomical object","scientist","organization","event","chemical compound","academic journal","university","award","discipline"],"instance":{"id":"39","words":["The","team","that","she","manages","has","specially","studied","the","role","of","Proinsulin","\/","insulin","in","the","development","of","the","central","nervous","system","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","B-protein","O","B-protein","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: protein, person, location, enzyme, country, chemical element, theory, astronomical object, scientist, organization, event, chemical compound, academic journal, university, award, discipline and O.\nSentence: The team that she manages has specially studied the role of Proinsulin \/ insulin in the development of the central nervous system .","prompt_labels":"The(O) team(O) that(O) she(O) manages(O) has(O) specially(O) studied(O) the(O) role(O) of(O) Proinsulin(B-protein) \/(O) insulin(B-protein) in(O) the(O) development(O) of(O) the(O) central(O) nervous(O) system(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["award","scientist","person","chemical element","organization","academic journal","theory","location","discipline","chemical compound","country","event","protein","university","enzyme","astronomical object"],"instance":{"id":"40","words":["Nitric","oxide","reacts","with","the","hydroperoxy","radical","(","HOsub2","\/","subsup","","\/","sup",")","to","form","nitrogen","dioxide","(","NOsub2","\/","sub",")",",","which","then","can","react","with","a","hydroxyl","radical","(","sup","Hydroxyl","radical","\/","sup","Hydroxyl","radical",")","to","produce","nitric","acid","(","HNOsub3","\/","sub",")",":"],"labels":["B-chemical compound","I-chemical compound","O","O","O","B-chemical compound","I-chemical compound","O","B-chemical compound","I-chemical compound","I-chemical compound","I-chemical compound","I-chemical compound","I-chemical compound","O","O","O","B-chemical compound","I-chemical compound","O","B-chemical compound","I-chemical compound","I-chemical compound","O","O","O","O","O","O","O","O","B-chemical compound","I-chemical compound","O","B-chemical compound","I-chemical compound","I-chemical compound","O","B-chemical compound","I-chemical compound","I-chemical compound","O","O","O","B-chemical compound","I-chemical compound","O","B-chemical compound","I-chemical compound","I-chemical compound","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, scientist, person, chemical element, organization, academic journal, theory, location, discipline, chemical compound, country, event, protein, university, enzyme, astronomical object and O.\nSentence: Nitric oxide reacts with the hydroperoxy radical ( HOsub2 \/ subsup  \/ sup ) to form nitrogen dioxide ( NOsub2 \/ sub ) , which then can react with a hydroxyl radical ( sup Hydroxyl radical \/ sup Hydroxyl radical ) to produce nitric acid ( HNOsub3 \/ sub ) :","prompt_labels":"Nitric(B-chemical compound) oxide(I-chemical compound) reacts(O) with(O) the(O) hydroperoxy(B-chemical compound) radical(I-chemical compound) ((O) HOsub2(B-chemical compound) \/(I-chemical compound) subsup(I-chemical compound) (I-chemical compound) \/(I-chemical compound) sup(I-chemical compound) )(O) to(O) form(O) nitrogen(B-chemical compound) dioxide(I-chemical compound) ((O) NOsub2(B-chemical compound) \/(I-chemical compound) sub(I-chemical compound) )(O) ,(O) which(O) then(O) can(O) react(O) with(O) a(O) hydroxyl(B-chemical compound) radical(I-chemical compound) ((O) sup(B-chemical compound) Hydroxyl(I-chemical compound) radical(I-chemical compound) \/(O) sup(B-chemical compound) Hydroxyl(I-chemical compound) radical(I-chemical compound) )(O) to(O) produce(O) nitric(B-chemical compound) acid(I-chemical compound) ((O) HNOsub3(B-chemical compound) \/(I-chemical compound) sub(I-chemical compound) )(O) :(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["chemical compound","theory","person","astronomical object","award","event","organization","protein","location","country","academic journal","enzyme","discipline","scientist","university","chemical element"],"instance":{"id":"41","words":["Hamilton","was","a","visiting","professor","at","Harvard","University","and","later","spent","nine","months","with","the","Royal","Society","'","s","and","the","Royal","Geographical","Society","'","s","Xavantina-Cachimbo","Expedition","as","a","visiting","professor","at","the","University","of","So","Paulo","."],"labels":["B-person","O","O","O","O","O","B-university","I-university","O","O","O","O","O","O","O","B-organization","I-organization","O","O","O","O","B-organization","I-organization","I-organization","O","O","O","O","O","O","O","O","O","O","B-university","I-university","I-university","I-university","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: chemical compound, theory, person, astronomical object, award, event, organization, protein, location, country, academic journal, enzyme, discipline, scientist, university, chemical element and O.\nSentence: Hamilton was a visiting professor at Harvard University and later spent nine months with the Royal Society ' s and the Royal Geographical Society ' s Xavantina-Cachimbo Expedition as a visiting professor at the University of So Paulo .","prompt_labels":"Hamilton(B-person) was(O) a(O) visiting(O) professor(O) at(O) Harvard(B-university) University(I-university) and(O) later(O) spent(O) nine(O) months(O) with(O) the(O) Royal(B-organization) Society(I-organization) '(O) s(O) and(O) the(O) Royal(B-organization) Geographical(I-organization) Society(I-organization) '(O) s(O) Xavantina-Cachimbo(O) Expedition(O) as(O) a(O) visiting(O) professor(O) at(O) the(O) University(B-university) of(I-university) So(I-university) Paulo(I-university) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["astronomical object","country","award","event","chemical element","theory","academic journal","discipline","enzyme","location","university","protein","scientist","organization","person","chemical compound"],"instance":{"id":"42","words":["Michelson","was","a","member","of","the","Royal","Society",",","the","National","Academy","of","Sciences",",","the","American","Physical","Society","and","the","American","Association","for","the","Advancement","of","Science","."],"labels":["B-scientist","O","O","O","O","O","B-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: astronomical object, country, award, event, chemical element, theory, academic journal, discipline, enzyme, location, university, protein, scientist, organization, person, chemical compound and O.\nSentence: Michelson was a member of the Royal Society , the National Academy of Sciences , the American Physical Society and the American Association for the Advancement of Science .","prompt_labels":"Michelson(B-scientist) was(O) a(O) member(O) of(O) the(O) Royal(B-organization) Society(I-organization) ,(O) the(O) National(B-organization) Academy(I-organization) of(I-organization) Sciences(I-organization) ,(O) the(O) American(B-organization) Physical(I-organization) Society(I-organization) and(O) the(O) American(B-organization) Association(I-organization) for(I-organization) the(I-organization) Advancement(I-organization) of(I-organization) Science(I-organization) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["chemical element","person","event","discipline","organization","chemical compound","scientist","academic journal","award","theory","astronomical object","enzyme","country","university","protein","location"],"instance":{"id":"43","words":["Heartstone","has","also","been","a","part","of","a","number","of","esport","demonstration","event","s","at","international","competitions",",","such","as","the","2017","Asian","Indoor","and","Martial","Arts","Games","and","2018","Asian","Games","."],"labels":["B-event","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-event","I-event","I-event","I-event","I-event","I-event","I-event","O","B-event","I-event","I-event","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: chemical element, person, event, discipline, organization, chemical compound, scientist, academic journal, award, theory, astronomical object, enzyme, country, university, protein, location and O.\nSentence: Heartstone has also been a part of a number of esport demonstration event s at international competitions , such as the 2017 Asian Indoor and Martial Arts Games and 2018 Asian Games .","prompt_labels":"Heartstone(B-event) has(O) also(O) been(O) a(O) part(O) of(O) a(O) number(O) of(O) esport(O) demonstration(O) event(O) s(O) at(O) international(O) competitions(O) ,(O) such(O) as(O) the(O) 2017(B-event) Asian(I-event) Indoor(I-event) and(I-event) Martial(I-event) Arts(I-event) Games(I-event) and(O) 2018(B-event) Asian(I-event) Games(I-event) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["university","scientist","theory","award","organization","chemical element","protein","country","location","astronomical object","chemical compound","event","enzyme","person","academic journal","discipline"],"instance":{"id":"44","words":["When","a","gene","is","expressed",",","its","DNA","sequence","is","copied","into","a","primary","RNA","sequence","by","the","enzyme","RNA","polymerase","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-enzyme","I-enzyme","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: university, scientist, theory, award, organization, chemical element, protein, country, location, astronomical object, chemical compound, event, enzyme, person, academic journal, discipline and O.\nSentence: When a gene is expressed , its DNA sequence is copied into a primary RNA sequence by the enzyme RNA polymerase .","prompt_labels":"When(O) a(O) gene(O) is(O) expressed(O) ,(O) its(O) DNA(O) sequence(O) is(O) copied(O) into(O) a(O) primary(O) RNA(O) sequence(O) by(O) the(O) enzyme(O) RNA(B-enzyme) polymerase(I-enzyme) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["location","astronomical object","country","chemical element","organization","protein","university","person","theory","discipline","chemical compound","enzyme","event","award","scientist","academic journal"],"instance":{"id":"45","words":["The","Asian","Football","Confederation",",","Oceania","Football","Confederation","and","CONCACAF","(","the","governing","body","of","football","in","North","and","Central","America","and","the","Caribbean",")","use","blue","text","on","their","logos","."],"labels":["O","B-organization","I-organization","I-organization","O","B-organization","I-organization","I-organization","O","B-organization","O","O","O","O","O","O","O","O","O","O","B-country","O","O","B-location","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, astronomical object, country, chemical element, organization, protein, university, person, theory, discipline, chemical compound, enzyme, event, award, scientist, academic journal and O.\nSentence: The Asian Football Confederation , Oceania Football Confederation and CONCACAF ( the governing body of football in North and Central America and the Caribbean ) use blue text on their logos .","prompt_labels":"The(O) Asian(B-organization) Football(I-organization) Confederation(I-organization) ,(O) Oceania(B-organization) Football(I-organization) Confederation(I-organization) and(O) CONCACAF(B-organization) ((O) the(O) governing(O) body(O) of(O) football(O) in(O) North(O) and(O) Central(O) America(B-country) and(O) the(O) Caribbean(B-location) )(O) use(O) blue(O) text(O) on(O) their(O) logos(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["event","country","astronomical object","person","enzyme","protein","discipline","academic journal","organization","chemical element","theory","chemical compound","university","location","scientist","award"],"instance":{"id":"46","words":["She","competed","in","the","4","","100","metres","relay","event","at","the","2015","World","Championships","in","Athletics","in","Beijing",",","China","."],"labels":["O","O","O","O","B-event","I-event","I-event","I-event","I-event","I-event","O","O","B-event","I-event","I-event","O","O","O","B-location","O","B-country","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, country, astronomical object, person, enzyme, protein, discipline, academic journal, organization, chemical element, theory, chemical compound, university, location, scientist, award and O.\nSentence: She competed in the 4  100 metres relay event at the 2015 World Championships in Athletics in Beijing , China .","prompt_labels":"She(O) competed(O) in(O) the(O) 4(B-event) (I-event) 100(I-event) metres(I-event) relay(I-event) event(I-event) at(O) the(O) 2015(B-event) World(I-event) Championships(I-event) in(O) Athletics(O) in(O) Beijing(B-location) ,(O) China(B-country) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["scientist","academic journal","theory","chemical element","country","person","protein","location","discipline","organization","enzyme","chemical compound","award","astronomical object","event","university"],"instance":{"id":"47","words":["Tremaine",",","along","with","Peter","Goldreich",",","correctly","predicted","that","shepherd","moon","s","created","Saturn","'","s","thin","F","ring",",","as","well","as","the","thin","rings","of","Uranus","in","1979","."],"labels":["O","O","O","O","B-scientist","I-scientist","O","O","O","O","B-astronomical object","I-astronomical object","O","O","B-astronomical object","O","O","O","O","O","O","O","O","O","O","O","O","O","B-astronomical object","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: scientist, academic journal, theory, chemical element, country, person, protein, location, discipline, organization, enzyme, chemical compound, award, astronomical object, event, university and O.\nSentence: Tremaine , along with Peter Goldreich , correctly predicted that shepherd moon s created Saturn ' s thin F ring , as well as the thin rings of Uranus in 1979 .","prompt_labels":"Tremaine(O) ,(O) along(O) with(O) Peter(B-scientist) Goldreich(I-scientist) ,(O) correctly(O) predicted(O) that(O) shepherd(B-astronomical object) moon(I-astronomical object) s(O) created(O) Saturn(B-astronomical object) '(O) s(O) thin(O) F(O) ring(O) ,(O) as(O) well(O) as(O) the(O) thin(O) rings(O) of(O) Uranus(B-astronomical object) in(O) 1979(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["enzyme","academic journal","scientist","person","theory","organization","location","university","chemical compound","award","event","country","astronomical object","chemical element","protein","discipline"],"instance":{"id":"48","words":["John","Hopkinson",",","FRS",",","(","27","July","1849","-","27","August","1898",")","was","a","United","Kingdom","physicist",",","electrical","engineer",",","Fellow","of","the","Royal","Society","and","President","of","the","Institution","of","Electrical","Engineers","twice","in","1890","and","1896","."],"labels":["B-scientist","I-scientist","O","B-award","O","O","O","O","O","O","O","O","O","O","O","O","B-country","I-country","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: enzyme, academic journal, scientist, person, theory, organization, location, university, chemical compound, award, event, country, astronomical object, chemical element, protein, discipline and O.\nSentence: John Hopkinson , FRS , ( 27 July 1849 - 27 August 1898 ) was a United Kingdom physicist , electrical engineer , Fellow of the Royal Society and President of the Institution of Electrical Engineers twice in 1890 and 1896 .","prompt_labels":"John(B-scientist) Hopkinson(I-scientist) ,(O) FRS(B-award) ,(O) ((O) 27(O) July(O) 1849(O) -(O) 27(O) August(O) 1898(O) )(O) was(O) a(O) United(B-country) Kingdom(I-country) physicist(O) ,(O) electrical(O) engineer(O) ,(O) Fellow(B-award) of(I-award) the(I-award) Royal(I-award) Society(I-award) and(O) President(O) of(O) the(O) Institution(B-organization) of(I-organization) Electrical(I-organization) Engineers(I-organization) twice(O) in(O) 1890(O) and(O) 1896(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["academic journal","location","event","award","chemical element","astronomical object","organization","person","chemical compound","discipline","enzyme","university","scientist","theory","protein","country"],"instance":{"id":"49","words":["He","also","received","the","Rumford","Medal","of","the","British","Royal","Society","in","1896",",","jointly","with","Philipp","Lenard",",","who","had","already","shown","that","a","portion","of","the","cathode","rays","could","pass","through","a","thin","film","of","a","metal","such","as","aluminum","."],"labels":["O","O","O","O","B-award","I-award","I-award","I-award","I-award","I-award","I-award","O","O","O","O","O","B-scientist","I-scientist","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-chemical element","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: academic journal, location, event, award, chemical element, astronomical object, organization, person, chemical compound, discipline, enzyme, university, scientist, theory, protein, country and O.\nSentence: He also received the Rumford Medal of the British Royal Society in 1896 , jointly with Philipp Lenard , who had already shown that a portion of the cathode rays could pass through a thin film of a metal such as aluminum .","prompt_labels":"He(O) also(O) received(O) the(O) Rumford(B-award) Medal(I-award) of(I-award) the(I-award) British(I-award) Royal(I-award) Society(I-award) in(O) 1896(O) ,(O) jointly(O) with(O) Philipp(B-scientist) Lenard(I-scientist) ,(O) who(O) had(O) already(O) shown(O) that(O) a(O) portion(O) of(O) the(O) cathode(O) rays(O) could(O) pass(O) through(O) a(O) thin(O) film(O) of(O) a(O) metal(O) such(O) as(O) aluminum(B-chemical element) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["protein","university","academic journal","discipline","enzyme","award","chemical element","location","person","chemical compound","event","theory","astronomical object","country","organization","scientist"],"instance":{"id":"50","words":["He","then","worked","at","the","Theoretical","Physics","Institute","of","the","University","of","Copenhagen","from","1928","to","1931",",","with","a","break","to","work","with","Ernest","Rutherford","at","the","Cavendish","Laboratory","in","Cambridge","."],"labels":["O","O","O","O","O","B-organization","I-organization","I-organization","O","O","B-university","I-university","I-university","O","O","O","O","O","O","O","O","O","O","O","B-scientist","I-scientist","O","O","B-organization","I-organization","O","B-university","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: protein, university, academic journal, discipline, enzyme, award, chemical element, location, person, chemical compound, event, theory, astronomical object, country, organization, scientist and O.\nSentence: He then worked at the Theoretical Physics Institute of the University of Copenhagen from 1928 to 1931 , with a break to work with Ernest Rutherford at the Cavendish Laboratory in Cambridge .","prompt_labels":"He(O) then(O) worked(O) at(O) the(O) Theoretical(B-organization) Physics(I-organization) Institute(I-organization) of(O) the(O) University(B-university) of(I-university) Copenhagen(I-university) from(O) 1928(O) to(O) 1931(O) ,(O) with(O) a(O) break(O) to(O) work(O) with(O) Ernest(B-scientist) Rutherford(I-scientist) at(O) the(O) Cavendish(B-organization) Laboratory(I-organization) in(O) Cambridge(B-university) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["theory","discipline","chemical compound","event","country","chemical element","award","protein","person","scientist","university","location","enzyme","academic journal","astronomical object","organization"],"instance":{"id":"51","words":["Genes","related","to","the","proximal","area","are","HFE2",",","TXNIP",",","POLR3GL",",","LIX1L",",","RBM8A",",","PEX11B",",","ITGA10",",","ANKRD35",",","PIAS3",",","NUDT17",",","POLR3C",",","RNF115",",","CD160",",","PDZK1",",","and","GPR89A","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: theory, discipline, chemical compound, event, country, chemical element, award, protein, person, scientist, university, location, enzyme, academic journal, astronomical object, organization and O.\nSentence: Genes related to the proximal area are HFE2 , TXNIP , POLR3GL , LIX1L , RBM8A , PEX11B , ITGA10 , ANKRD35 , PIAS3 , NUDT17 , POLR3C , RNF115 , CD160 , PDZK1 , and GPR89A .","prompt_labels":"Genes(O) related(O) to(O) the(O) proximal(O) area(O) are(O) HFE2(O) ,(O) TXNIP(O) ,(O) POLR3GL(O) ,(O) LIX1L(O) ,(O) RBM8A(O) ,(O) PEX11B(O) ,(O) ITGA10(O) ,(O) ANKRD35(O) ,(O) PIAS3(O) ,(O) NUDT17(O) ,(O) POLR3C(O) ,(O) RNF115(O) ,(O) CD160(O) ,(O) PDZK1(O) ,(O) and(O) GPR89A(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["country","theory","enzyme","protein","astronomical object","chemical compound","discipline","event","university","scientist","award","person","location","organization","chemical element","academic journal"],"instance":{"id":"52","words":["From","1884","to","1888","he","studied","at","the","universities","of","Humboldt","University","of","Berlin","and","University","of","Strasbourg",",","after","which","he","became","an","assistant","at","the","Academy","of","Mnster","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-university","I-university","I-university","I-university","O","B-university","I-university","I-university","O","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, theory, enzyme, protein, astronomical object, chemical compound, discipline, event, university, scientist, award, person, location, organization, chemical element, academic journal and O.\nSentence: From 1884 to 1888 he studied at the universities of Humboldt University of Berlin and University of Strasbourg , after which he became an assistant at the Academy of Mnster .","prompt_labels":"From(O) 1884(O) to(O) 1888(O) he(O) studied(O) at(O) the(O) universities(O) of(O) Humboldt(B-university) University(I-university) of(I-university) Berlin(I-university) and(O) University(B-university) of(I-university) Strasbourg(I-university) ,(O) after(O) which(O) he(O) became(O) an(O) assistant(O) at(O) the(O) Academy(B-organization) of(I-organization) Mnster(I-organization) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["award","academic journal","person","scientist","discipline","chemical compound","astronomical object","enzyme","theory","country","protein","organization","university","event","location","chemical element"],"instance":{"id":"53","words":["The","effect","was","first","predicted","as","the","diffraction","of","electrons","from","a","standing","wave","of","light","by","Paul","Dirac","and","Pyotr","Kapitsa","(","or","Peter","Kapitza",")","in","1933","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-scientist","I-scientist","O","B-scientist","I-scientist","O","O","B-scientist","I-scientist","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, academic journal, person, scientist, discipline, chemical compound, astronomical object, enzyme, theory, country, protein, organization, university, event, location, chemical element and O.\nSentence: The effect was first predicted as the diffraction of electrons from a standing wave of light by Paul Dirac and Pyotr Kapitsa ( or Peter Kapitza ) in 1933 .","prompt_labels":"The(O) effect(O) was(O) first(O) predicted(O) as(O) the(O) diffraction(O) of(O) electrons(O) from(O) a(O) standing(O) wave(O) of(O) light(O) by(O) Paul(B-scientist) Dirac(I-scientist) and(O) Pyotr(B-scientist) Kapitsa(I-scientist) ((O) or(O) Peter(B-scientist) Kapitza(I-scientist) )(O) in(O) 1933(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["discipline","country","enzyme","award","university","academic journal","person","protein","theory","location","organization","astronomical object","scientist","chemical element","chemical compound","event"],"instance":{"id":"54","words":["In","August","2017","a","group","of","scientists","from","Oregon","published","an","article","in","Nature","journal","detailing","the","successful","use","of","CRISPR","to","edit","out","a","mutation","responsible","for","congenital","heart","disease","."],"labels":["O","O","O","O","O","O","O","O","B-location","O","O","O","O","B-academic journal","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: discipline, country, enzyme, award, university, academic journal, person, protein, theory, location, organization, astronomical object, scientist, chemical element, chemical compound, event and O.\nSentence: In August 2017 a group of scientists from Oregon published an article in Nature journal detailing the successful use of CRISPR to edit out a mutation responsible for congenital heart disease .","prompt_labels":"In(O) August(O) 2017(O) a(O) group(O) of(O) scientists(O) from(O) Oregon(B-location) published(O) an(O) article(O) in(O) Nature(B-academic journal) journal(O) detailing(O) the(O) successful(O) use(O) of(O) CRISPR(O) to(O) edit(O) out(O) a(O) mutation(O) responsible(O) for(O) congenital(O) heart(O) disease(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["discipline","enzyme","organization","chemical compound","chemical element","university","academic journal","country","scientist","person","award","location","protein","theory","event","astronomical object"],"instance":{"id":"55","words":["Not","only","were","these","initiators","the","first","to","achieve","relatively","high","molecular","weight","poly","(","1-alkenes",")","(","currently","the","most","widely","produced","thermoplastic","in","the","world","PE","(","Polyethylene",")","and","PP","(","Polypropylene",")"],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-chemical compound","O","O","O","O","O","O","O","O","O","O","O","B-chemical compound","O","B-chemical compound","O","O","B-chemical compound","O","B-chemical compound","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: discipline, enzyme, organization, chemical compound, chemical element, university, academic journal, country, scientist, person, award, location, protein, theory, event, astronomical object and O.\nSentence: Not only were these initiators the first to achieve relatively high molecular weight poly ( 1-alkenes ) ( currently the most widely produced thermoplastic in the world PE ( Polyethylene ) and PP ( Polypropylene )","prompt_labels":"Not(O) only(O) were(O) these(O) initiators(O) the(O) first(O) to(O) achieve(O) relatively(O) high(O) molecular(O) weight(O) poly(O) ((O) 1-alkenes(B-chemical compound) )(O) ((O) currently(O) the(O) most(O) widely(O) produced(O) thermoplastic(O) in(O) the(O) world(O) PE(B-chemical compound) ((O) Polyethylene(B-chemical compound) )(O) and(O) PP(B-chemical compound) ((O) Polypropylene(B-chemical compound) )(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["country","award","university","enzyme","chemical element","academic journal","organization","event","theory","chemical compound","location","discipline","protein","astronomical object","person","scientist"],"instance":{"id":"56","words":["UCSI","University",",","Sarawak","Campus",",","University","College","of","Technology","Sarawak","(","UCTS",")","Tunku","Abdul","Rahman","University","College","(","Sabah","campus",")",",","International","University","College","Of","Technology","Twintech","(","Sabah","campus",")",",","and","Open","University","Malaysia","(","Sabah","campus",")","have","local","private","university","branch","campuses","in","East","Malaysia","."],"labels":["B-university","I-university","I-university","I-university","I-university","O","B-university","I-university","I-university","I-university","I-university","O","B-university","O","B-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","O","B-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","O","O","B-university","I-university","I-university","I-university","I-university","I-university","I-university","O","O","O","O","O","O","O","B-location","I-location","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, award, university, enzyme, chemical element, academic journal, organization, event, theory, chemical compound, location, discipline, protein, astronomical object, person, scientist and O.\nSentence: UCSI University , Sarawak Campus , University College of Technology Sarawak ( UCTS ) Tunku Abdul Rahman University College ( Sabah campus ) , International University College Of Technology Twintech ( Sabah campus ) , and Open University Malaysia ( Sabah campus ) have local private university branch campuses in East Malaysia .","prompt_labels":"UCSI(B-university) University(I-university) ,(I-university) Sarawak(I-university) Campus(I-university) ,(O) University(B-university) College(I-university) of(I-university) Technology(I-university) Sarawak(I-university) ((O) UCTS(B-university) )(O) Tunku(B-university) Abdul(I-university) Rahman(I-university) University(I-university) College(I-university) ((I-university) Sabah(I-university) campus(I-university) )(I-university) ,(O) International(B-university) University(I-university) College(I-university) Of(I-university) Technology(I-university) Twintech(I-university) ((I-university) Sabah(I-university) campus(I-university) )(I-university) ,(O) and(O) Open(B-university) University(I-university) Malaysia(I-university) ((I-university) Sabah(I-university) campus(I-university) )(I-university) have(O) local(O) private(O) university(O) branch(O) campuses(O) in(O) East(B-location) Malaysia(I-location) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["chemical compound","protein","country","theory","event","scientist","discipline","chemical element","person","organization","academic journal","location","enzyme","university","award","astronomical object"],"instance":{"id":"57","words":["He","also","included","perturbations","due","to","the","other","planets","(","principally","Jupiter","and","Venus",")","and","also","accounted","for","the","more","difficult","problem","of","the","non-spherical","nature","of","the","Earth","and","Moon","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","B-astronomical object","O","B-astronomical object","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-astronomical object","O","B-astronomical object","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: chemical compound, protein, country, theory, event, scientist, discipline, chemical element, person, organization, academic journal, location, enzyme, university, award, astronomical object and O.\nSentence: He also included perturbations due to the other planets ( principally Jupiter and Venus ) and also accounted for the more difficult problem of the non-spherical nature of the Earth and Moon .","prompt_labels":"He(O) also(O) included(O) perturbations(O) due(O) to(O) the(O) other(O) planets(O) ((O) principally(O) Jupiter(B-astronomical object) and(O) Venus(B-astronomical object) )(O) and(O) also(O) accounted(O) for(O) the(O) more(O) difficult(O) problem(O) of(O) the(O) non-spherical(O) nature(O) of(O) the(O) Earth(B-astronomical object) and(O) Moon(B-astronomical object) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["discipline","astronomical object","person","protein","location","scientist","university","organization","chemical compound","country","enzyme","award","theory","event","academic journal","chemical element"],"instance":{"id":"58","words":["Thompson","endowed","the","Rumford","medal","s","of","the","Royal","Society","and","the","American","Academy","of","Arts","and","Sciences",",","and","endowed","a","professorship","at","Harvard","University","."],"labels":["B-scientist","O","O","B-award","I-award","O","O","O","B-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","O","O","O","O","O","B-university","I-university","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: discipline, astronomical object, person, protein, location, scientist, university, organization, chemical compound, country, enzyme, award, theory, event, academic journal, chemical element and O.\nSentence: Thompson endowed the Rumford medal s of the Royal Society and the American Academy of Arts and Sciences , and endowed a professorship at Harvard University .","prompt_labels":"Thompson(B-scientist) endowed(O) the(O) Rumford(B-award) medal(I-award) s(O) of(O) the(O) Royal(B-organization) Society(I-organization) and(O) the(O) American(B-organization) Academy(I-organization) of(I-organization) Arts(I-organization) and(I-organization) Sciences(I-organization) ,(O) and(O) endowed(O) a(O) professorship(O) at(O) Harvard(B-university) University(I-university) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["country","organization","event","person","location","academic journal","discipline","university","scientist","protein","enzyme","chemical compound","chemical element","award","astronomical object","theory"],"instance":{"id":"59","words":["This","latter","restriction","excludes","objects","whose","orbits","may","cross","but","that","will","never","collide","with","each","other","due","to","orbital","resonance",",","such","as","Jupiter","and","its","trojans",",","Earth","and","3753","Cruithne",",","or","Neptune","and","the","plutino","s","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-theory","I-theory","O","O","O","B-astronomical object","O","O","O","O","B-astronomical object","O","B-astronomical object","I-astronomical object","O","O","B-astronomical object","O","O","B-astronomical object","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, organization, event, person, location, academic journal, discipline, university, scientist, protein, enzyme, chemical compound, chemical element, award, astronomical object, theory and O.\nSentence: This latter restriction excludes objects whose orbits may cross but that will never collide with each other due to orbital resonance , such as Jupiter and its trojans , Earth and 3753 Cruithne , or Neptune and the plutino s .","prompt_labels":"This(O) latter(O) restriction(O) excludes(O) objects(O) whose(O) orbits(O) may(O) cross(O) but(O) that(O) will(O) never(O) collide(O) with(O) each(O) other(O) due(O) to(O) orbital(B-theory) resonance(I-theory) ,(O) such(O) as(O) Jupiter(B-astronomical object) and(O) its(O) trojans(O) ,(O) Earth(B-astronomical object) and(O) 3753(B-astronomical object) Cruithne(I-astronomical object) ,(O) or(O) Neptune(B-astronomical object) and(O) the(O) plutino(B-astronomical object) s(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["chemical element","academic journal","chemical compound","discipline","organization","enzyme","protein","scientist","country","person","location","astronomical object","award","theory","event","university"],"instance":{"id":"60","words":["In","2007",",","Sawa",",","Nusinow",",","Kay",",","and","Imaizumi","identified","how","Arabidopsis","proteins","FKF1","(","Flavin-binding",",","Kelch","repeat",",","F-box","protein",")","and","GI","(","Gigantea",")","helped","regulate","flowering","photoperiods","in","Arabidopsis","."],"labels":["O","O","O","B-scientist","O","B-scientist","O","B-scientist","O","O","B-scientist","O","O","O","O","B-protein","O","B-protein","I-protein","I-protein","I-protein","I-protein","I-protein","I-protein","O","O","B-protein","O","B-protein","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: chemical element, academic journal, chemical compound, discipline, organization, enzyme, protein, scientist, country, person, location, astronomical object, award, theory, event, university and O.\nSentence: In 2007 , Sawa , Nusinow , Kay , and Imaizumi identified how Arabidopsis proteins FKF1 ( Flavin-binding , Kelch repeat , F-box protein ) and GI ( Gigantea ) helped regulate flowering photoperiods in Arabidopsis .","prompt_labels":"In(O) 2007(O) ,(O) Sawa(B-scientist) ,(O) Nusinow(B-scientist) ,(O) Kay(B-scientist) ,(O) and(O) Imaizumi(B-scientist) identified(O) how(O) Arabidopsis(O) proteins(O) FKF1(B-protein) ((O) Flavin-binding(B-protein) ,(I-protein) Kelch(I-protein) repeat(I-protein) ,(I-protein) F-box(I-protein) protein(I-protein) )(O) and(O) GI(B-protein) ((O) Gigantea(B-protein) )(O) helped(O) regulate(O) flowering(O) photoperiods(O) in(O) Arabidopsis(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["organization","person","university","award","astronomical object","event","location","enzyme","academic journal","chemical element","chemical compound","discipline","theory","scientist","protein","country"],"instance":{"id":"61","words":["Robot","designer","Hans","Moravec",",","cyberneticist","Kevin","Warwick","and","inventor","Ray","Kurzweil","have","predicted","that","humans","and","machines","will","merge","in","the","future","into","cyborg","s","that","are","more","capable","and","powerful","than","either","."],"labels":["O","O","B-scientist","I-scientist","O","O","B-scientist","I-scientist","O","O","B-person","I-person","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, person, university, award, astronomical object, event, location, enzyme, academic journal, chemical element, chemical compound, discipline, theory, scientist, protein, country and O.\nSentence: Robot designer Hans Moravec , cyberneticist Kevin Warwick and inventor Ray Kurzweil have predicted that humans and machines will merge in the future into cyborg s that are more capable and powerful than either .","prompt_labels":"Robot(O) designer(O) Hans(B-scientist) Moravec(I-scientist) ,(O) cyberneticist(O) Kevin(B-scientist) Warwick(I-scientist) and(O) inventor(O) Ray(B-person) Kurzweil(I-person) have(O) predicted(O) that(O) humans(O) and(O) machines(O) will(O) merge(O) in(O) the(O) future(O) into(O) cyborg(O) s(O) that(O) are(O) more(O) capable(O) and(O) powerful(O) than(O) either(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["chemical element","chemical compound","university","enzyme","event","protein","organization","academic journal","award","scientist","country","discipline","theory","location","person","astronomical object"],"instance":{"id":"62","words":["Matja","Perc","is","editorial","board","member","at","Physical","Review","E",",","New","Journal","of","Physics",",","EPL",",","European","Physical","Journal","B",",","Advances","in","Complex","Systems",",","Frontiers","in","Interdisciplinary","Physics",",","International","Journal","of","Bifurcation","and","Chaos",",","PLOS","ONE",",","Scientific","Reports",",","Royal","Society","Open","Science",",","'","."],"labels":["B-scientist","I-scientist","O","O","O","O","O","B-academic journal","I-academic journal","I-academic journal","O","B-academic journal","I-academic journal","I-academic journal","I-academic journal","O","B-academic journal","O","B-academic journal","I-academic journal","I-academic journal","I-academic journal","O","B-academic journal","I-academic journal","I-academic journal","I-academic journal","O","B-academic journal","I-academic journal","I-academic journal","I-academic journal","O","B-academic journal","I-academic journal","I-academic journal","I-academic journal","I-academic journal","I-academic journal","O","B-academic journal","I-academic journal","O","B-academic journal","I-academic journal","O","B-academic journal","I-academic journal","I-academic journal","I-academic journal","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: chemical element, chemical compound, university, enzyme, event, protein, organization, academic journal, award, scientist, country, discipline, theory, location, person, astronomical object and O.\nSentence: Matja Perc is editorial board member at Physical Review E , New Journal of Physics , EPL , European Physical Journal B , Advances in Complex Systems , Frontiers in Interdisciplinary Physics , International Journal of Bifurcation and Chaos , PLOS ONE , Scientific Reports , Royal Society Open Science , ' .","prompt_labels":"Matja(B-scientist) Perc(I-scientist) is(O) editorial(O) board(O) member(O) at(O) Physical(B-academic journal) Review(I-academic journal) E(I-academic journal) ,(O) New(B-academic journal) Journal(I-academic journal) of(I-academic journal) Physics(I-academic journal) ,(O) EPL(B-academic journal) ,(O) European(B-academic journal) Physical(I-academic journal) Journal(I-academic journal) B(I-academic journal) ,(O) Advances(B-academic journal) in(I-academic journal) Complex(I-academic journal) Systems(I-academic journal) ,(O) Frontiers(B-academic journal) in(I-academic journal) Interdisciplinary(I-academic journal) Physics(I-academic journal) ,(O) International(B-academic journal) Journal(I-academic journal) of(I-academic journal) Bifurcation(I-academic journal) and(I-academic journal) Chaos(I-academic journal) ,(O) PLOS(B-academic journal) ONE(I-academic journal) ,(O) Scientific(B-academic journal) Reports(I-academic journal) ,(O) Royal(B-academic journal) Society(I-academic journal) Open(I-academic journal) Science(I-academic journal) ,(O) '(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["theory","country","university","event","person","protein","chemical compound","location","organization","astronomical object","scientist","award","enzyme","chemical element","discipline","academic journal"],"instance":{"id":"63","words":["On","the","same","night",",","the","trio","of","astronomers","also","discovered","the","minor","planets","1912","Anubis",",","1923","Osiris","and","1924","Horus",",","which","were","also","named","after","Ancient","Egyptian","deities","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-astronomical object","I-astronomical object","O","B-astronomical object","I-astronomical object","O","B-astronomical object","I-astronomical object","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: theory, country, university, event, person, protein, chemical compound, location, organization, astronomical object, scientist, award, enzyme, chemical element, discipline, academic journal and O.\nSentence: On the same night , the trio of astronomers also discovered the minor planets 1912 Anubis , 1923 Osiris and 1924 Horus , which were also named after Ancient Egyptian deities .","prompt_labels":"On(O) the(O) same(O) night(O) ,(O) the(O) trio(O) of(O) astronomers(O) also(O) discovered(O) the(O) minor(O) planets(O) 1912(B-astronomical object) Anubis(I-astronomical object) ,(O) 1923(B-astronomical object) Osiris(I-astronomical object) and(O) 1924(B-astronomical object) Horus(I-astronomical object) ,(O) which(O) were(O) also(O) named(O) after(O) Ancient(O) Egyptian(O) deities(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["award","chemical compound","country","organization","person","enzyme","scientist","academic journal","protein","university","astronomical object","event","theory","location","discipline","chemical element"],"instance":{"id":"64","words":["Gavrilo","Princip",",","Nedeljko","abrinovi","and","Trifko","Grabe","were","smuggled","across","the","border","back","into","Bosnia","via","a","chain","of","underground-railroad","style","contacts","."],"labels":["B-person","I-person","O","B-person","I-person","O","B-person","I-person","O","O","O","O","O","O","O","B-country","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, chemical compound, country, organization, person, enzyme, scientist, academic journal, protein, university, astronomical object, event, theory, location, discipline, chemical element and O.\nSentence: Gavrilo Princip , Nedeljko abrinovi and Trifko Grabe were smuggled across the border back into Bosnia via a chain of underground-railroad style contacts .","prompt_labels":"Gavrilo(B-person) Princip(I-person) ,(O) Nedeljko(B-person) abrinovi(I-person) and(O) Trifko(B-person) Grabe(I-person) were(O) smuggled(O) across(O) the(O) border(O) back(O) into(O) Bosnia(B-country) via(O) a(O) chain(O) of(O) underground-railroad(O) style(O) contacts(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["protein","organization","astronomical object","person","enzyme","chemical element","academic journal","university","award","discipline","event","scientist","theory","chemical compound","country","location"],"instance":{"id":"65","words":["A","diverse","faculty","of","more","than","4,700","scholars","includes","4","Nobel","laureates",",","6","Pulitzer","Prize","winners",",","4","MacArthur","Fellows","Program","Genius","Grant","members","and","19","National","Academy","of","Sciences","members","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-award","O","O","O","B-award","I-award","O","O","O","B-award","I-award","I-award","B-award","I-award","O","O","O","B-organization","I-organization","I-organization","I-organization","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: protein, organization, astronomical object, person, enzyme, chemical element, academic journal, university, award, discipline, event, scientist, theory, chemical compound, country, location and O.\nSentence: A diverse faculty of more than 4,700 scholars includes 4 Nobel laureates , 6 Pulitzer Prize winners , 4 MacArthur Fellows Program Genius Grant members and 19 National Academy of Sciences members .","prompt_labels":"A(O) diverse(O) faculty(O) of(O) more(O) than(O) 4,700(O) scholars(O) includes(O) 4(O) Nobel(B-award) laureates(O) ,(O) 6(O) Pulitzer(B-award) Prize(I-award) winners(O) ,(O) 4(O) MacArthur(B-award) Fellows(I-award) Program(I-award) Genius(B-award) Grant(I-award) members(O) and(O) 19(O) National(B-organization) Academy(I-organization) of(I-organization) Sciences(I-organization) members(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["location","chemical element","person","university","organization","country","chemical compound","event","discipline","academic journal","award","theory","scientist","astronomical object","protein","enzyme"],"instance":{"id":"66","words":["Rubbia","studied","physics","at","the","University","of","Pisa","and","Scuola","Normale","Superiore","di","Pisa","in","Pisa",".ref","name","=","CVCR","\/","He","graduated","on","cosmic","ray","experiments","in","1957","with","Marcello","Conversi","."],"labels":["B-scientist","O","B-discipline","O","O","B-university","I-university","I-university","O","B-university","I-university","I-university","I-university","I-university","O","B-location","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-scientist","I-scientist","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, chemical element, person, university, organization, country, chemical compound, event, discipline, academic journal, award, theory, scientist, astronomical object, protein, enzyme and O.\nSentence: Rubbia studied physics at the University of Pisa and Scuola Normale Superiore di Pisa in Pisa .ref name = CVCR \/ He graduated on cosmic ray experiments in 1957 with Marcello Conversi .","prompt_labels":"Rubbia(B-scientist) studied(O) physics(B-discipline) at(O) the(O) University(B-university) of(I-university) Pisa(I-university) and(O) Scuola(B-university) Normale(I-university) Superiore(I-university) di(I-university) Pisa(I-university) in(O) Pisa(B-location) .ref(O) name(O) =(O) CVCR(O) \/(O) He(O) graduated(O) on(O) cosmic(O) ray(O) experiments(O) in(O) 1957(O) with(O) Marcello(B-scientist) Conversi(I-scientist) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["country","university","enzyme","astronomical object","event","chemical element","discipline","protein","theory","chemical compound","person","scientist","award","location","organization","academic journal"],"instance":{"id":"67","words":["As","regards","epigenomics",",","thousands","of","zero-mode","waveguide","s","(","ZMWs",")","are","used","to","capture","the","DNA","polymerase",":","when","a","modified","base","is","present",",","the","biophysical","dynamics","of","its","movement","changes",",","creating","a","unique","kinetic","signature","before",",","during",",","and","after","the","base","incorporation","."],"labels":["O","O","B-discipline","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-enzyme","I-enzyme","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, university, enzyme, astronomical object, event, chemical element, discipline, protein, theory, chemical compound, person, scientist, award, location, organization, academic journal and O.\nSentence: As regards epigenomics , thousands of zero-mode waveguide s ( ZMWs ) are used to capture the DNA polymerase : when a modified base is present , the biophysical dynamics of its movement changes , creating a unique kinetic signature before , during , and after the base incorporation .","prompt_labels":"As(O) regards(O) epigenomics(B-discipline) ,(O) thousands(O) of(O) zero-mode(O) waveguide(O) s(O) ((O) ZMWs(O) )(O) are(O) used(O) to(O) capture(O) the(O) DNA(B-enzyme) polymerase(I-enzyme) :(O) when(O) a(O) modified(O) base(O) is(O) present(O) ,(O) the(O) biophysical(O) dynamics(O) of(O) its(O) movement(O) changes(O) ,(O) creating(O) a(O) unique(O) kinetic(O) signature(O) before(O) ,(O) during(O) ,(O) and(O) after(O) the(O) base(O) incorporation(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["theory","chemical element","scientist","university","astronomical object","chemical compound","organization","protein","country","enzyme","location","person","award","event","academic journal","discipline"],"instance":{"id":"68","words":["The","concept","that","the","composition","of","plant","communities","such","as","temperate","broadleaf","forest","changes","by","a","process","of","ecological","succession","was","developed","by","Henry","Chandler","Cowles",",","Arthur","Tansley","and","Frederic","Clements","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-scientist","I-scientist","I-scientist","O","B-scientist","I-scientist","O","B-scientist","I-scientist","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: theory, chemical element, scientist, university, astronomical object, chemical compound, organization, protein, country, enzyme, location, person, award, event, academic journal, discipline and O.\nSentence: The concept that the composition of plant communities such as temperate broadleaf forest changes by a process of ecological succession was developed by Henry Chandler Cowles , Arthur Tansley and Frederic Clements .","prompt_labels":"The(O) concept(O) that(O) the(O) composition(O) of(O) plant(O) communities(O) such(O) as(O) temperate(O) broadleaf(O) forest(O) changes(O) by(O) a(O) process(O) of(O) ecological(O) succession(O) was(O) developed(O) by(O) Henry(B-scientist) Chandler(I-scientist) Cowles(I-scientist) ,(O) Arthur(B-scientist) Tansley(I-scientist) and(O) Frederic(B-scientist) Clements(I-scientist) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["scientist","enzyme","academic journal","theory","event","award","chemical compound","discipline","protein","astronomical object","organization","country","location","person","chemical element","university"],"instance":{"id":"69","words":["For","some","articles","I","am","interested","in","I","did","some","images",":","actin",",","Arp2","\/","3","complex",",","MreB",",","Profilin",",","Zinc","finger","(","Protein","+","DNA",")"],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","B-protein","O","B-protein","I-protein","I-protein","I-protein","O","B-protein","O","B-protein","O","B-protein","I-protein","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: scientist, enzyme, academic journal, theory, event, award, chemical compound, discipline, protein, astronomical object, organization, country, location, person, chemical element, university and O.\nSentence: For some articles I am interested in I did some images : actin , Arp2 \/ 3 complex , MreB , Profilin , Zinc finger ( Protein + DNA )","prompt_labels":"For(O) some(O) articles(O) I(O) am(O) interested(O) in(O) I(O) did(O) some(O) images(O) :(O) actin(B-protein) ,(O) Arp2(B-protein) \/(I-protein) 3(I-protein) complex(I-protein) ,(O) MreB(B-protein) ,(O) Profilin(B-protein) ,(O) Zinc(B-protein) finger(I-protein) ((O) Protein(O) +(O) DNA(O) )(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["chemical compound","location","academic journal","country","award","theory","discipline","person","protein","enzyme","university","organization","event","scientist","astronomical object","chemical element"],"instance":{"id":"70","words":["FastPP","can","be","used","on","unpurified",",","complex","mixtures","of","proteins","and","proteins","fused","with","other","proteins",",","such","as","Glutathione","S-transferase","or","Green","fluorescent","protein",",","as","long","as","the","sequence","that","is","the","target","of","the","western","blot",",","e.g.",",","His-tag",",","is","directly","linked","to","the","protein","of","interest","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-protein","I-protein","O","B-protein","I-protein","I-protein","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: chemical compound, location, academic journal, country, award, theory, discipline, person, protein, enzyme, university, organization, event, scientist, astronomical object, chemical element and O.\nSentence: FastPP can be used on unpurified , complex mixtures of proteins and proteins fused with other proteins , such as Glutathione S-transferase or Green fluorescent protein , as long as the sequence that is the target of the western blot , e.g. , His-tag , is directly linked to the protein of interest .","prompt_labels":"FastPP(O) can(O) be(O) used(O) on(O) unpurified(O) ,(O) complex(O) mixtures(O) of(O) proteins(O) and(O) proteins(O) fused(O) with(O) other(O) proteins(O) ,(O) such(O) as(O) Glutathione(B-protein) S-transferase(I-protein) or(O) Green(B-protein) fluorescent(I-protein) protein(I-protein) ,(O) as(O) long(O) as(O) the(O) sequence(O) that(O) is(O) the(O) target(O) of(O) the(O) western(O) blot(O) ,(O) e.g.(O) ,(O) His-tag(O) ,(O) is(O) directly(O) linked(O) to(O) the(O) protein(O) of(O) interest(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["chemical compound","protein","scientist","event","country","academic journal","person","award","organization","university","location","discipline","chemical element","theory","astronomical object","enzyme"],"instance":{"id":"71","words":["The","theory","has","been","published","in","three","peer-reviewed","journals",":","The","Quarterly","Review","of","Biology",",","Evolutionary","Anthropology","and","the","Journal","of","Theoretical","Biology","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-academic journal","I-academic journal","I-academic journal","I-academic journal","I-academic journal","O","B-academic journal","I-academic journal","O","O","B-academic journal","I-academic journal","I-academic journal","I-academic journal","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: chemical compound, protein, scientist, event, country, academic journal, person, award, organization, university, location, discipline, chemical element, theory, astronomical object, enzyme and O.\nSentence: The theory has been published in three peer-reviewed journals : The Quarterly Review of Biology , Evolutionary Anthropology and the Journal of Theoretical Biology .","prompt_labels":"The(O) theory(O) has(O) been(O) published(O) in(O) three(O) peer-reviewed(O) journals(O) :(O) The(B-academic journal) Quarterly(I-academic journal) Review(I-academic journal) of(I-academic journal) Biology(I-academic journal) ,(O) Evolutionary(B-academic journal) Anthropology(I-academic journal) and(O) the(O) Journal(B-academic journal) of(I-academic journal) Theoretical(I-academic journal) Biology(I-academic journal) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["protein","scientist","award","location","theory","enzyme","country","chemical compound","astronomical object","academic journal","organization","university","person","chemical element","discipline","event"],"instance":{"id":"72","words":["Since","its","first","season",",","the","series","received","accolades","ranging","from","Emmy","Award","to","Teen","Choice","Awards","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","B-award","I-award","O","B-award","I-award","I-award","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: protein, scientist, award, location, theory, enzyme, country, chemical compound, astronomical object, academic journal, organization, university, person, chemical element, discipline, event and O.\nSentence: Since its first season , the series received accolades ranging from Emmy Award to Teen Choice Awards .","prompt_labels":"Since(O) its(O) first(O) season(O) ,(O) the(O) series(O) received(O) accolades(O) ranging(O) from(O) Emmy(B-award) Award(I-award) to(O) Teen(B-award) Choice(I-award) Awards(I-award) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["country","protein","person","scientist","astronomical object","theory","chemical compound","discipline","enzyme","event","award","organization","location","academic journal","university","chemical element"],"instance":{"id":"73","words":["Glenn","was","an","honorary","member","of","the","International","Academy","of","Astronautics","and","a","member","of","the","Society","of","Experimental","Test","Pilots",",","Marine","Corps","Aviation","Association",",","Order","of","Daedalians",",","National","Space","Club","board","of","trustees",",","National","Space","Society","board","of","governors",",","International","Association","of","Holiday","Inns",",","Ohio","Democratic","Party",",","State","Democratic","Executive","Committee",",","Franklin","County","(","Ohio",")","Democratic","Party","and","the","10th","District","(","Ohio",")","Democratic","Action","Club","."],"labels":["B-scientist","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","B-organization","I-organization","I-organization","I-organization","O","B-organization","I-organization","I-organization","O","B-organization","I-organization","I-organization","O","O","O","O","B-organization","I-organization","I-organization","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","B-organization","I-organization","I-organization","O","B-organization","I-organization","I-organization","I-organization","O","B-location","I-location","O","B-location","O","B-organization","I-organization","O","O","B-location","I-location","O","B-location","O","B-organization","I-organization","I-organization","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, protein, person, scientist, astronomical object, theory, chemical compound, discipline, enzyme, event, award, organization, location, academic journal, university, chemical element and O.\nSentence: Glenn was an honorary member of the International Academy of Astronautics and a member of the Society of Experimental Test Pilots , Marine Corps Aviation Association , Order of Daedalians , National Space Club board of trustees , National Space Society board of governors , International Association of Holiday Inns , Ohio Democratic Party , State Democratic Executive Committee , Franklin County ( Ohio ) Democratic Party and the 10th District ( Ohio ) Democratic Action Club .","prompt_labels":"Glenn(B-scientist) was(O) an(O) honorary(O) member(O) of(O) the(O) International(B-organization) Academy(I-organization) of(I-organization) Astronautics(I-organization) and(O) a(O) member(O) of(O) the(O) Society(B-organization) of(I-organization) Experimental(I-organization) Test(I-organization) Pilots(I-organization) ,(O) Marine(B-organization) Corps(I-organization) Aviation(I-organization) Association(I-organization) ,(O) Order(B-organization) of(I-organization) Daedalians(I-organization) ,(O) National(B-organization) Space(I-organization) Club(I-organization) board(O) of(O) trustees(O) ,(O) National(B-organization) Space(I-organization) Society(I-organization) board(O) of(O) governors(O) ,(O) International(B-organization) Association(I-organization) of(I-organization) Holiday(I-organization) Inns(I-organization) ,(O) Ohio(B-organization) Democratic(I-organization) Party(I-organization) ,(O) State(B-organization) Democratic(I-organization) Executive(I-organization) Committee(I-organization) ,(O) Franklin(B-location) County(I-location) ((O) Ohio(B-location) )(O) Democratic(B-organization) Party(I-organization) and(O) the(O) 10th(B-location) District(I-location) ((O) Ohio(B-location) )(O) Democratic(B-organization) Action(I-organization) Club(I-organization) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["organization","protein","discipline","astronomical object","enzyme","country","theory","chemical element","university","location","chemical compound","award","event","scientist","person","academic journal"],"instance":{"id":"74","words":["1879","saw","the","establishment","of","the","Anthropological","Society","of","Washington","(","which","first","published","the","journal","American","Anthropologist",",","before","it","became","a","national","journal",")",",","and","1882","saw","the","American","Association","for","the","Advancement","of","Science","established","an","anthropological","section","."],"labels":["O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O","O","O","O","O","O","B-academic journal","I-academic journal","O","O","O","O","O","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, protein, discipline, astronomical object, enzyme, country, theory, chemical element, university, location, chemical compound, award, event, scientist, person, academic journal and O.\nSentence: 1879 saw the establishment of the Anthropological Society of Washington ( which first published the journal American Anthropologist , before it became a national journal ) , and 1882 saw the American Association for the Advancement of Science established an anthropological section .","prompt_labels":"1879(O) saw(O) the(O) establishment(O) of(O) the(O) Anthropological(B-organization) Society(I-organization) of(I-organization) Washington(I-organization) ((O) which(O) first(O) published(O) the(O) journal(O) American(B-academic journal) Anthropologist(I-academic journal) ,(O) before(O) it(O) became(O) a(O) national(O) journal(O) )(O) ,(O) and(O) 1882(O) saw(O) the(O) American(B-organization) Association(I-organization) for(I-organization) the(I-organization) Advancement(I-organization) of(I-organization) Science(I-organization) established(O) an(O) anthropological(O) section(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["protein","chemical element","organization","university","theory","discipline","astronomical object","academic journal","scientist","chemical compound","award","location","enzyme","country","person","event"],"instance":{"id":"75","words":["The","Voyager","Program","(","namely","Voyager","2",")","only","nominally","confirmed","the","existence","of","similar","belts","around","Uranus","and","Neptune","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-astronomical object","O","B-astronomical object","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: protein, chemical element, organization, university, theory, discipline, astronomical object, academic journal, scientist, chemical compound, award, location, enzyme, country, person, event and O.\nSentence: The Voyager Program ( namely Voyager 2 ) only nominally confirmed the existence of similar belts around Uranus and Neptune .","prompt_labels":"The(O) Voyager(O) Program(O) ((O) namely(O) Voyager(O) 2(O) )(O) only(O) nominally(O) confirmed(O) the(O) existence(O) of(O) similar(O) belts(O) around(O) Uranus(B-astronomical object) and(O) Neptune(B-astronomical object) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["scientist","organization","university","astronomical object","enzyme","theory","academic journal","country","chemical compound","chemical element","award","discipline","protein","event","location","person"],"instance":{"id":"76","words":["It","is","also","the","first","Doctor","Who","appearance","of","Gwen","Cooper","(","Eve","Myles",")",";","Ianto","Jones","(","Gareth","David-Lloyd",")",";","Luke","Smith","(","Tommy","Knight",")",";","and","Mr","Smith","(","voiced","by","Alexander","Armstrong",")",",","though","Myles","and","Armstrong","appeared","in","other","episodes","playing","different","roles","."],"labels":["O","O","O","O","O","O","O","O","O","B-person","I-person","O","B-person","I-person","O","O","B-person","I-person","O","B-person","I-person","O","O","B-person","I-person","O","B-person","I-person","O","O","O","B-person","I-person","O","O","O","B-person","I-person","O","O","O","B-person","O","B-person","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: scientist, organization, university, astronomical object, enzyme, theory, academic journal, country, chemical compound, chemical element, award, discipline, protein, event, location, person and O.\nSentence: It is also the first Doctor Who appearance of Gwen Cooper ( Eve Myles ) ; Ianto Jones ( Gareth David-Lloyd ) ; Luke Smith ( Tommy Knight ) ; and Mr Smith ( voiced by Alexander Armstrong ) , though Myles and Armstrong appeared in other episodes playing different roles .","prompt_labels":"It(O) is(O) also(O) the(O) first(O) Doctor(O) Who(O) appearance(O) of(O) Gwen(B-person) Cooper(I-person) ((O) Eve(B-person) Myles(I-person) )(O) ;(O) Ianto(B-person) Jones(I-person) ((O) Gareth(B-person) David-Lloyd(I-person) )(O) ;(O) Luke(B-person) Smith(I-person) ((O) Tommy(B-person) Knight(I-person) )(O) ;(O) and(O) Mr(B-person) Smith(I-person) ((O) voiced(O) by(O) Alexander(B-person) Armstrong(I-person) )(O) ,(O) though(O) Myles(B-person) and(O) Armstrong(B-person) appeared(O) in(O) other(O) episodes(O) playing(O) different(O) roles(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["chemical element","protein","theory","location","scientist","person","university","discipline","country","academic journal","astronomical object","organization","chemical compound","enzyme","event","award"],"instance":{"id":"77","words":["In","the","second","half","of","the","20th","century",",","plate","tectonics","theory","was","developed","by","several","contributors","including","Alfred","Wegener",",","Maurice","Ewing",",","Robert","S.","Dietz",",","Harry","Hammond","Hess",",","Hugo","Benioff",",","Walter","C.","Pitman",",","III",",","Frederick","Vine",",","Drummond","Matthews",",","Keith","Runcorn",",","Bryan","L.","Isacks",",","Edward","Bullard",",","Xavier","Le","Pichon",",","Dan","McKenzie",",","W.","Jason","Morgan","and","John","Tuzo","Wilson","."],"labels":["O","O","O","O","O","O","O","O","O","B-theory","I-theory","I-theory","O","O","O","O","O","O","B-scientist","I-scientist","O","B-scientist","I-scientist","O","B-scientist","I-scientist","I-scientist","O","B-scientist","I-scientist","I-scientist","O","B-scientist","I-scientist","O","B-scientist","I-scientist","I-scientist","I-scientist","I-scientist","O","B-scientist","I-scientist","O","B-scientist","I-scientist","O","B-scientist","I-scientist","O","B-scientist","I-scientist","I-scientist","O","B-scientist","I-scientist","O","B-scientist","I-scientist","I-scientist","O","B-scientist","I-scientist","O","B-scientist","I-scientist","I-scientist","O","B-scientist","I-scientist","I-scientist","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: chemical element, protein, theory, location, scientist, person, university, discipline, country, academic journal, astronomical object, organization, chemical compound, enzyme, event, award and O.\nSentence: In the second half of the 20th century , plate tectonics theory was developed by several contributors including Alfred Wegener , Maurice Ewing , Robert S. Dietz , Harry Hammond Hess , Hugo Benioff , Walter C. Pitman , III , Frederick Vine , Drummond Matthews , Keith Runcorn , Bryan L. Isacks , Edward Bullard , Xavier Le Pichon , Dan McKenzie , W. Jason Morgan and John Tuzo Wilson .","prompt_labels":"In(O) the(O) second(O) half(O) of(O) the(O) 20th(O) century(O) ,(O) plate(B-theory) tectonics(I-theory) theory(I-theory) was(O) developed(O) by(O) several(O) contributors(O) including(O) Alfred(B-scientist) Wegener(I-scientist) ,(O) Maurice(B-scientist) Ewing(I-scientist) ,(O) Robert(B-scientist) S.(I-scientist) Dietz(I-scientist) ,(O) Harry(B-scientist) Hammond(I-scientist) Hess(I-scientist) ,(O) Hugo(B-scientist) Benioff(I-scientist) ,(O) Walter(B-scientist) C.(I-scientist) Pitman(I-scientist) ,(I-scientist) III(I-scientist) ,(O) Frederick(B-scientist) Vine(I-scientist) ,(O) Drummond(B-scientist) Matthews(I-scientist) ,(O) Keith(B-scientist) Runcorn(I-scientist) ,(O) Bryan(B-scientist) L.(I-scientist) Isacks(I-scientist) ,(O) Edward(B-scientist) Bullard(I-scientist) ,(O) Xavier(B-scientist) Le(I-scientist) Pichon(I-scientist) ,(O) Dan(B-scientist) McKenzie(I-scientist) ,(O) W.(B-scientist) Jason(I-scientist) Morgan(I-scientist) and(O) John(B-scientist) Tuzo(I-scientist) Wilson(I-scientist) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["chemical element","event","award","discipline","chemical compound","astronomical object","country","university","enzyme","theory","scientist","protein","academic journal","location","person","organization"],"instance":{"id":"78","words":["He","was","member","of","the","Deutsche","Akademie","of","Munich",",","Swiss","Physical","Society","of","Zrich",",","Royal","Philosophical","Society","of","Glasgow",",","Royal","Irish","Academy",",","Hungarian","Academy","of","Sciences",",","Academy","of","Sciences","of","the","U.S.S.R.",",","Optical","Society","of","America","and","Mineralogical","Society","of","America",",","Romanian","Academy","of","Sciences",",","Catgut","Acoustical","Society","of","America",",","and","Czechoslovak","Academy","of","Sciences","."],"labels":["O","O","O","O","O","B-university","I-university","I-university","I-university","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","B-organization","I-organization","I-organization","O","B-organization","I-organization","I-organization","I-organization","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","B-organization","I-organization","I-organization","I-organization","O","B-organization","I-organization","I-organization","I-organization","O","B-organization","I-organization","I-organization","I-organization","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: chemical element, event, award, discipline, chemical compound, astronomical object, country, university, enzyme, theory, scientist, protein, academic journal, location, person, organization and O.\nSentence: He was member of the Deutsche Akademie of Munich , Swiss Physical Society of Zrich , Royal Philosophical Society of Glasgow , Royal Irish Academy , Hungarian Academy of Sciences , Academy of Sciences of the U.S.S.R. , Optical Society of America and Mineralogical Society of America , Romanian Academy of Sciences , Catgut Acoustical Society of America , and Czechoslovak Academy of Sciences .","prompt_labels":"He(O) was(O) member(O) of(O) the(O) Deutsche(B-university) Akademie(I-university) of(I-university) Munich(I-university) ,(O) Swiss(B-organization) Physical(I-organization) Society(I-organization) of(I-organization) Zrich(I-organization) ,(O) Royal(B-organization) Philosophical(I-organization) Society(I-organization) of(I-organization) Glasgow(I-organization) ,(O) Royal(B-organization) Irish(I-organization) Academy(I-organization) ,(O) Hungarian(B-organization) Academy(I-organization) of(I-organization) Sciences(I-organization) ,(O) Academy(B-organization) of(I-organization) Sciences(I-organization) of(I-organization) the(I-organization) U.S.S.R.(I-organization) ,(O) Optical(B-organization) Society(I-organization) of(I-organization) America(I-organization) and(O) Mineralogical(B-organization) Society(I-organization) of(I-organization) America(I-organization) ,(O) Romanian(B-organization) Academy(I-organization) of(I-organization) Sciences(I-organization) ,(O) Catgut(B-organization) Acoustical(I-organization) Society(I-organization) of(I-organization) America(I-organization) ,(O) and(O) Czechoslovak(B-organization) Academy(I-organization) of(I-organization) Sciences(I-organization) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["university","location","chemical element","country","organization","discipline","protein","event","person","scientist","academic journal","theory","chemical compound","astronomical object","award","enzyme"],"instance":{"id":"79","words":["He","served","as","President","of","the","Ecological","Society","of","America","in","1917",",","the","Association","of","American","Geographers","in","1923","and","President","of","the","Board","of","Directors","of","the","Society","for","Biodemography","and","Social","Biology","from","1934","to","1938","."],"labels":["O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O","O","O","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: university, location, chemical element, country, organization, discipline, protein, event, person, scientist, academic journal, theory, chemical compound, astronomical object, award, enzyme and O.\nSentence: He served as President of the Ecological Society of America in 1917 , the Association of American Geographers in 1923 and President of the Board of Directors of the Society for Biodemography and Social Biology from 1934 to 1938 .","prompt_labels":"He(O) served(O) as(O) President(O) of(O) the(O) Ecological(B-organization) Society(I-organization) of(I-organization) America(I-organization) in(O) 1917(O) ,(O) the(O) Association(B-organization) of(I-organization) American(I-organization) Geographers(I-organization) in(O) 1923(O) and(O) President(O) of(O) the(O) Board(O) of(O) Directors(O) of(O) the(O) Society(B-organization) for(I-organization) Biodemography(I-organization) and(I-organization) Social(I-organization) Biology(I-organization) from(O) 1934(O) to(O) 1938(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["location","astronomical object","country","academic journal","chemical element","theory","protein","chemical compound","discipline","person","event","scientist","enzyme","university","organization","award"],"instance":{"id":"80","words":["(","1976",")",";","Guggenheim","Fellow","(","1977",")",";","Member","National","Academy","of","Sciences","(","1979",")",";","Member","International","Academy","of","Science",",","Member","Academia","Sinica","(","1980",")",";","E.O.","Lawrence","Award","(","1981",")",";","Miller","Professor",",","Berkeley","(","1981",")",";","Fairchild","Distinguished","Scholar","(","1983",")",";","Harrison","Howe","Award","(","1983",")",";","Peter","Debye","Award","(","1986",")",";","National","Medal","of","Science","(","1986",")","."],"labels":["O","O","O","O","B-award","I-award","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O","O","B-organization","I-organization","O","O","O","O","B-award","I-award","I-award","O","O","O","O","B-scientist","O","O","B-university","O","O","O","O","B-award","I-award","I-award","O","O","O","O","B-award","I-award","I-award","O","O","O","O","B-award","I-award","I-award","O","O","O","O","B-award","I-award","I-award","I-award","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, astronomical object, country, academic journal, chemical element, theory, protein, chemical compound, discipline, person, event, scientist, enzyme, university, organization, award and O.\nSentence: ( 1976 ) ; Guggenheim Fellow ( 1977 ) ; Member National Academy of Sciences ( 1979 ) ; Member International Academy of Science , Member Academia Sinica ( 1980 ) ; E.O. Lawrence Award ( 1981 ) ; Miller Professor , Berkeley ( 1981 ) ; Fairchild Distinguished Scholar ( 1983 ) ; Harrison Howe Award ( 1983 ) ; Peter Debye Award ( 1986 ) ; National Medal of Science ( 1986 ) .","prompt_labels":"((O) 1976(O) )(O) ;(O) Guggenheim(B-award) Fellow(I-award) ((O) 1977(O) )(O) ;(O) Member(O) National(B-organization) Academy(I-organization) of(I-organization) Sciences(I-organization) ((O) 1979(O) )(O) ;(O) Member(O) International(B-organization) Academy(I-organization) of(I-organization) Science(I-organization) ,(O) Member(O) Academia(B-organization) Sinica(I-organization) ((O) 1980(O) )(O) ;(O) E.O.(B-award) Lawrence(I-award) Award(I-award) ((O) 1981(O) )(O) ;(O) Miller(B-scientist) Professor(O) ,(O) Berkeley(B-university) ((O) 1981(O) )(O) ;(O) Fairchild(B-award) Distinguished(I-award) Scholar(I-award) ((O) 1983(O) )(O) ;(O) Harrison(B-award) Howe(I-award) Award(I-award) ((O) 1983(O) )(O) ;(O) Peter(B-award) Debye(I-award) Award(I-award) ((O) 1986(O) )(O) ;(O) National(B-award) Medal(I-award) of(I-award) Science(I-award) ((O) 1986(O) )(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["discipline","chemical compound","award","location","enzyme","organization","university","theory","protein","person","academic journal","scientist","chemical element","astronomical object","country","event"],"instance":{"id":"81","words":["ESA","'s","Advanced","Concepts","Team","has","also","demonstrated","theoretically","that","a","deflection","of","99942","Apophis","could","be","achieved","by","sending","a","simple","spacecraft"],"labels":["B-organization","O","B-organization","I-organization","I-organization","O","O","O","O","O","O","O","O","B-astronomical object","I-astronomical object","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: discipline, chemical compound, award, location, enzyme, organization, university, theory, protein, person, academic journal, scientist, chemical element, astronomical object, country, event and O.\nSentence: ESA 's Advanced Concepts Team has also demonstrated theoretically that a deflection of 99942 Apophis could be achieved by sending a simple spacecraft","prompt_labels":"ESA(B-organization) 's(O) Advanced(B-organization) Concepts(I-organization) Team(I-organization) has(O) also(O) demonstrated(O) theoretically(O) that(O) a(O) deflection(O) of(O) 99942(B-astronomical object) Apophis(I-astronomical object) could(O) be(O) achieved(O) by(O) sending(O) a(O) simple(O) spacecraft(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["award","enzyme","country","astronomical object","person","scientist","chemical compound","academic journal","chemical element","event","theory","location","discipline","university","protein","organization"],"instance":{"id":"82","words":["They","are","made","up","of","monomers","called","nucleotide","s","which","consist","of","an","organic","base",":","Adenine",",","Guanine",",","Cytosine","and","Tyrosine","or","Uracil",",","a","pentose","sugar",",","and","a","Phosphate","."],"labels":["O","O","O","O","O","O","O","B-chemical compound","O","O","O","O","O","O","O","O","B-chemical compound","O","B-chemical compound","O","B-chemical compound","O","B-chemical compound","O","B-chemical compound","O","O","B-chemical compound","I-chemical compound","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, enzyme, country, astronomical object, person, scientist, chemical compound, academic journal, chemical element, event, theory, location, discipline, university, protein, organization and O.\nSentence: They are made up of monomers called nucleotide s which consist of an organic base : Adenine , Guanine , Cytosine and Tyrosine or Uracil , a pentose sugar , and a Phosphate .","prompt_labels":"They(O) are(O) made(O) up(O) of(O) monomers(O) called(O) nucleotide(B-chemical compound) s(O) which(O) consist(O) of(O) an(O) organic(O) base(O) :(O) Adenine(B-chemical compound) ,(O) Guanine(B-chemical compound) ,(O) Cytosine(B-chemical compound) and(O) Tyrosine(B-chemical compound) or(O) Uracil(B-chemical compound) ,(O) a(O) pentose(B-chemical compound) sugar(I-chemical compound) ,(O) and(O) a(O) Phosphate(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["organization","award","academic journal","event","theory","person","university","scientist","discipline","country","protein","chemical compound","astronomical object","chemical element","enzyme","location"],"instance":{"id":"83","words":["Other","higher","education","organizations","present","in","the","community",",","but","not","offering","classes","locally",",","include","the","Oak","Ridge","Institute","for","Science","and","Education",",","Oak","Ridge","Associated","Universities",",","and","the","University","of","Tennessee","Forestry","Stations","and","Arboretum","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","B-university","I-university","I-university","I-university","O","O","O","B-university","I-university","I-university","B-organization","I-organization","O","B-organization","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, award, academic journal, event, theory, person, university, scientist, discipline, country, protein, chemical compound, astronomical object, chemical element, enzyme, location and O.\nSentence: Other higher education organizations present in the community , but not offering classes locally , include the Oak Ridge Institute for Science and Education , Oak Ridge Associated Universities , and the University of Tennessee Forestry Stations and Arboretum .","prompt_labels":"Other(O) higher(O) education(O) organizations(O) present(O) in(O) the(O) community(O) ,(O) but(O) not(O) offering(O) classes(O) locally(O) ,(O) include(O) the(O) Oak(B-organization) Ridge(I-organization) Institute(I-organization) for(I-organization) Science(I-organization) and(I-organization) Education(I-organization) ,(O) Oak(B-university) Ridge(I-university) Associated(I-university) Universities(I-university) ,(O) and(O) the(O) University(B-university) of(I-university) Tennessee(I-university) Forestry(B-organization) Stations(I-organization) and(O) Arboretum(B-organization) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["organization","scientist","academic journal","enzyme","protein","university","chemical element","person","theory","country","event","discipline","award","chemical compound","location","astronomical object"],"instance":{"id":"84","words":["In","the","first","half","of","the","20th","century",",","advances","in","electronics","enabled","investigation","of","the","electrical","properties","of","nerve","cells",",","culminating","in","work","by","Alan","Hodgkin",",","Andrew","Huxley",",","and","others","on","the","biophysics","of","the","action","potential",",","and","the","work","of","Bernard","Katz","and","others","on","the","electrochemistry","of","the","synapse","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-scientist","I-scientist","O","B-scientist","I-scientist","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-scientist","I-scientist","O","O","O","O","B-discipline","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, scientist, academic journal, enzyme, protein, university, chemical element, person, theory, country, event, discipline, award, chemical compound, location, astronomical object and O.\nSentence: In the first half of the 20th century , advances in electronics enabled investigation of the electrical properties of nerve cells , culminating in work by Alan Hodgkin , Andrew Huxley , and others on the biophysics of the action potential , and the work of Bernard Katz and others on the electrochemistry of the synapse .","prompt_labels":"In(O) the(O) first(O) half(O) of(O) the(O) 20th(O) century(O) ,(O) advances(O) in(O) electronics(O) enabled(O) investigation(O) of(O) the(O) electrical(O) properties(O) of(O) nerve(O) cells(O) ,(O) culminating(O) in(O) work(O) by(O) Alan(B-scientist) Hodgkin(I-scientist) ,(O) Andrew(B-scientist) Huxley(I-scientist) ,(O) and(O) others(O) on(O) the(O) biophysics(O) of(O) the(O) action(O) potential(O) ,(O) and(O) the(O) work(O) of(O) Bernard(B-scientist) Katz(I-scientist) and(O) others(O) on(O) the(O) electrochemistry(B-discipline) of(O) the(O) synapse(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["protein","person","scientist","academic journal","theory","chemical compound","organization","country","enzyme","chemical element","location","discipline","university","astronomical object","award","event"],"instance":{"id":"85","words":["Jupiter","rarely","occults","Saturn","."],"labels":["B-astronomical object","O","O","B-astronomical object","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: protein, person, scientist, academic journal, theory, chemical compound, organization, country, enzyme, chemical element, location, discipline, university, astronomical object, award, event and O.\nSentence: Jupiter rarely occults Saturn .","prompt_labels":"Jupiter(B-astronomical object) rarely(O) occults(O) Saturn(B-astronomical object) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["organization","location","award","event","country","discipline","university","astronomical object","chemical element","theory","chemical compound","scientist","protein","enzyme","person","academic journal"],"instance":{"id":"86","words":["The","Voyager","program","is","an","American","scientific","program","that","employs","two","robotic","probes",",","Voyager","1","and","Voyager","2",",","launched","in","1977","to","take","advantage","of","a","favorable","alignment","of","Jupiter",",","Saturn",",","Uranus",",","and","Neptune","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-astronomical object","O","B-astronomical object","O","B-astronomical object","O","O","B-astronomical object","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, location, award, event, country, discipline, university, astronomical object, chemical element, theory, chemical compound, scientist, protein, enzyme, person, academic journal and O.\nSentence: The Voyager program is an American scientific program that employs two robotic probes , Voyager 1 and Voyager 2 , launched in 1977 to take advantage of a favorable alignment of Jupiter , Saturn , Uranus , and Neptune .","prompt_labels":"The(O) Voyager(O) program(O) is(O) an(O) American(O) scientific(O) program(O) that(O) employs(O) two(O) robotic(O) probes(O) ,(O) Voyager(O) 1(O) and(O) Voyager(O) 2(O) ,(O) launched(O) in(O) 1977(O) to(O) take(O) advantage(O) of(O) a(O) favorable(O) alignment(O) of(O) Jupiter(B-astronomical object) ,(O) Saturn(B-astronomical object) ,(O) Uranus(B-astronomical object) ,(O) and(O) Neptune(B-astronomical object) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["event","award","academic journal","country","university","theory","enzyme","location","discipline","scientist","protein","person","chemical compound","astronomical object","chemical element","organization"],"instance":{"id":"87","words":["He","is","known","for","his","studies","on","the","Pore-forming","toxin","and","T-cell","costimulatory","molecules","."],"labels":["O","O","O","O","O","O","O","O","B-protein","I-protein","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, award, academic journal, country, university, theory, enzyme, location, discipline, scientist, protein, person, chemical compound, astronomical object, chemical element, organization and O.\nSentence: He is known for his studies on the Pore-forming toxin and T-cell costimulatory molecules .","prompt_labels":"He(O) is(O) known(O) for(O) his(O) studies(O) on(O) the(O) Pore-forming(B-protein) toxin(I-protein) and(O) T-cell(O) costimulatory(O) molecules(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["chemical compound","astronomical object","theory","academic journal","location","university","person","country","protein","organization","award","enzyme","discipline","chemical element","event","scientist"],"instance":{"id":"88","words":["The","name","was","suggested","by","John","Herschel","(","son","of","William","Herschel",",","discoverer","of","Mimas","and","Enceladus",")","in","his","1847","publication","Results","of","Astronomical","Observations","made","at","the","Cape","of","Good","Hope",",","in","which","he","advocated","naming","the","moons","of","Saturn","after","the","Titans",",","brothers","and","sisters","of","the","Titan","Cronus","(","whom","the","Romans","equated","with","their","god","Saturn",")","."],"labels":["O","O","O","O","O","B-scientist","I-scientist","O","O","O","B-scientist","I-scientist","O","O","O","B-astronomical object","O","B-astronomical object","O","O","O","O","O","O","O","O","O","O","O","O","B-location","I-location","I-location","I-location","O","O","O","O","O","O","O","O","O","B-astronomical object","O","O","B-astronomical object","O","O","O","O","O","O","B-person","I-person","O","O","O","O","O","O","O","O","B-astronomical object","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: chemical compound, astronomical object, theory, academic journal, location, university, person, country, protein, organization, award, enzyme, discipline, chemical element, event, scientist and O.\nSentence: The name was suggested by John Herschel ( son of William Herschel , discoverer of Mimas and Enceladus ) in his 1847 publication Results of Astronomical Observations made at the Cape of Good Hope , in which he advocated naming the moons of Saturn after the Titans , brothers and sisters of the Titan Cronus ( whom the Romans equated with their god Saturn ) .","prompt_labels":"The(O) name(O) was(O) suggested(O) by(O) John(B-scientist) Herschel(I-scientist) ((O) son(O) of(O) William(B-scientist) Herschel(I-scientist) ,(O) discoverer(O) of(O) Mimas(B-astronomical object) and(O) Enceladus(B-astronomical object) )(O) in(O) his(O) 1847(O) publication(O) Results(O) of(O) Astronomical(O) Observations(O) made(O) at(O) the(O) Cape(B-location) of(I-location) Good(I-location) Hope(I-location) ,(O) in(O) which(O) he(O) advocated(O) naming(O) the(O) moons(O) of(O) Saturn(B-astronomical object) after(O) the(O) Titans(B-astronomical object) ,(O) brothers(O) and(O) sisters(O) of(O) the(O) Titan(B-person) Cronus(I-person) ((O) whom(O) the(O) Romans(O) equated(O) with(O) their(O) god(O) Saturn(B-astronomical object) )(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["enzyme","chemical compound","person","event","country","academic journal","university","theory","scientist","protein","astronomical object","organization","award","location","discipline","chemical element"],"instance":{"id":"89","words":["The","testing","station","is","where","Rexer",",","F.","Berkei",",","W.","Borrmann",",","W.","Czulius",",","Kurt","Diebner",",","Georg","Hartwig",",","Karl-Heinz","Hcker",",","Walter","Herrmann",",","and","Heinz","Pose",",","compared","the","effectiveness","of","neutron","production","in","a","paraffin-moderated","reactor","using","uranium","plates",",","rods",",","and","cubes","."],"labels":["O","O","O","O","O","B-scientist","O","B-scientist","I-scientist","O","B-scientist","I-scientist","O","B-scientist","I-scientist","O","B-scientist","I-scientist","O","B-scientist","I-scientist","O","B-scientist","I-scientist","O","B-scientist","I-scientist","O","O","B-scientist","I-scientist","O","O","O","O","O","O","O","O","O","O","O","O","B-chemical element","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: enzyme, chemical compound, person, event, country, academic journal, university, theory, scientist, protein, astronomical object, organization, award, location, discipline, chemical element and O.\nSentence: The testing station is where Rexer , F. Berkei , W. Borrmann , W. Czulius , Kurt Diebner , Georg Hartwig , Karl-Heinz Hcker , Walter Herrmann , and Heinz Pose , compared the effectiveness of neutron production in a paraffin-moderated reactor using uranium plates , rods , and cubes .","prompt_labels":"The(O) testing(O) station(O) is(O) where(O) Rexer(B-scientist) ,(O) F.(B-scientist) Berkei(I-scientist) ,(O) W.(B-scientist) Borrmann(I-scientist) ,(O) W.(B-scientist) Czulius(I-scientist) ,(O) Kurt(B-scientist) Diebner(I-scientist) ,(O) Georg(B-scientist) Hartwig(I-scientist) ,(O) Karl-Heinz(B-scientist) Hcker(I-scientist) ,(O) Walter(B-scientist) Herrmann(I-scientist) ,(O) and(O) Heinz(B-scientist) Pose(I-scientist) ,(O) compared(O) the(O) effectiveness(O) of(O) neutron(O) production(O) in(O) a(O) paraffin-moderated(O) reactor(O) using(O) uranium(B-chemical element) plates(O) ,(O) rods(O) ,(O) and(O) cubes(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["academic journal","protein","theory","scientist","chemical element","person","event","location","organization","enzyme","university","astronomical object","country","award","chemical compound","discipline"],"instance":{"id":"90","words":["He","was","a","fellow","of","the","Society","of","Experimental","Test","Pilots","(","SETP",")","and","the","American","Astronautical","Society",",","as","well","as","an","associate","fellow","of","the","American","Institute","of","Aeronautics","and","Astronautics","."],"labels":["O","O","O","B-award","I-award","I-award","I-award","I-award","I-award","I-award","I-award","O","B-organization","O","O","O","B-organization","I-organization","I-organization","O","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","I-award","I-award","I-award","I-award","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: academic journal, protein, theory, scientist, chemical element, person, event, location, organization, enzyme, university, astronomical object, country, award, chemical compound, discipline and O.\nSentence: He was a fellow of the Society of Experimental Test Pilots ( SETP ) and the American Astronautical Society , as well as an associate fellow of the American Institute of Aeronautics and Astronautics .","prompt_labels":"He(O) was(O) a(O) fellow(B-award) of(I-award) the(I-award) Society(I-award) of(I-award) Experimental(I-award) Test(I-award) Pilots(I-award) ((O) SETP(B-organization) )(O) and(O) the(O) American(B-organization) Astronautical(I-organization) Society(I-organization) ,(O) as(O) well(O) as(O) an(O) associate(O) fellow(B-award) of(I-award) the(I-award) American(I-award) Institute(I-award) of(I-award) Aeronautics(I-award) and(I-award) Astronautics(I-award) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["event","award","chemical compound","university","discipline","protein","country","astronomical object","theory","enzyme","chemical element","organization","academic journal","person","scientist","location"],"instance":{"id":"91","words":["Various","acids","were","used","in","the","past","such","as","Phosphoric","acid","as","used","in","Calcium","Lime","Rust","Remover","(","CLR",")","and","Hydrofluoric","acid","as","used","in","the","Australian","product","made","in","Queensland","called","Rustiban","."],"labels":["O","O","O","O","O","O","O","O","O","B-chemical compound","I-chemical compound","O","O","O","O","O","O","O","O","O","O","O","B-chemical compound","I-chemical compound","O","O","O","O","O","O","O","O","B-location","O","B-location","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, award, chemical compound, university, discipline, protein, country, astronomical object, theory, enzyme, chemical element, organization, academic journal, person, scientist, location and O.\nSentence: Various acids were used in the past such as Phosphoric acid as used in Calcium Lime Rust Remover ( CLR ) and Hydrofluoric acid as used in the Australian product made in Queensland called Rustiban .","prompt_labels":"Various(O) acids(O) were(O) used(O) in(O) the(O) past(O) such(O) as(O) Phosphoric(B-chemical compound) acid(I-chemical compound) as(O) used(O) in(O) Calcium(O) Lime(O) Rust(O) Remover(O) ((O) CLR(O) )(O) and(O) Hydrofluoric(B-chemical compound) acid(I-chemical compound) as(O) used(O) in(O) the(O) Australian(O) product(O) made(O) in(O) Queensland(B-location) called(O) Rustiban(B-location) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["discipline","person","protein","chemical element","astronomical object","country","location","scientist","organization","enzyme","university","event","chemical compound","award","theory","academic journal"],"instance":{"id":"92","words":["Of","the","eight","solar","planet","s",",","all","but","Venus","and","Uranus","have","prograde","rotation","-","that","is",",","they","rotate","more","than","once","per","year","in","the","same","direction","as","they","orbit","the","Sun",",","so","the","Sun","rises","in","the","east","."],"labels":["O","O","O","O","O","O","O","O","O","B-astronomical object","O","B-astronomical object","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-astronomical object","O","O","O","B-astronomical object","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: discipline, person, protein, chemical element, astronomical object, country, location, scientist, organization, enzyme, university, event, chemical compound, award, theory, academic journal and O.\nSentence: Of the eight solar planet s , all but Venus and Uranus have prograde rotation - that is , they rotate more than once per year in the same direction as they orbit the Sun , so the Sun rises in the east .","prompt_labels":"Of(O) the(O) eight(O) solar(O) planet(O) s(O) ,(O) all(O) but(O) Venus(B-astronomical object) and(O) Uranus(B-astronomical object) have(O) prograde(O) rotation(O) -(O) that(O) is(O) ,(O) they(O) rotate(O) more(O) than(O) once(O) per(O) year(O) in(O) the(O) same(O) direction(O) as(O) they(O) orbit(O) the(O) Sun(B-astronomical object) ,(O) so(O) the(O) Sun(B-astronomical object) rises(O) in(O) the(O) east(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["theory","discipline","organization","chemical compound","protein","award","enzyme","event","scientist","astronomical object","university","person","country","chemical element","location","academic journal"],"instance":{"id":"93","words":["Angelina","is","an","uncommon","form","of","E-type","asteroid",";","it","is","the","third","largest","E-type","after","44","Nysa","and","55","Pandora",",","and","has","an","exceptionally","high","albedo","in","January","2010","."],"labels":["B-astronomical object","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-astronomical object","I-astronomical object","O","B-astronomical object","I-astronomical object","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: theory, discipline, organization, chemical compound, protein, award, enzyme, event, scientist, astronomical object, university, person, country, chemical element, location, academic journal and O.\nSentence: Angelina is an uncommon form of E-type asteroid ; it is the third largest E-type after 44 Nysa and 55 Pandora , and has an exceptionally high albedo in January 2010 .","prompt_labels":"Angelina(B-astronomical object) is(O) an(O) uncommon(O) form(O) of(O) E-type(O) asteroid(O) ;(O) it(O) is(O) the(O) third(O) largest(O) E-type(O) after(O) 44(B-astronomical object) Nysa(I-astronomical object) and(O) 55(B-astronomical object) Pandora(I-astronomical object) ,(O) and(O) has(O) an(O) exceptionally(O) high(O) albedo(O) in(O) January(O) 2010(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["chemical element","theory","country","discipline","enzyme","person","location","organization","academic journal","protein","scientist","chemical compound","university","event","award","astronomical object"],"instance":{"id":"94","words":["Some","ligninolytic","enzymes","include","Haem","peroxidase","such","as","lignin","peroxidase","s",",","manganese","peroxidase","s",",","versatile","peroxidase","s",",","and","Dye","decolorizing","peroxidase","as","well","as","copper-based","laccase","s","."],"labels":["O","O","O","O","B-enzyme","I-enzyme","O","O","B-enzyme","I-enzyme","O","O","B-enzyme","I-enzyme","O","O","B-enzyme","I-enzyme","O","O","O","B-enzyme","I-enzyme","I-enzyme","O","O","O","O","B-enzyme","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: chemical element, theory, country, discipline, enzyme, person, location, organization, academic journal, protein, scientist, chemical compound, university, event, award, astronomical object and O.\nSentence: Some ligninolytic enzymes include Haem peroxidase such as lignin peroxidase s , manganese peroxidase s , versatile peroxidase s , and Dye decolorizing peroxidase as well as copper-based laccase s .","prompt_labels":"Some(O) ligninolytic(O) enzymes(O) include(O) Haem(B-enzyme) peroxidase(I-enzyme) such(O) as(O) lignin(B-enzyme) peroxidase(I-enzyme) s(O) ,(O) manganese(B-enzyme) peroxidase(I-enzyme) s(O) ,(O) versatile(B-enzyme) peroxidase(I-enzyme) s(O) ,(O) and(O) Dye(B-enzyme) decolorizing(I-enzyme) peroxidase(I-enzyme) as(O) well(O) as(O) copper-based(O) laccase(B-enzyme) s(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["country","enzyme","person","event","chemical compound","location","chemical element","award","discipline","scientist","theory","protein","astronomical object","organization","university","academic journal"],"instance":{"id":"95","words":["Menzel",",","a","mentor","of","several","prolific","astronomers",",","calculated","Atomic","Transition","Probabilities",",","analysed","the","composition","of","stars","from","their","spectra",",","studied","the","physics","of","gaseous","nebulae","and","the","Sun","'s","chromosphere",",","observed","solar","eclipses",",","and","measured","the","rotation","period","of","Uranus","and","Neptune","by","means","of","spectroscopy","."],"labels":["B-scientist","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-discipline","I-discipline","I-discipline","I-discipline","O","O","B-astronomical object","O","O","O","O","B-event","I-event","O","O","O","O","O","O","O","B-astronomical object","O","B-astronomical object","O","O","O","B-discipline","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, enzyme, person, event, chemical compound, location, chemical element, award, discipline, scientist, theory, protein, astronomical object, organization, university, academic journal and O.\nSentence: Menzel , a mentor of several prolific astronomers , calculated Atomic Transition Probabilities , analysed the composition of stars from their spectra , studied the physics of gaseous nebulae and the Sun 's chromosphere , observed solar eclipses , and measured the rotation period of Uranus and Neptune by means of spectroscopy .","prompt_labels":"Menzel(B-scientist) ,(O) a(O) mentor(O) of(O) several(O) prolific(O) astronomers(O) ,(O) calculated(O) Atomic(O) Transition(O) Probabilities(O) ,(O) analysed(O) the(O) composition(O) of(O) stars(O) from(O) their(O) spectra(O) ,(O) studied(O) the(O) physics(B-discipline) of(I-discipline) gaseous(I-discipline) nebulae(I-discipline) and(O) the(O) Sun(B-astronomical object) 's(O) chromosphere(O) ,(O) observed(O) solar(B-event) eclipses(I-event) ,(O) and(O) measured(O) the(O) rotation(O) period(O) of(O) Uranus(B-astronomical object) and(O) Neptune(B-astronomical object) by(O) means(O) of(O) spectroscopy(B-discipline) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["chemical element","astronomical object","organization","theory","event","chemical compound","award","location","discipline","protein","person","academic journal","university","enzyme","scientist","country"],"instance":{"id":"96","words":["Gas","giants","with","a","large","radius","and","very","low","density","are","sometimes","called","puffy","planets","COROT-1b",",","TrES-4",",","WASP-12b",",","WASP-17b",",","and","Kepler-7b","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-astronomical object","O","B-astronomical object","O","B-astronomical object","O","B-astronomical object","O","O","B-astronomical object","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: chemical element, astronomical object, organization, theory, event, chemical compound, award, location, discipline, protein, person, academic journal, university, enzyme, scientist, country and O.\nSentence: Gas giants with a large radius and very low density are sometimes called puffy planets COROT-1b , TrES-4 , WASP-12b , WASP-17b , and Kepler-7b .","prompt_labels":"Gas(O) giants(O) with(O) a(O) large(O) radius(O) and(O) very(O) low(O) density(O) are(O) sometimes(O) called(O) puffy(O) planets(O) COROT-1b(B-astronomical object) ,(O) TrES-4(B-astronomical object) ,(O) WASP-12b(B-astronomical object) ,(O) WASP-17b(B-astronomical object) ,(O) and(O) Kepler-7b(B-astronomical object) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["academic journal","country","discipline","location","person","organization","enzyme","protein","chemical element","award","theory","event","scientist","astronomical object","chemical compound","university"],"instance":{"id":"97","words":["ATX-II","slows","down","the","inactivation","of","different","Voltage-gated","ion","channel",",","including","Nasubv","\/","sub1.1","and","Nasubv","\/","sub1.2",",","thus","prolonging","action","potentials","."],"labels":["B-chemical compound","O","O","O","O","O","O","O","O","O","O","O","B-protein","I-protein","I-protein","O","B-protein","I-protein","I-protein","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: academic journal, country, discipline, location, person, organization, enzyme, protein, chemical element, award, theory, event, scientist, astronomical object, chemical compound, university and O.\nSentence: ATX-II slows down the inactivation of different Voltage-gated ion channel , including Nasubv \/ sub1.1 and Nasubv \/ sub1.2 , thus prolonging action potentials .","prompt_labels":"ATX-II(B-chemical compound) slows(O) down(O) the(O) inactivation(O) of(O) different(O) Voltage-gated(O) ion(O) channel(O) ,(O) including(O) Nasubv(B-protein) \/(I-protein) sub1.1(I-protein) and(O) Nasubv(B-protein) \/(I-protein) sub1.2(I-protein) ,(O) thus(O) prolonging(O) action(O) potentials(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["organization","theory","protein","astronomical object","academic journal","discipline","scientist","award","person","chemical compound","country","location","event","chemical element","university","enzyme"],"instance":{"id":"98","words":["It","was","discovered","on","24","September","1960",",","by","Ingrid","van","Houten-Groeneveld","and","Cornelis","van","Houten","at","Leiden",",","and","Tom","Gehrels","at","Palomar","Observatory","in","California","."],"labels":["O","O","O","O","O","O","O","O","O","B-scientist","I-scientist","I-scientist","O","B-scientist","I-scientist","I-scientist","O","B-location","O","O","B-scientist","I-scientist","O","B-location","I-location","O","B-location","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, theory, protein, astronomical object, academic journal, discipline, scientist, award, person, chemical compound, country, location, event, chemical element, university, enzyme and O.\nSentence: It was discovered on 24 September 1960 , by Ingrid van Houten-Groeneveld and Cornelis van Houten at Leiden , and Tom Gehrels at Palomar Observatory in California .","prompt_labels":"It(O) was(O) discovered(O) on(O) 24(O) September(O) 1960(O) ,(O) by(O) Ingrid(B-scientist) van(I-scientist) Houten-Groeneveld(I-scientist) and(O) Cornelis(B-scientist) van(I-scientist) Houten(I-scientist) at(O) Leiden(B-location) ,(O) and(O) Tom(B-scientist) Gehrels(I-scientist) at(O) Palomar(B-location) Observatory(I-location) in(O) California(B-location) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["academic journal","award","discipline","event","scientist","university","theory","chemical element","location","enzyme","country","chemical compound","astronomical object","organization","protein","person"],"instance":{"id":"99","words":["They","spent","the","winter","of","1866-67","in","Paris",",","where","Gibbs","attended","lectures","at","the","University","of","Paris","and","the","Collge","de","France",",","given","by","such","distinguished","mathematical","scientists","as","Joseph","Liouville","and","Michel","Chasles","."],"labels":["O","O","O","O","O","O","O","B-location","O","O","B-scientist","O","O","O","O","B-university","I-university","I-university","O","O","B-university","I-university","I-university","O","O","O","O","O","O","O","O","B-scientist","I-scientist","O","B-scientist","I-scientist","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: academic journal, award, discipline, event, scientist, university, theory, chemical element, location, enzyme, country, chemical compound, astronomical object, organization, protein, person and O.\nSentence: They spent the winter of 1866-67 in Paris , where Gibbs attended lectures at the University of Paris and the Collge de France , given by such distinguished mathematical scientists as Joseph Liouville and Michel Chasles .","prompt_labels":"They(O) spent(O) the(O) winter(O) of(O) 1866-67(O) in(O) Paris(B-location) ,(O) where(O) Gibbs(B-scientist) attended(O) lectures(O) at(O) the(O) University(B-university) of(I-university) Paris(I-university) and(O) the(O) Collge(B-university) de(I-university) France(I-university) ,(O) given(O) by(O) such(O) distinguished(O) mathematical(O) scientists(O) as(O) Joseph(B-scientist) Liouville(I-scientist) and(O) Michel(B-scientist) Chasles(I-scientist) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["theory","organization","event","location","academic journal","protein","astronomical object","chemical element","enzyme","scientist","person","country","university","discipline","award","chemical compound"],"instance":{"id":"100","words":["The","invitees","included","Walther","Bothe",",","Siegfried","Flgge",",","Hans","Geiger",",","Otto","Hahn",",","Paul","Harteck",",","Gerhard","Hoffmann",",","Josef","Mattauch",",","and","Georg","Stetter","."],"labels":["O","O","O","B-scientist","I-scientist","O","B-scientist","I-scientist","O","B-scientist","I-scientist","O","B-scientist","I-scientist","O","B-scientist","I-scientist","O","B-scientist","I-scientist","O","B-scientist","I-scientist","O","O","B-scientist","I-scientist","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: theory, organization, event, location, academic journal, protein, astronomical object, chemical element, enzyme, scientist, person, country, university, discipline, award, chemical compound and O.\nSentence: The invitees included Walther Bothe , Siegfried Flgge , Hans Geiger , Otto Hahn , Paul Harteck , Gerhard Hoffmann , Josef Mattauch , and Georg Stetter .","prompt_labels":"The(O) invitees(O) included(O) Walther(B-scientist) Bothe(I-scientist) ,(O) Siegfried(B-scientist) Flgge(I-scientist) ,(O) Hans(B-scientist) Geiger(I-scientist) ,(O) Otto(B-scientist) Hahn(I-scientist) ,(O) Paul(B-scientist) Harteck(I-scientist) ,(O) Gerhard(B-scientist) Hoffmann(I-scientist) ,(O) Josef(B-scientist) Mattauch(I-scientist) ,(O) and(O) Georg(B-scientist) Stetter(I-scientist) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["event","organization","theory","university","country","chemical element","academic journal","chemical compound","person","award","protein","location","enzyme","discipline","astronomical object","scientist"],"instance":{"id":"101","words":["Eggleton","is","the","author","and","coauthor","of","more","than","480","journal","publications",",","including","articles","in","Nature","Photonics",",","Nature","Physics",",","Nature","Communications",",","Physical","Review","Letters","and","Optica","and","over","200","invited","presentations","."],"labels":["B-scientist","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-academic journal","I-academic journal","O","B-academic journal","I-academic journal","O","B-academic journal","I-academic journal","O","B-academic journal","I-academic journal","I-academic journal","O","B-academic journal","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, organization, theory, university, country, chemical element, academic journal, chemical compound, person, award, protein, location, enzyme, discipline, astronomical object, scientist and O.\nSentence: Eggleton is the author and coauthor of more than 480 journal publications , including articles in Nature Photonics , Nature Physics , Nature Communications , Physical Review Letters and Optica and over 200 invited presentations .","prompt_labels":"Eggleton(B-scientist) is(O) the(O) author(O) and(O) coauthor(O) of(O) more(O) than(O) 480(O) journal(O) publications(O) ,(O) including(O) articles(O) in(O) Nature(B-academic journal) Photonics(I-academic journal) ,(O) Nature(B-academic journal) Physics(I-academic journal) ,(O) Nature(B-academic journal) Communications(I-academic journal) ,(O) Physical(B-academic journal) Review(I-academic journal) Letters(I-academic journal) and(O) Optica(B-academic journal) and(O) over(O) 200(O) invited(O) presentations(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["chemical compound","academic journal","astronomical object","scientist","enzyme","discipline","event","organization","protein","country","university","theory","location","chemical element","person","award"],"instance":{"id":"102","words":["It","is","operated","by","the","National","Centre","for","Radio","Astrophysics",",","a","part","of","the","Tata","Institute","of","Fundamental","Research",",","Mumbai","."],"labels":["O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","B-location","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: chemical compound, academic journal, astronomical object, scientist, enzyme, discipline, event, organization, protein, country, university, theory, location, chemical element, person, award and O.\nSentence: It is operated by the National Centre for Radio Astrophysics , a part of the Tata Institute of Fundamental Research , Mumbai .","prompt_labels":"It(O) is(O) operated(O) by(O) the(O) National(B-organization) Centre(I-organization) for(I-organization) Radio(I-organization) Astrophysics(I-organization) ,(O) a(O) part(O) of(O) the(O) Tata(B-organization) Institute(I-organization) of(I-organization) Fundamental(I-organization) Research(I-organization) ,(O) Mumbai(B-location) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["country","enzyme","chemical compound","academic journal","event","location","award","theory","university","scientist","discipline","astronomical object","chemical element","protein","organization","person"],"instance":{"id":"103","words":["The","Council","of","Europe","also","has","a","Congress","of","the","Council","of","Europe",",","similar","to","the","EU","'s","Committee","of","the","Regions","."],"labels":["O","B-organization","I-organization","I-organization","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, enzyme, chemical compound, academic journal, event, location, award, theory, university, scientist, discipline, astronomical object, chemical element, protein, organization, person and O.\nSentence: The Council of Europe also has a Congress of the Council of Europe , similar to the EU 's Committee of the Regions .","prompt_labels":"The(O) Council(B-organization) of(I-organization) Europe(I-organization) also(O) has(O) a(O) Congress(B-organization) of(I-organization) the(I-organization) Council(I-organization) of(I-organization) Europe(I-organization) ,(O) similar(O) to(O) the(O) EU(B-organization) 's(I-organization) Committee(I-organization) of(I-organization) the(I-organization) Regions(I-organization) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["discipline","event","award","astronomical object","location","country","theory","organization","academic journal","university","chemical compound","enzyme","chemical element","scientist","person","protein"],"instance":{"id":"104","words":["The","discovery","of","several","other","trans-Neptunian","object","s",",","such","as","50000","Quaoar","and","90377","Sedna",",","continued","to","erode","arguments","that","Pluto","was","exceptional","from","the","rest","of","the","trans-Neptunian","population","."],"labels":["O","O","O","O","O","B-astronomical object","O","O","O","O","O","B-astronomical object","I-astronomical object","O","B-astronomical object","I-astronomical object","O","O","O","O","O","O","B-astronomical object","O","O","O","O","O","O","O","B-astronomical object","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: discipline, event, award, astronomical object, location, country, theory, organization, academic journal, university, chemical compound, enzyme, chemical element, scientist, person, protein and O.\nSentence: The discovery of several other trans-Neptunian object s , such as 50000 Quaoar and 90377 Sedna , continued to erode arguments that Pluto was exceptional from the rest of the trans-Neptunian population .","prompt_labels":"The(O) discovery(O) of(O) several(O) other(O) trans-Neptunian(B-astronomical object) object(O) s(O) ,(O) such(O) as(O) 50000(B-astronomical object) Quaoar(I-astronomical object) and(O) 90377(B-astronomical object) Sedna(I-astronomical object) ,(O) continued(O) to(O) erode(O) arguments(O) that(O) Pluto(B-astronomical object) was(O) exceptional(O) from(O) the(O) rest(O) of(O) the(O) trans-Neptunian(B-astronomical object) population(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["country","person","astronomical object","discipline","event","university","scientist","award","location","protein","academic journal","chemical element","chemical compound","enzyme","theory","organization"],"instance":{"id":"105","words":["She","won","the","Tony","Award",",","Drama","Desk","Award",",","and","Outer","Critics","Circle","Award","for","the","Broadway","musical","Ragtime","."],"labels":["O","O","O","B-award","I-award","O","B-award","I-award","I-award","O","O","B-award","I-award","I-award","I-award","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, person, astronomical object, discipline, event, university, scientist, award, location, protein, academic journal, chemical element, chemical compound, enzyme, theory, organization and O.\nSentence: She won the Tony Award , Drama Desk Award , and Outer Critics Circle Award for the Broadway musical Ragtime .","prompt_labels":"She(O) won(O) the(O) Tony(B-award) Award(I-award) ,(O) Drama(B-award) Desk(I-award) Award(I-award) ,(O) and(O) Outer(B-award) Critics(I-award) Circle(I-award) Award(I-award) for(O) the(O) Broadway(O) musical(O) Ragtime(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["theory","organization","chemical element","academic journal","event","enzyme","person","country","discipline","university","award","astronomical object","chemical compound","location","scientist","protein"],"instance":{"id":"106","words":["Cotton","served","on","various","editorial","boards","of","scientific","journals",",","including","those","of","the","Journal","of","the","American","Chemical","Society",",","Inorganic","Chemistry",",","and","Organometallics","."],"labels":["B-scientist","O","O","O","O","O","O","O","O","O","O","O","O","O","B-academic journal","I-academic journal","I-academic journal","I-academic journal","I-academic journal","I-academic journal","O","B-academic journal","I-academic journal","O","O","B-academic journal","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: theory, organization, chemical element, academic journal, event, enzyme, person, country, discipline, university, award, astronomical object, chemical compound, location, scientist, protein and O.\nSentence: Cotton served on various editorial boards of scientific journals , including those of the Journal of the American Chemical Society , Inorganic Chemistry , and Organometallics .","prompt_labels":"Cotton(B-scientist) served(O) on(O) various(O) editorial(O) boards(O) of(O) scientific(O) journals(O) ,(O) including(O) those(O) of(O) the(O) Journal(B-academic journal) of(I-academic journal) the(I-academic journal) American(I-academic journal) Chemical(I-academic journal) Society(I-academic journal) ,(O) Inorganic(B-academic journal) Chemistry(I-academic journal) ,(O) and(O) Organometallics(B-academic journal) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["location","chemical element","country","theory","discipline","organization","university","astronomical object","protein","scientist","event","chemical compound","person","academic journal","enzyme","award"],"instance":{"id":"107","words":["The","Haldane","Lecture","at","the","John","Innes","Centre",",","of","The","Genetics","Society","is","also","named","in","his","honour","."],"labels":["O","B-award","I-award","O","O","B-location","I-location","I-location","O","O","B-organization","I-organization","I-organization","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, chemical element, country, theory, discipline, organization, university, astronomical object, protein, scientist, event, chemical compound, person, academic journal, enzyme, award and O.\nSentence: The Haldane Lecture at the John Innes Centre , of The Genetics Society is also named in his honour .","prompt_labels":"The(O) Haldane(B-award) Lecture(I-award) at(O) the(O) John(B-location) Innes(I-location) Centre(I-location) ,(O) of(O) The(B-organization) Genetics(I-organization) Society(I-organization) is(O) also(O) named(O) in(O) his(O) honour(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["theory","university","chemical element","location","academic journal","organization","award","country","discipline","event","scientist","person","astronomical object","protein","chemical compound","enzyme"],"instance":{"id":"108","words":["The","pyrimidines",",","thymine",",","cytosine","and","uracil",",","form","the","complementary","bases","to","the","purine","bases","in","DNA","and","RNA",",","and","are","also","components","of","Cytidine","triphosphate",",","Uridine","monophosphate",",","Uridine","diphosphate","and","Uridine","triphosphate","."],"labels":["O","B-chemical compound","O","B-chemical compound","O","B-chemical compound","O","B-chemical compound","O","O","O","O","O","O","O","B-chemical compound","O","O","O","O","O","O","O","O","O","O","O","B-chemical compound","I-chemical compound","O","B-chemical compound","I-chemical compound","O","B-chemical compound","I-chemical compound","O","B-chemical compound","I-chemical compound","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: theory, university, chemical element, location, academic journal, organization, award, country, discipline, event, scientist, person, astronomical object, protein, chemical compound, enzyme and O.\nSentence: The pyrimidines , thymine , cytosine and uracil , form the complementary bases to the purine bases in DNA and RNA , and are also components of Cytidine triphosphate , Uridine monophosphate , Uridine diphosphate and Uridine triphosphate .","prompt_labels":"The(O) pyrimidines(B-chemical compound) ,(O) thymine(B-chemical compound) ,(O) cytosine(B-chemical compound) and(O) uracil(B-chemical compound) ,(O) form(O) the(O) complementary(O) bases(O) to(O) the(O) purine(B-chemical compound) bases(O) in(O) DNA(O) and(O) RNA(O) ,(O) and(O) are(O) also(O) components(O) of(O) Cytidine(B-chemical compound) triphosphate(I-chemical compound) ,(O) Uridine(B-chemical compound) monophosphate(I-chemical compound) ,(O) Uridine(B-chemical compound) diphosphate(I-chemical compound) and(O) Uridine(B-chemical compound) triphosphate(I-chemical compound) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["protein","discipline","university","country","event","chemical element","organization","award","academic journal","theory","location","scientist","chemical compound","person","enzyme","astronomical object"],"instance":{"id":"109","words":["He","has","received","Academy","Awards",",","Grammy","Award",",","and","Golden","Globe","Award","s",",","and","he","is","an","inductee","to","the","Rock","and","Roll","Hall","of","Fame","."],"labels":["O","O","O","B-award","I-award","O","B-award","I-award","O","O","B-award","I-award","I-award","O","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: protein, discipline, university, country, event, chemical element, organization, award, academic journal, theory, location, scientist, chemical compound, person, enzyme, astronomical object and O.\nSentence: He has received Academy Awards , Grammy Award , and Golden Globe Award s , and he is an inductee to the Rock and Roll Hall of Fame .","prompt_labels":"He(O) has(O) received(O) Academy(B-award) Awards(I-award) ,(O) Grammy(B-award) Award(I-award) ,(O) and(O) Golden(B-award) Globe(I-award) Award(I-award) s(O) ,(O) and(O) he(O) is(O) an(O) inductee(O) to(O) the(O) Rock(B-organization) and(I-organization) Roll(I-organization) Hall(I-organization) of(I-organization) Fame(I-organization) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["theory","enzyme","location","astronomical object","country","scientist","organization","chemical element","discipline","event","person","award","academic journal","protein","university","chemical compound"],"instance":{"id":"110","words":["He","was","also","awarded","the","Eddington","Medal","of","the","Royal","Astronomical","Society","in","1969","."],"labels":["O","O","O","O","O","B-award","I-award","O","O","B-organization","I-organization","I-organization","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: theory, enzyme, location, astronomical object, country, scientist, organization, chemical element, discipline, event, person, award, academic journal, protein, university, chemical compound and O.\nSentence: He was also awarded the Eddington Medal of the Royal Astronomical Society in 1969 .","prompt_labels":"He(O) was(O) also(O) awarded(O) the(O) Eddington(B-award) Medal(I-award) of(O) the(O) Royal(B-organization) Astronomical(I-organization) Society(I-organization) in(O) 1969(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["country","award","location","protein","chemical element","theory","discipline","organization","person","chemical compound","academic journal","event","enzyme","astronomical object","scientist","university"],"instance":{"id":"111","words":["He","was","elected","to","the","National","Academy","of","Sciences","in","1879","and","received","the","1880","Rumford","Prize","from","the","American","Academy","of","Arts","and","Sciences","for","his","work","on","chemical","thermodynamics","."],"labels":["O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O","O","O","O","O","O","B-award","I-award","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","O","O","O","B-discipline","I-discipline","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, award, location, protein, chemical element, theory, discipline, organization, person, chemical compound, academic journal, event, enzyme, astronomical object, scientist, university and O.\nSentence: He was elected to the National Academy of Sciences in 1879 and received the 1880 Rumford Prize from the American Academy of Arts and Sciences for his work on chemical thermodynamics .","prompt_labels":"He(O) was(O) elected(O) to(O) the(O) National(B-organization) Academy(I-organization) of(I-organization) Sciences(I-organization) in(O) 1879(O) and(O) received(O) the(O) 1880(O) Rumford(B-award) Prize(I-award) from(O) the(O) American(B-organization) Academy(I-organization) of(I-organization) Arts(I-organization) and(I-organization) Sciences(I-organization) for(O) his(O) work(O) on(O) chemical(B-discipline) thermodynamics(I-discipline) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["chemical element","country","person","theory","location","award","organization","scientist","academic journal","event","chemical compound","discipline","enzyme","protein","astronomical object","university"],"instance":{"id":"112","words":["It","was","discovered","on","24","September","1960",",","by","astronomers","Cornelis","Johannes","van","Houten",",","Ingrid","van","Houten-Groeneveld","and","Tom","Gehrels","at","Palomar","Observatory","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-scientist","I-scientist","I-scientist","I-scientist","O","B-scientist","I-scientist","I-scientist","O","B-scientist","I-scientist","O","B-location","I-location","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: chemical element, country, person, theory, location, award, organization, scientist, academic journal, event, chemical compound, discipline, enzyme, protein, astronomical object, university and O.\nSentence: It was discovered on 24 September 1960 , by astronomers Cornelis Johannes van Houten , Ingrid van Houten-Groeneveld and Tom Gehrels at Palomar Observatory .","prompt_labels":"It(O) was(O) discovered(O) on(O) 24(O) September(O) 1960(O) ,(O) by(O) astronomers(O) Cornelis(B-scientist) Johannes(I-scientist) van(I-scientist) Houten(I-scientist) ,(O) Ingrid(B-scientist) van(I-scientist) Houten-Groeneveld(I-scientist) and(O) Tom(B-scientist) Gehrels(I-scientist) at(O) Palomar(B-location) Observatory(I-location) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["enzyme","chemical element","country","discipline","person","university","award","academic journal","astronomical object","protein","location","scientist","chemical compound","organization","event","theory"],"instance":{"id":"113","words":["Major","species","assessors","include","BirdLife","International",",","the","Institute","of","Zoology","(","the","research","division","of","the","Zoological","Society","of","London",")",",","the","World","Conservation","Monitoring","Centre",",","and","many","Specialist","Groups","within","the","IUCN","Species","Survival","Commission","(","SSC",")","."],"labels":["O","O","O","O","B-organization","I-organization","O","O","B-organization","I-organization","I-organization","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O","O","O","B-organization","I-organization","I-organization","I-organization","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O","B-organization","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: enzyme, chemical element, country, discipline, person, university, award, academic journal, astronomical object, protein, location, scientist, chemical compound, organization, event, theory and O.\nSentence: Major species assessors include BirdLife International , the Institute of Zoology ( the research division of the Zoological Society of London ) , the World Conservation Monitoring Centre , and many Specialist Groups within the IUCN Species Survival Commission ( SSC ) .","prompt_labels":"Major(O) species(O) assessors(O) include(O) BirdLife(B-organization) International(I-organization) ,(O) the(O) Institute(B-organization) of(I-organization) Zoology(I-organization) ((O) the(O) research(O) division(O) of(O) the(O) Zoological(B-organization) Society(I-organization) of(I-organization) London(I-organization) )(O) ,(O) the(O) World(B-organization) Conservation(I-organization) Monitoring(I-organization) Centre(I-organization) ,(O) and(O) many(O) Specialist(O) Groups(O) within(O) the(O) IUCN(B-organization) Species(I-organization) Survival(I-organization) Commission(I-organization) ((O) SSC(B-organization) )(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["event","award","university","organization","person","protein","enzyme","scientist","chemical element","astronomical object","discipline","chemical compound","theory","country","location","academic journal"],"instance":{"id":"114","words":["Uranus","is","similar","in","composition","to","Neptune",",","and","both","have","bulk","chemical","compositions","which","differ","from","that","of","the","larger","gas","giant","s","Jupiter","and","Saturn","."],"labels":["B-astronomical object","O","O","O","O","O","B-astronomical object","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-astronomical object","O","B-astronomical object","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, award, university, organization, person, protein, enzyme, scientist, chemical element, astronomical object, discipline, chemical compound, theory, country, location, academic journal and O.\nSentence: Uranus is similar in composition to Neptune , and both have bulk chemical compositions which differ from that of the larger gas giant s Jupiter and Saturn .","prompt_labels":"Uranus(B-astronomical object) is(O) similar(O) in(O) composition(O) to(O) Neptune(B-astronomical object) ,(O) and(O) both(O) have(O) bulk(O) chemical(O) compositions(O) which(O) differ(O) from(O) that(O) of(O) the(O) larger(O) gas(O) giant(O) s(O) Jupiter(B-astronomical object) and(O) Saturn(B-astronomical object) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["event","country","chemical compound","discipline","chemical element","academic journal","person","university","location","organization","scientist","award","astronomical object","enzyme","protein","theory"],"instance":{"id":"115","words":["In","1999",",","Haraway","received","the","Society","for","Social","Studies","of","Science","'","s","(","4S",")","Ludwik","Fleck","Prize","."],"labels":["O","O","O","B-scientist","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","O","O","B-organization","O","B-award","I-award","I-award","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, country, chemical compound, discipline, chemical element, academic journal, person, university, location, organization, scientist, award, astronomical object, enzyme, protein, theory and O.\nSentence: In 1999 , Haraway received the Society for Social Studies of Science ' s ( 4S ) Ludwik Fleck Prize .","prompt_labels":"In(O) 1999(O) ,(O) Haraway(B-scientist) received(O) the(O) Society(B-organization) for(I-organization) Social(I-organization) Studies(I-organization) of(I-organization) Science(I-organization) '(O) s(O) ((O) 4S(B-organization) )(O) Ludwik(B-award) Fleck(I-award) Prize(I-award) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["location","protein","chemical element","chemical compound","academic journal","discipline","event","country","astronomical object","scientist","person","organization","enzyme","university","theory","award"],"instance":{"id":"116","words":["Knowles","collaborated","with","several","studio","personalities",",","including","Jack","Splash",",","Shea","Taylor",",","Mr.","Familiar",",","Lamont","Dozier",",","production","teams","Soulshock","&","Karlin","and","Bama","Boyz",",","as","well","as","singers","and","rappers","Pharrell","Williams",",","Bilal",",","Q-Tip","and","Lil","Wayne","respectively","."],"labels":["B-person","O","O","O","O","O","O","O","B-person","I-person","O","B-person","I-person","O","B-person","I-person","O","B-person","I-person","O","O","O","B-organization","I-organization","I-organization","O","B-organization","I-organization","O","O","O","O","O","O","O","B-person","I-person","O","B-person","O","B-person","O","B-person","I-person","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, protein, chemical element, chemical compound, academic journal, discipline, event, country, astronomical object, scientist, person, organization, enzyme, university, theory, award and O.\nSentence: Knowles collaborated with several studio personalities , including Jack Splash , Shea Taylor , Mr. Familiar , Lamont Dozier , production teams Soulshock & Karlin and Bama Boyz , as well as singers and rappers Pharrell Williams , Bilal , Q-Tip and Lil Wayne respectively .","prompt_labels":"Knowles(B-person) collaborated(O) with(O) several(O) studio(O) personalities(O) ,(O) including(O) Jack(B-person) Splash(I-person) ,(O) Shea(B-person) Taylor(I-person) ,(O) Mr.(B-person) Familiar(I-person) ,(O) Lamont(B-person) Dozier(I-person) ,(O) production(O) teams(O) Soulshock(B-organization) &(I-organization) Karlin(I-organization) and(O) Bama(B-organization) Boyz(I-organization) ,(O) as(O) well(O) as(O) singers(O) and(O) rappers(O) Pharrell(B-person) Williams(I-person) ,(O) Bilal(B-person) ,(O) Q-Tip(B-person) and(O) Lil(B-person) Wayne(I-person) respectively(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["chemical compound","academic journal","award","location","discipline","protein","university","event","scientist","country","enzyme","theory","organization","person","astronomical object","chemical element"],"instance":{"id":"117","words":["Next","stations","were","the","University","of","Vienna",",","the","University","of","Krakw","and","finally","the","University","of","Gttingen",",","where","he","studied","mathematics","under","David","Hilbert",",","Woldemar","Voigt",",","Walther","Nernst",",","Karl","Schwarzschild","and","Hermann","Minkowski","."],"labels":["O","O","O","O","B-university","I-university","I-university","O","O","B-university","I-university","I-university","O","O","O","B-university","I-university","I-university","O","O","O","O","B-discipline","O","B-scientist","I-scientist","O","B-scientist","I-scientist","O","B-scientist","I-scientist","O","B-scientist","I-scientist","O","B-scientist","I-scientist","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: chemical compound, academic journal, award, location, discipline, protein, university, event, scientist, country, enzyme, theory, organization, person, astronomical object, chemical element and O.\nSentence: Next stations were the University of Vienna , the University of Krakw and finally the University of Gttingen , where he studied mathematics under David Hilbert , Woldemar Voigt , Walther Nernst , Karl Schwarzschild and Hermann Minkowski .","prompt_labels":"Next(O) stations(O) were(O) the(O) University(B-university) of(I-university) Vienna(I-university) ,(O) the(O) University(B-university) of(I-university) Krakw(I-university) and(O) finally(O) the(O) University(B-university) of(I-university) Gttingen(I-university) ,(O) where(O) he(O) studied(O) mathematics(B-discipline) under(O) David(B-scientist) Hilbert(I-scientist) ,(O) Woldemar(B-scientist) Voigt(I-scientist) ,(O) Walther(B-scientist) Nernst(I-scientist) ,(O) Karl(B-scientist) Schwarzschild(I-scientist) and(O) Hermann(B-scientist) Minkowski(I-scientist) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["astronomical object","person","country","scientist","discipline","enzyme","award","chemical compound","organization","academic journal","chemical element","location","protein","event","university","theory"],"instance":{"id":"118","words":["The","Dirac","Medal","of","the","ICTP","is","not","awarded","to","Nobel","Prize",",","Fields","Medal","ists",",","or","Wolf","Prize","winners","."],"labels":["O","B-award","I-award","I-award","I-award","I-award","O","O","O","O","B-award","I-award","O","B-award","I-award","O","O","O","B-award","I-award","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: astronomical object, person, country, scientist, discipline, enzyme, award, chemical compound, organization, academic journal, chemical element, location, protein, event, university, theory and O.\nSentence: The Dirac Medal of the ICTP is not awarded to Nobel Prize , Fields Medal ists , or Wolf Prize winners .","prompt_labels":"The(O) Dirac(B-award) Medal(I-award) of(I-award) the(I-award) ICTP(I-award) is(O) not(O) awarded(O) to(O) Nobel(B-award) Prize(I-award) ,(O) Fields(B-award) Medal(I-award) ists(O) ,(O) or(O) Wolf(B-award) Prize(I-award) winners(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["person","chemical compound","scientist","academic journal","event","astronomical object","country","protein","award","enzyme","theory","university","chemical element","location","organization","discipline"],"instance":{"id":"119","words":["Thus",",","Jupiter","and","Saturn","are","gas","giants",",","and","Uranus","and","Neptune","are","ice","giant","s",",","even","though","the","vast","majority","of","the","gas","and","ice","in","their","interiors","is","a","hot",",","highly","dense","fluid","that","gets","denser","as","the","center","of","the","planet","is","approached","."],"labels":["O","O","B-astronomical object","O","B-astronomical object","O","O","O","O","O","B-astronomical object","O","B-astronomical object","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, chemical compound, scientist, academic journal, event, astronomical object, country, protein, award, enzyme, theory, university, chemical element, location, organization, discipline and O.\nSentence: Thus , Jupiter and Saturn are gas giants , and Uranus and Neptune are ice giant s , even though the vast majority of the gas and ice in their interiors is a hot , highly dense fluid that gets denser as the center of the planet is approached .","prompt_labels":"Thus(O) ,(O) Jupiter(B-astronomical object) and(O) Saturn(B-astronomical object) are(O) gas(O) giants(O) ,(O) and(O) Uranus(B-astronomical object) and(O) Neptune(B-astronomical object) are(O) ice(O) giant(O) s(O) ,(O) even(O) though(O) the(O) vast(O) majority(O) of(O) the(O) gas(O) and(O) ice(O) in(O) their(O) interiors(O) is(O) a(O) hot(O) ,(O) highly(O) dense(O) fluid(O) that(O) gets(O) denser(O) as(O) the(O) center(O) of(O) the(O) planet(O) is(O) approached(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["country","scientist","discipline","enzyme","organization","astronomical object","protein","academic journal","location","theory","chemical compound","award","person","event","university","chemical element"],"instance":{"id":"120","words":["GSK-3","has","been","implicated","in","bipolar","disorder",",","as","bipolar","medications","lithium","and","valproate","have","been","shown","to","increase","its","phosphorylation",",","thereby","inhibiting","it","."],"labels":["B-protein","O","O","O","O","O","O","O","O","O","O","B-chemical element","O","B-chemical compound","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, scientist, discipline, enzyme, organization, astronomical object, protein, academic journal, location, theory, chemical compound, award, person, event, university, chemical element and O.\nSentence: GSK-3 has been implicated in bipolar disorder , as bipolar medications lithium and valproate have been shown to increase its phosphorylation , thereby inhibiting it .","prompt_labels":"GSK-3(B-protein) has(O) been(O) implicated(O) in(O) bipolar(O) disorder(O) ,(O) as(O) bipolar(O) medications(O) lithium(B-chemical element) and(O) valproate(B-chemical compound) have(O) been(O) shown(O) to(O) increase(O) its(O) phosphorylation(O) ,(O) thereby(O) inhibiting(O) it(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["chemical compound","country","event","chemical element","protein","university","discipline","theory","organization","award","enzyme","astronomical object","location","academic journal","scientist","person"],"instance":{"id":"121","words":["This","subcategory","includes","Pluto",",","Haumea",",","Makemake","and","Eris","."],"labels":["O","O","O","B-astronomical object","O","B-astronomical object","O","B-astronomical object","O","B-astronomical object","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: chemical compound, country, event, chemical element, protein, university, discipline, theory, organization, award, enzyme, astronomical object, location, academic journal, scientist, person and O.\nSentence: This subcategory includes Pluto , Haumea , Makemake and Eris .","prompt_labels":"This(O) subcategory(O) includes(O) Pluto(B-astronomical object) ,(O) Haumea(B-astronomical object) ,(O) Makemake(B-astronomical object) and(O) Eris(B-astronomical object) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["enzyme","protein","discipline","location","country","astronomical object","chemical element","scientist","chemical compound","event","academic journal","person","theory","award","organization","university"],"instance":{"id":"122","words":["Since","then",",","names","have","been","given","to","134","additional","satellites",":","57","satellites","of","Jupiter",",","43","of","Saturn",",","22","of","Uranus",",","12","of","Neptune",",","5","of","Pluto",",","1","of","Eris",",","and","2","of","Haumea","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-astronomical object","O","O","O","B-astronomical object","O","O","O","B-astronomical object","O","O","O","B-astronomical object","O","O","O","B-astronomical object","O","O","O","B-astronomical object","O","O","O","O","B-astronomical object","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: enzyme, protein, discipline, location, country, astronomical object, chemical element, scientist, chemical compound, event, academic journal, person, theory, award, organization, university and O.\nSentence: Since then , names have been given to 134 additional satellites : 57 satellites of Jupiter , 43 of Saturn , 22 of Uranus , 12 of Neptune , 5 of Pluto , 1 of Eris , and 2 of Haumea .","prompt_labels":"Since(O) then(O) ,(O) names(O) have(O) been(O) given(O) to(O) 134(O) additional(O) satellites(O) :(O) 57(O) satellites(O) of(O) Jupiter(B-astronomical object) ,(O) 43(O) of(O) Saturn(B-astronomical object) ,(O) 22(O) of(O) Uranus(B-astronomical object) ,(O) 12(O) of(O) Neptune(B-astronomical object) ,(O) 5(O) of(O) Pluto(B-astronomical object) ,(O) 1(O) of(O) Eris(B-astronomical object) ,(O) and(O) 2(O) of(O) Haumea(B-astronomical object) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["award","person","chemical element","country","location","theory","organization","chemical compound","scientist","university","protein","discipline","enzyme","event","astronomical object","academic journal"],"instance":{"id":"123","words":["A","super-Earth","is","an","extrasolar","planet","with","a","mass","higher","than","Earth","'","s",",","but","substantially","below","those","of","the","Solar","System","'s","ice","giant","s",",","Uranus","and","Neptune",",","which","are","14.5","and","17","times","Earth","'s",",","respectively","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","B-astronomical object","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-astronomical object","O","B-astronomical object","O","O","O","O","O","O","O","B-astronomical object","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, person, chemical element, country, location, theory, organization, chemical compound, scientist, university, protein, discipline, enzyme, event, astronomical object, academic journal and O.\nSentence: A super-Earth is an extrasolar planet with a mass higher than Earth ' s , but substantially below those of the Solar System 's ice giant s , Uranus and Neptune , which are 14.5 and 17 times Earth 's , respectively .","prompt_labels":"A(O) super-Earth(O) is(O) an(O) extrasolar(O) planet(O) with(O) a(O) mass(O) higher(O) than(O) Earth(B-astronomical object) '(O) s(O) ,(O) but(O) substantially(O) below(O) those(O) of(O) the(O) Solar(O) System(O) 's(O) ice(O) giant(O) s(O) ,(O) Uranus(B-astronomical object) and(O) Neptune(B-astronomical object) ,(O) which(O) are(O) 14.5(O) and(O) 17(O) times(O) Earth(B-astronomical object) 's(O) ,(O) respectively(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["protein","discipline","academic journal","event","theory","chemical element","person","astronomical object","country","location","award","organization","scientist","enzyme","university","chemical compound"],"instance":{"id":"124","words":["Cooper","was","a","member","of","the","Society","of","Experimental","Test","Pilots",",","the","American","Institute","of","Aeronautics","and","Astronautics",",","the","American","Astronautical","Society",",","Scottish","Rite","and","York","Rite","Masons",",","Shriners",",","the","Royal","Order","of","Jesters",",","the","Rotary","Club",",","Order","of","Daedalians",",","Confederate","Air","Force",",","Adventurers","'","Club","of","Los","Angeles",",","and","Boy","Scouts","of","America","."],"labels":["B-person","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","O","O","O","O","O","O","O","O","B-organization","O","O","B-organization","I-organization","I-organization","I-organization","O","O","B-organization","I-organization","O","B-organization","I-organization","I-organization","O","B-organization","I-organization","I-organization","O","B-organization","I-organization","I-organization","O","B-location","I-location","O","O","B-organization","I-organization","I-organization","I-organization","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: protein, discipline, academic journal, event, theory, chemical element, person, astronomical object, country, location, award, organization, scientist, enzyme, university, chemical compound and O.\nSentence: Cooper was a member of the Society of Experimental Test Pilots , the American Institute of Aeronautics and Astronautics , the American Astronautical Society , Scottish Rite and York Rite Masons , Shriners , the Royal Order of Jesters , the Rotary Club , Order of Daedalians , Confederate Air Force , Adventurers ' Club of Los Angeles , and Boy Scouts of America .","prompt_labels":"Cooper(B-person) was(O) a(O) member(O) of(O) the(O) Society(B-organization) of(I-organization) Experimental(I-organization) Test(I-organization) Pilots(I-organization) ,(O) the(O) American(B-organization) Institute(I-organization) of(I-organization) Aeronautics(I-organization) and(I-organization) Astronautics(I-organization) ,(O) the(O) American(B-organization) Astronautical(I-organization) Society(I-organization) ,(O) Scottish(O) Rite(O) and(O) York(O) Rite(O) Masons(O) ,(O) Shriners(B-organization) ,(O) the(O) Royal(B-organization) Order(I-organization) of(I-organization) Jesters(I-organization) ,(O) the(O) Rotary(B-organization) Club(I-organization) ,(O) Order(B-organization) of(I-organization) Daedalians(I-organization) ,(O) Confederate(B-organization) Air(I-organization) Force(I-organization) ,(O) Adventurers(B-organization) '(I-organization) Club(I-organization) of(O) Los(B-location) Angeles(I-location) ,(O) and(O) Boy(B-organization) Scouts(I-organization) of(I-organization) America(I-organization) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["academic journal","chemical compound","event","astronomical object","university","organization","location","person","chemical element","discipline","enzyme","protein","country","award","theory","scientist"],"instance":{"id":"125","words":["Indeed",",","almost","the","entire","generation","of","physicists","and","mathematicians","who","came","to","maturity","in","the","1820s","-","Pouillet",",","Savart",",","Gabriel","Lam",",","Claude-Louis","Navier",",","Joseph","Liouville",",","Cauchy","-","seem","to","have","adopted","the","theory","immediately","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-scientist","O","B-scientist","O","B-scientist","I-scientist","O","B-scientist","I-scientist","O","B-scientist","I-scientist","O","B-scientist","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: academic journal, chemical compound, event, astronomical object, university, organization, location, person, chemical element, discipline, enzyme, protein, country, award, theory, scientist and O.\nSentence: Indeed , almost the entire generation of physicists and mathematicians who came to maturity in the 1820s - Pouillet , Savart , Gabriel Lam , Claude-Louis Navier , Joseph Liouville , Cauchy - seem to have adopted the theory immediately .","prompt_labels":"Indeed(O) ,(O) almost(O) the(O) entire(O) generation(O) of(O) physicists(O) and(O) mathematicians(O) who(O) came(O) to(O) maturity(O) in(O) the(O) 1820s(O) -(O) Pouillet(B-scientist) ,(O) Savart(B-scientist) ,(O) Gabriel(B-scientist) Lam(I-scientist) ,(O) Claude-Louis(B-scientist) Navier(I-scientist) ,(O) Joseph(B-scientist) Liouville(I-scientist) ,(O) Cauchy(B-scientist) -(O) seem(O) to(O) have(O) adopted(O) the(O) theory(O) immediately(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["award","country","academic journal","scientist","location","person","event","chemical element","protein","enzyme","discipline","university","theory","astronomical object","chemical compound","organization"],"instance":{"id":"126","words":["The","maximum","and","minimum","brightness","of","Jupiter","differ","by","only","a","factor","of","3.3","times",",","whilst","those","of","Uranus",";","which","is","the","most","distant","Solar","System","body","visible","to","the","naked","eye",";","differ","by","a","factor","of","1.7","times","."],"labels":["O","O","O","O","O","O","B-astronomical object","O","O","O","O","O","O","O","O","O","O","O","O","B-astronomical object","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, country, academic journal, scientist, location, person, event, chemical element, protein, enzyme, discipline, university, theory, astronomical object, chemical compound, organization and O.\nSentence: The maximum and minimum brightness of Jupiter differ by only a factor of 3.3 times , whilst those of Uranus ; which is the most distant Solar System body visible to the naked eye ; differ by a factor of 1.7 times .","prompt_labels":"The(O) maximum(O) and(O) minimum(O) brightness(O) of(O) Jupiter(B-astronomical object) differ(O) by(O) only(O) a(O) factor(O) of(O) 3.3(O) times(O) ,(O) whilst(O) those(O) of(O) Uranus(B-astronomical object) ;(O) which(O) is(O) the(O) most(O) distant(O) Solar(O) System(O) body(O) visible(O) to(O) the(O) naked(O) eye(O) ;(O) differ(O) by(O) a(O) factor(O) of(O) 1.7(O) times(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["country","discipline","person","academic journal","theory","chemical element","astronomical object","university","location","protein","event","organization","award","enzyme","chemical compound","scientist"],"instance":{"id":"127","words":["Portions","of","Galveston","County","are","served","by","College","of","the","Mainland","and","Galveston","College","."],"labels":["O","O","B-location","I-location","O","O","O","B-university","I-university","I-university","I-university","O","B-university","I-university","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, discipline, person, academic journal, theory, chemical element, astronomical object, university, location, protein, event, organization, award, enzyme, chemical compound, scientist and O.\nSentence: Portions of Galveston County are served by College of the Mainland and Galveston College .","prompt_labels":"Portions(O) of(O) Galveston(B-location) County(I-location) are(O) served(O) by(O) College(B-university) of(I-university) the(I-university) Mainland(I-university) and(O) Galveston(B-university) College(I-university) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["person","chemical compound","award","event","country","scientist","organization","theory","chemical element","astronomical object","location","university","discipline","protein","enzyme","academic journal"],"instance":{"id":"128","words":["This","range",",","as","well","as","the","relative","speeds","between","the","planets",",","led","Kepler","to","conclude","that","the","Solar","System","was","composed","of","two","basses","(","Saturn","and","Jupiter",")",",","a","tenor","(","Mars",")",",","two","altos","(","Venus","and","Earth",")",",","and","a","soprano","(","Mercury",")",",","which","had","sung","in","perfect","concord",",","at","the","beginning","of","time",",","and","could","potentially","arrange","themselves","to","do","so","again","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-scientist","O","O","O","O","O","O","O","O","O","O","O","O","B-astronomical object","O","B-astronomical object","O","O","O","O","O","B-astronomical object","O","O","O","O","O","B-astronomical object","O","B-astronomical object","O","O","O","O","O","O","B-astronomical object","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, chemical compound, award, event, country, scientist, organization, theory, chemical element, astronomical object, location, university, discipline, protein, enzyme, academic journal and O.\nSentence: This range , as well as the relative speeds between the planets , led Kepler to conclude that the Solar System was composed of two basses ( Saturn and Jupiter ) , a tenor ( Mars ) , two altos ( Venus and Earth ) , and a soprano ( Mercury ) , which had sung in perfect concord , at the beginning of time , and could potentially arrange themselves to do so again .","prompt_labels":"This(O) range(O) ,(O) as(O) well(O) as(O) the(O) relative(O) speeds(O) between(O) the(O) planets(O) ,(O) led(O) Kepler(B-scientist) to(O) conclude(O) that(O) the(O) Solar(O) System(O) was(O) composed(O) of(O) two(O) basses(O) ((O) Saturn(B-astronomical object) and(O) Jupiter(B-astronomical object) )(O) ,(O) a(O) tenor(O) ((O) Mars(B-astronomical object) )(O) ,(O) two(O) altos(O) ((O) Venus(B-astronomical object) and(O) Earth(B-astronomical object) )(O) ,(O) and(O) a(O) soprano(O) ((O) Mercury(B-astronomical object) )(O) ,(O) which(O) had(O) sung(O) in(O) perfect(O) concord(O) ,(O) at(O) the(O) beginning(O) of(O) time(O) ,(O) and(O) could(O) potentially(O) arrange(O) themselves(O) to(O) do(O) so(O) again(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["discipline","award","chemical element","astronomical object","organization","person","scientist","location","event","academic journal","theory","chemical compound","protein","university","country","enzyme"],"instance":{"id":"129","words":["Many","families","of","proteins","act","as","negative","regulators","categorized","into","either","antiapoptotic","factors",",","such","as","IAP","nowiki","\/","s","and","Bcl-2","family","proteins","or","prosurvival","factors","like","cFLIP",",","BNIP3",",","FADD",",","Protein","kinase","B",",","and","NF-B","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-protein","O","O","O","O","B-protein","I-protein","O","O","O","O","O","B-protein","O","B-protein","O","B-protein","O","B-protein","I-protein","I-protein","O","O","B-protein","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: discipline, award, chemical element, astronomical object, organization, person, scientist, location, event, academic journal, theory, chemical compound, protein, university, country, enzyme and O.\nSentence: Many families of proteins act as negative regulators categorized into either antiapoptotic factors , such as IAP nowiki \/ s and Bcl-2 family proteins or prosurvival factors like cFLIP , BNIP3 , FADD , Protein kinase B , and NF-B .","prompt_labels":"Many(O) families(O) of(O) proteins(O) act(O) as(O) negative(O) regulators(O) categorized(O) into(O) either(O) antiapoptotic(O) factors(O) ,(O) such(O) as(O) IAP(B-protein) nowiki(O) \/(O) s(O) and(O) Bcl-2(B-protein) family(I-protein) proteins(O) or(O) prosurvival(O) factors(O) like(O) cFLIP(B-protein) ,(O) BNIP3(B-protein) ,(O) FADD(B-protein) ,(O) Protein(B-protein) kinase(I-protein) B(I-protein) ,(O) and(O) NF-B(B-protein) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["chemical element","event","chemical compound","award","university","location","organization","scientist","person","astronomical object","academic journal","enzyme","discipline","theory","country","protein"],"instance":{"id":"130","words":["Seven","other","objects","are","classified","as","both","periodic","comets","and","numbered","asteroids",":","2060","Chiron","(","95P","\/","Chiron",")",",","4015","Wilson-Harrington","(","107P","\/","Wilson-Harrington",")",",","7968","Elst-Pizarro","(","133P","\/","Elst-Pizarro",")",",","60558","Echeclus","(","174P","\/","Echeclus",")",",","(","362P","\/","2008","GOsub98","\/","sub",")","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","B-astronomical object","I-astronomical object","O","B-astronomical object","I-astronomical object","I-astronomical object","O","O","B-astronomical object","I-astronomical object","O","B-astronomical object","I-astronomical object","I-astronomical object","O","O","B-astronomical object","I-astronomical object","O","B-astronomical object","I-astronomical object","I-astronomical object","O","O","B-astronomical object","I-astronomical object","O","B-astronomical object","I-astronomical object","I-astronomical object","O","O","O","B-astronomical object","I-astronomical object","I-astronomical object","I-astronomical object","I-astronomical object","I-astronomical object","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: chemical element, event, chemical compound, award, university, location, organization, scientist, person, astronomical object, academic journal, enzyme, discipline, theory, country, protein and O.\nSentence: Seven other objects are classified as both periodic comets and numbered asteroids : 2060 Chiron ( 95P \/ Chiron ) , 4015 Wilson-Harrington ( 107P \/ Wilson-Harrington ) , 7968 Elst-Pizarro ( 133P \/ Elst-Pizarro ) , 60558 Echeclus ( 174P \/ Echeclus ) , ( 362P \/ 2008 GOsub98 \/ sub ) .","prompt_labels":"Seven(O) other(O) objects(O) are(O) classified(O) as(O) both(O) periodic(O) comets(O) and(O) numbered(O) asteroids(O) :(O) 2060(B-astronomical object) Chiron(I-astronomical object) ((O) 95P(B-astronomical object) \/(I-astronomical object) Chiron(I-astronomical object) )(O) ,(O) 4015(B-astronomical object) Wilson-Harrington(I-astronomical object) ((O) 107P(B-astronomical object) \/(I-astronomical object) Wilson-Harrington(I-astronomical object) )(O) ,(O) 7968(B-astronomical object) Elst-Pizarro(I-astronomical object) ((O) 133P(B-astronomical object) \/(I-astronomical object) Elst-Pizarro(I-astronomical object) )(O) ,(O) 60558(B-astronomical object) Echeclus(I-astronomical object) ((O) 174P(B-astronomical object) \/(I-astronomical object) Echeclus(I-astronomical object) )(O) ,(O) ((O) 362P(B-astronomical object) \/(I-astronomical object) 2008(I-astronomical object) GOsub98(I-astronomical object) \/(I-astronomical object) sub(I-astronomical object) )(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["scientist","discipline","location","theory","country","astronomical object","protein","enzyme","event","academic journal","chemical element","person","award","organization","chemical compound","university"],"instance":{"id":"131","words":["Wasserburg","completed","his","Ph.D.","from","the","University","of","Chicago","in","1954",",","with","a","thesis","on","the","development","of","K-Ar","dating",",","done","under","the","sponsorship","of","Harold","Urey","and","Mark","Inghram","."],"labels":["B-scientist","O","O","O","O","O","B-university","I-university","I-university","O","O","O","O","O","O","O","O","O","O","B-theory","I-theory","O","O","O","O","O","O","B-scientist","I-scientist","O","B-scientist","I-scientist","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: scientist, discipline, location, theory, country, astronomical object, protein, enzyme, event, academic journal, chemical element, person, award, organization, chemical compound, university and O.\nSentence: Wasserburg completed his Ph.D. from the University of Chicago in 1954 , with a thesis on the development of K-Ar dating , done under the sponsorship of Harold Urey and Mark Inghram .","prompt_labels":"Wasserburg(B-scientist) completed(O) his(O) Ph.D.(O) from(O) the(O) University(B-university) of(I-university) Chicago(I-university) in(O) 1954(O) ,(O) with(O) a(O) thesis(O) on(O) the(O) development(O) of(O) K-Ar(B-theory) dating(I-theory) ,(O) done(O) under(O) the(O) sponsorship(O) of(O) Harold(B-scientist) Urey(I-scientist) and(O) Mark(B-scientist) Inghram(I-scientist) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["academic journal","country","scientist","location","chemical element","chemical compound","astronomical object","university","person","theory","award","protein","discipline","enzyme","organization","event"],"instance":{"id":"132","words":["At","Rockefeller","University","he","worked","on","macrophage","Fc","receptor","s","and","lysosomal","proteases","."],"labels":["O","B-university","I-university","O","O","O","B-protein","I-protein","I-protein","O","O","B-enzyme","I-enzyme","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: academic journal, country, scientist, location, chemical element, chemical compound, astronomical object, university, person, theory, award, protein, discipline, enzyme, organization, event and O.\nSentence: At Rockefeller University he worked on macrophage Fc receptor s and lysosomal proteases .","prompt_labels":"At(O) Rockefeller(B-university) University(I-university) he(O) worked(O) on(O) macrophage(B-protein) Fc(I-protein) receptor(I-protein) s(O) and(O) lysosomal(B-enzyme) proteases(I-enzyme) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["chemical compound","country","person","award","organization","discipline","astronomical object","chemical element","theory","location","university","scientist","enzyme","event","academic journal","protein"],"instance":{"id":"133","words":["The","term","redox","state","is","often","used","to","describe","the","balance","of","Glutathione",",","NADsup","+","\/","sup","\/","NADH","and","Nicotinamide","adenine","dinucleotide","phosphate","in","a","biological","system","such","as","a","cell","or","organ","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","B-chemical compound","O","B-chemical compound","I-chemical compound","I-chemical compound","I-chemical compound","I-chemical compound","I-chemical compound","O","B-chemical compound","I-chemical compound","I-chemical compound","I-chemical compound","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: chemical compound, country, person, award, organization, discipline, astronomical object, chemical element, theory, location, university, scientist, enzyme, event, academic journal, protein and O.\nSentence: The term redox state is often used to describe the balance of Glutathione , NADsup + \/ sup \/ NADH and Nicotinamide adenine dinucleotide phosphate in a biological system such as a cell or organ .","prompt_labels":"The(O) term(O) redox(O) state(O) is(O) often(O) used(O) to(O) describe(O) the(O) balance(O) of(O) Glutathione(B-chemical compound) ,(O) NADsup(B-chemical compound) +(I-chemical compound) \/(I-chemical compound) sup(I-chemical compound) \/(I-chemical compound) NADH(I-chemical compound) and(O) Nicotinamide(B-chemical compound) adenine(I-chemical compound) dinucleotide(I-chemical compound) phosphate(I-chemical compound) in(O) a(O) biological(O) system(O) such(O) as(O) a(O) cell(O) or(O) organ(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["protein","award","theory","chemical element","enzyme","country","location","astronomical object","event","scientist","organization","university","discipline","academic journal","person","chemical compound"],"instance":{"id":"134","words":["The","Montreal","Neurological","Institute",",","the","former","Royal","Victoria","Hospital",",","Allan","Memorial","Institute","and","the","Montreal","General","Hospital","of","McGill","University","are","on","Pine","Avenue",",","as","is","Cormier","House",",","the","former","residence","of","Pierre","Elliott","Trudeau","."],"labels":["O","B-organization","I-organization","I-organization","O","O","O","B-organization","I-organization","I-organization","O","B-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","O","B-location","I-location","O","O","O","B-location","I-location","O","O","O","O","O","B-person","I-person","I-person","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: protein, award, theory, chemical element, enzyme, country, location, astronomical object, event, scientist, organization, university, discipline, academic journal, person, chemical compound and O.\nSentence: The Montreal Neurological Institute , the former Royal Victoria Hospital , Allan Memorial Institute and the Montreal General Hospital of McGill University are on Pine Avenue , as is Cormier House , the former residence of Pierre Elliott Trudeau .","prompt_labels":"The(O) Montreal(B-organization) Neurological(I-organization) Institute(I-organization) ,(O) the(O) former(O) Royal(B-organization) Victoria(I-organization) Hospital(I-organization) ,(O) Allan(B-organization) Memorial(I-organization) Institute(I-organization) and(O) the(O) Montreal(B-organization) General(I-organization) Hospital(I-organization) of(I-organization) McGill(I-organization) University(I-organization) are(O) on(O) Pine(B-location) Avenue(I-location) ,(O) as(O) is(O) Cormier(B-location) House(I-location) ,(O) the(O) former(O) residence(O) of(O) Pierre(B-person) Elliott(I-person) Trudeau(I-person) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["event","chemical compound","protein","enzyme","person","country","award","academic journal","organization","chemical element","discipline","university","scientist","location","theory","astronomical object"],"instance":{"id":"135","words":["In","Oct","2002","and","after",",","Science",",","Physical","Review",",","and","Applied","Physics","Letters","withdrew","more","than","a","dozen","papers","."],"labels":["O","O","O","O","O","O","B-academic journal","O","B-academic journal","I-academic journal","O","O","B-academic journal","I-academic journal","I-academic journal","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, chemical compound, protein, enzyme, person, country, award, academic journal, organization, chemical element, discipline, university, scientist, location, theory, astronomical object and O.\nSentence: In Oct 2002 and after , Science , Physical Review , and Applied Physics Letters withdrew more than a dozen papers .","prompt_labels":"In(O) Oct(O) 2002(O) and(O) after(O) ,(O) Science(B-academic journal) ,(O) Physical(B-academic journal) Review(I-academic journal) ,(O) and(O) Applied(B-academic journal) Physics(I-academic journal) Letters(I-academic journal) withdrew(O) more(O) than(O) a(O) dozen(O) papers(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["enzyme","award","location","university","discipline","organization","country","theory","event","protein","astronomical object","scientist","person","chemical element","chemical compound","academic journal"],"instance":{"id":"136","words":["Gas","giants","with","a","large","radius","and","very","low","density","are","sometimes","called","puffy","planets","COROT-1b",",","TrES-4",",","WASP-12b",",","WASP-17b",",","and","Kepler-7b","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-astronomical object","O","B-astronomical object","O","B-astronomical object","O","B-astronomical object","O","O","B-astronomical object","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: enzyme, award, location, university, discipline, organization, country, theory, event, protein, astronomical object, scientist, person, chemical element, chemical compound, academic journal and O.\nSentence: Gas giants with a large radius and very low density are sometimes called puffy planets COROT-1b , TrES-4 , WASP-12b , WASP-17b , and Kepler-7b .","prompt_labels":"Gas(O) giants(O) with(O) a(O) large(O) radius(O) and(O) very(O) low(O) density(O) are(O) sometimes(O) called(O) puffy(O) planets(O) COROT-1b(B-astronomical object) ,(O) TrES-4(B-astronomical object) ,(O) WASP-12b(B-astronomical object) ,(O) WASP-17b(B-astronomical object) ,(O) and(O) Kepler-7b(B-astronomical object) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["person","chemical element","university","astronomical object","theory","event","country","discipline","chemical compound","award","scientist","organization","enzyme","location","protein","academic journal"],"instance":{"id":"137","words":["Garca-Sastre","is","an","editor","for","the","Journal","of","Experimental","Medicine","and","PLOS","Pathogens",",","and","he","sits","on","the","editorial","boards","of","the","Journal","of","Virology",",","Virology",",","Virus","Research","and","the","Journal","of","General","Virology","."],"labels":["B-scientist","O","O","O","O","O","B-academic journal","I-academic journal","I-academic journal","I-academic journal","O","B-academic journal","I-academic journal","O","O","O","O","O","O","O","O","O","O","B-academic journal","I-academic journal","I-academic journal","O","B-academic journal","O","B-academic journal","I-academic journal","O","O","B-academic journal","I-academic journal","I-academic journal","I-academic journal","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, chemical element, university, astronomical object, theory, event, country, discipline, chemical compound, award, scientist, organization, enzyme, location, protein, academic journal and O.\nSentence: Garca-Sastre is an editor for the Journal of Experimental Medicine and PLOS Pathogens , and he sits on the editorial boards of the Journal of Virology , Virology , Virus Research and the Journal of General Virology .","prompt_labels":"Garca-Sastre(B-scientist) is(O) an(O) editor(O) for(O) the(O) Journal(B-academic journal) of(I-academic journal) Experimental(I-academic journal) Medicine(I-academic journal) and(O) PLOS(B-academic journal) Pathogens(I-academic journal) ,(O) and(O) he(O) sits(O) on(O) the(O) editorial(O) boards(O) of(O) the(O) Journal(B-academic journal) of(I-academic journal) Virology(I-academic journal) ,(O) Virology(B-academic journal) ,(O) Virus(B-academic journal) Research(I-academic journal) and(O) the(O) Journal(B-academic journal) of(I-academic journal) General(I-academic journal) Virology(I-academic journal) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["location","person","protein","organization","country","scientist","award","event","chemical element","enzyme","astronomical object","university","discipline","theory","chemical compound","academic journal"],"instance":{"id":"138","words":["catalyzed","by","Phosphoenolpyruvate","carboxylase","(","PEPC",")",",","to","carboxylate","phosphoenolpyruvate","(","PEP",")","to","oxaloacetate","(","OAA",")","which","is","a","Csub4","\/","sub","dicarboxylic","acid","."],"labels":["O","O","B-enzyme","I-enzyme","O","B-enzyme","O","O","O","B-chemical compound","I-chemical compound","O","B-chemical compound","O","O","B-chemical compound","O","B-chemical compound","O","O","O","O","B-chemical compound","I-chemical compound","I-chemical compound","I-chemical compound","I-chemical compound","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, person, protein, organization, country, scientist, award, event, chemical element, enzyme, astronomical object, university, discipline, theory, chemical compound, academic journal and O.\nSentence: catalyzed by Phosphoenolpyruvate carboxylase ( PEPC ) , to carboxylate phosphoenolpyruvate ( PEP ) to oxaloacetate ( OAA ) which is a Csub4 \/ sub dicarboxylic acid .","prompt_labels":"catalyzed(O) by(O) Phosphoenolpyruvate(B-enzyme) carboxylase(I-enzyme) ((O) PEPC(B-enzyme) )(O) ,(O) to(O) carboxylate(B-chemical compound) phosphoenolpyruvate(I-chemical compound) ((O) PEP(B-chemical compound) )(O) to(O) oxaloacetate(B-chemical compound) ((O) OAA(B-chemical compound) )(O) which(O) is(O) a(O) Csub4(B-chemical compound) \/(I-chemical compound) sub(I-chemical compound) dicarboxylic(I-chemical compound) acid(I-chemical compound) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["protein","country","enzyme","scientist","theory","chemical compound","discipline","chemical element","university","organization","event","award","person","location","astronomical object","academic journal"],"instance":{"id":"139","words":["Some","of","these","mechanisms","include","ATP-dependent","chromatin","remodeling",",","LINE1",",","and","prion","protein-based","modifications","."],"labels":["O","O","O","O","O","O","O","O","O","B-protein","O","O","B-protein","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: protein, country, enzyme, scientist, theory, chemical compound, discipline, chemical element, university, organization, event, award, person, location, astronomical object, academic journal and O.\nSentence: Some of these mechanisms include ATP-dependent chromatin remodeling , LINE1 , and prion protein-based modifications .","prompt_labels":"Some(O) of(O) these(O) mechanisms(O) include(O) ATP-dependent(O) chromatin(O) remodeling(O) ,(O) LINE1(B-protein) ,(O) and(O) prion(B-protein) protein-based(O) modifications(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["university","country","academic journal","discipline","astronomical object","chemical element","scientist","event","award","enzyme","organization","chemical compound","protein","person","theory","location"],"instance":{"id":"140","words":["Later",",","scientists","such","as","Ludwig","Boltzmann",",","Josiah","Willard","Gibbs",",","and","James","Clerk","Maxwell","gave","entropy","a","statistical","basis","."],"labels":["O","O","O","O","O","B-scientist","I-scientist","O","B-scientist","I-scientist","I-scientist","O","O","B-scientist","I-scientist","I-scientist","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: university, country, academic journal, discipline, astronomical object, chemical element, scientist, event, award, enzyme, organization, chemical compound, protein, person, theory, location and O.\nSentence: Later , scientists such as Ludwig Boltzmann , Josiah Willard Gibbs , and James Clerk Maxwell gave entropy a statistical basis .","prompt_labels":"Later(O) ,(O) scientists(O) such(O) as(O) Ludwig(B-scientist) Boltzmann(I-scientist) ,(O) Josiah(B-scientist) Willard(I-scientist) Gibbs(I-scientist) ,(O) and(O) James(B-scientist) Clerk(I-scientist) Maxwell(I-scientist) gave(O) entropy(O) a(O) statistical(O) basis(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["theory","person","organization","university","enzyme","astronomical object","discipline","chemical element","protein","chemical compound","country","award","academic journal","event","location","scientist"],"instance":{"id":"141","words":["A","stretch","of","road","in","the","natural","park","is","notable","for","being","the","scene","in","the","1969","James","Bond","film","On","Her","Majesty","'s","Secret","Service","where","Tracy","Bond","(","played","by","Diana","Rigg",")","is","shot","dead","by","Irma","Bunt","(","Ilse","Steppat",")","in","a","drive-by","shooting","at","the","end","of","the","film.","at","the","Internet","Movie","Database"],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-person","I-person","O","O","O","O","O","O","O","O","B-person","I-person","O","O","O","B-person","I-person","O","O","O","O","O","O","O","O","B-person","I-person","O","O","O","B-person","I-person","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: theory, person, organization, university, enzyme, astronomical object, discipline, chemical element, protein, chemical compound, country, award, academic journal, event, location, scientist and O.\nSentence: A stretch of road in the natural park is notable for being the scene in the 1969 James Bond film On Her Majesty 's Secret Service where Tracy Bond ( played by Diana Rigg ) is shot dead by Irma Bunt ( Ilse Steppat ) in a drive-by shooting at the end of the film. at the Internet Movie Database","prompt_labels":"A(O) stretch(O) of(O) road(O) in(O) the(O) natural(O) park(O) is(O) notable(O) for(O) being(O) the(O) scene(O) in(O) the(O) 1969(O) James(B-person) Bond(I-person) film(O) On(O) Her(O) Majesty(O) 's(O) Secret(O) Service(O) where(O) Tracy(B-person) Bond(I-person) ((O) played(O) by(O) Diana(B-person) Rigg(I-person) )(O) is(O) shot(O) dead(O) by(O) Irma(O) Bunt(O) ((O) Ilse(B-person) Steppat(I-person) )(O) in(O) a(O) drive-by(B-person) shooting(I-person) at(O) the(O) end(O) of(O) the(O) film.(O) at(O) the(O) Internet(O) Movie(O) Database(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["university","academic journal","enzyme","astronomical object","location","country","event","chemical element","organization","chemical compound","award","scientist","protein","theory","person","discipline"],"instance":{"id":"142","words":["In","2013",",","the","exoplanet","Kepler-62f","was","discovered",",","along","with","Kepler-62e","and","Kepler-62c","."],"labels":["O","O","O","O","O","B-astronomical object","O","O","O","O","O","B-astronomical object","O","B-astronomical object","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: university, academic journal, enzyme, astronomical object, location, country, event, chemical element, organization, chemical compound, award, scientist, protein, theory, person, discipline and O.\nSentence: In 2013 , the exoplanet Kepler-62f was discovered , along with Kepler-62e and Kepler-62c .","prompt_labels":"In(O) 2013(O) ,(O) the(O) exoplanet(O) Kepler-62f(B-astronomical object) was(O) discovered(O) ,(O) along(O) with(O) Kepler-62e(B-astronomical object) and(O) Kepler-62c(B-astronomical object) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["chemical element","person","theory","university","scientist","organization","event","chemical compound","protein","enzyme","astronomical object","academic journal","award","location","discipline","country"],"instance":{"id":"143","words":["Although","the","notion","of","higher","dimensions","goes","back","to","Ren","Descartes",",","substantial","development","of","a","higher-dimensional","geometry","only","began","in","the","19th","century",",","via","the","work","of","Arthur","Cayley",",","William","Rowan","Hamilton",",","Ludwig","Schlfli","and","Bernhard","Riemann","."],"labels":["O","O","O","O","O","O","O","O","O","B-scientist","I-scientist","O","O","O","O","O","O","B-discipline","O","O","O","O","O","O","O","O","O","O","O","B-scientist","I-scientist","O","B-scientist","I-scientist","I-scientist","O","B-scientist","I-scientist","O","B-scientist","I-scientist","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: chemical element, person, theory, university, scientist, organization, event, chemical compound, protein, enzyme, astronomical object, academic journal, award, location, discipline, country and O.\nSentence: Although the notion of higher dimensions goes back to Ren Descartes , substantial development of a higher-dimensional geometry only began in the 19th century , via the work of Arthur Cayley , William Rowan Hamilton , Ludwig Schlfli and Bernhard Riemann .","prompt_labels":"Although(O) the(O) notion(O) of(O) higher(O) dimensions(O) goes(O) back(O) to(O) Ren(B-scientist) Descartes(I-scientist) ,(O) substantial(O) development(O) of(O) a(O) higher-dimensional(O) geometry(B-discipline) only(O) began(O) in(O) the(O) 19th(O) century(O) ,(O) via(O) the(O) work(O) of(O) Arthur(B-scientist) Cayley(I-scientist) ,(O) William(B-scientist) Rowan(I-scientist) Hamilton(I-scientist) ,(O) Ludwig(B-scientist) Schlfli(I-scientist) and(O) Bernhard(B-scientist) Riemann(I-scientist) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["event","scientist","chemical element","enzyme","university","protein","location","organization","chemical compound","theory","discipline","award","person","country","astronomical object","academic journal"],"instance":{"id":"144","words":["DNA","cytosine","methylation","is","catalyzed","by","DNA","methyltransferase","."],"labels":["O","O","O","O","O","O","B-enzyme","I-enzyme","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, scientist, chemical element, enzyme, university, protein, location, organization, chemical compound, theory, discipline, award, person, country, astronomical object, academic journal and O.\nSentence: DNA cytosine methylation is catalyzed by DNA methyltransferase .","prompt_labels":"DNA(O) cytosine(O) methylation(O) is(O) catalyzed(O) by(O) DNA(B-enzyme) methyltransferase(I-enzyme) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["event","award","discipline","country","astronomical object","person","protein","academic journal","enzyme","chemical element","location","theory","chemical compound","university","organization","scientist"],"instance":{"id":"145","words":["He","was","a","professor","of","microbiology",",","and","of","public","health","at","the","Prince","Leopold","Institute","of","Tropical","Medicine",",","in","Antwerp",",","and","at","the","University","of","Nairobi",",","Vrije","Universiteit","Brussel",",","the","University","of","Lausanne",",","and","a","visiting","professor","at","the","London","School","of","Economics","."],"labels":["O","O","O","O","O","B-discipline","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","O","B-location","O","O","O","O","B-university","I-university","I-university","O","B-university","I-university","I-university","O","O","B-university","I-university","I-university","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, award, discipline, country, astronomical object, person, protein, academic journal, enzyme, chemical element, location, theory, chemical compound, university, organization, scientist and O.\nSentence: He was a professor of microbiology , and of public health at the Prince Leopold Institute of Tropical Medicine , in Antwerp , and at the University of Nairobi , Vrije Universiteit Brussel , the University of Lausanne , and a visiting professor at the London School of Economics .","prompt_labels":"He(O) was(O) a(O) professor(O) of(O) microbiology(B-discipline) ,(O) and(O) of(O) public(O) health(O) at(O) the(O) Prince(B-organization) Leopold(I-organization) Institute(I-organization) of(I-organization) Tropical(I-organization) Medicine(I-organization) ,(O) in(O) Antwerp(B-location) ,(O) and(O) at(O) the(O) University(B-university) of(I-university) Nairobi(I-university) ,(O) Vrije(B-university) Universiteit(I-university) Brussel(I-university) ,(O) the(O) University(B-university) of(I-university) Lausanne(I-university) ,(O) and(O) a(O) visiting(O) professor(O) at(O) the(O) London(B-organization) School(I-organization) of(I-organization) Economics(I-organization) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["scientist","discipline","organization","chemical element","theory","country","protein","astronomical object","university","academic journal","chemical compound","award","enzyme","location","event","person"],"instance":{"id":"146","words":["Chiron","'s","orbit","was","found","to","be","highly","eccentric","(","0.37",")",",","with","perihelion","just","inside","the","orbit","of","Saturn","and","aphelion","just","outside","the","perihelion","of","Uranus","(","it","does","not","reach","the","average","distance","of","Uranus",",","however",")","."],"labels":["B-astronomical object","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-astronomical object","O","O","O","O","O","O","O","B-astronomical object","O","O","O","O","O","O","O","O","O","B-astronomical object","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: scientist, discipline, organization, chemical element, theory, country, protein, astronomical object, university, academic journal, chemical compound, award, enzyme, location, event, person and O.\nSentence: Chiron 's orbit was found to be highly eccentric ( 0.37 ) , with perihelion just inside the orbit of Saturn and aphelion just outside the perihelion of Uranus ( it does not reach the average distance of Uranus , however ) .","prompt_labels":"Chiron(B-astronomical object) 's(O) orbit(O) was(O) found(O) to(O) be(O) highly(O) eccentric(O) ((O) 0.37(O) )(O) ,(O) with(O) perihelion(O) just(O) inside(O) the(O) orbit(O) of(O) Saturn(B-astronomical object) and(O) aphelion(O) just(O) outside(O) the(O) perihelion(O) of(O) Uranus(B-astronomical object) ((O) it(O) does(O) not(O) reach(O) the(O) average(O) distance(O) of(O) Uranus(B-astronomical object) ,(O) however(O) )(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["enzyme","organization","protein","chemical element","location","country","astronomical object","university","award","discipline","person","chemical compound","academic journal","theory","event","scientist"],"instance":{"id":"147","words":["In","fact",",","it","is","the","third","dimmest","of","the","first","twenty-three","asteroids","discovered",",","with","only","13","Egeria","and","17","Thetis","having","lower","mean","opposition","magnitude","s","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-astronomical object","I-astronomical object","O","B-astronomical object","I-astronomical object","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: enzyme, organization, protein, chemical element, location, country, astronomical object, university, award, discipline, person, chemical compound, academic journal, theory, event, scientist and O.\nSentence: In fact , it is the third dimmest of the first twenty-three asteroids discovered , with only 13 Egeria and 17 Thetis having lower mean opposition magnitude s .","prompt_labels":"In(O) fact(O) ,(O) it(O) is(O) the(O) third(O) dimmest(O) of(O) the(O) first(O) twenty-three(O) asteroids(O) discovered(O) ,(O) with(O) only(O) 13(B-astronomical object) Egeria(I-astronomical object) and(O) 17(B-astronomical object) Thetis(I-astronomical object) having(O) lower(O) mean(O) opposition(O) magnitude(O) s(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["chemical compound","discipline","enzyme","person","astronomical object","academic journal","university","award","scientist","organization","protein","location","country","theory","chemical element","event"],"instance":{"id":"148","words":["The","amino","acid","sequence","of","arginine","vasopressin","(","argipressin",")","is","Cys","-","Tyr","-","Phenylalanine","-","Gln","-","Asn","-","Cysteine","-","Pro","-","Arg","-","Gly","-NHsub2","\/","sub",",","with","the","cysteine","residues","forming","a","disulfide","bond","and","the","C","-terminus","of","the","sequence","converted","to","a","primary","amide","."],"labels":["O","O","O","O","O","B-protein","I-protein","O","B-protein","O","O","B-chemical compound","O","B-chemical compound","O","B-chemical compound","O","B-chemical compound","O","B-chemical compound","O","B-chemical compound","O","B-chemical compound","O","B-chemical compound","O","B-chemical compound","B-chemical compound","I-chemical compound","I-chemical compound","O","O","O","O","O","O","O","B-chemical compound","I-chemical compound","O","O","O","O","O","O","O","O","O","O","B-chemical compound","I-chemical compound","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: chemical compound, discipline, enzyme, person, astronomical object, academic journal, university, award, scientist, organization, protein, location, country, theory, chemical element, event and O.\nSentence: The amino acid sequence of arginine vasopressin ( argipressin ) is Cys - Tyr - Phenylalanine - Gln - Asn - Cysteine - Pro - Arg - Gly -NHsub2 \/ sub , with the cysteine residues forming a disulfide bond and the C -terminus of the sequence converted to a primary amide .","prompt_labels":"The(O) amino(O) acid(O) sequence(O) of(O) arginine(B-protein) vasopressin(I-protein) ((O) argipressin(B-protein) )(O) is(O) Cys(B-chemical compound) -(O) Tyr(B-chemical compound) -(O) Phenylalanine(B-chemical compound) -(O) Gln(B-chemical compound) -(O) Asn(B-chemical compound) -(O) Cysteine(B-chemical compound) -(O) Pro(B-chemical compound) -(O) Arg(B-chemical compound) -(O) Gly(B-chemical compound) -NHsub2(B-chemical compound) \/(I-chemical compound) sub(I-chemical compound) ,(O) with(O) the(O) cysteine(O) residues(O) forming(O) a(O) disulfide(B-chemical compound) bond(I-chemical compound) and(O) the(O) C(O) -terminus(O) of(O) the(O) sequence(O) converted(O) to(O) a(O) primary(B-chemical compound) amide(I-chemical compound) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["protein","discipline","astronomical object","award","academic journal","chemical element","scientist","theory","chemical compound","event","enzyme","country","university","organization","person","location"],"instance":{"id":"149","words":["During","the","Industrial","Revolution",",","it","became","an","important","industrial","chemical","for","many","applications",",","including","the","large","scale","production","of","organic","compounds","such","as","vinyl","chloride","for","PVC","plastic","and","Methylene","diphenyl","diisocyanate","\/","Toluene","diisocyanate","for","polyurethane","and","smaller","scale","applications",",","such","as","production","of","gelatin","and","other","ingredients","in","food",",","and","leather","processing","."],"labels":["O","O","B-event","I-event","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-chemical compound","I-chemical compound","O","B-chemical compound","O","O","B-chemical compound","I-chemical compound","I-chemical compound","O","B-chemical compound","I-chemical compound","O","B-chemical compound","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: protein, discipline, astronomical object, award, academic journal, chemical element, scientist, theory, chemical compound, event, enzyme, country, university, organization, person, location and O.\nSentence: During the Industrial Revolution , it became an important industrial chemical for many applications , including the large scale production of organic compounds such as vinyl chloride for PVC plastic and Methylene diphenyl diisocyanate \/ Toluene diisocyanate for polyurethane and smaller scale applications , such as production of gelatin and other ingredients in food , and leather processing .","prompt_labels":"During(O) the(O) Industrial(B-event) Revolution(I-event) ,(O) it(O) became(O) an(O) important(O) industrial(O) chemical(O) for(O) many(O) applications(O) ,(O) including(O) the(O) large(O) scale(O) production(O) of(O) organic(O) compounds(O) such(O) as(O) vinyl(B-chemical compound) chloride(I-chemical compound) for(O) PVC(B-chemical compound) plastic(O) and(O) Methylene(B-chemical compound) diphenyl(I-chemical compound) diisocyanate(I-chemical compound) \/(O) Toluene(B-chemical compound) diisocyanate(I-chemical compound) for(O) polyurethane(B-chemical compound) and(O) smaller(O) scale(O) applications(O) ,(O) such(O) as(O) production(O) of(O) gelatin(O) and(O) other(O) ingredients(O) in(O) food(O) ,(O) and(O) leather(O) processing(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["event","theory","country","chemical element","discipline","scientist","academic journal","person","enzyme","astronomical object","chemical compound","award","university","location","protein","organization"],"instance":{"id":"150","words":["Eduard","Otto","Emil","Karl","Adam","Freiherr","von","Stackelberg","(","6","November","1867","in","Sillame",",","Estonia","-","7","April","1943","in","Munich",",","Nazi","Germany",")","was","an","Estonian","chemist",",","landowner","and","politician","who","belonged","to","the","Stackelberg","family","."],"labels":["B-scientist","I-scientist","I-scientist","I-scientist","I-scientist","I-scientist","I-scientist","I-scientist","O","O","O","O","O","B-location","O","B-country","O","O","O","O","O","B-location","O","B-country","I-country","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, theory, country, chemical element, discipline, scientist, academic journal, person, enzyme, astronomical object, chemical compound, award, university, location, protein, organization and O.\nSentence: Eduard Otto Emil Karl Adam Freiherr von Stackelberg ( 6 November 1867 in Sillame , Estonia - 7 April 1943 in Munich , Nazi Germany ) was an Estonian chemist , landowner and politician who belonged to the Stackelberg family .","prompt_labels":"Eduard(B-scientist) Otto(I-scientist) Emil(I-scientist) Karl(I-scientist) Adam(I-scientist) Freiherr(I-scientist) von(I-scientist) Stackelberg(I-scientist) ((O) 6(O) November(O) 1867(O) in(O) Sillame(B-location) ,(O) Estonia(B-country) -(O) 7(O) April(O) 1943(O) in(O) Munich(B-location) ,(O) Nazi(B-country) Germany(I-country) )(O) was(O) an(O) Estonian(O) chemist(O) ,(O) landowner(O) and(O) politician(O) who(O) belonged(O) to(O) the(O) Stackelberg(O) family(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["award","protein","event","university","theory","discipline","chemical compound","location","country","chemical element","scientist","organization","enzyme","academic journal","person","astronomical object"],"instance":{"id":"151","words":["The","scientists","found","that","while","CRISPR","could","effectively","cleave","the","-globin","gene","(","HBB",")",",","the","efficiency","of","homologous","recombination","directed","repair","of","HBB","was","highly","inefficient","and","did","not","do","so","in","a","majority","of","the","trials","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","B-protein","O","O","O","O","O","O","O","O","O","O","B-protein","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, protein, event, university, theory, discipline, chemical compound, location, country, chemical element, scientist, organization, enzyme, academic journal, person, astronomical object and O.\nSentence: The scientists found that while CRISPR could effectively cleave the -globin gene ( HBB ) , the efficiency of homologous recombination directed repair of HBB was highly inefficient and did not do so in a majority of the trials .","prompt_labels":"The(O) scientists(O) found(O) that(O) while(O) CRISPR(O) could(O) effectively(O) cleave(O) the(O) -globin(O) gene(O) ((O) HBB(B-protein) )(O) ,(O) the(O) efficiency(O) of(O) homologous(O) recombination(O) directed(O) repair(O) of(O) HBB(B-protein) was(O) highly(O) inefficient(O) and(O) did(O) not(O) do(O) so(O) in(O) a(O) majority(O) of(O) the(O) trials(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["protein","enzyme","chemical element","location","chemical compound","academic journal","event","theory","discipline","person","astronomical object","country","scientist","award","organization","university"],"instance":{"id":"152","words":["A","specialist","in","polymers",",","Peterlin","was","a","member","of","numerous","scientific","societies",",","including","the","American","Physical","Society",",","the","Deutsche","Kolloid","Gesellschaft",",","the","Deutsche","Physikalische","Gesellschaft",",","and","the","Slovenian","Academy","of","Sciences","and","Arts","."],"labels":["O","O","O","O","O","B-person","O","O","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: protein, enzyme, chemical element, location, chemical compound, academic journal, event, theory, discipline, person, astronomical object, country, scientist, award, organization, university and O.\nSentence: A specialist in polymers , Peterlin was a member of numerous scientific societies , including the American Physical Society , the Deutsche Kolloid Gesellschaft , the Deutsche Physikalische Gesellschaft , and the Slovenian Academy of Sciences and Arts .","prompt_labels":"A(O) specialist(O) in(O) polymers(O) ,(O) Peterlin(B-person) was(O) a(O) member(O) of(O) numerous(O) scientific(O) societies(O) ,(O) including(O) the(O) American(B-organization) Physical(I-organization) Society(I-organization) ,(O) the(O) Deutsche(B-organization) Kolloid(I-organization) Gesellschaft(I-organization) ,(O) the(O) Deutsche(B-organization) Physikalische(I-organization) Gesellschaft(I-organization) ,(O) and(O) the(O) Slovenian(B-organization) Academy(I-organization) of(I-organization) Sciences(I-organization) and(I-organization) Arts(I-organization) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["organization","person","discipline","award","protein","country","enzyme","chemical compound","chemical element","astronomical object","university","location","event","scientist","theory","academic journal"],"instance":{"id":"153","words":["In","this","respect","he","was","the","equivalent","of","Mars",",","Janus",",","Saturn","and","even","Jupiter","among","Latin","tribes","."],"labels":["O","O","O","O","O","O","O","O","B-astronomical object","O","B-astronomical object","O","B-astronomical object","O","O","B-astronomical object","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, person, discipline, award, protein, country, enzyme, chemical compound, chemical element, astronomical object, university, location, event, scientist, theory, academic journal and O.\nSentence: In this respect he was the equivalent of Mars , Janus , Saturn and even Jupiter among Latin tribes .","prompt_labels":"In(O) this(O) respect(O) he(O) was(O) the(O) equivalent(O) of(O) Mars(B-astronomical object) ,(O) Janus(B-astronomical object) ,(O) Saturn(B-astronomical object) and(O) even(O) Jupiter(B-astronomical object) among(O) Latin(O) tribes(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["person","chemical compound","discipline","enzyme","scientist","country","theory","location","protein","astronomical object","award","organization","event","academic journal","chemical element","university"],"instance":{"id":"154","words":["His","work","has","been","published","in","international","refereed","journals",",","including","American","Economic","Review",",","Journal","of","European","Economic","Association",",","Journal","of","Economic","Perspectives",",","Economic","Journal","and","American","Political","Science","Review","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","B-academic journal","I-academic journal","I-academic journal","O","O","O","B-academic journal","I-academic journal","I-academic journal","O","B-academic journal","I-academic journal","I-academic journal","I-academic journal","O","B-academic journal","I-academic journal","O","B-academic journal","I-academic journal","I-academic journal","I-academic journal","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, chemical compound, discipline, enzyme, scientist, country, theory, location, protein, astronomical object, award, organization, event, academic journal, chemical element, university and O.\nSentence: His work has been published in international refereed journals , including American Economic Review , Journal of European Economic Association , Journal of Economic Perspectives , Economic Journal and American Political Science Review .","prompt_labels":"His(O) work(O) has(O) been(O) published(O) in(O) international(O) refereed(O) journals(O) ,(O) including(O) American(B-academic journal) Economic(I-academic journal) Review(I-academic journal) ,(O) Journal(O) of(O) European(B-academic journal) Economic(I-academic journal) Association(I-academic journal) ,(O) Journal(B-academic journal) of(I-academic journal) Economic(I-academic journal) Perspectives(I-academic journal) ,(O) Economic(B-academic journal) Journal(I-academic journal) and(O) American(B-academic journal) Political(I-academic journal) Science(I-academic journal) Review(I-academic journal) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["organization","scientist","enzyme","location","academic journal","astronomical object","protein","event","theory","chemical compound","discipline","country","university","award","chemical element","person"],"instance":{"id":"155","words":["Known","for","his","research","on","Mitogen-activated","protein","kinase","(","MAPK",")","cascade","in","plants",",","he","is","a","three-time","Alexander","von","Humboldt","Fellow","and","an","elected","fellow","of","the","National","Academy","of","Sciences",",","India","."],"labels":["O","O","O","O","O","B-enzyme","I-enzyme","I-enzyme","O","B-enzyme","O","O","O","O","O","O","O","O","O","B-award","I-award","I-award","I-award","O","O","O","B-award","I-award","I-award","I-award","I-award","I-award","I-award","O","B-country","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, scientist, enzyme, location, academic journal, astronomical object, protein, event, theory, chemical compound, discipline, country, university, award, chemical element, person and O.\nSentence: Known for his research on Mitogen-activated protein kinase ( MAPK ) cascade in plants , he is a three-time Alexander von Humboldt Fellow and an elected fellow of the National Academy of Sciences , India .","prompt_labels":"Known(O) for(O) his(O) research(O) on(O) Mitogen-activated(B-enzyme) protein(I-enzyme) kinase(I-enzyme) ((O) MAPK(B-enzyme) )(O) cascade(O) in(O) plants(O) ,(O) he(O) is(O) a(O) three-time(O) Alexander(B-award) von(I-award) Humboldt(I-award) Fellow(I-award) and(O) an(O) elected(O) fellow(B-award) of(I-award) the(I-award) National(I-award) Academy(I-award) of(I-award) Sciences(I-award) ,(O) India(B-country) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["chemical compound","organization","location","protein","person","university","scientist","country","event","chemical element","discipline","astronomical object","award","academic journal","enzyme","theory"],"instance":{"id":"156","words":["An","approved","residency","program","and","certification","(","in","the","U.S.",",","the","American","Board","of","Pathology","or","the","American","Osteopathic","Board","of","Pathology",")","is","usually","required","to","obtain","employment","or","hospital","privileges","."],"labels":["O","O","O","O","O","O","O","O","O","B-country","O","O","B-organization","I-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: chemical compound, organization, location, protein, person, university, scientist, country, event, chemical element, discipline, astronomical object, award, academic journal, enzyme, theory and O.\nSentence: An approved residency program and certification ( in the U.S. , the American Board of Pathology or the American Osteopathic Board of Pathology ) is usually required to obtain employment or hospital privileges .","prompt_labels":"An(O) approved(O) residency(O) program(O) and(O) certification(O) ((O) in(O) the(O) U.S.(B-country) ,(O) the(O) American(B-organization) Board(I-organization) of(I-organization) Pathology(I-organization) or(O) the(O) American(B-organization) Osteopathic(I-organization) Board(I-organization) of(I-organization) Pathology(I-organization) )(O) is(O) usually(O) required(O) to(O) obtain(O) employment(O) or(O) hospital(O) privileges(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["protein","theory","organization","chemical element","location","scientist","academic journal","award","discipline","enzyme","event","university","chemical compound","astronomical object","person","country"],"instance":{"id":"157","words":["Singer","is","a","member","of","the","National","Academy","of","Sciences","and","the","American","Academy","of","Arts","and","Sciences","."],"labels":["B-scientist","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: protein, theory, organization, chemical element, location, scientist, academic journal, award, discipline, enzyme, event, university, chemical compound, astronomical object, person, country and O.\nSentence: Singer is a member of the National Academy of Sciences and the American Academy of Arts and Sciences .","prompt_labels":"Singer(B-scientist) is(O) a(O) member(O) of(O) the(O) National(B-organization) Academy(I-organization) of(I-organization) Sciences(I-organization) and(O) the(O) American(B-organization) Academy(I-organization) of(I-organization) Arts(I-organization) and(I-organization) Sciences(I-organization) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["organization","location","enzyme","discipline","event","protein","scientist","theory","award","chemical element","country","university","chemical compound","academic journal","person","astronomical object"],"instance":{"id":"158","words":["In","1966","he","won","the","silver","medal","of","the","Football","at","the","1966","Asian","Games",",","in","1974","he","captained","the","Iranian","team","to","win","the","football","tournament","of","the","Football","at","the","1974","Asian","Games","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","B-event","I-event","I-event","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-event","I-event","I-event","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, location, enzyme, discipline, event, protein, scientist, theory, award, chemical element, country, university, chemical compound, academic journal, person, astronomical object and O.\nSentence: In 1966 he won the silver medal of the Football at the 1966 Asian Games , in 1974 he captained the Iranian team to win the football tournament of the Football at the 1974 Asian Games .","prompt_labels":"In(O) 1966(O) he(O) won(O) the(O) silver(O) medal(O) of(O) the(O) Football(O) at(O) the(O) 1966(B-event) Asian(I-event) Games(I-event) ,(O) in(O) 1974(O) he(O) captained(O) the(O) Iranian(O) team(O) to(O) win(O) the(O) football(O) tournament(O) of(O) the(O) Football(O) at(O) the(O) 1974(B-event) Asian(I-event) Games(I-event) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["protein","person","country","chemical element","chemical compound","award","event","enzyme","location","academic journal","astronomical object","theory","scientist","discipline","university","organization"],"instance":{"id":"159","words":["Bennett","was","the","flight","safety","manager","for","the","radioisotope","power","sources","currently","in","use","on","the","Voyager","1","and","Voyager","2","spacecraft","(","which","went","to","Jupiter",",","Saturn",",","Uranus",",","Neptune","and","beyond",")","and","on","Lincoln","Laboratory","'","s","LES","8","and","LES","9","communications","satellites","."],"labels":["B-person","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-astronomical object","O","B-astronomical object","O","B-astronomical object","O","B-astronomical object","O","O","O","O","O","B-organization","I-organization","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: protein, person, country, chemical element, chemical compound, award, event, enzyme, location, academic journal, astronomical object, theory, scientist, discipline, university, organization and O.\nSentence: Bennett was the flight safety manager for the radioisotope power sources currently in use on the Voyager 1 and Voyager 2 spacecraft ( which went to Jupiter , Saturn , Uranus , Neptune and beyond ) and on Lincoln Laboratory ' s LES 8 and LES 9 communications satellites .","prompt_labels":"Bennett(B-person) was(O) the(O) flight(O) safety(O) manager(O) for(O) the(O) radioisotope(O) power(O) sources(O) currently(O) in(O) use(O) on(O) the(O) Voyager(O) 1(O) and(O) Voyager(O) 2(O) spacecraft(O) ((O) which(O) went(O) to(O) Jupiter(B-astronomical object) ,(O) Saturn(B-astronomical object) ,(O) Uranus(B-astronomical object) ,(O) Neptune(B-astronomical object) and(O) beyond(O) )(O) and(O) on(O) Lincoln(B-organization) Laboratory(I-organization) '(O) s(O) LES(O) 8(O) and(O) LES(O) 9(O) communications(O) satellites(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["chemical element","location","chemical compound","organization","academic journal","protein","discipline","theory","astronomical object","person","university","country","scientist","enzyme","award","event"],"instance":{"id":"160","words":["Models","of","heat","retention","and","heating","via","radioactive","decay","in","smaller","icy","Solar","System","bodies","suggest","that","Rhea",",","Titania",",","Oberon",",","Triton",",","Pluto",",","Eris",",","90377","Sedna",",","and","90482","Orcus","may","have","oceans","underneath","solid","icy","crusts","approximately","100","km","thick","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-astronomical object","O","B-astronomical object","O","B-astronomical object","O","B-astronomical object","O","B-astronomical object","O","B-astronomical object","O","B-astronomical object","I-astronomical object","O","O","B-astronomical object","I-astronomical object","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: chemical element, location, chemical compound, organization, academic journal, protein, discipline, theory, astronomical object, person, university, country, scientist, enzyme, award, event and O.\nSentence: Models of heat retention and heating via radioactive decay in smaller icy Solar System bodies suggest that Rhea , Titania , Oberon , Triton , Pluto , Eris , 90377 Sedna , and 90482 Orcus may have oceans underneath solid icy crusts approximately 100 km thick .","prompt_labels":"Models(O) of(O) heat(O) retention(O) and(O) heating(O) via(O) radioactive(O) decay(O) in(O) smaller(O) icy(O) Solar(O) System(O) bodies(O) suggest(O) that(O) Rhea(B-astronomical object) ,(O) Titania(B-astronomical object) ,(O) Oberon(B-astronomical object) ,(O) Triton(B-astronomical object) ,(O) Pluto(B-astronomical object) ,(O) Eris(B-astronomical object) ,(O) 90377(B-astronomical object) Sedna(I-astronomical object) ,(O) and(O) 90482(B-astronomical object) Orcus(I-astronomical object) may(O) have(O) oceans(O) underneath(O) solid(O) icy(O) crusts(O) approximately(O) 100(O) km(O) thick(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["event","astronomical object","discipline","enzyme","chemical element","protein","theory","scientist","location","university","award","person","organization","chemical compound","country","academic journal"],"instance":{"id":"161","words":["The","Perturb-seq","protocol","uses","CRISPR","technology","to","inactivate","specific","genes","and","DNA","barcoding","of","each","guide","RNA","to","allow","for","all","perturbations","to","be","pooled","together","and","later","deconvoluted",",","with","assignment","of","each","phenotype","to","a","specific","guide","RNA","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, astronomical object, discipline, enzyme, chemical element, protein, theory, scientist, location, university, award, person, organization, chemical compound, country, academic journal and O.\nSentence: The Perturb-seq protocol uses CRISPR technology to inactivate specific genes and DNA barcoding of each guide RNA to allow for all perturbations to be pooled together and later deconvoluted , with assignment of each phenotype to a specific guide RNA .","prompt_labels":"The(O) Perturb-seq(O) protocol(O) uses(O) CRISPR(O) technology(O) to(O) inactivate(O) specific(O) genes(O) and(O) DNA(O) barcoding(O) of(O) each(O) guide(O) RNA(O) to(O) allow(O) for(O) all(O) perturbations(O) to(O) be(O) pooled(O) together(O) and(O) later(O) deconvoluted(O) ,(O) with(O) assignment(O) of(O) each(O) phenotype(O) to(O) a(O) specific(O) guide(O) RNA(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["location","person","discipline","astronomical object","protein","university","organization","theory","country","event","academic journal","chemical element","chemical compound","scientist","enzyme","award"],"instance":{"id":"162","words":["The","film","was","nominated","for","two","Academy","Awards","for","Academy","Award","for","Best","Cinematography","and","Academy","Award","for","Best","Visual","Effects","."],"labels":["O","O","O","O","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","O","B-award","I-award","I-award","I-award","I-award","I-award","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, person, discipline, astronomical object, protein, university, organization, theory, country, event, academic journal, chemical element, chemical compound, scientist, enzyme, award and O.\nSentence: The film was nominated for two Academy Awards for Academy Award for Best Cinematography and Academy Award for Best Visual Effects .","prompt_labels":"The(O) film(O) was(O) nominated(O) for(O) two(O) Academy(O) Awards(O) for(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Cinematography(I-award) and(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Visual(I-award) Effects(I-award) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["university","award","organization","location","chemical element","scientist","theory","discipline","country","event","protein","enzyme","person","chemical compound","academic journal","astronomical object"],"instance":{"id":"163","words":["Within","the","Solar","System","there","are","five","candidates","for","Schumann","resonance","detection","besides","the","Earth",":","Venus",",","Mars",",","Jupiter",",","Saturn",",","and","Saturn","'s","biggest","moon","Titan","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-astronomical object","O","B-astronomical object","O","B-astronomical object","O","B-astronomical object","O","B-astronomical object","O","O","B-astronomical object","O","O","O","B-astronomical object","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: university, award, organization, location, chemical element, scientist, theory, discipline, country, event, protein, enzyme, person, chemical compound, academic journal, astronomical object and O.\nSentence: Within the Solar System there are five candidates for Schumann resonance detection besides the Earth : Venus , Mars , Jupiter , Saturn , and Saturn 's biggest moon Titan .","prompt_labels":"Within(O) the(O) Solar(O) System(O) there(O) are(O) five(O) candidates(O) for(O) Schumann(O) resonance(O) detection(O) besides(O) the(O) Earth(B-astronomical object) :(O) Venus(B-astronomical object) ,(O) Mars(B-astronomical object) ,(O) Jupiter(B-astronomical object) ,(O) Saturn(B-astronomical object) ,(O) and(O) Saturn(B-astronomical object) 's(O) biggest(O) moon(O) Titan(B-astronomical object) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["organization","enzyme","scientist","discipline","award","university","country","location","astronomical object","protein","chemical compound","theory","academic journal","chemical element","event","person"],"instance":{"id":"164","words":["Published","in","1993",",","it","won","the","1994","Nebula","Award","for","Best","Novel","."],"labels":["O","O","O","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, enzyme, scientist, discipline, award, university, country, location, astronomical object, protein, chemical compound, theory, academic journal, chemical element, event, person and O.\nSentence: Published in 1993 , it won the 1994 Nebula Award for Best Novel .","prompt_labels":"Published(O) in(O) 1993(O) ,(O) it(O) won(O) the(O) 1994(O) Nebula(B-award) Award(I-award) for(I-award) Best(I-award) Novel(I-award) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["award","scientist","event","academic journal","astronomical object","country","protein","enzyme","university","theory","person","organization","chemical compound","discipline","chemical element","location"],"instance":{"id":"165","words":["After","school",",","he","studied","physics","and","mathematics","at","the","University","of","Gttingen","and","University","of","Hamburg","."],"labels":["O","O","O","O","O","B-discipline","O","B-discipline","O","O","B-university","I-university","I-university","O","B-university","I-university","I-university","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, scientist, event, academic journal, astronomical object, country, protein, enzyme, university, theory, person, organization, chemical compound, discipline, chemical element, location and O.\nSentence: After school , he studied physics and mathematics at the University of Gttingen and University of Hamburg .","prompt_labels":"After(O) school(O) ,(O) he(O) studied(O) physics(B-discipline) and(O) mathematics(B-discipline) at(O) the(O) University(B-university) of(I-university) Gttingen(I-university) and(O) University(B-university) of(I-university) Hamburg(I-university) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["enzyme","chemical compound","discipline","protein","chemical element","person","theory","astronomical object","location","award","country","scientist","university","academic journal","organization","event"],"instance":{"id":"166","words":["19126","Ottohahn","named","in","his","honor",",","as","were","the","Otto","Hahn","Prize","of","both","the","German","Chemical","and","Physical","Societies","and","the","city","of","Frankfurt","\/","Main",",","the","Otto","Hahn","Medal",",","and","the","Otto","Hahn","Award","of","the","Max","Planck","Society","and",",","since","1988",",","the","Otto","Hahn","Peace","Medal","in","Gold","of","the","United","Nations","Association","of","Germany","(","DGVN",")","in","Berlin","."],"labels":["B-astronomical object","I-astronomical object","O","O","O","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","I-award","I-award","I-award","I-award","I-award","I-award","O","O","O","O","B-location","O","O","O","O","B-award","I-award","I-award","O","O","O","B-award","I-award","I-award","I-award","I-award","I-award","I-award","I-award","O","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","I-award","I-award","I-award","I-award","I-award","I-award","I-award","I-award","O","B-organization","O","O","B-location","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: enzyme, chemical compound, discipline, protein, chemical element, person, theory, astronomical object, location, award, country, scientist, university, academic journal, organization, event and O.\nSentence: 19126 Ottohahn named in his honor , as were the Otto Hahn Prize of both the German Chemical and Physical Societies and the city of Frankfurt \/ Main , the Otto Hahn Medal , and the Otto Hahn Award of the Max Planck Society and , since 1988 , the Otto Hahn Peace Medal in Gold of the United Nations Association of Germany ( DGVN ) in Berlin .","prompt_labels":"19126(B-astronomical object) Ottohahn(I-astronomical object) named(O) in(O) his(O) honor(O) ,(O) as(O) were(O) the(O) Otto(B-award) Hahn(I-award) Prize(I-award) of(I-award) both(I-award) the(I-award) German(I-award) Chemical(I-award) and(I-award) Physical(I-award) Societies(I-award) and(O) the(O) city(O) of(O) Frankfurt(B-location) \/(O) Main(O) ,(O) the(O) Otto(B-award) Hahn(I-award) Medal(I-award) ,(O) and(O) the(O) Otto(B-award) Hahn(I-award) Award(I-award) of(I-award) the(I-award) Max(I-award) Planck(I-award) Society(I-award) and(O) ,(O) since(O) 1988(O) ,(O) the(O) Otto(B-award) Hahn(I-award) Peace(I-award) Medal(I-award) in(I-award) Gold(I-award) of(I-award) the(I-award) United(I-award) Nations(I-award) Association(I-award) of(I-award) Germany(I-award) ((O) DGVN(B-organization) )(O) in(O) Berlin(B-location) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["academic journal","theory","discipline","event","award","protein","scientist","chemical compound","organization","university","location","person","astronomical object","enzyme","chemical element","country"],"instance":{"id":"167","words":["She","also","played","at","1986",",","1989",",","1991",",","1993",",","1995","AFC","Championship",",","1990","and","Football","at","the","1994","Asian","Games","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","B-event","I-event","O","O","O","O","O","O","O","B-event","I-event","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: academic journal, theory, discipline, event, award, protein, scientist, chemical compound, organization, university, location, person, astronomical object, enzyme, chemical element, country and O.\nSentence: She also played at 1986 , 1989 , 1991 , 1993 , 1995 AFC Championship , 1990 and Football at the 1994 Asian Games .","prompt_labels":"She(O) also(O) played(O) at(O) 1986(O) ,(O) 1989(O) ,(O) 1991(O) ,(O) 1993(O) ,(O) 1995(O) AFC(B-event) Championship(I-event) ,(O) 1990(O) and(O) Football(O) at(O) the(O) 1994(O) Asian(B-event) Games(I-event) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["academic journal","event","protein","country","scientist","discipline","university","person","chemical compound","location","enzyme","organization","astronomical object","award","chemical element","theory"],"instance":{"id":"168","words":["A","physician","and","professor","of","public","health",",","he","worked","first","in","social","medicine","at","the","University","of","Sassari","(","1969-1974",")","and","then","in","occupational","health","at","the","Sapienza","University","of","Rome","(","1975-1999",")","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","B-discipline","I-discipline","O","O","B-university","I-university","I-university","O","O","O","O","O","O","O","O","O","O","B-university","I-university","I-university","I-university","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: academic journal, event, protein, country, scientist, discipline, university, person, chemical compound, location, enzyme, organization, astronomical object, award, chemical element, theory and O.\nSentence: A physician and professor of public health , he worked first in social medicine at the University of Sassari ( 1969-1974 ) and then in occupational health at the Sapienza University of Rome ( 1975-1999 ) .","prompt_labels":"A(O) physician(O) and(O) professor(O) of(O) public(O) health(O) ,(O) he(O) worked(O) first(O) in(O) social(B-discipline) medicine(I-discipline) at(O) the(O) University(B-university) of(I-university) Sassari(I-university) ((O) 1969-1974(O) )(O) and(O) then(O) in(O) occupational(O) health(O) at(O) the(O) Sapienza(B-university) University(I-university) of(I-university) Rome(I-university) ((O) 1975-1999(O) )(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["award","astronomical object","academic journal","enzyme","discipline","organization","location","scientist","chemical compound","university","event","country","theory","person","protein","chemical element"],"instance":{"id":"169","words":["Segment","7","encodes","the","M1","protein","and","the","smaller","M2","proton","channel","protein",",","which","is","produced","by","RNA","splicing","."],"labels":["O","O","O","O","B-protein","I-protein","O","O","O","B-protein","I-protein","I-protein","I-protein","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, astronomical object, academic journal, enzyme, discipline, organization, location, scientist, chemical compound, university, event, country, theory, person, protein, chemical element and O.\nSentence: Segment 7 encodes the M1 protein and the smaller M2 proton channel protein , which is produced by RNA splicing .","prompt_labels":"Segment(O) 7(O) encodes(O) the(O) M1(B-protein) protein(I-protein) and(O) the(O) smaller(O) M2(B-protein) proton(I-protein) channel(I-protein) protein(I-protein) ,(O) which(O) is(O) produced(O) by(O) RNA(O) splicing(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["discipline","organization","event","enzyme","theory","astronomical object","university","protein","chemical element","scientist","award","country","academic journal","location","chemical compound","person"],"instance":{"id":"170","words":["These","usually","are","limited","to","the","planets","from","Mercury","to","Saturn",",","although","some","include","Uranus","."],"labels":["O","O","O","O","O","O","O","O","B-astronomical object","O","B-astronomical object","O","O","O","O","B-astronomical object","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: discipline, organization, event, enzyme, theory, astronomical object, university, protein, chemical element, scientist, award, country, academic journal, location, chemical compound, person and O.\nSentence: These usually are limited to the planets from Mercury to Saturn , although some include Uranus .","prompt_labels":"These(O) usually(O) are(O) limited(O) to(O) the(O) planets(O) from(O) Mercury(B-astronomical object) to(O) Saturn(B-astronomical object) ,(O) although(O) some(O) include(O) Uranus(B-astronomical object) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["country","award","event","location","discipline","protein","university","person","organization","theory","chemical compound","astronomical object","scientist","academic journal","enzyme","chemical element"],"instance":{"id":"171","words":["The","discipline","emerged","after","2010","following","the","development","of","genome","editing","technology","including","TALENS","and","CRISPR","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, award, event, location, discipline, protein, university, person, organization, theory, chemical compound, astronomical object, scientist, academic journal, enzyme, chemical element and O.\nSentence: The discipline emerged after 2010 following the development of genome editing technology including TALENS and CRISPR .","prompt_labels":"The(O) discipline(O) emerged(O) after(O) 2010(O) following(O) the(O) development(O) of(O) genome(O) editing(O) technology(O) including(O) TALENS(O) and(O) CRISPR(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["location","university","scientist","discipline","astronomical object","enzyme","award","academic journal","chemical element","event","chemical compound","theory","protein","country","organization","person"],"instance":{"id":"172","words":["Instead",",","for","the","UEFA","Euro","2008","articles","(","UEFA","Euro","2008",",","UEFA","Euro","2008","Group","A",",","UEFA","Euro","2008","Group","B",",","UEFA","Euro","2008","Group","C",",","UEFA","Euro","2008","Group","D","and","UEFA","Euro","2008","knockout","stage",")",",","the","old","partial","URL","string","ones",":"],"labels":["O","O","O","O","B-event","I-event","I-event","O","O","B-event","I-event","I-event","O","B-event","I-event","I-event","O","O","O","B-event","I-event","I-event","O","O","O","B-event","I-event","I-event","O","O","O","B-event","I-event","I-event","O","O","O","B-event","I-event","I-event","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, university, scientist, discipline, astronomical object, enzyme, award, academic journal, chemical element, event, chemical compound, theory, protein, country, organization, person and O.\nSentence: Instead , for the UEFA Euro 2008 articles ( UEFA Euro 2008 , UEFA Euro 2008 Group A , UEFA Euro 2008 Group B , UEFA Euro 2008 Group C , UEFA Euro 2008 Group D and UEFA Euro 2008 knockout stage ) , the old partial URL string ones :","prompt_labels":"Instead(O) ,(O) for(O) the(O) UEFA(B-event) Euro(I-event) 2008(I-event) articles(O) ((O) UEFA(B-event) Euro(I-event) 2008(I-event) ,(O) UEFA(B-event) Euro(I-event) 2008(I-event) Group(O) A(O) ,(O) UEFA(B-event) Euro(I-event) 2008(I-event) Group(O) B(O) ,(O) UEFA(B-event) Euro(I-event) 2008(I-event) Group(O) C(O) ,(O) UEFA(B-event) Euro(I-event) 2008(I-event) Group(O) D(O) and(O) UEFA(B-event) Euro(I-event) 2008(I-event) knockout(O) stage(O) )(O) ,(O) the(O) old(O) partial(O) URL(O) string(O) ones(O) :(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["person","event","academic journal","theory","chemical compound","protein","scientist","award","university","organization","enzyme","astronomical object","location","discipline","country","chemical element"],"instance":{"id":"173","words":["Among","the","researchers","who","laid","the","foundations","of","AI","were","Alan","Turing",",","John","von","Neumann",",","Norbert","Wiener",",","Claude","Shannon",",","Warren","McCullough",",","Walter","Pitts","and","Donald","Hebb","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-scientist","I-scientist","O","B-scientist","I-scientist","I-scientist","O","B-scientist","I-scientist","O","B-scientist","I-scientist","O","B-scientist","I-scientist","O","B-scientist","I-scientist","O","B-scientist","I-scientist","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, event, academic journal, theory, chemical compound, protein, scientist, award, university, organization, enzyme, astronomical object, location, discipline, country, chemical element and O.\nSentence: Among the researchers who laid the foundations of AI were Alan Turing , John von Neumann , Norbert Wiener , Claude Shannon , Warren McCullough , Walter Pitts and Donald Hebb .","prompt_labels":"Among(O) the(O) researchers(O) who(O) laid(O) the(O) foundations(O) of(O) AI(O) were(O) Alan(B-scientist) Turing(I-scientist) ,(O) John(B-scientist) von(I-scientist) Neumann(I-scientist) ,(O) Norbert(B-scientist) Wiener(I-scientist) ,(O) Claude(B-scientist) Shannon(I-scientist) ,(O) Warren(B-scientist) McCullough(I-scientist) ,(O) Walter(B-scientist) Pitts(I-scientist) and(O) Donald(B-scientist) Hebb(I-scientist) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["discipline","university","location","award","scientist","event","country","astronomical object","organization","enzyme","theory","chemical compound","protein","person","academic journal","chemical element"],"instance":{"id":"174","words":["The","two","factions",",","Lawrence","Murphy","-","Dolan","and","John","Tunstall","-","McSween",",","fought","a","series","of","escalating","battles","with","such","murderous","ferocity","that","the","repercussions","were","felt","as","far","away","as","the","state","capital","Santa","Fe","and","even","in","Washington",",","D.C."],"labels":["O","O","O","O","B-person","I-person","O","B-person","O","B-person","I-person","O","B-person","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-location","I-location","O","O","O","B-location","I-location","I-location"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: discipline, university, location, award, scientist, event, country, astronomical object, organization, enzyme, theory, chemical compound, protein, person, academic journal, chemical element and O.\nSentence: The two factions , Lawrence Murphy - Dolan and John Tunstall - McSween , fought a series of escalating battles with such murderous ferocity that the repercussions were felt as far away as the state capital Santa Fe and even in Washington , D.C.","prompt_labels":"The(O) two(O) factions(O) ,(O) Lawrence(B-person) Murphy(I-person) -(O) Dolan(B-person) and(O) John(B-person) Tunstall(I-person) -(O) McSween(B-person) ,(O) fought(O) a(O) series(O) of(O) escalating(O) battles(O) with(O) such(O) murderous(O) ferocity(O) that(O) the(O) repercussions(O) were(O) felt(O) as(O) far(O) away(O) as(O) the(O) state(O) capital(O) Santa(B-location) Fe(I-location) and(O) even(O) in(O) Washington(B-location) ,(I-location) D.C.(I-location)"}}
{"dataset":"crossner_science","split":"dev","label_list":["university","enzyme","award","theory","chemical compound","discipline","scientist","protein","event","academic journal","country","organization","person","location","chemical element","astronomical object"],"instance":{"id":"175","words":["His","72","peer","reviewed","scientific","papers","have","been","cite","d","3333","times","in","journals","such","as","the","Journal","of","the","American","Chemical","Society",",","the","Journal","of","Physical","Chemistry",",","the","Journal","of","Chemical","Physics",",","the","Journal","of","Computational","Chemistry",",","Chemical","Physics","Letters","and","Theoretical","Chemistry","Accounts","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-academic journal","I-academic journal","I-academic journal","I-academic journal","I-academic journal","I-academic journal","O","O","B-academic journal","I-academic journal","I-academic journal","I-academic journal","O","O","B-academic journal","I-academic journal","I-academic journal","I-academic journal","O","O","B-academic journal","I-academic journal","I-academic journal","I-academic journal","O","B-academic journal","I-academic journal","I-academic journal","O","B-academic journal","I-academic journal","I-academic journal","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: university, enzyme, award, theory, chemical compound, discipline, scientist, protein, event, academic journal, country, organization, person, location, chemical element, astronomical object and O.\nSentence: His 72 peer reviewed scientific papers have been cite d 3333 times in journals such as the Journal of the American Chemical Society , the Journal of Physical Chemistry , the Journal of Chemical Physics , the Journal of Computational Chemistry , Chemical Physics Letters and Theoretical Chemistry Accounts .","prompt_labels":"His(O) 72(O) peer(O) reviewed(O) scientific(O) papers(O) have(O) been(O) cite(O) d(O) 3333(O) times(O) in(O) journals(O) such(O) as(O) the(O) Journal(B-academic journal) of(I-academic journal) the(I-academic journal) American(I-academic journal) Chemical(I-academic journal) Society(I-academic journal) ,(O) the(O) Journal(B-academic journal) of(I-academic journal) Physical(I-academic journal) Chemistry(I-academic journal) ,(O) the(O) Journal(B-academic journal) of(I-academic journal) Chemical(I-academic journal) Physics(I-academic journal) ,(O) the(O) Journal(B-academic journal) of(I-academic journal) Computational(I-academic journal) Chemistry(I-academic journal) ,(O) Chemical(B-academic journal) Physics(I-academic journal) Letters(I-academic journal) and(O) Theoretical(B-academic journal) Chemistry(I-academic journal) Accounts(I-academic journal) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["person","theory","enzyme","academic journal","location","discipline","country","university","protein","organization","event","astronomical object","award","chemical compound","scientist","chemical element"],"instance":{"id":"176","words":["It","was","discovered","on","24","September","1960",",","by","Dutch","astronomer","couple","Ingrid","van","Houten-Groeneveld","and","Cornelis","van","Houten","in","collaboration","with","Dutch-American","astronomer","Tom","Gehrels","at","the","U.S.","Palomar","Observatory","in","California",",","and","named","after","Dutch","astronomer","Gerard","Kuiper","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","B-scientist","I-scientist","I-scientist","O","B-scientist","I-scientist","I-scientist","O","O","O","O","O","B-scientist","I-scientist","O","O","B-location","I-location","I-location","O","B-location","O","O","O","O","O","O","B-scientist","I-scientist","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, theory, enzyme, academic journal, location, discipline, country, university, protein, organization, event, astronomical object, award, chemical compound, scientist, chemical element and O.\nSentence: It was discovered on 24 September 1960 , by Dutch astronomer couple Ingrid van Houten-Groeneveld and Cornelis van Houten in collaboration with Dutch-American astronomer Tom Gehrels at the U.S. Palomar Observatory in California , and named after Dutch astronomer Gerard Kuiper .","prompt_labels":"It(O) was(O) discovered(O) on(O) 24(O) September(O) 1960(O) ,(O) by(O) Dutch(O) astronomer(O) couple(O) Ingrid(B-scientist) van(I-scientist) Houten-Groeneveld(I-scientist) and(O) Cornelis(B-scientist) van(I-scientist) Houten(I-scientist) in(O) collaboration(O) with(O) Dutch-American(O) astronomer(O) Tom(B-scientist) Gehrels(I-scientist) at(O) the(O) U.S.(B-location) Palomar(I-location) Observatory(I-location) in(O) California(B-location) ,(O) and(O) named(O) after(O) Dutch(O) astronomer(O) Gerard(B-scientist) Kuiper(I-scientist) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["chemical compound","discipline","enzyme","academic journal","award","scientist","protein","theory","organization","astronomical object","event","country","person","location","chemical element","university"],"instance":{"id":"177","words":["He","was","internationally","recognized","with","membership","in","the","Japan","Academy","and","the","Brazilian","Academy","of","Sciences",",","and","in","1959","was","appointed","a","member","of","the","Board","of","Governors","of","the","Weizmann","Institute","of","Science","in","Israel","."],"labels":["O","O","O","O","O","O","O","O","B-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-university","I-university","I-university","I-university","O","B-country","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: chemical compound, discipline, enzyme, academic journal, award, scientist, protein, theory, organization, astronomical object, event, country, person, location, chemical element, university and O.\nSentence: He was internationally recognized with membership in the Japan Academy and the Brazilian Academy of Sciences , and in 1959 was appointed a member of the Board of Governors of the Weizmann Institute of Science in Israel .","prompt_labels":"He(O) was(O) internationally(O) recognized(O) with(O) membership(O) in(O) the(O) Japan(B-organization) Academy(I-organization) and(O) the(O) Brazilian(B-organization) Academy(I-organization) of(I-organization) Sciences(I-organization) ,(O) and(O) in(O) 1959(O) was(O) appointed(O) a(O) member(O) of(O) the(O) Board(O) of(O) Governors(O) of(O) the(O) Weizmann(B-university) Institute(I-university) of(I-university) Science(I-university) in(O) Israel(B-country) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["award","theory","location","chemical element","chemical compound","person","scientist","academic journal","protein","discipline","university","astronomical object","event","country","enzyme","organization"],"instance":{"id":"178","words":["Among","Einstein","'s","well-known","friends","were","Michele","Besso",",","Paul","Ehrenfest",",","Marcel","Grossmann",",","Jnos","Plesch",",","Daniel","Q.","Posin",",","Maurice","Solovine",",","and","Stephen","Samuel","Wise","."],"labels":["O","B-scientist","O","O","O","O","B-person","I-person","O","B-scientist","I-scientist","O","B-scientist","I-scientist","O","B-scientist","I-scientist","O","B-scientist","I-scientist","I-scientist","O","B-scientist","I-scientist","O","O","B-person","I-person","I-person","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, theory, location, chemical element, chemical compound, person, scientist, academic journal, protein, discipline, university, astronomical object, event, country, enzyme, organization and O.\nSentence: Among Einstein 's well-known friends were Michele Besso , Paul Ehrenfest , Marcel Grossmann , Jnos Plesch , Daniel Q. Posin , Maurice Solovine , and Stephen Samuel Wise .","prompt_labels":"Among(O) Einstein(B-scientist) 's(O) well-known(O) friends(O) were(O) Michele(B-person) Besso(I-person) ,(O) Paul(B-scientist) Ehrenfest(I-scientist) ,(O) Marcel(B-scientist) Grossmann(I-scientist) ,(O) Jnos(B-scientist) Plesch(I-scientist) ,(O) Daniel(B-scientist) Q.(I-scientist) Posin(I-scientist) ,(O) Maurice(B-scientist) Solovine(I-scientist) ,(O) and(O) Stephen(B-person) Samuel(I-person) Wise(I-person) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["award","discipline","person","chemical compound","academic journal","organization","enzyme","protein","location","astronomical object","event","chemical element","scientist","theory","country","university"],"instance":{"id":"179","words":["In","1955",",","he","was","elected","a","Fellow","of","the","Royal","Society","and","served","on","the","Council","of","the","Royal","Society","from","1960","to","1962","."],"labels":["O","O","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, discipline, person, chemical compound, academic journal, organization, enzyme, protein, location, astronomical object, event, chemical element, scientist, theory, country, university and O.\nSentence: In 1955 , he was elected a Fellow of the Royal Society and served on the Council of the Royal Society from 1960 to 1962 .","prompt_labels":"In(O) 1955(O) ,(O) he(O) was(O) elected(O) a(O) Fellow(B-award) of(I-award) the(I-award) Royal(I-award) Society(I-award) and(O) served(O) on(O) the(O) Council(B-organization) of(I-organization) the(I-organization) Royal(I-organization) Society(I-organization) from(O) 1960(O) to(O) 1962(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["person","country","astronomical object","academic journal","event","enzyme","chemical compound","university","discipline","location","chemical element","organization","award","protein","theory","scientist"],"instance":{"id":"180","words":["The","following","asteroids","were","also","named","in","memory","of","the","other","six","members","of","STS-107",":","51823","Rickhusband",",","51824","Mikeanderson",",","51826","Kalpanachawla",",","51827","Laurelclark",",","51828","Ilanramon","and","51829","Williemccool","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-event","O","B-astronomical object","I-astronomical object","O","B-astronomical object","I-astronomical object","O","B-astronomical object","I-astronomical object","O","B-astronomical object","I-astronomical object","O","B-astronomical object","I-astronomical object","O","B-astronomical object","I-astronomical object","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, country, astronomical object, academic journal, event, enzyme, chemical compound, university, discipline, location, chemical element, organization, award, protein, theory, scientist and O.\nSentence: The following asteroids were also named in memory of the other six members of STS-107 : 51823 Rickhusband , 51824 Mikeanderson , 51826 Kalpanachawla , 51827 Laurelclark , 51828 Ilanramon and 51829 Williemccool .","prompt_labels":"The(O) following(O) asteroids(O) were(O) also(O) named(O) in(O) memory(O) of(O) the(O) other(O) six(O) members(O) of(O) STS-107(B-event) :(O) 51823(B-astronomical object) Rickhusband(I-astronomical object) ,(O) 51824(B-astronomical object) Mikeanderson(I-astronomical object) ,(O) 51826(B-astronomical object) Kalpanachawla(I-astronomical object) ,(O) 51827(B-astronomical object) Laurelclark(I-astronomical object) ,(O) 51828(B-astronomical object) Ilanramon(I-astronomical object) and(O) 51829(B-astronomical object) Williemccool(I-astronomical object) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["chemical compound","person","protein","organization","discipline","scientist","academic journal","theory","university","astronomical object","event","award","enzyme","location","chemical element","country"],"instance":{"id":"181","words":["He","was","elected","a","foreign","member","of","the","Royal","Swedish","Academy","of","Sciences","in","1836",",","and","a","Foreign","Honorary","Member","of","the","American","Academy","of","Arts","and","Sciences","in","1849","."],"labels":["O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","O","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: chemical compound, person, protein, organization, discipline, scientist, academic journal, theory, university, astronomical object, event, award, enzyme, location, chemical element, country and O.\nSentence: He was elected a foreign member of the Royal Swedish Academy of Sciences in 1836 , and a Foreign Honorary Member of the American Academy of Arts and Sciences in 1849 .","prompt_labels":"He(O) was(O) elected(O) a(O) foreign(O) member(O) of(O) the(O) Royal(B-organization) Swedish(I-organization) Academy(I-organization) of(I-organization) Sciences(I-organization) in(O) 1836(O) ,(O) and(O) a(O) Foreign(O) Honorary(O) Member(O) of(O) the(O) American(B-organization) Academy(I-organization) of(I-organization) Arts(I-organization) and(I-organization) Sciences(I-organization) in(O) 1849(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["person","country","university","astronomical object","event","chemical compound","organization","chemical element","discipline","award","academic journal","scientist","enzyme","location","theory","protein"],"instance":{"id":"182","words":["Lysostaphin","can","lyse","Staphylococcus",",","but","Micrococcus","bacteria","are","resistant","to","the","chemical","."],"labels":["B-enzyme","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, country, university, astronomical object, event, chemical compound, organization, chemical element, discipline, award, academic journal, scientist, enzyme, location, theory, protein and O.\nSentence: Lysostaphin can lyse Staphylococcus , but Micrococcus bacteria are resistant to the chemical .","prompt_labels":"Lysostaphin(B-enzyme) can(O) lyse(O) Staphylococcus(O) ,(O) but(O) Micrococcus(O) bacteria(O) are(O) resistant(O) to(O) the(O) chemical(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["astronomical object","chemical compound","academic journal","theory","scientist","enzyme","event","university","location","chemical element","country","organization","award","protein","discipline","person"],"instance":{"id":"183","words":["Other","notable","German","scientists",",","who","worked","on","the","Soviet","atomic","bomb","project","and","joined","Schintlmeister","at","the","Technische","Hochschule","Dresden","were","the","physicists","Heinz","Barwich","and","Werner","Hartmann","from","Institute","G","in","Agudzery","and","Heinz","Pose","and","Ernst","Rexer","from","Laboratory","V","in","Obninsk","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-scientist","O","O","B-university","I-university","I-university","O","O","O","B-scientist","I-scientist","O","B-scientist","I-scientist","O","B-organization","I-organization","O","B-location","O","B-scientist","I-scientist","O","B-scientist","I-scientist","O","B-organization","I-organization","O","B-location","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: astronomical object, chemical compound, academic journal, theory, scientist, enzyme, event, university, location, chemical element, country, organization, award, protein, discipline, person and O.\nSentence: Other notable German scientists , who worked on the Soviet atomic bomb project and joined Schintlmeister at the Technische Hochschule Dresden were the physicists Heinz Barwich and Werner Hartmann from Institute G in Agudzery and Heinz Pose and Ernst Rexer from Laboratory V in Obninsk .","prompt_labels":"Other(O) notable(O) German(O) scientists(O) ,(O) who(O) worked(O) on(O) the(O) Soviet(O) atomic(O) bomb(O) project(O) and(O) joined(O) Schintlmeister(B-scientist) at(O) the(O) Technische(B-university) Hochschule(I-university) Dresden(I-university) were(O) the(O) physicists(O) Heinz(B-scientist) Barwich(I-scientist) and(O) Werner(B-scientist) Hartmann(I-scientist) from(O) Institute(B-organization) G(I-organization) in(O) Agudzery(B-location) and(O) Heinz(B-scientist) Pose(I-scientist) and(O) Ernst(B-scientist) Rexer(I-scientist) from(O) Laboratory(B-organization) V(I-organization) in(O) Obninsk(B-location) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["event","chemical element","astronomical object","discipline","university","enzyme","organization","protein","theory","scientist","country","location","award","academic journal","person","chemical compound"],"instance":{"id":"184","words":["Starting","with","1972",",","the","Review","no","longer","appear","exclusively","in","Reviews","of","Modern","Physics",",","but","also","in","Physics","Letters","B",",","European","Physical","Journal","C",",","Journal","of","Physics","G",",","Physical","Review","D",",","and","Chinese","Physics","C","(","depending","on","the","year",")","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","B-academic journal","I-academic journal","I-academic journal","I-academic journal","O","O","O","O","B-academic journal","I-academic journal","I-academic journal","O","B-academic journal","I-academic journal","I-academic journal","I-academic journal","O","B-academic journal","I-academic journal","I-academic journal","I-academic journal","O","B-academic journal","I-academic journal","I-academic journal","O","O","B-academic journal","I-academic journal","I-academic journal","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, chemical element, astronomical object, discipline, university, enzyme, organization, protein, theory, scientist, country, location, award, academic journal, person, chemical compound and O.\nSentence: Starting with 1972 , the Review no longer appear exclusively in Reviews of Modern Physics , but also in Physics Letters B , European Physical Journal C , Journal of Physics G , Physical Review D , and Chinese Physics C ( depending on the year ) .","prompt_labels":"Starting(O) with(O) 1972(O) ,(O) the(O) Review(O) no(O) longer(O) appear(O) exclusively(O) in(O) Reviews(B-academic journal) of(I-academic journal) Modern(I-academic journal) Physics(I-academic journal) ,(O) but(O) also(O) in(O) Physics(B-academic journal) Letters(I-academic journal) B(I-academic journal) ,(O) European(B-academic journal) Physical(I-academic journal) Journal(I-academic journal) C(I-academic journal) ,(O) Journal(B-academic journal) of(I-academic journal) Physics(I-academic journal) G(I-academic journal) ,(O) Physical(B-academic journal) Review(I-academic journal) D(I-academic journal) ,(O) and(O) Chinese(B-academic journal) Physics(I-academic journal) C(I-academic journal) ((O) depending(O) on(O) the(O) year(O) )(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["protein","event","scientist","university","chemical compound","chemical element","enzyme","person","award","country","discipline","theory","academic journal","location","astronomical object","organization"],"instance":{"id":"185","words":["Cooper","studied","with","Oliver","Coleman","and","Walter","Dyett","in","the","late","1950s","and","early","1960s",",","then","studied","at","the","American","Conservatory","and","Loop","College","."],"labels":["O","O","O","B-person","I-person","O","B-person","I-person","O","O","O","O","O","O","O","O","O","O","O","O","B-organization","I-organization","O","B-university","I-university","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: protein, event, scientist, university, chemical compound, chemical element, enzyme, person, award, country, discipline, theory, academic journal, location, astronomical object, organization and O.\nSentence: Cooper studied with Oliver Coleman and Walter Dyett in the late 1950s and early 1960s , then studied at the American Conservatory and Loop College .","prompt_labels":"Cooper(O) studied(O) with(O) Oliver(B-person) Coleman(I-person) and(O) Walter(B-person) Dyett(I-person) in(O) the(O) late(O) 1950s(O) and(O) early(O) 1960s(O) ,(O) then(O) studied(O) at(O) the(O) American(B-organization) Conservatory(I-organization) and(O) Loop(B-university) College(I-university) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["country","theory","chemical element","protein","academic journal","location","event","award","enzyme","chemical compound","astronomical object","university","scientist","discipline","organization","person"],"instance":{"id":"186","words":["He","was","awarded","honorary","doctorate","degrees","by","Princeton","University","(","1958",")",",","Moscow","State","University","(","1992",")",",","and","the","Chinese","University","of","Hong","Kong","(","1997",")","."],"labels":["O","O","O","O","O","O","O","B-university","I-university","O","O","O","O","B-university","I-university","I-university","O","O","O","O","O","O","B-university","I-university","I-university","I-university","I-university","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, theory, chemical element, protein, academic journal, location, event, award, enzyme, chemical compound, astronomical object, university, scientist, discipline, organization, person and O.\nSentence: He was awarded honorary doctorate degrees by Princeton University ( 1958 ) , Moscow State University ( 1992 ) , and the Chinese University of Hong Kong ( 1997 ) .","prompt_labels":"He(O) was(O) awarded(O) honorary(O) doctorate(O) degrees(O) by(O) Princeton(B-university) University(I-university) ((O) 1958(O) )(O) ,(O) Moscow(B-university) State(I-university) University(I-university) ((O) 1992(O) )(O) ,(O) and(O) the(O) Chinese(B-university) University(I-university) of(I-university) Hong(I-university) Kong(I-university) ((O) 1997(O) )(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["scientist","theory","location","enzyme","chemical element","chemical compound","event","discipline","award","university","organization","academic journal","astronomical object","protein","country","person"],"instance":{"id":"187","words":["The","orbit","of","53","Kalypso","places","it","in","a","mean","motion","resonance","with","the","planets","Jupiter","and","Saturn","."],"labels":["O","O","O","B-astronomical object","I-astronomical object","O","O","O","O","O","O","O","O","O","O","B-astronomical object","O","B-astronomical object","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: scientist, theory, location, enzyme, chemical element, chemical compound, event, discipline, award, university, organization, academic journal, astronomical object, protein, country, person and O.\nSentence: The orbit of 53 Kalypso places it in a mean motion resonance with the planets Jupiter and Saturn .","prompt_labels":"The(O) orbit(O) of(O) 53(B-astronomical object) Kalypso(I-astronomical object) places(O) it(O) in(O) a(O) mean(O) motion(O) resonance(O) with(O) the(O) planets(O) Jupiter(B-astronomical object) and(O) Saturn(B-astronomical object) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["theory","chemical element","astronomical object","protein","event","university","discipline","enzyme","country","person","academic journal","location","chemical compound","scientist","award","organization"],"instance":{"id":"188","words":["Michel","Adanson","(","1763",")",",","Antoine","Laurent","de","Jussieu","(","1789",")",",","and","Augustin","Pyramus","de","Candolle","(","1819",")","all","proposed","various","alternative","natural","systems","of","classification","that","grouped","plants","using","a","wider","range","of","shared","characters","and","were","widely","followed","."],"labels":["B-scientist","I-scientist","O","O","O","O","B-scientist","I-scientist","I-scientist","I-scientist","O","O","O","O","O","B-scientist","I-scientist","I-scientist","I-scientist","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: theory, chemical element, astronomical object, protein, event, university, discipline, enzyme, country, person, academic journal, location, chemical compound, scientist, award, organization and O.\nSentence: Michel Adanson ( 1763 ) , Antoine Laurent de Jussieu ( 1789 ) , and Augustin Pyramus de Candolle ( 1819 ) all proposed various alternative natural systems of classification that grouped plants using a wider range of shared characters and were widely followed .","prompt_labels":"Michel(B-scientist) Adanson(I-scientist) ((O) 1763(O) )(O) ,(O) Antoine(B-scientist) Laurent(I-scientist) de(I-scientist) Jussieu(I-scientist) ((O) 1789(O) )(O) ,(O) and(O) Augustin(B-scientist) Pyramus(I-scientist) de(I-scientist) Candolle(I-scientist) ((O) 1819(O) )(O) all(O) proposed(O) various(O) alternative(O) natural(O) systems(O) of(O) classification(O) that(O) grouped(O) plants(O) using(O) a(O) wider(O) range(O) of(O) shared(O) characters(O) and(O) were(O) widely(O) followed(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["scientist","university","protein","theory","organization","award","astronomical object","academic journal","event","person","chemical compound","location","enzyme","country","chemical element","discipline"],"instance":{"id":"189","words":["The","first","committed","step","is","the","reaction","of","PRPP",",","glutamine","and","water","to","5","'","-phosphoribosylamine","(","PRA",")",",","glutamate",",","and","pyrophosphate","-","catalyzed","by","amidophosphoribosyltransferase",",","which","is","activated","by","PRPP","and","inhibited","by","Adenosine","monophosphate",",","Guanosine","monophosphate","and","Inosinic","acid","."],"labels":["O","O","O","O","O","O","O","O","B-chemical compound","O","B-chemical compound","O","B-chemical compound","O","B-chemical compound","I-chemical compound","I-chemical compound","O","B-chemical compound","O","O","B-chemical compound","O","O","B-chemical compound","O","O","O","B-enzyme","O","O","O","O","O","B-chemical compound","O","O","O","B-chemical compound","I-chemical compound","O","B-chemical compound","I-chemical compound","O","B-chemical compound","I-chemical compound","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: scientist, university, protein, theory, organization, award, astronomical object, academic journal, event, person, chemical compound, location, enzyme, country, chemical element, discipline and O.\nSentence: The first committed step is the reaction of PRPP , glutamine and water to 5 ' -phosphoribosylamine ( PRA ) , glutamate , and pyrophosphate - catalyzed by amidophosphoribosyltransferase , which is activated by PRPP and inhibited by Adenosine monophosphate , Guanosine monophosphate and Inosinic acid .","prompt_labels":"The(O) first(O) committed(O) step(O) is(O) the(O) reaction(O) of(O) PRPP(B-chemical compound) ,(O) glutamine(B-chemical compound) and(O) water(B-chemical compound) to(O) 5(B-chemical compound) '(I-chemical compound) -phosphoribosylamine(I-chemical compound) ((O) PRA(B-chemical compound) )(O) ,(O) glutamate(B-chemical compound) ,(O) and(O) pyrophosphate(B-chemical compound) -(O) catalyzed(O) by(O) amidophosphoribosyltransferase(B-enzyme) ,(O) which(O) is(O) activated(O) by(O) PRPP(B-chemical compound) and(O) inhibited(O) by(O) Adenosine(B-chemical compound) monophosphate(I-chemical compound) ,(O) Guanosine(B-chemical compound) monophosphate(I-chemical compound) and(O) Inosinic(B-chemical compound) acid(I-chemical compound) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["event","person","award","astronomical object","chemical compound","scientist","chemical element","academic journal","enzyme","protein","theory","university","country","organization","discipline","location"],"instance":{"id":"190","words":["Assuming","its","TRUE","mass","is","comparable","to","those","of","Neptune","and","Gliese","436","b",",","14","Earth","masses","is","theoretically","the","maximum","size","for","a","terrestrial","planet","."],"labels":["O","O","O","O","O","O","O","O","O","B-astronomical object","O","B-astronomical object","I-astronomical object","I-astronomical object","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, person, award, astronomical object, chemical compound, scientist, chemical element, academic journal, enzyme, protein, theory, university, country, organization, discipline, location and O.\nSentence: Assuming its TRUE mass is comparable to those of Neptune and Gliese 436 b , 14 Earth masses is theoretically the maximum size for a terrestrial planet .","prompt_labels":"Assuming(O) its(O) TRUE(O) mass(O) is(O) comparable(O) to(O) those(O) of(O) Neptune(B-astronomical object) and(O) Gliese(B-astronomical object) 436(I-astronomical object) b(I-astronomical object) ,(O) 14(O) Earth(O) masses(O) is(O) theoretically(O) the(O) maximum(O) size(O) for(O) a(O) terrestrial(O) planet(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["location","theory","enzyme","person","award","organization","university","chemical element","chemical compound","academic journal","protein","event","astronomical object","country","discipline","scientist"],"instance":{"id":"191","words":["Adjoa","Andoh","and","Penelope","Wilton","reprise","supporting","roles","as","Martha","'s","mother","Francine","Jones","and","former","Prime","Minister","Harriet","Jones","respectively","."],"labels":["B-person","I-person","O","B-person","I-person","O","O","O","O","B-person","O","O","B-person","I-person","O","O","O","O","B-person","I-person","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, theory, enzyme, person, award, organization, university, chemical element, chemical compound, academic journal, protein, event, astronomical object, country, discipline, scientist and O.\nSentence: Adjoa Andoh and Penelope Wilton reprise supporting roles as Martha 's mother Francine Jones and former Prime Minister Harriet Jones respectively .","prompt_labels":"Adjoa(B-person) Andoh(I-person) and(O) Penelope(B-person) Wilton(I-person) reprise(O) supporting(O) roles(O) as(O) Martha(B-person) 's(O) mother(O) Francine(B-person) Jones(I-person) and(O) former(O) Prime(O) Minister(O) Harriet(B-person) Jones(I-person) respectively(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["event","organization","discipline","chemical element","award","theory","protein","university","country","enzyme","academic journal","scientist","chemical compound","person","location","astronomical object"],"instance":{"id":"192","words":["LH","is","released","from","the","pituitary","gland","along","with","Follicle-stimulating","hormone","in","response","to","GnRH","release","into","the","hypophyseal","portal","system","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, organization, discipline, chemical element, award, theory, protein, university, country, enzyme, academic journal, scientist, chemical compound, person, location, astronomical object and O.\nSentence: LH is released from the pituitary gland along with Follicle-stimulating hormone in response to GnRH release into the hypophyseal portal system .","prompt_labels":"LH(O) is(O) released(O) from(O) the(O) pituitary(O) gland(O) along(O) with(O) Follicle-stimulating(O) hormone(O) in(O) response(O) to(O) GnRH(O) release(O) into(O) the(O) hypophyseal(O) portal(O) system(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["scientist","enzyme","event","protein","organization","academic journal","award","chemical compound","chemical element","theory","country","location","discipline","person","university","astronomical object"],"instance":{"id":"193","words":["He","was","educated","at","the","Technical","University","of","Munich","from","1925","to","1927","and","then","entered","the","Technical","University","of","Berlin",",","where","he","posited","that","microscope","s","using","electrons",",","with","wavelengths","1000","times","shorter","than","those","of","light",",","could","provide","a","more","detailed","picture","of","an","object","than","a","microscope","utilizing","light",",","in","which","magnification","is","limited","by","the","size","of","the","wavelengths","."],"labels":["O","O","O","O","O","B-university","I-university","I-university","I-university","O","O","O","O","O","O","O","O","B-university","I-university","I-university","I-university","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: scientist, enzyme, event, protein, organization, academic journal, award, chemical compound, chemical element, theory, country, location, discipline, person, university, astronomical object and O.\nSentence: He was educated at the Technical University of Munich from 1925 to 1927 and then entered the Technical University of Berlin , where he posited that microscope s using electrons , with wavelengths 1000 times shorter than those of light , could provide a more detailed picture of an object than a microscope utilizing light , in which magnification is limited by the size of the wavelengths .","prompt_labels":"He(O) was(O) educated(O) at(O) the(O) Technical(B-university) University(I-university) of(I-university) Munich(I-university) from(O) 1925(O) to(O) 1927(O) and(O) then(O) entered(O) the(O) Technical(B-university) University(I-university) of(I-university) Berlin(I-university) ,(O) where(O) he(O) posited(O) that(O) microscope(O) s(O) using(O) electrons(O) ,(O) with(O) wavelengths(O) 1000(O) times(O) shorter(O) than(O) those(O) of(O) light(O) ,(O) could(O) provide(O) a(O) more(O) detailed(O) picture(O) of(O) an(O) object(O) than(O) a(O) microscope(O) utilizing(O) light(O) ,(O) in(O) which(O) magnification(O) is(O) limited(O) by(O) the(O) size(O) of(O) the(O) wavelengths(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["scientist","academic journal","protein","enzyme","person","chemical element","event","country","theory","university","award","astronomical object","chemical compound","organization","discipline","location"],"instance":{"id":"194","words":["The","manufacturing","process","of","Technora","reacts","P-Phenylenediamine","and","3,4","'","-diaminodiphenylether","(","3,4","'","-ODA",")","with","Terephthaloyl","chloride","."],"labels":["O","O","O","O","B-chemical compound","O","B-chemical compound","O","B-chemical compound","I-chemical compound","I-chemical compound","O","B-chemical compound","I-chemical compound","I-chemical compound","O","O","B-chemical compound","I-chemical compound","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: scientist, academic journal, protein, enzyme, person, chemical element, event, country, theory, university, award, astronomical object, chemical compound, organization, discipline, location and O.\nSentence: The manufacturing process of Technora reacts P-Phenylenediamine and 3,4 ' -diaminodiphenylether ( 3,4 ' -ODA ) with Terephthaloyl chloride .","prompt_labels":"The(O) manufacturing(O) process(O) of(O) Technora(B-chemical compound) reacts(O) P-Phenylenediamine(B-chemical compound) and(O) 3,4(B-chemical compound) '(I-chemical compound) -diaminodiphenylether(I-chemical compound) ((O) 3,4(B-chemical compound) '(I-chemical compound) -ODA(I-chemical compound) )(O) with(O) Terephthaloyl(B-chemical compound) chloride(I-chemical compound) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["organization","university","chemical element","protein","award","country","event","academic journal","astronomical object","scientist","theory","discipline","location","enzyme","person","chemical compound"],"instance":{"id":"195","words":["The","minor","planets","105","Artemis",",","399","Persephone",",","1388","Aphrodite","and","5731","Zeus","were","named","for","these","Greek","gods","."],"labels":["O","O","O","B-astronomical object","I-astronomical object","O","B-astronomical object","I-astronomical object","O","B-astronomical object","I-astronomical object","O","B-astronomical object","I-astronomical object","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, university, chemical element, protein, award, country, event, academic journal, astronomical object, scientist, theory, discipline, location, enzyme, person, chemical compound and O.\nSentence: The minor planets 105 Artemis , 399 Persephone , 1388 Aphrodite and 5731 Zeus were named for these Greek gods .","prompt_labels":"The(O) minor(O) planets(O) 105(B-astronomical object) Artemis(I-astronomical object) ,(O) 399(B-astronomical object) Persephone(I-astronomical object) ,(O) 1388(B-astronomical object) Aphrodite(I-astronomical object) and(O) 5731(B-astronomical object) Zeus(I-astronomical object) were(O) named(O) for(O) these(O) Greek(O) gods(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["country","organization","astronomical object","protein","theory","discipline","chemical compound","award","academic journal","location","university","enzyme","person","scientist","event","chemical element"],"instance":{"id":"196","words":["Two","further","super-Earths","were","discovered","in","2006",":","OGLE-2005-BLG-390Lb","with","a","mass","of","5.5","Earth","masses",",","which","was","found","by","gravitational","microlensing",",","and","HD","69830","b","with","a","mass","of","10","Earth","masses","."],"labels":["O","O","O","O","O","O","O","O","B-astronomical object","O","O","O","O","O","B-astronomical object","O","O","O","O","O","O","O","O","O","O","B-astronomical object","I-astronomical object","I-astronomical object","O","O","O","O","O","B-astronomical object","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, organization, astronomical object, protein, theory, discipline, chemical compound, award, academic journal, location, university, enzyme, person, scientist, event, chemical element and O.\nSentence: Two further super-Earths were discovered in 2006 : OGLE-2005-BLG-390Lb with a mass of 5.5 Earth masses , which was found by gravitational microlensing , and HD 69830 b with a mass of 10 Earth masses .","prompt_labels":"Two(O) further(O) super-Earths(O) were(O) discovered(O) in(O) 2006(O) :(O) OGLE-2005-BLG-390Lb(B-astronomical object) with(O) a(O) mass(O) of(O) 5.5(O) Earth(B-astronomical object) masses(O) ,(O) which(O) was(O) found(O) by(O) gravitational(O) microlensing(O) ,(O) and(O) HD(B-astronomical object) 69830(I-astronomical object) b(I-astronomical object) with(O) a(O) mass(O) of(O) 10(O) Earth(B-astronomical object) masses(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["protein","scientist","enzyme","chemical compound","discipline","organization","person","academic journal","event","astronomical object","chemical element","award","country","university","theory","location"],"instance":{"id":"197","words":["In","2010",",","Goodall","through","JGI","formed","a","coalition","with","a","number","of","organizations","such","as","the","Wildlife","Conservation","Society","(","WCS",")","and","the","Humane","Society","of","the","United","States","(","HSUS",")","and","petitioned","to","list","all","chimpanzees","including","those","that","are","captive","as","endangered","."],"labels":["O","O","O","B-scientist","O","B-organization","O","O","O","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","O","B-organization","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","B-organization","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: protein, scientist, enzyme, chemical compound, discipline, organization, person, academic journal, event, astronomical object, chemical element, award, country, university, theory, location and O.\nSentence: In 2010 , Goodall through JGI formed a coalition with a number of organizations such as the Wildlife Conservation Society ( WCS ) and the Humane Society of the United States ( HSUS ) and petitioned to list all chimpanzees including those that are captive as endangered .","prompt_labels":"In(O) 2010(O) ,(O) Goodall(B-scientist) through(O) JGI(B-organization) formed(O) a(O) coalition(O) with(O) a(O) number(O) of(O) organizations(O) such(O) as(O) the(O) Wildlife(B-organization) Conservation(I-organization) Society(I-organization) ((O) WCS(B-organization) )(O) and(O) the(O) Humane(B-organization) Society(I-organization) of(I-organization) the(I-organization) United(I-organization) States(I-organization) ((O) HSUS(B-organization) )(O) and(O) petitioned(O) to(O) list(O) all(O) chimpanzees(O) including(O) those(O) that(O) are(O) captive(O) as(O) endangered(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["chemical element","theory","scientist","chemical compound","award","academic journal","organization","country","event","astronomical object","protein","location","enzyme","university","person","discipline"],"instance":{"id":"198","words":["Phthalocyanine","s",",","which",",","like","Phthalocyanine","Blue","BN","and","Phthalocyanine","Green","G",",","often","contain","a","transition","metal","ion",",","exchange","an","electron","with","the","complexed","transition","metal","ion","that","easily","changes","its","oxidation","state","."],"labels":["B-chemical compound","O","O","O","O","O","B-chemical compound","I-chemical compound","I-chemical compound","O","B-chemical compound","I-chemical compound","I-chemical compound","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: chemical element, theory, scientist, chemical compound, award, academic journal, organization, country, event, astronomical object, protein, location, enzyme, university, person, discipline and O.\nSentence: Phthalocyanine s , which , like Phthalocyanine Blue BN and Phthalocyanine Green G , often contain a transition metal ion , exchange an electron with the complexed transition metal ion that easily changes its oxidation state .","prompt_labels":"Phthalocyanine(B-chemical compound) s(O) ,(O) which(O) ,(O) like(O) Phthalocyanine(B-chemical compound) Blue(I-chemical compound) BN(I-chemical compound) and(O) Phthalocyanine(B-chemical compound) Green(I-chemical compound) G(I-chemical compound) ,(O) often(O) contain(O) a(O) transition(O) metal(O) ion(O) ,(O) exchange(O) an(O) electron(O) with(O) the(O) complexed(O) transition(O) metal(O) ion(O) that(O) easily(O) changes(O) its(O) oxidation(O) state(O) .(O)"}}
{"dataset":"crossner_science","split":"dev","label_list":["astronomical object","scientist","event","theory","organization","country","university","person","discipline","location","protein","award","chemical element","academic journal","enzyme","chemical compound"],"instance":{"id":"199","words":["He","was","also","awarded","the","Davy","Medal","in","1971",",","the","Rumford","Medal","in","1978",",","the","Ellison-Cliffe","Medal","in","1991","and","the","Copley","Medal","in","1992","."],"labels":["O","O","O","O","O","B-award","I-award","O","O","O","O","B-award","I-award","O","O","O","O","B-award","I-award","O","O","O","O","B-award","I-award","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: astronomical object, scientist, event, theory, organization, country, university, person, discipline, location, protein, award, chemical element, academic journal, enzyme, chemical compound and O.\nSentence: He was also awarded the Davy Medal in 1971 , the Rumford Medal in 1978 , the Ellison-Cliffe Medal in 1991 and the Copley Medal in 1992 .","prompt_labels":"He(O) was(O) also(O) awarded(O) the(O) Davy(B-award) Medal(I-award) in(O) 1971(O) ,(O) the(O) Rumford(B-award) Medal(I-award) in(O) 1978(O) ,(O) the(O) Ellison-Cliffe(B-award) Medal(I-award) in(O) 1991(O) and(O) the(O) Copley(B-award) Medal(I-award) in(O) 1992(O) .(O)"}}
